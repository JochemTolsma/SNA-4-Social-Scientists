% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={SNASS},
  pdfauthor={Jochem Tolsma; Bas hofstra},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{SNASS}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Social Network Analysis for Social Scientists}
\author{Jochem Tolsma \and Bas hofstra}
\date{2021-07-31}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{about-the-authors}{%
\chapter*{About the authors}\label{about-the-authors}}
\addcontentsline{toc}{chapter}{About the authors}

\hypertarget{intro}{%
\chapter{Introduction}\label{intro}}

\hypertarget{overview}{%
\section{Overview}\label{overview}}

Sociologists study how societies affect the lives of their members and, vice versa, how individuals shape the societies in which they live. Within societies people make and break relations with specific others and thereby form \textbf{social networks}.\\
Individuals are embedded in many different social networks (e.g.~based on friendships, bullying, family relations). Within these social networks individuals influence each others' attitudes, behaviors and relations via complex dynamic processes. The attitudes, behaviors and relations of individuals shape, in turn, the societies they live in. They give rise to \textbf{social phenomena} such as inequality, segregation, polarization and cohesion. It is not possible to explain many macro-level social phenomena, let alone to solve many urgent \textbf{social problems}, without taking into account social networks. For example, researchers may be able to deduce hypotheses from an established theory on political opinions of individuals but the same theory is not able to explain when and where \textbf{political polarization} occurs. For this, a social network perspective is necessary. It can thus be no surprise that the study of the causes and consequences of social networks lies at the core of sociology.

\hypertarget{definitions}{%
\subsection{Definitions}\label{definitions}}

\begin{quote}
\begin{description}
\item[\textbf{Social Networks}]
A social network is an finite set of actors and the relation(s) defined on this set. The actors are social entities (people, organizations, countries, etc.) whose specific ties (friendship, competition, collaboration, etc.), constitute the network \citep[ : 20]{Wasserman1994}.\\
Networks are also called: graphs or sociograms\\
Actors are also called: points, nodes, agents or vertices.\\
Relations are also called: ties, edges or connections.
\end{description}

\textcolor{red}{**Social Networks is/are no theory nor a method.**} Social networks are social phenomena with causes and consequences. The size, composition, structure, and evolution of social networks can be explained. Social networks have an impact on individuals (e.g.~attitudes and behavior), dyads (e.g.~relations), institutions (e.g.~efficiency) and societies (e.g.~segregation, opinion polarization).
\end{quote}

\begin{quote}
\begin{description}
\item[\textbf{Social Network Perspective}]
It is the acknowledgment that individuals are embedded within social networks - no man is an island - and that this has theoretical, data, and methodological consequences.\\
Theoretical consequences: A social network perspective may force to a rethinking of existing hypotheses and may lead to new research questions on the causes and consequences of social networks.\\
Data consequences: To apply a Social Network Perspective, we need data on social networks. Social network data is special in that we need not only information on the social agents (e.g.~people, organizations) but also on the ties (or relations) between them. As a consequence, there are many unique practical and ethical aspects related to the collection of network data. Methodological consequences: A social network perspective will make explicit that empirical observations of individuals are not always independent and that the (complex) interdependencies between observations that result from social networks have consequences for many of our traditional research methods which assume independence of observations. It may lead to the development and adoption of new social network analysis techniques.
\end{description}

Applying a social network perspective leads to theoretical, data collection, and methodological advancements.
\end{quote}

\begin{quote}
\begin{description}
\item[\textbf{Social phenomenon}]
collective human behavior
\end{description}
\end{quote}

\begin{quote}
\begin{description}
\item[\textbf{Social problem}]
a social phenomenon which people consider undesired.
\end{description}
\end{quote}

\begin{quote}
\begin{description}
\item[\textbf{Polarization}]
Polarization is a social problem and a society is said to be polarized when (sizeable) (and clearly distinguishable) groups in society hold (ever more) opposing, extreme (political) attitudes.
\end{description}
\end{quote}

\hypertarget{aim}{%
\section{Aim}\label{aim}}

The intended learning outcomes of the course are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Theoretical knowledge and insight:

  \begin{itemize}
  \tightlist
  \item
    you will be able to define core concepts related to a social network perspective.\\
  \item
    You will be able to summarize what a social network perspective in social science research entails.\\
  \end{itemize}
\item
  Academic attitude:\\

  \begin{itemize}
  \tightlist
  \item
    you develop a positive attitude towards applying a social network perspective in social science research.\\
  \end{itemize}
\item
  Research skills: you will be able to apply a social network perspective in social science research. This encompasses that:\\

  \begin{itemize}
  \tightlist
  \item
    you will be able to deduce relevant and new social network hypotheses from existing theories.\\
  \item
    you will be able able to collect and wrangle social network data.\\
  \item
    you will be able to test these hypotheses with different social network analysis techniques.\\
  \end{itemize}
\end{enumerate}

\hypertarget{structure}{%
\section{Structure}\label{structure}}

This course is structured along three different dimensions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Type} of Social Network: dyad, egonet, socionet (complete network)\\
\item
  \textbf{Causes or Consequences} of social networks
\item
  \textbf{Implications} of applying a social network perspective: Theoretical, Data and Methodological
\end{enumerate}

\textbf{Table. 1.1 } Topics discussed within the course

\begin{longtable}[]{@{}llll@{}}
\toprule
Type of Social Network & Causes or Consequences & Implications & Book section\tabularnewline
\midrule
\endhead
Dyads & Causes & Theory &\tabularnewline
Dyads & Causes & Method &\tabularnewline
Dyads & Consequences & Theory &\tabularnewline
Dyads & Consequences & Method &\tabularnewline
Dyads & NA & Data &\tabularnewline
Egonets & Causes & Theory &\tabularnewline
Egonets & Causes & Method &\tabularnewline
Egonets & Consequences & Theory &\tabularnewline
Egonets & Consequences & Method &\tabularnewline
Egonets & NA & Data &\tabularnewline
Socionet & Causes & Theory &\tabularnewline
Socionet & Causes & Method &\tabularnewline
Socionet & Consequences & Theory &\tabularnewline
Socionet & Consequences & Method &\tabularnewline
Socionet & NA & Data &\tabularnewline
\bottomrule
\end{longtable}

\textcolor{red}{**Feel free to jump to the section you are most interested in. But there is a clear order in the sections. The best way to accumulate theoretical and methodological knowledge, and to gain the necessary R-skills to successfully apply a social network perspective to your own research is by going through the sections one by.**}

\hypertarget{type-of-social-network}{%
\subsection{Type of Social Network}\label{type-of-social-network}}

\hypertarget{dyads}{%
\subsubsection*{\texorpdfstring{\textbf{Dyads}}{Dyads}}\label{dyads}}
\addcontentsline{toc}{subsubsection}{\textbf{Dyads}}

The smallest possible social network is a network between two persons (or, more precisely, between two social agents). A network between two persons is also called a dyad. In the clip below I will introduce you to the the main concepts involved in a dyad. Naturally, the same concepts also play a role in larger social networks.

For slides, see \href{dyads.pdf}{here}.

\begin{quote}
After having watched the video you should be able to:

\begin{itemize}
\tightlist
\item
  give a definition of a dyad.\\
\item
  explain what is meant by time-varying and time-constant actor attributes and dyad attributes.\\
\item
  explain that relations between ego and alter can be classified based on whether relations are directed or undirected and on the level of measurement of the relation (i.e.~nominal, ordinal, interval, ratio).\\
\item
  be familiar with al the synonyms for networks, agents and relations.\\
\item
  provide examples of dyads, and the relations between ego and alter.\\
\end{itemize}
\end{quote}

\hypertarget{egonets}{%
\subsubsection*{\texorpdfstring{\textbf{Egonets}}{Egonets}}\label{egonets}}
\addcontentsline{toc}{subsubsection}{\textbf{Egonets}}

We could define an egocentric social network as a set of actors that all have relationships with ego. This definition is quite similar to Marsden's \citep{marsden1990} definition: ``Sets of ties surrounding sampled individual units.'' To illustrate what is meant by these definitions, let us us consider the following `world'. And visualize the best-friend-forever relationships in this world.

\includegraphics{01-intro_files/figure-latex/unnamed-chunk-2-1.pdf}\\
And now sample a random person. The person we sampled, ego, is made red and square in our network.

\includegraphics{01-intro_files/figure-latex/unnamed-chunk-3-1.pdf}\\
Let us zoom in a little bit.

\includegraphics{01-intro_files/figure-latex/unnamed-chunk-4-1.pdf}

\hypertarget{degree}{%
\paragraph{1.0 degree}\label{degree}}
\addcontentsline{toc}{paragraph}{1.0 degree}

Let's suppose we had asked this person to name all its best-friend-forevers (BFFs). If we would assume that BFF relations are undirected, then this person's egocentric or 1.0 degree network would look like this:

\includegraphics{01-intro_files/figure-latex/unnamed-chunk-5-1.pdf}\\
The alters with whom ego is not connected are not part of the egocentric network. And generally, if we collect data we do not have any information on these unconnected alters.

\hypertarget{degree-network}{%
\paragraph{1.5 degree network}\label{degree-network}}
\addcontentsline{toc}{paragraph}{1.5 degree network}

We may have asked ego - with the question below - whether its BFFs are also BFFs of one another.

Please think about the relations between the people you just mentioned. Some of them may be total strangers in the sense that they wouldn't recognize each other if they bumped into each other on the street. Others may be especially close, as close or closer to each other as they are to you. Are they especially close? PROBE: As close or closer to each other as they are to you?

It turns out that two alters in ego's BFF-network are also BFFs of each other. If we know the relations between the alters in a 1.0 degree network it becomes a 1.5 degree network. See below:

\includegraphics{01-intro_files/figure-latex/unnamed-chunk-6-1.pdf}\\
In the lower-left corner we see a closed \emph{Triad}. For more information on Triads jump to this \href{https://www.jochemtolsma.nl/courses/complete-networks/socio2/\#triad-level}{section}.

\hypertarget{degree-network-1}{%
\paragraph{2.0 degree network}\label{degree-network-1}}
\addcontentsline{toc}{paragraph}{2.0 degree network}

Perhaps, instead of asking whether there are BFF relations between the BFFs of ego, we could also have used a snowball sampling method and interviewed the alters (or BFFs) of ego. Note that the focal actor (initial sampled unit) remains ego.
Thus, if we would have asked ego's alters to name their BFFs, we would have discovered the following 2.0 degree network:
\includegraphics{01-intro_files/figure-latex/unnamed-chunk-7-1.pdf}\\
The newly discovered alters are in light blue. Naturally, we also observe the BFF relation between ego's alters appearing. Please note that in a 2.0 degree network the number of alters within the 1.0 degree network of ego will remain the same (assuming that ego did not forget to mention a BFF).

\hypertarget{x-degree-network}{%
\paragraph{2.X degree network}\label{x-degree-network}}
\addcontentsline{toc}{paragraph}{2.X degree network}

Any ideas about what a 2.5 degree network would look like. To be honest, I don't. Do these networks include all relations between all nodes, or only the relations between the alters in the separate 1.0 degree networks? Perhaps we could call the latter a 2.5 degree network and the former a 2.75 degree network.

\hypertarget{socionets}{%
\subsubsection*{\texorpdfstring{\textbf{Socionets}}{Socionets}}\label{socionets}}
\addcontentsline{toc}{subsubsection}{\textbf{Socionets}}

A complete, full, or sociocentric network is a network within a sampled context or foci of which we know all nodes and all connections between nodes. The boundaries of the network are thus a priori defined and the contexts in which nodes are present are the sampled units.
We may for example sample a classroom, neighborhood, university or country and collect all relations between all nodes within this context.

\begin{quote}
You now have come across a general definition for social networks and specific definitions for dyadic, egocentric and sociocentric social networks. You also know that the social agents within the networks may not necessarily have to be persons but can also be companies, or political parties for example. A network in which the relations between two different type of nodes are present are called \textbf{multiple-mode networks}.\\
Similarly, between one type of node (e.g.~persons) we may have information on more than one type of relation. These networks are called \textbf{multiplex networks}.\\
The networks we have considered so far refer to networks of binary relations (yes/no). If the relations can vary in strength, we call the networks a \textbf{weighted network}.\\
Thus, we can have a two-mode, multiplex, weighted, directed network but also a single-mode, uniplex, binary, undirected network.
\end{quote}

It turns out that many (complete) social networks share certain network characteristics. This is called the small-world phenomena and is discussed in more detail \href{}{here}. But let us start with a teaser. Suppose we live in a world, called ``Smallworld'', of 105 persons (a small world indeed) and have information on all friendship (or trust) relations between its citizens. How could such a network look like? It turns out that (large) social networks of positive relations often have a specific structure. And this structure is called \textbf{A Small World}. Lets have a look at the small world structure of SmallWorld.

Play with the small world network of Smallworld. Zoom in and out, turn it around and click on some nodes. How would you describe the structure of the network in Smallworld. Well, I would describe it as a network with a: (1) \textbf{relatively low density}; (2) \textbf{relatively high degree of clustering} and (3) \textbf{a relatively low average degree of separation (or path length)}. These three characteristics are defining features of small world networks. But what does density, clustering and path length mean?, and what do we mean with `relatively', that does not sound very scientific does it?! Don't you worry, you will learn this during the course.

\hypertarget{causes-and-consequences}{%
\subsection{Causes and Consequences}\label{causes-and-consequences}}

\textbf{\ldots or Selection and Influence}\\
Social networks consist of social relations between people. For example friendships, bullying relations or working-together-during-the-course-social-networks relations.\\
The continuous process of making and breaking social relations is also called \textbf{selection}. And the reasons why we make and brake relations with specific persons are important \textbf{causes} for the structures of the social networks we observe. Thus the causes of social networks are strongly related to selection processes.\\
The people with whom we form social relations also \textbf{influence} our attitudes, behaviors and future relations. How we think, behave and with whom we make, break or maintain social relations is for an important part the \textbf{consequence} of the social networks in which we are embedded. Thus the consequences of social networks are strongly related to influence processes (but also to selection processes).\\
Selection and influence processes are firmly entangled. See below for an example.

\begin{itemize}
\tightlist
\item
  The shapes represent social agents (e.g.~individuals).\\
\item
  The shape (circle or square) of the social agent is a time-stable characteristic (e.g.~sex).\\
\item
  The fill of the shape (no fill, pattern fill, solid fill) is a time-varying characteristic (e.g.~music taste).
\item
  The line between the shapes (no line, dashed, solid) signifies the strength of the relationship (e.g.~romantic relationship)
\end{itemize}

We could call the selection process `Opposite Attracts' and we could call the influence process `Circle beats square'.~Let us focus on the selection process first. If there is no tie between the agents, you will notice that a tie will be formed (becomes stronger) between dissimilar agents. When a tie is present between agents, you will notice that a tie will be broken (becomes weaker) when agents are similar with respect to their time-varying characteristic.~Let us now focus on the influence process. When a strong tie is present, you will notice that the square agents will assimilate to the time-varying characteristic of the circle agents. We do not know of course the mechanism behind this assimilation (or influence) process. Is it the square who (voluntary) adopts the behavior of the circle or does the circle forces the square to follow suit?

\hypertarget{implications}{%
\subsection{Implications}\label{implications}}

Individuals - or social agents more generally (e.g.~institutions, societies) - are part of many different social networks.

\hypertarget{theoretical-implications}{%
\subsubsection{Theoretical implications}\label{theoretical-implications}}

A social network perspective may force to a rethinking of existing hypotheses and may lead to new research questions on the causes and consequences of social networks. That individuals are interconnected and hence that observations are (cor)related and characteristics of these observations co-vary is \textbf{theoretically interesting}.~
It gives rise to a complete new type of research questions. Where normally our research questions refer to describing or explaining the variance between individuals (e.g.~why individuals differ) a new set of research questions describe, compare and explain the covariance between individuals. For example, why connected people are more (dis)similar to one another than non-connected others. The social network functions as explanans in these questions.\\
A different set of new research questions takes the social network itself as explanandum. These research questions aim to describe, compare and explain characteristics of social networks (e.g.~with respect to size, composition, structure and evolution).

\hypertarget{methodological-implications}{%
\subsubsection{Methodological implications}\label{methodological-implications}}

That individuals are interconnected and hence that observations are not independent can be seen as a \textbf{nuisance}. That our observations are not independent violates many assumptions of analysis techniques that social scientists commonly apply (e.g.~OLS). In order to correctly estimate the effects of interest we need to take these interdependencies into account with social network analysis techniques.\\

\hypertarget{data-implications}{%
\subsubsection{Data implications}\label{data-implications}}

If we want to collect data on social networks, we need not only information on specific focal social agents (egos) but also on its relations with other egos (ego's alters) and information on characteristics of these alters. Is it ethical that we collect data on an alter via ego? What do we do if in a school class a pupil does not wish to participate in a study on bullying? Do we delete this child from our bullying networks altogether, thus both as sender and receiver of bullying relations? Collecting data on social networks gives rise to specific \textbf{ethical issues}.~
If we want to collect data on complete social networks, the sampling unit is no longer an individual but the context in which these ties occur. How do we determine the boundaries of this context and how do we sample these. Collecting network data comes with specific \textbf{sampling issues}.~
Network data also has a specific format (e.g.~an adjacency matrix) and can become very big. How to wrangle these network data objects? Network data oftentimes lead to specific practical data \textbf{wrangling issues}.\\

\hypertarget{what-makes-this-course-stand-out}{%
\section{What makes this course stand out?}\label{what-makes-this-course-stand-out}}

This course is not an introduction to Sociology, Social Networks or Social Network Analysis. It is also not a course in R. I assume you have some intuitive understanding of what social networks are and have opened R or RStudio at one point in your life but both are not necessary prerequisites to follow this course. There are very good (online) introductions to the study of Social Networks, see for example \href{https://bookdown.org/markhoff/social_network_analysis/}{here} and \href{https://eehh-stanford.github.io/SNA-workshop/}{here}. A good short introduction to R for this course can be found in Chapter \ref{tutorial} or have a look \href{https://rafalab.github.io/dsbook/}{here} for a more thorough introduction to Data Science with R.\\
This course is tailored for research master and PhD students. I will assume that you are interested in and have studied social problems in your academic career and that your research interests fits one of the following broad themes: \textbf{inequality}, \textbf{cohesion} and \textbf{diversity}. For an excellent introduction into sociology see \citep{Tubergen2020}. However, up to this point, when you deduced hypotheses from existing theories you did not explicitly acknowledge that individuals are interconnected in social networks. You were neither aware that this may have theoretical consequences for existing hypotheses nor that this gives rise to new research questions. Up to this point, when you tested your hypotheses you assumed that your observations were independent (e.g.~OLS) or, at most, that the nonindependence was relatively easy to take into account (e.g.~multi-level analysis).\\
In this course you will learn to apply a social network perspective in the study of inequality, cohesion and diversity. You will become able to deduce more precise and new hypotheses. You will become able to test these hypotheses with social network techniques that take into account and explain complex interdependencies.

Enjoy!!

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{part-part-i-dyads}{%
\part{Part I DYADS}\label{part-part-i-dyads}}

\hypertarget{theory}{%
\chapter{Theory}\label{theory}}

The smallest possible social network is a network between two persons (or, more precisely, between two social agents). A network between two persons is also called a dyad. In the clip below I will introduce you to the the main concepts involved in a dyad. Naturally, the same concepts also play a role in larger social networks.

For slides, see \href{dyads.pdf}{here}.

\begin{quote}
After having watched the video you should be able to:

\begin{itemize}
\tightlist
\item
  give a definition of a dyad.\\
\item
  explain what is meant by time-varying and time-constant actor attributes and dyad attributes.\\
\item
  explain that relations between ego and alter can be classified based on whether relations are directed or undirected and on the level of measurement of the relation (i.e.~nominal, ordinal, interval, ratio).\\
\item
  be familiar with al the synonyms for networks, agents and relations.\\
\item
  provide examples of dyads, and the relations between ego and alter.\\
\end{itemize}
\end{quote}

\hypertarget{causes-of-dyads}{%
\section{Causes of dyads}\label{causes-of-dyads}}

An important research topic within sociology is assortative mating (or intermarriage) (see: \citep{kalmijn1998, schwartz2013, blossfeld2009}). Scholars in this field try to explain why two people in an exclusive relationship like marriage (or cohabition or best friends) are more similar to one another with respect to defining characteristics (e.g.~social class, ethnicity) than two random persons. Assortative mating is a special case of \textbf{homophily}. Assortative mating is an important topic within sociology because it is, next to social mobility, an important indicator of the \textbf{openness of society}.~

\textbf{Selection} and \textbf{influence} processes are important reasons why partners (ego and alter) within a dyad are more similar than two random persons. We may prefer to marry someone who is similar to us on key social dimensions, share our attitudes and opinions and show similar behavior. Once married we may influence each other and assimilate to one another. A third reason why we observe homophily within couples is that partners are likely to have shared and will share the \textbf{same social context}. With shared social context we mean the shared social and physical environment and shared life experiences. The environment pre-marriage may in part determine characteristics of the pool of potential marriage partners (i.e.~the choice set). For example when neighbourhoods and schools are segregated along ethnic and educational division lines, the potential marriage partners we meet are likely to be more similar to us than a random person in society at large. The shared social environment post-marriage may exert a similar influence on both partners, consider for example economic recession's effects on different geographic regions. This may impact the job opportunities for both partners similarly (assuming they live in the same house). An example of shared life experiences, would be having children.

\begin{quote}
Please note that causes and consequences of homophily are closely related. A shared social context and partner preferences may predict (or cause) homophily within dyads. But once a dyad is formed, a consequence of this relationship may be that partnes become more similar over time, as a result of a shared environment, influence and (de)selection processes. If you want to disentangle these processes, it is necessarry to have information on the degree of homophily between potential marriage partners would they be randomly assigned to one another, the degree of homophily at the beginning of the union, the degree of homophily within couples after a specific time period.
\end{quote}

\begin{quote}
\begin{description}
\item[\textbf{homophily}]
Homophily is the principle that a contact between similar people occurs at a
higher rate than among dissimilar people \citep{mcpherson2001}.
You will also come across the terms:
- baseline or structural homophily: this is the degree of homophily we observe simply as a result of the composition of the total choice set, the people with whom we can, in principle, form a relationship.\\
- inbreeding homophily: this is the degree of homophily we observe over and above the level of baseline homophily. This may be caused by taste homophily and differences in resources and restrictions (other than set by the total choice set).\\
- taste or choice homophily: the extent of homophily induced by personal preferences.\\
\end{description}
\end{quote}

\begin{quote}
\begin{description}
\item[\textbf{openness of society}]
The openness of society refers to the level of inequality of opportunities within society. The social problem of inequality consists of two sub-problems. The first refers to inequality in outcomes: the unequal distribution of resources (e.g.~economic, cultural, social, knowledge, power). The second refers to inquality in opportunities, the association between specific individual or group charactersitics and the likelihood to obtain these resources. Here the opennes of society is clearly linked to the second sub-problem. Where in questions of (inter-generational) social mobility the association between social position of parents and the social position of children is assessed, within the literature on intermarriage the association between the social positions of the two spouses is assessed. Both questions or associations will tell you something about the strenght of class/social position boundaries.
\end{description}
\end{quote}

\hypertarget{general-theoretical-framework}{%
\subsection{General Theoretical Framework}\label{general-theoretical-framework}}

In this section, I would like to introduce a General Theoretical Framework (or micro-macro model) which can be used to explain more or less any social phenomena you are interested in. The GTF can thus also be used to explain the emergence of social networks, and thus also to explain the emergence of dyads, and thus also to explain educational intermarriage.

For slides, see \href{multilevel-framework.pdf}{here}.

\begin{quote}
After having watched the video and after heaving read this page, you should be able to:

\begin{itemize}
\tightlist
\item
  Understand and summarize the building blocks of the multi-level framework which can be used to explain the emergence of social networks.\\
\item
  macro-level (independent) variable(s)\\
\item
  social conditions\\
\item
  restrictions\\
\item
  bridge assumptions (also called social context effects)\\
\item
  Theory of Action\\
\item
  preferences\\
\item
  resources\\
\item
  choice-set\\
\item
  choice-input\\
\item
  choice-output\\
\item
  Transformation rules (also called aggregation mechanism)\\
\item
  social interdependencies\\
\item
  unintended/unforeseen consequences of micro-level behavior\\
\item
  macro-level (dependent) variable
\item
  Provide examples of all building blocks in the context of explaining the emergence of dyads
\end{itemize}
\end{quote}

For more background reading on the multi-level framework (aka ``Coleman-boat'', ``Coleman-bathtub'', ``micro-macro models'') see \citep{coleman1994} and \citep[especially paragraph 4.4]{raub2011}.

\textcolor{red}{**The GTF is a framework, not a theory from which you can deduce hypotheses.**} Before we can do that, we need to fill in the blanks. That is, we need to make the social contexts (bridge assumptions) explicit. We need a Theory of Action. We need to think of the interdependencies and how they impact the aggregation mechanism.

So, let's get started\ldots{}

\hypertarget{social-context-effects}{%
\subsubsection*{Social context effects}\label{social-context-effects}}
\addcontentsline{toc}{subsubsection}{Social context effects}

\textbf{Characteristics of the social context} in which people are embedded (the marco- and meso-level) may impact people's preferences and resources.\\
Example 1: The level of economic inequality impacts how financial resources are unequally distributed across educational groups within society.\\
Hypo1: In countries with more wealth inequality, the difference between educational groups in economic resources is larger.\\
Example 2: Societal norms may impact your own views and opinions and thus preferences.\\
Hypo2: In countries with more equal gender norms, men's (women's) preferences for a partner with a higher education are stronger (weaker).

\hypertarget{the-special-role-of-restrictions}{%
\subsubsection*{The special role of restrictions}\label{the-special-role-of-restrictions}}
\addcontentsline{toc}{subsubsection}{The special role of restrictions}

\textbf{Restrictions} or constraints also refer to macro-level characteristics but restrictions do not directly impact preferences and resources (i.e.~choice input) but instead influence, or \emph{constrain} how these preferences and resources lead to choice-output; we have a constrained choice model. Restrictions - in studies on the emergence of social networks - impact the \emph{choice-set}, the relevant choice-options that a person has.\\
If I would like to marry a grizzly bear but if there are no grizzly bears around which I can marry, I cannot act upon my preferences (commonly the example is about Eskimos but that may be considered more politically incorrect). This is called a \emph{structural restriction}. A more realistic example would be the distribution of educational degrees within society, which depend on educational expansion and inequality of educational opportunities.\\
Next, to structural restrictions we may also have \emph{normative restrictions}, the formal and informal rules of institutions. A formal normative restriction would be a \emph{law} that forbids me to marry a grizzly bear. An informal normative restriction would be a \emph{social norm}, e.g.~my parents who disapprove of my preference to marry a grizzly bear.\\
Please note that social norms may thus impact my preferences directly (a social context effect) and indirectly (act as a restriction).
Example1: Preferences for a partner with a similar educational level are more likely to lead to educational homogamy, if educational degrees are more evenly distributed across men and women.

\textcolor{red}{In the literature on resources you will see that restrictions are also commonly understood as the absence of resources. I am a stubborn scientists and DO NOT FOLLOW THIS TERMINOLOGY and neither should you.}

\hypertarget{theory-of-action}{%
\subsubsection*{Theory of Action}\label{theory-of-action}}
\addcontentsline{toc}{subsubsection}{Theory of Action}

Persons have \textbf{preferences} for a partner with a specific educational-level. Commonly, people prefer higher-educated partners (because of instrumental motives) and people have homomphilic preferences. Preferences may differ between persons with different educational levels and between men and women.\\
Persons also have \textbf{resources} (i.e.~economic, cultural, cognitive, social resources) that may affect the search behavior of persons.~
Example1: persons with more economic resources have more options to meet different people and may thus select a partner from a larger choice-set.
Hypo1: persons with more economic resources are more likely to marry a partner that meet their preferences, i.e.~a more similar partner.

We would like to apply the GTF to explain the emergence of social networks. The networks we observe are the result of people making and breaking social relations. Consequently, a theory of action to explain decision about social relations should explain not only decisions about making new relations (i.e.~\textbf{selection}) but also about decision whether or not to maintain or break existing relations (i.e.~\textbf{deselection}). When we talk about selection processess, we implicitly mean both selection and deselection.~\\
Concretely, if we want to explain the degree of intermarriage within society, we need to take into account both who is marrying whom \emph{and} who is divorcing whom! Consider the following example. For some people the saying `opposite attracts' may hold true and they may be unaware of or ignore the social norm not to intermarry. But once married the couple may face unanticipated sanctions of violating the social norm, they may be ostracized. Being faced with this unanticipated consequence of their marriage decision, the couple may subsequently decide to divorce. In this example, the social norm thus not influences the selection process (more precisely, does not moderate the impact of preferences on marriage decisions) but it does influence the deselection process.~

\begin{quote}
Our Theory of Action assumes a cost benefit evaluation of some sort, in line with Rational Action Theory. However, social scientists' view on human's rationality is different than the view of classical economists. Social scientists speak of restricted or bounded rationality (i.e.~a weak rationality assumption); people are not always able to have or process all relevant information to make accurate and correct cost-benefit evaluations. We make questimates about the costs involved in our decision and about the likelihood that our behavior will yield the desired goal. Within sociology, actor's goals are not only economic, monatory goals. Actor's goals can be physical and social goals (i.e.~health, happiness, avoidance of downwards mobility). For a nice paper on Rational Action Theory for Sociologists, see \citep{goldthorpe1998}.
\end{quote}

\hypertarget{transformation-rules}{%
\subsubsection*{Transformation rules}\label{transformation-rules}}
\addcontentsline{toc}{subsubsection}{Transformation rules}

We now almost have all ingredients to explain (or predict) the degree of intermarriage in society. We `only' need the aggregation mechanisms: the micro-to-macro link. We thereby need to know the macro-level (intended and unintended) consequences of individual actions. That is, we need to know how the marriage market functions.~

Let us assume the following:

\begin{itemize}
\tightlist
\item
  Someone takes the initiative. This is determined by chance.
\item
  The initial choice-set is formed by 5 random partners of the opposite sex (no assumptions about search behavior). Possible partners who are already married are removed from the initial choice-set. The possible partners that remain constitute the (final) choice set.\\
\item
  Persons may prefer a partner with a higher education. These preferences may differ between educational levels and between the sexes.
\item
  Persons choose a partner from their choice set (not marrying is not an option). Possible partners with a higher education have a larger chance to be chosen. How important a partner's education is, depends on the preference of the one taking the initiative.
\item
  The persons who is being proposed to always accepts.
\item
  We observe no divorces.
\item
  Resources do not play any role (e.g the higher educated do not have a larger choice set)
\item
  Educational degrees are either `high' or `low'.
\end{itemize}

With the above marriage-market model we have a limited number of ingredients that impact the observed degree of educational intermarriage within society:

\begin{itemize}
\tightlist
\item
  gender composition within society\\
\item
  the distribution of educational degrees in society\\
\item
  preferences\\
\item
  the number of marriage proposals
\end{itemize}

I hope you see that marriage choices are interdependent. If I marry person A, you no longer can marry person A.
These interdependencies make it difficult to predict the macro-level dependent variable, degree of educational homogamy.~

Given the market model above, can you predict who will marry whom?

Well, I can not. You may be a mathematical wizard and able to find a closed solution by some algebra. Another option could be to to make a simplified model and try to simulate the macro-level outcome based purely on our micro-level theory of action and the rules of the marriage market. We call this Agent-Based-Modelling (see ). I programmed a simply ABM based on the above. There are some parameters in the model which you can change.

Suppose\ldots{}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  **\%\_men=50**: We have an equal gender distribution in society (50\% men, 50\% women; range: 1-99).\\
\item
  **\_men\_EducHigh=50**: 50\% of our male population is higher educated and 50\% is lower educated (range: 1-99).\\
\item
  **\_women\_EducHigh=50**: 50\% of our female population is higher educated and 50\% is lower educated (range: 1-99).\\
\item
  \textbf{pref\_men\_EH=0}: Higher educated men do not have any preference with respect to the educational level of their partner. (range: 0-10)
\item
  \textbf{pref\_men\_EL=0}: Lower educated men do not have any preference with respect to the educational level of their partner. (range: 0-10)
\item
  \textbf{pref\_women\_EH=0}: Higher educated women do not have any preference with respect to the educational level of their partner. (range: 0-10)
\item
  \textbf{pref\_women\_EL=0}: Lower educated women do not have any preference with respect to the educational level of their partner. (range: 0-10)
\end{enumerate}

Can you make a guess about the resulting degree of eductional homogamy?? Press update to see if you were correct.
Play around with (agent-based simulation) model below.

Go to app \href{https://jtolsma.shinyapps.io/marriagemarket/}{here}

\hypertarget{causes-of-dyads-methods}{%
\subsection{Causes of dyads (methods)}\label{causes-of-dyads-methods}}

When testing hypotheses on assortative mating two methodological approaches can be used. We may predict the \textbf{frequency of specific dyads} in our population with loglinear models and the data we use is commonly structured in a table like the one below.

\textbf{Table.} Dyad frequencies

\begin{longtable}[]{@{}lll@{}}
\toprule
& Wife educ-high & Wife educ-low\tabularnewline
\midrule
\endhead
\textbf{Husband educ-high} & 350 & 150\tabularnewline
\textbf{Husband educ-low} & 200 & 400\tabularnewline
\bottomrule
\end{longtable}

Another approach is to take the \textbf{characteristics of the dyad} (e.g.~endogamy versus mixed) as the dependent variable. This dependent variable can than be explained by applying (conditional) (multinomial) logistic regression techniques. In this case, the data is commonly structured in long format and looks something like the table below.

\textbf{Table.} Dyad characteristics

\begin{longtable}[]{@{}llll@{}}
\toprule
Dyad\_id & Wife educ & Husband educ & dyad\_educ\tabularnewline
\midrule
\endhead
1 & high & low & high-low\tabularnewline
2 & high & low & high-low\tabularnewline
3 & low & low & low-low\tabularnewline
4 & low & high & low-high\tabularnewline
5 & high & low & high-low\tabularnewline
\ldots{} & \ldots{} & \ldots{} & \ldots{}\tabularnewline
\bottomrule
\end{longtable}

Which methodology is preferred should depend on your hypotheses and on the data you have to your availability. Since I assume most readers are raised within the regression tradition, in {[}this section{]} we will practice with estimating conditional multinomial logistic regression models.

\begin{quote}
Please be aware that in both approaches we normally do not have information on (the frequency or characteristics of) dyads in which there is no relation between ego and alter. Thus, you may have information on characteristics of me and my wife but you do not have information on all other women (or men) I could have married but didn't. I fished my wife out of the sea but we don't know what the other fish looked like. (Luckily my wife is no scientist and won't read this clarification.)
\end{quote}

\hypertarget{consequences-of-dyads-theory}{%
\section{Consequences of dyads (theory)}\label{consequences-of-dyads-theory}}

Assortative mating, or more generally mating, has consequences for both partners. Just to mention a few: relationship quality; time spend together on culture consumption; divorce rates; number of children; household income; working hours. I hope you see that these concepts all refer to the dyad-level but that you may group these concepts by how they are measured, namely at the dyad-level itself (yes/no divorce, number of children) or at the ego/alter-level and aggregated to the dyad-level (e.g.~total working hours of the couple is the sum of the working hours of both individual partners, culture consumption is the consumed culture of both partners (alone and together)). But with both type of concepts, it should be clear that they are the consequence of interdependent actions of both partners (e.g.~commonly both partners decide on whether to have and make children).

Thus, once again, homophily within couples may be the result of:

\begin{itemize}
\tightlist
\item
  \textbf{selection}\\
\item
  \textbf{shared context}
\item
  \textbf{(dyadic) influence}
\end{itemize}

But what do we mean with `influence'? Let's read the following quote.

People influence one another, and as the importance and immediacy of a group or individual increases, this influence becomes stronger (Latané, 1981). Forces of influence are especially strong within romantic relationships because these relationships are important, are predicated on mutual acceptance, and involve frequent exposure to the habits of one's partner." \citet{bartel2017romantic}

It would say this a quite naive conceptualisation of \textbf{influence}. It is implicitly assumed that partners will match their opinions/behaviors. Thus influence here is convergence. But why should partners' characteristics converge over time, why would homophily increase? And, it still does not become clear what the `forces of influence' are.

Let us make a distinction between:

\begin{itemize}
\tightlist
\item
  positive influence: alters become more similar to each other over time\\
\item
  negative influence: alters become more distinct to each other over time
\item
  positive feedback influence: characteristics develop in same direction over time
\end{itemize}

Now suppose these influence processes are the only reasons why alters change (i.e.~the \emph{ceteris paribus} condition). How could dyad similarity develop over time. See below:

\begin{figure}
\centering
\includegraphics{02-Dyads_files/figure-latex/unnamed-chunk-1-1.pdf}
\caption{\label{fig:unnamed-chunk-1}Positive influence}
\end{figure}

\begin{figure}
\centering
\includegraphics{02-Dyads_files/figure-latex/unnamed-chunk-2-1.pdf}
\caption{\label{fig:unnamed-chunk-2}Negative influence}
\end{figure}

\begin{figure}
\centering
\includegraphics{02-Dyads_files/figure-latex/unnamed-chunk-3-1.pdf}
\caption{\label{fig:unnamed-chunk-3}Positive feedback influence}
\end{figure}

There are several `forces of positive influence mechanisms':

\begin{itemize}
\tightlist
\item
  information: We may exchange new effective information and arguments with our alters.
\item
  persuasion (and dissuasion): we may convince, force or pressure our alters to become similar to us.\\
\item
  contagion: this can be taken quite literally, like how the flu spreads but also more metaphorically like how (health) behaviors like drinking, smoking, sporting spread (because our alters increase the opportunities for these behaviors).\\
\item
  assimilation: we may mimic our alters because of a psychological need for similarity, because we think this will be good for our identity / social status, etc.
\end{itemize}

\textcolor{red}{The literature is not very clear and consistent about different type of incluence processes and which influence mechanisms are at play. You will thus also see that authors use socialisation when talking about (positive) influence processes. }

There are several `forces of negative influence mechanisms':

\begin{itemize}
\tightlist
\item
  information: We may exchange new counter-effective information and arguments with our alters. This would especially become relevant whey we don't like or belief the source of information and arguments.\\
\item
  persuasion (and dissuasion): we may convince, force or pressure our alters to become dissimilar to us.
\item
  polarisation: we may distance ourselves from our alters because of a psychological need for distinctiveness. This would especially become relevant when we are already distinct on key social dimensions.
\end{itemize}

There are several `forces of positive feedback influence mechanisms':

\begin{itemize}
\tightlist
\item
  confirmation: information and arguments are repeated and existing opinions and behaviors of both alters reinforced.\\
\item
  competition: we may have a psychological need to be better/higher/more than our alter.
\end{itemize}

The crucial difference between the positive feedback mechanisms and the positive influence mechanisms are that as a result of the former homophily between the alters does not necessarily change. Note that positive feedback could entail increasing and decreasing the opinion or behavior.

\hypertarget{consequences-of-dyads-methods}{%
\section{Consequences of dyads (methods)}\label{consequences-of-dyads-methods}}

The method used to explain consequences of dyads depends on our Unit of Analysis. If it is the dyad itself (e.g.~mean relationship quality) methods are relatively straightforward, because we may assume that the observations at the dyad-level are independent. If, on the other hand, the unit of analysis are the partners themselves that make up the dyad, we need to acknowledge that the observations between the partners of the same couple are not independent. In part exactly because partners select and influence each other and share a social context. One solution could be to simply randomly select one partner of each couple or, if partners can be clearly distinguished - for example men and women in heterosexual couples - the different partners could be analyzed separately. A disadvantage of the latter two approaches is, however, that the covariance between the partners cannot be explained anymore, although this may exactly be the focus of our research questions. A more elegant solution, is to take the interdependencies into account and model these explicitly. This can be done within a multi-level framework and within a structural-equation modelling framework.

When we discussed the methods to analyze causes of homogamy, we were interested in homophily within couples at one point in time and focus on selection as explanans. Now, when we discuss the consequences of dyads, we are interested in explaining trends in homophily within couples and focus on shared context and influence processes as explanans.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{methods}{%
\chapter{Methods}\label{methods}}

\hypertarget{before-you-start}{%
\section{Before you start}\label{before-you-start}}

\hypertarget{causes}{%
\section{Causes}\label{causes}}

\hypertarget{odds-ratio}{%
\subsection{Odds Ratio}\label{odds-ratio}}

\hypertarget{loglinear-model}{%
\subsection{Loglinear Model}\label{loglinear-model}}

\hypertarget{conditional-multinomial-logit-model}{%
\subsection{Conditional multinomial logit model}\label{conditional-multinomial-logit-model}}

\hypertarget{consequences}{%
\section{Consequences}\label{consequences}}

\hypertarget{apim}{%
\subsection{APIM}\label{apim}}

\hypertarget{clpm}{%
\subsection{CLPM}\label{clpm}}

\hypertarget{ri-clpm}{%
\subsection{RI-CLPM}\label{ri-clpm}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{data}{%
\chapter{Data}\label{data}}

\hypertarget{sampling}{%
\section{Sampling}\label{sampling}}

\hypertarget{ethical-considerations}{%
\section{Ethical considerations}\label{ethical-considerations}}

\hypertarget{measurement}{%
\section{Measurement}\label{measurement}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{part-part-2-egonets}{%
\part{Part 2 EGONETS}\label{part-part-2-egonets}}

\hypertarget{theory-1}{%
\chapter{Theory}\label{theory-1}}

\hypertarget{causes-1}{%
\section{Causes}\label{causes-1}}

\hypertarget{consequences-1}{%
\section{Consequences}\label{consequences-1}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{methods-1}{%
\chapter{Methods}\label{methods-1}}

\hypertarget{before-you-start-1}{%
\section{Before you start}\label{before-you-start-1}}

\hypertarget{causes-2}{%
\section{Causes}\label{causes-2}}

\hypertarget{aggregation}{%
\subsection{Aggregation}\label{aggregation}}

\hypertarget{disaggregation}{%
\subsection{Disaggregation}\label{disaggregation}}

\hypertarget{micro-macro-model}{%
\subsection{Micro-macro Model}\label{micro-macro-model}}

\hypertarget{multi-level-framework}{%
\subsubsection{Multi-level framework}\label{multi-level-framework}}

\hypertarget{sem}{%
\subsubsection{SEM}\label{sem}}

\hypertarget{consequences-2}{%
\section{Consequences}\label{consequences-2}}

\hypertarget{macro-micro-model}{%
\subsection{Macro-micro model}\label{macro-micro-model}}

\hypertarget{multi-level-framework-1}{%
\subsubsection{Multi-level framework}\label{multi-level-framework-1}}

\hypertarget{sem-1}{%
\subsubsection{SEM}\label{sem-1}}

\hypertarget{micro-macro-ri-clpm}{%
\subsection{Micro-macro-RI-CLPM}\label{micro-macro-ri-clpm}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{data-1}{%
\chapter{Data}\label{data-1}}

\hypertarget{sampling-1}{%
\section{Sampling}\label{sampling-1}}

\hypertarget{ethical-considerations-1}{%
\section{Ethical considerations}\label{ethical-considerations-1}}

\hypertarget{measurement-1}{%
\section{Measurement}\label{measurement-1}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{part-part-3-socionets}{%
\part{Part 3 SOCIONETS}\label{part-part-3-socionets}}

\hypertarget{theory-2}{%
\chapter{Theory}\label{theory-2}}

\hypertarget{causes-3}{%
\section{Causes}\label{causes-3}}

\hypertarget{consequences-3}{%
\section{Consequences}\label{consequences-3}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{methods-2}{%
\chapter{Methods}\label{methods-2}}

\hypertarget{causes-4}{%
\section{Causes}\label{causes-4}}

\hypertarget{consequences-4}{%
\section{Consequences}\label{consequences-4}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{data-2}{%
\chapter{Data}\label{data-2}}

\hypertarget{sampling-2}{%
\section{Sampling}\label{sampling-2}}

\hypertarget{ethical-considerations-2}{%
\section{Ethical considerations}\label{ethical-considerations-2}}

\hypertarget{measurement-2}{%
\section{Measurement}\label{measurement-2}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{part-part-4-webscraping}{%
\part{Part 4 Webscraping}\label{part-part-4-webscraping}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{part-part-5-network-visualisation}{%
\part{Part 5 Network Visualisation}\label{part-part-5-network-visualisation}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{appendix-appendix}{%
\appendix}


\hypertarget{tutorial}{%
\chapter{Introduction to R for SNA}\label{tutorial}}

\begin{verbatim}
## Loading required package: xfun
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'xfun'
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:base':
## 
##     attr, isFALSE
\end{verbatim}

\begin{verbatim}
## Loading required package: foreign
\end{verbatim}

\begin{verbatim}
## Loading required package: tidyverse
\end{verbatim}

\begin{verbatim}
## -- Attaching packages ----------------------------------------------------------- tidyverse 1.3.0 --
\end{verbatim}

\begin{verbatim}
## v ggplot2 3.3.2     v purrr   0.3.4
## v tibble  3.0.4     v dplyr   1.0.2
## v tidyr   1.1.2     v stringr 1.4.0
## v readr   1.4.0     v forcats 0.5.0
\end{verbatim}

\begin{verbatim}
## -- Conflicts -------------------------------------------------------------- tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
\end{verbatim}

\begin{verbatim}
## Loading required package: mice
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'mice'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:stats':
## 
##     filter
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:base':
## 
##     cbind, rbind
\end{verbatim}

\begin{verbatim}
## Loading required package: labelled
\end{verbatim}

Latest Version: 31-07-2021

Please email any comments to: \href{mailto:j.tolsma@ru.nl}{\nolinkurl{j.tolsma@ru.nl}}

\hypertarget{preliminary-notes}{%
\section{Preliminary notes}\label{preliminary-notes}}

This very short R tutorial is for students who already have some experience with R who want to make the switch from stata/spss to R.

- In this tutorial I assume you will work with RScripts (.R files) not with Rmarkdown (.Rmd files)\\
- I will show you how to do things in base R and in a Tidyverse way.

\hypertarget{getting-up-and-running}{%
\section{Getting up and running}\label{getting-up-and-running}}

\begin{itemize}
\tightlist
\item
  install the latest version of R: \href{https://cran.r-project.org/}{R}
\item
  install the latest version of RStudio: \href{www.rstudio.com}{RStudio}
\item
  open RStudio and follow a brief tour/tutorial \href{https://web.cs.ucla.edu/~gulzar/rstudio/basic-tutorial.html}{brief tour of Gulzar}
\end{itemize}

Do you Want more information, or are you looking for a different (tidyverse) tutorial?

\begin{itemize}
\tightlist
\item
  \href{https://www.r-bloggers.com/how-to-learn-r-2/}{R-bloggers}
\item
  \href{https://www.rstudio.com/resources/cheatsheets/}{RStudio cheatsheets}
\item
  \href{http://r4ds.had.co.nz/}{R for Data Science}
\item
  \href{https://www.moderndive.com/}{Statistical Inference via Data Science: A Modern Dive into R and the tidyverse}
\end{itemize}

Are you a Research Master Social and Cultural Science student? Or, a social science student/scientists with some statistical background in descriptive and explanatory statistics (e.g.~regression analysis) who wants to make a switch from SPSS to R? Please read on.

Open RStudio. Your screen will look something like this:

\begin{figure}
\includegraphics[width=1\linewidth]{screenshot} \caption{Screenshot Rstudio}\label{fig:screenshot}
\end{figure}

\begin{itemize}
\tightlist
\item
  During the workgroup I will show you around the major subwindows and taps in RStudio.
\end{itemize}

\hypertarget{working-with-rscript}{%
\section{Working with RScript}\label{working-with-rscript}}

\begin{itemize}
\tightlist
\item
  Open a new R-script (via file --\textgreater{} new --\textgreater{} RScript (see Figure \ref{fig:screenshot} \textbf{Arrow 1}), or simply hit \emph{Ctrl+Shift+N})
\item
  Start your script with your name and date.
\item
  Start with a clean workspace.
\item
  Start with the latest versions of R, RStudio and your packages.
\item
  Load the additional packages you will need later.
\item
  Define your workdirectory.
\end{itemize}

Thus your RScript will look something like this:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{###########################}
\CommentTok{# Title: Introducation to R for SNA}
\CommentTok{# Author: J Tolsma}
\CommentTok{# version: 30-10-2019}
\CommentTok{###########################}

\CommentTok{#start with clean workspace }
\KeywordTok{rm}\NormalTok{(}\DataTypeTok{list=}\KeywordTok{ls}\NormalTok{())}

\CommentTok{#install.packages I will need later here}
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"installr"}\NormalTok{) }\CommentTok{#you  first install packages}
\KeywordTok{require}\NormalTok{(installr) }\CommentTok{#then you will need to load them. This package is used to simply update R}
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"foreign"}\NormalTok{)}
\KeywordTok{require}\NormalTok{(foreign) }\CommentTok{#used to read in spss data files}
\KeywordTok{require}\NormalTok{(tidyverse)}
\CommentTok{#update if necessarry}
\KeywordTok{updateR}\NormalTok{()}

\CommentTok{#define workdirectory, note the double backslashes}
\KeywordTok{setwd}\NormalTok{(}\StringTok{'C:}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{SNA-4-Social-Scientists}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{'}\NormalTok{) }\CommentTok{#change to your own workdirectory}
\end{Highlighting}
\end{Shaded}

Do you see I start some lines with a \texttt{\#} these lines are comments and not code/commands. This is similar as the \texttt{*} sign in SPSS.\\
To run some code, you place your cursor in the line and hit \emph{Ctrl+Enter}. You may also select the code you want to run, or copy and paste it directly in the console window (\ref{fig:screenshot} \textbf{Arrow 2}). To see which commands you have executed, you may want to have a look at the history tab (\ref{fig:screenshot} \textbf{Arrow 3}).

\begin{quote}
Hint 1: In the upper right corner of the code blocks you see a \emph{copy-and-paste} sign. You may use this to copy and paste the code of this tutorial in your own script.\\
Hint 2: You really want to learn R? Never ever copy and paste code. Type the code yourself.
\end{quote}

\hypertarget{installing-additional-packages}{%
\section{Installing additional packages}\label{installing-additional-packages}}

You will probably always need to load and/or install additional packages. You may want to use RStudio's functionality (\ref{fig:screenshot} \textbf{Arrow 4}). I normally prefer to put everything in my script. See for example in the code block above, line 9 to 12.

\hypertarget{i-dont-understand-the-code}{%
\section{I don't understand the code!!}\label{i-dont-understand-the-code}}

When you see \texttt{functionname()}\footnote{Programmers like to confuse us simple persons. They thus make up mock names to indicate that the name is irrelevant. Thus a real programmer will never use \texttt{functionname()} but will use \texttt{foo()} or \texttt{bar()} or \texttt{foobar()} .} it means we use a build-in function of R If you want to see how lines/commands/functions work, try to decipher them from the inside out. Thus if you want to dechiper \texttt{rm(list=ls())}:

\begin{itemize}
\tightlist
\item
  \texttt{ls()}
\item
  \texttt{list=ls()}
\item
  \texttt{list}
\end{itemize}

Let's give it a go:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{tesvariable <-}\StringTok{ }\DecValTok{4}
\KeywordTok{ls}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "tesvariable"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{list=}\KeywordTok{ls}\NormalTok{()}
\NormalTok{list}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "tesvariable"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{ls}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "list"        "tesvariable"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{rm}\NormalTok{(list)}
\KeywordTok{ls}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "tesvariable"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#? :-)}
\KeywordTok{rm}\NormalTok{(}\DataTypeTok{list=}\KeywordTok{ls}\NormalTok{())}
\KeywordTok{ls}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## character(0)
\end{verbatim}

If you want to know more about specific functions, try to use the help function. For example try the following:

\begin{itemize}
\tightlist
\item
  \texttt{?ls}
\item
  \texttt{?rm}
\end{itemize}

Any idea what \texttt{\textless{}-} does?

At first it will be difficult to read the R Documentation pages. Don't worry, you will get the hang of it.

How am I to remember all that code/syntax??!!

\begin{itemize}
\tightlist
\item
  By using them.
\item
  You don't need to, you just need to remember in which script you used them before.
\item
  By using the existing cheat sheets:
\item
  By making your own cheat sheets.
\end{itemize}

\begin{quote}
You being the ideal student, you started your own cheat sheet. What should be on it by know?

\textbf{Functions}:

\begin{itemize}
\tightlist
\item
  \texttt{install.packages()} \# to install additional packages. Only do this once or to update package.
\item
  \texttt{require()} \# activate installed package
\item
  \texttt{setwd()} \# set your working directory
\item
  \texttt{ls()} \# list the objects in your environment
\item
  \texttt{rm()} \# to remove objects
\end{itemize}

\textbf{packages}:

\begin{itemize}
\tightlist
\item
  \texttt{installr} \# a package to easily update R (needs to be run in Rgui directly instead of RStudio )
\item
  \texttt{foreign} \# to read in spss data files
\item
  \texttt{tidyverse} \# a bunch of packages which allows for a completely different way of programming/scripting in R.\\
\end{itemize}

\textbf{operators / symbols}:

\begin{itemize}
\tightlist
\item
  \texttt{?} \# if placed in front of a function opens up the help pages.
\item
  \texttt{\textless{}-} \# used to assign values/objects to a different object.
\item
  \texttt{=} \# used to assign values/objects to arguments within a function.
\end{itemize}
\end{quote}

\hypertarget{reading-in-data-files}{%
\section{Reading in data files}\label{reading-in-data-files}}

We are going to work with two datasets: ``Culturele Veranderingen''. For more information on these datasets, see \href{https://www.scp.nl/Onderzoek/Bronnen/Beknopte_onderzoeksbeschrijvingen/Culturele_veranderingen_in_Nederland_CV}{here}.

Please download the files to your working directory.

\href{\%22addfiles/Cultural_Changes_2008.sav\%22}{Cultural\_Changes\_2008.sav}\\
\href{\%22addfiles/Cultural_Changes_2008.sav\%22}{Cultural\_Changes\_2010.sav} ~

There are different packages to read in data. Generally, I would recommend to use the \texttt{haven} package. In the past I used to \texttt{foreign} package. The advantage of using \texttt{haven::read\_spss} is that more information is stored in the dataset and in the variables (variable/value labels!!). A disadvantage is that not all other functions/packages of R are capable of dealing with the dataobject that haven produces.

\begin{quote}
below I will use \texttt{package\_name::function\_name} notation, to make explicit from which package the function belongs.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#ignore the warnings  }
\CommentTok{#?read.spss}
\CommentTok{#note that I have saved the data files in a folder called 'addfiles'. }

\NormalTok{cv08 <-}\StringTok{ }\NormalTok{foreign}\OperatorTok{::}\KeywordTok{read.spss}\NormalTok{(}\StringTok{"addfiles}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{Cultural_Changes_2008.sav"}\NormalTok{, }\DataTypeTok{use.value.labels=}\NormalTok{T, }\DataTypeTok{to.data.frame=}\NormalTok{T)}
\NormalTok{cv10 <-}\StringTok{ }\NormalTok{foreign}\OperatorTok{::}\KeywordTok{read.spss}\NormalTok{(}\StringTok{"addfiles}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{Cultural_Changes_2010.sav"}\NormalTok{, }\DataTypeTok{use.value.labels=}\NormalTok{T, }\DataTypeTok{to.data.frame=}\NormalTok{T)}

\CommentTok{#normally I think setting use.value.labels=F is more convenient. Thus lets load the data again but now without labels }
\NormalTok{cv08_nolab <-}\StringTok{ }\NormalTok{foreign}\OperatorTok{::}\KeywordTok{read.spss}\NormalTok{(}\StringTok{"addfiles}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{Cultural_Changes_2008.sav"}\NormalTok{, }\DataTypeTok{use.value.labels=}\NormalTok{F, }\DataTypeTok{to.data.frame=}\NormalTok{T)}
\NormalTok{cv10_nolab <-}\StringTok{ }\NormalTok{foreign}\OperatorTok{::}\KeywordTok{read.spss}\NormalTok{(}\StringTok{"addfiles}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{Cultural_Changes_2010.sav"}\NormalTok{, }\DataTypeTok{use.value.labels=}\NormalTok{F, }\DataTypeTok{to.data.frame=}\NormalTok{T)}

\CommentTok{#finally, import the data using haven}
\NormalTok{cv08_haven <-}\StringTok{ }\NormalTok{haven}\OperatorTok{::}\KeywordTok{read_spss}\NormalTok{(}\StringTok{"addfiles}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{Cultural_Changes_2008.sav"}\NormalTok{)}
\NormalTok{cv10_haven <-}\StringTok{ }\NormalTok{haven}\OperatorTok{::}\KeywordTok{read_spss}\NormalTok{(}\StringTok{"addfiles}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{Cultural_Changes_2010.sav"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

So you see I read in the data by using the function \texttt{read.spss()} of the package `foreign'. Within this function I set some arguments/parameters (e.g.~use.value.labels).

Now we can inspect our datasets and look for some differences:

\begin{itemize}
\item
  Find the \emph{Environment} tab in the upper right window (\ref{fig:screenshot} \textbf{Arrow 5}).

  \begin{itemize}
  \tightlist
  \item
    Find the little arrow and decollapse.
  \item
    What do we see?\\
  \end{itemize}
\item
  Double click on the three versions of the cv08 datasets.

  \begin{itemize}
  \tightlist
  \item
    What happens?
  \item
    Go to the new windows and have a look at the data. What are the differences?
  \item
    Close this window when finished.\\
  \end{itemize}
\item
  Lets use some build-in functions to get more information of our dataset.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{str}\NormalTok{(cv08)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    1963 obs. of  278 variables:
##  $ we_id   : Factor w/ 1963 levels "36775330","36775340",..: 1 2 3 4 5 6 7 8 9 10 ...
##  $ veilignr: num  8.11e+08 8.11e+08 8.11e+08 8.11e+08 8.11e+08 ...
##  $ lft1    : Factor w/ 78 levels "0","15","16",..: 38 26 3 17 44 36 49 21 46 28 ...
##  $ geslacht: Factor w/ 3 levels "Onbekend","Man",..: 2 3 3 2 2 3 2 3 2 2 ...
##  $ allochtn: Factor w/ 4 levels "geen allochtoon",..: 1 1 2 1 1 2 1 2 1 1 ...
##  $ lft01   : Factor w/ 82 levels "< één jaar","één jaar",..: 40 28 4 19 46 38 51 23 48 30 ...
##  $ lftop   : Factor w/ 81 levels "< één jaar","één jaar",..: 40 28 4 18 46 38 51 23 48 30 ...
##  $ gewicht : num  8423 6244 13434 8997 8423 ...
##  $ var006n : Factor w/ 11 levels "onbekend","OP < 12 jr  of volgt actueel bas.ondw.",..: 8 10 5 10 8 4 4 7 7 3 ...
##  $ v040    : Factor w/ 6 levels "Geen opgave",..: 6 5 6 5 6 6 5 5 5 5 ...
##  $ var723  : Factor w/ 62 levels "Weigert","Weet niet",..: 3 43 3 17 3 3 39 30 28 17 ...
##  $ var723a : Factor w/ 8 levels "Geen opgave",..: 2 2 2 2 2 2 2 2 2 2 ...
##  $ v202n   : Factor w/ 10 levels "-3","werkt >12 uur",..: 6 2 9 2 5 4 2 2 2 2 ...
##  $ var1061a: Factor w/ 6 levels "Geen opgave",..: 5 6 6 6 6 6 6 6 6 6 ...
##  $ var1061b: Factor w/ 31 levels "Weigert","Weet niet",..: 17 3 3 3 3 3 3 3 3 3 ...
##  $ var1062a: Factor w/ 6 levels "Geen opgave",..: 6 6 6 6 6 6 6 6 5 6 ...
##  $ var1062b: Factor w/ 31 levels "Weigert","Weet niet",..: 3 3 3 3 3 3 3 3 21 3 ...
##  $ int137n : Factor w/ 8 levels "Geen opgave",..: 2 7 2 5 2 5 6 7 7 6 ...
##  $ int138n : Factor w/ 8 levels "Geen opgave",..: 7 7 7 7 6 7 7 6 7 7 ...
##  $ int139n : Factor w/ 8 levels "Geen opgave",..: 2 7 2 2 2 7 5 5 7 2 ...
##  $ int140n : Factor w/ 8 levels "Geen opgave",..: 2 7 7 7 5 7 5 5 7 7 ...
##  $ int141n : Factor w/ 8 levels "Geen opgave",..: 5 7 5 7 5 7 5 5 7 5 ...
##  $ v401    : Factor w/ 9 levels "Geen opgave",..: 6 6 6 6 7 6 7 6 6 6 ...
##  $ var1343 : Factor w/ 7 levels "Geen opgave",..: 7 7 7 7 6 7 7 7 7 7 ...
##  $ var648  : Factor w/ 9 levels "Geen opgave",..: 7 5 7 8 7 7 7 8 7 7 ...
##  $ var149  : Factor w/ 8 levels "Geen opgave",..: 6 5 3 7 6 6 6 6 5 6 ...
##  $ var058  : Factor w/ 6 levels "Geen opgave",..: 5 5 5 5 5 6 6 5 5 5 ...
##  $ var059  : Factor w/ 6 levels "Geen opgave",..: 5 5 5 6 5 5 5 5 5 6 ...
##  $ var064  : Factor w/ 6 levels "Geen opgave",..: 5 5 6 5 6 6 6 5 6 6 ...
##  $ var365  : Factor w/ 6 levels "Geen opgave",..: 5 5 6 5 5 5 5 6 6 6 ...
##  $ var065  : Factor w/ 6 levels "Geen opgave",..: 6 5 5 6 3 5 6 6 5 5 ...
##  $ var092  : Factor w/ 9 levels "Geen opgave",..: 6 3 6 8 8 8 8 7 8 7 ...
##  $ var096  : Factor w/ 10 levels "Geen opgave",..: 7 7 6 7 7 5 6 6 5 5 ...
##  $ int054  : Factor w/ 8 levels "Geen opgave",..: 8 3 7 7 5 5 6 7 6 5 ...
##  $ int055  : Factor w/ 8 levels "Geen opgave",..: 7 7 7 6 3 5 6 7 7 6 ...
##  $ int056  : Factor w/ 8 levels "Geen opgave",..: 6 6 7 7 6 5 5 7 6 7 ...
##  $ int057  : Factor w/ 8 levels "Geen opgave",..: 6 7 6 6 5 6 7 7 6 5 ...
##  $ int058  : Factor w/ 8 levels "Geen opgave",..: 7 7 6 6 3 5 6 7 8 6 ...
##  $ int059  : Factor w/ 8 levels "Geen opgave",..: 6 7 3 7 7 5 5 6 8 6 ...
##  $ int059a : Factor w/ 8 levels "Geen opgave",..: 7 6 6 6 7 5 6 6 7 6 ...
##  $ var571  : Factor w/ 7 levels "Geen opgave",..: 6 7 7 6 6 6 6 7 6 7 ...
##  $ var572  : Factor w/ 7 levels "Geen opgave",..: 2 5 7 2 2 2 2 7 2 5 ...
##  $ var573  : Factor w/ 7 levels "Geen opgave",..: 5 6 7 6 5 5 5 5 6 6 ...
##  $ var574  : Factor w/ 7 levels "Geen opgave",..: 7 2 7 2 6 7 7 6 2 2 ...
##  $ var576  : Factor w/ 10 levels "Geen opgave",..: 9 6 7 8 9 6 9 8 8 9 ...
##  $ var153  : Factor w/ 7 levels "Geen opgave",..: 7 5 5 5 5 5 5 5 5 5 ...
##  $ var154  : Factor w/ 7 levels "Geen opgave",..: 7 6 6 6 7 6 7 6 7 7 ...
##  $ var155  : Factor w/ 7 levels "Geen opgave",..: 6 6 6 7 7 7 7 3 6 6 ...
##  $ var156  : Factor w/ 7 levels "Geen opgave",..: 7 6 6 6 6 3 7 6 6 6 ...
##  $ var157  : Factor w/ 7 levels "Geen opgave",..: 6 3 6 6 6 7 7 3 6 3 ...
##  $ var157a : Factor w/ 7 levels "Geen opgave",..: 7 3 6 6 7 7 7 6 6 6 ...
##  $ var154a : Factor w/ 7 levels "Geen opgave",..: 3 3 6 6 6 6 6 6 6 6 ...
##  $ var164  : Factor w/ 8 levels "Geen opgave",..: 6 6 6 5 5 5 5 6 5 5 ...
##  $ var165  : Factor w/ 10 levels "Geen opgave",..: 7 7 7 8 9 9 8 8 9 8 ...
##  $ var166  : Factor w/ 10 levels "Geen opgave",..: 7 7 8 7 9 9 8 7 8 8 ...
##  $ var179  : Factor w/ 6 levels "Geen opgave",..: 5 5 6 5 5 5 5 5 5 5 ...
##  $ var180  : Factor w/ 6 levels "Geen opgave",..: 5 5 5 6 5 6 6 5 5 5 ...
##  $ var184  : Factor w/ 6 levels "Geen opgave",..: 5 5 6 5 6 5 5 5 5 5 ...
##  $ var185  : Factor w/ 6 levels "Geen opgave",..: 6 5 5 5 6 5 5 5 5 5 ...
##  $ var198a : Factor w/ 6 levels "Geen opgave",..: 6 5 5 5 5 5 6 6 6 5 ...
##  $ var198  : Factor w/ 11 levels "Geen opgave",..: 2 7 9 7 5 5 2 2 2 7 ...
##  $ var201a : Factor w/ 6 levels "Geen opgave",..: 6 5 5 6 6 5 6 6 6 6 ...
##  $ var201b : Factor w/ 10 levels "Geen opgave",..: 2 6 8 2 2 5 2 2 2 2 ...
##  $ var204  : Factor w/ 9 levels "Geen opgave",..: 9 8 9 8 9 8 9 9 7 9 ...
##  $ int257  : Factor w/ 11 levels "Geen opgave",..: 11 7 7 8 10 6 7 9 7 11 ...
##  $ var211  : Factor w/ 7 levels "Geen opgave",..: 7 6 7 7 7 5 7 6 6 7 ...
##  $ var223  : Factor w/ 7 levels "Geen opgave",..: 5 6 5 7 5 5 5 7 5 5 ...
##  $ var1320 : Factor w/ 9 levels "Geen opgave",..: 5 6 6 6 6 6 6 7 5 5 ...
##  $ var1321 : Factor w/ 9 levels "Geen opgave",..: 5 8 6 6 8 6 8 8 6 6 ...
##  $ var1322 : Factor w/ 7 levels "Geen opgave",..: 7 7 6 6 7 5 5 6 5 5 ...
##  $ var1323 : Factor w/ 7 levels "Geen opgave",..: 7 7 6 7 7 6 7 7 7 7 ...
##  $ var1324 : Factor w/ 7 levels "Geen opgave",..: 7 7 6 7 7 7 7 7 7 7 ...
##  $ var1325 : Factor w/ 7 levels "Geen opgave",..: 7 7 7 7 7 6 7 7 7 6 ...
##  $ var1326 : Factor w/ 7 levels "Geen opgave",..: 7 7 7 7 7 7 7 7 7 7 ...
##  $ var1327 : Factor w/ 7 levels "Geen opgave",..: 7 7 6 7 7 6 7 7 6 7 ...
##  $ var1328 : Factor w/ 7 levels "Geen opgave",..: 7 7 7 7 7 7 7 7 7 7 ...
##  $ var229  : Factor w/ 12 levels "Geen opgave",..: 7 7 7 12 7 7 7 6 7 7 ...
##  $ int218  : Factor w/ 9 levels "Geen opgave",..: 6 6 7 7 6 8 7 7 8 7 ...
##  $ int219  : Factor w/ 9 levels "Geen opgave",..: 6 6 7 7 7 6 6 6 7 7 ...
##  $ int221  : Factor w/ 9 levels "Geen opgave",..: 9 6 9 7 7 6 7 7 6 7 ...
##  $ int222  : Factor w/ 9 levels "Geen opgave",..: 6 6 7 6 8 7 7 6 8 7 ...
##  $ int223  : Factor w/ 9 levels "Geen opgave",..: 7 7 5 6 7 6 7 6 5 8 ...
##  $ int710  : Factor w/ 9 levels "Geen opgave",..: 8 6 5 7 7 6 7 7 6 7 ...
##  $ int711  : Factor w/ 9 levels "Geen opgave",..: 8 6 7 6 7 9 7 6 5 8 ...
##  $ int712  : Factor w/ 9 levels "Geen opgave",..: 6 7 7 7 7 6 8 6 8 8 ...
##  $ int713  : Factor w/ 9 levels "Geen opgave",..: 7 7 3 7 6 8 8 6 8 7 ...
##  $ int714  : Factor w/ 9 levels "Geen opgave",..: 7 6 3 7 7 7 8 7 8 8 ...
##  $ int715  : Factor w/ 9 levels "Geen opgave",..: 7 6 9 6 6 7 9 7 7 8 ...
##  $ int716  : Factor w/ 9 levels "Geen opgave",..: 9 7 7 7 6 6 7 7 7 7 ...
##  $ var433  : Factor w/ 10 levels "Geen opgave",..: 6 6 7 7 7 5 9 6 7 6 ...
##  $ var439  : Factor w/ 10 levels "Geen opgave",..: 6 5 9 8 3 5 5 8 5 9 ...
##  $ var1329 : Factor w/ 10 levels "Geen opgave",..: 6 8 6 8 6 5 6 5 5 6 ...
##  $ var1330 : Factor w/ 10 levels "Geen opgave",..: 9 9 8 7 9 5 5 8 5 6 ...
##  $ var445  : Factor w/ 10 levels "Geen opgave",..: 8 9 6 6 8 8 9 6 7 6 ...
##  $ var446  : Factor w/ 10 levels "Geen opgave",..: 7 9 5 8 6 5 6 7 5 5 ...
##  $ var447  : Factor w/ 10 levels "Geen opgave",..: 7 9 5 8 6 5 8 7 5 5 ...
##  $ var451  : Factor w/ 10 levels "Geen opgave",..: 9 9 8 8 8 5 8 9 9 8 ...
##  $ var452  : Factor w/ 10 levels "Geen opgave",..: 6 7 6 6 6 5 8 7 5 5 ...
##  $ var1316 : Factor w/ 10 levels "Geen opgave",..: 9 9 8 8 9 5 6 6 5 9 ...
##   [list output truncated]
##  - attr(*, "variable.labels")= Named chr [1:278] "WE_ID" "veilignummer" "Leeftijd op 1-jan-2009" "Geslacht hhpersoon (GBA)" ...
##   ..- attr(*, "names")= chr [1:278] "we_id" "veilignr" "lft1" "geslacht" ...
##  - attr(*, "codepage")= int 1252
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{str}\NormalTok{(cv08_nolab)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    1963 obs. of  278 variables:
##  $ we_id   : num  36775330 36775340 36775420 36775440 36775450 ...
##   ..- attr(*, "value.labels")= Named num(0) 
##   .. ..- attr(*, "names")= chr(0) 
##  $ veilignr: num  8.11e+08 8.11e+08 8.11e+08 8.11e+08 8.11e+08 ...
##  $ lft1    : num  51 39 16 30 57 49 62 34 59 41 ...
##   ..- attr(*, "value.labels")= Named chr "99"
##   .. ..- attr(*, "names")= chr "Onbekend"
##  $ geslacht: chr  "M" "V" "V" "M" ...
##   ..- attr(*, "value.labels")= Named chr [1:3] "V       " "M       " "9       "
##   .. ..- attr(*, "names")= chr [1:3] "Vrouw" "Man" "Onbekend"
##  $ allochtn: num  0 0 1 0 0 1 0 1 0 0 ...
##   ..- attr(*, "value.labels")= Named chr [1:4] "9" "2" "1" "0"
##   .. ..- attr(*, "names")= chr [1:4] "Onbekend" "onbekend" "allochtoon" "geen allochtoon"
##  $ lft01   : num  50 38 15 29 56 48 61 33 58 40 ...
##   ..- attr(*, "value.labels")= Named chr [1:5] "125" "99" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:5] "125 jaar" "Onbekend" "twee jaar" "één jaar" ...
##  $ lftop   : num  51 39 16 29 57 49 62 34 59 41 ...
##   ..- attr(*, "value.labels")= Named chr [1:5] "125" "99" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:5] "125 jaar" "Onbekend" "twee jaar" "één jaar" ...
##  $ gewicht : num  8423 6244 13434 8997 8423 ...
##  $ var006n : num  6 8 3 8 6 2 2 5 5 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:11] "9999999999" "8" "7" "6" ...
##   .. ..- attr(*, "names")= chr [1:11] "Onbekend" "wo" "wo" "hbo" ...
##  $ v040    : num  2 1 2 1 2 2 1 1 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:6] "2" "1" "-2" "-3" ...
##   .. ..- attr(*, "names")= chr [1:6] "Nee" "Ja" "Weigert" "Weet niet" ...
##  $ var723  : num  -5 45 -5 20 -5 -5 40 32 30 20 ...
##   ..- attr(*, "value.labels")= Named chr [1:4] "-2" "-3" "-5" "-6"
##   .. ..- attr(*, "names")= chr [1:4] "Weigert" "Weet niet" "N.v.t." "Geen opgave"
##  $ var723a : num  -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 ...
##   ..- attr(*, "value.labels")= Named chr [1:8] "4" "3" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:8] "of om 30 uur of meer per week ?" "minder dan 30 uur," "minder dan 12 uur," "4 uur of minder per week," ...
##  $ v202n   : num  4 1 7 1 3 2 1 1 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "10" "8" "7" "6" ...
##   .. ..- attr(*, "names")= chr [1:9] "vrijwilliger" "anders" "scholier, student" "werkt <12 uur" ...
##  $ var1061a: num  1 2 2 2 2 2 2 2 2 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:6] "2" "1" "-2" "-3" ...
##   .. ..- attr(*, "names")= chr [1:6] "Nee" "Ja" "Weigert" "Weet niet" ...
##  $ var1061b: num  23 -5 -5 -5 -5 -5 -5 -5 -5 -5 ...
##   ..- attr(*, "value.labels")= Named chr [1:4] "-2" "-3" "-5" "-6"
##   .. ..- attr(*, "names")= chr [1:4] "Weigert" "Weet niet" "N.v.t." "Geen opgave"
##  $ var1062a: num  2 2 2 2 2 2 2 2 1 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:6] "2" "1" "-2" "-3" ...
##   .. ..- attr(*, "names")= chr [1:6] "Nee" "Ja" "Weigert" "Weet niet" ...
##  $ var1062b: num  -5 -5 -5 -5 -5 -5 -5 -5 3 -5 ...
##   ..- attr(*, "value.labels")= Named chr [1:4] "-2" "-3" "-5" "-6"
##   .. ..- attr(*, "names")= chr [1:4] "Weigert" "Weet niet" "N.v.t." "Geen opgave"
##  $ int137n : num  -5 3 -5 1 -5 1 2 3 3 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:8] "4" "3" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:8] "Niet van toepassing (niet noemen)" "of net zoveel tijd als nu?" "minder tijd," "meer tijd," ...
##  $ int138n : num  3 3 3 3 2 3 3 2 3 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:8] "4" "3" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:8] "Niet van toepassing (niet noemen)" "Net zoveel tijd als nu" "Minder tijd" "Meer tijd" ...
##  $ int139n : num  -5 3 -5 -5 -5 3 1 1 3 -5 ...
##   ..- attr(*, "value.labels")= Named chr [1:8] "4" "3" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:8] "Niet van toepassing (niet noemen)" "Net zoveel tijd als nu" "Minder tijd" "Meer tijd" ...
##  $ int140n : num  -5 3 3 3 1 3 1 1 3 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:8] "4" "3" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:8] "Niet van toepassing (niet noemen)" "of net zoveel tijd als nu?" "minder tijd," "meer tijd," ...
##  $ int141n : num  1 3 1 3 1 3 1 1 3 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:8] "4" "3" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:8] "Niet van toepassing (niet noemen)" "Net zoveel tijd als nu" "Minder tijd" "Meer tijd" ...
##  $ v401    : num  2 2 2 2 3 2 3 2 2 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "of zeer slecht?" "slecht," "gaat wel," "goed," ...
##  $ var1343 : num  3 3 3 3 2 3 3 3 3 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Nee" "Soms" "Ja" "Weigert" ...
##  $ var648  : num  3 1 3 4 3 3 3 4 3 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "of niet zo tevreden?" "tamelijk tevreden," "tevreden," "zeer tevreden," ...
##  $ var149  : num  2 1 -3 3 2 2 2 2 1 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:8] "4" "3" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:8] "Geen mening" "Niet tevreden" "Tamelijk tevreden" "Tevreden" ...
##  $ var058  : num  1 1 1 1 1 2 2 1 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:6] "2" "1" "-2" "-3" ...
##   .. ..- attr(*, "names")= chr [1:6] "Nee" "Ja" "Weigert" "Weet niet" ...
##  $ var059  : num  1 1 1 2 1 1 1 1 1 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:6] "2" "1" "-2" "-3" ...
##   .. ..- attr(*, "names")= chr [1:6] "Nee" "Ja" "Weigert" "Weet niet" ...
##  $ var064  : num  1 1 2 1 2 2 2 1 2 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:6] "2" "1" "-2" "-3" ...
##   .. ..- attr(*, "names")= chr [1:6] "Onvoldoende" "Voldoende" "Weigert" "Weet niet" ...
##  $ var365  : num  1 1 2 1 1 1 1 2 2 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:6] "2" "1" "-2" "-3" ...
##   .. ..- attr(*, "names")= chr [1:6] "Nee" "Ja" "Weigert" "Weet niet" ...
##  $ var065  : num  2 1 1 2 -3 1 2 2 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:6] "2" "1" "-2" "-3" ...
##   .. ..- attr(*, "names")= chr [1:6] "Welvaart houdt aan" "Voorziet crisis" "Weigert" "Weet niet" ...
##  $ var092  : num  2 -3 2 4 4 4 4 3 4 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "Geen mening" "of gaat achteruit?" "blijft ongeveer gelijk," "gedeeltelijk vooruit  gedeeltelijk achteruit," ...
##  $ var096  : num  3 3 2 3 3 1 2 2 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:10] "6" "5" "4" "3" ...
##   .. ..- attr(*, "names")= chr [1:10] "Geen mening" "Veel minder" "Een beetje minder" "Laten zoals nu" ...
##  $ int054  : num  4 -3 3 3 1 1 2 3 2 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:8] "4" "3" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:8] "Helemaal geen tegenstelling" "Niet zo groot" "Groot" "Zeer groot" ...
##  $ int055  : num  3 3 3 2 -3 1 2 3 3 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:8] "4" "3" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:8] "Helemaal geen tegenstelling" "Niet zo groot" "Groot" "Zeer groot" ...
##  $ int056  : num  2 2 3 3 2 1 1 3 2 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:8] "4" "3" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:8] "Helemaal geen tegenstelling" "Niet zo groot" "Groot" "Zeer groot" ...
##  $ int057  : num  2 3 2 2 1 2 3 3 2 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:8] "4" "3" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:8] "Helemaal geen tegenstelling" "Niet zo groot" "Groot" "Zeer groot" ...
##  $ int058  : num  3 3 2 2 -3 1 2 3 4 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:8] "4" "3" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:8] "Helemaal geen tegenstelling" "Niet zo groot" "Groot" "Zeer groot" ...
##  $ int059  : num  2 3 -3 3 3 1 1 2 4 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:8] "4" "3" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:8] "Helemaal geen tegenstelling" "Niet zo groot" "Groot" "Zeer groot" ...
##  $ int059a : num  3 2 2 2 3 1 2 2 3 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:8] "4" "3" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:8] "Helemaal geen tegenstelling" "Niet zo groot" "Groot" "Zeer groot" ...
##  $ var571  : num  2 3 3 2 2 2 2 3 2 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Dalen" "Gelijk blijven" "Stijgen" "Weigert" ...
##  $ var572  : num  -5 1 3 -5 -5 -5 -5 3 -5 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Een klein beetje" "Enigszins" "Sterk" "Weigert" ...
##  $ var573  : num  1 2 3 2 1 1 1 1 2 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Dalen" "Gelijk blijven" "Stijgen" "Weigert" ...
##  $ var574  : num  3 -5 3 -5 2 3 3 2 -5 -5 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Een klein beetje" "Enigszins" "Sterk" "Weigert" ...
##  $ var576  : num  5 2 3 4 5 2 5 4 4 5 ...
##   ..- attr(*, "value.labels")= Named chr [1:10] "6" "5" "4" "3" ...
##   .. ..- attr(*, "names")= chr [1:10] "Geen mening" "of sterk mee oneens?" "mee oneens," "noch mee eens, noch mee oneens," ...
##  $ var153  : num  3 1 1 1 1 1 1 1 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Geen oordeel" "Ontevreden" "Tevreden" "Weigert" ...
##  $ var154  : num  3 2 2 2 3 2 3 2 3 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Onvoldoende" "Voldoende" "Te goed (niet noemen)" "Weigert" ...
##  $ var155  : num  2 2 2 3 3 3 3 -3 2 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Onvoldoende" "Voldoende" "Te goed (niet noemen)" "Weigert" ...
##  $ var156  : num  3 2 2 2 2 -3 3 2 2 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Onvoldoende" "Voldoende" "Te goed (niet noemen)" "Weigert" ...
##  $ var157  : num  2 -3 2 2 2 3 3 -3 2 -3 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Onvoldoende" "Voldoende" "Te goed (niet noemen)" "Weigert" ...
##  $ var157a : num  3 -3 2 2 3 3 3 2 2 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Onvoldoende" "Voldoende" "Te goed (niet noemen)" "Weigert" ...
##  $ var154a : num  -3 -3 2 2 2 2 2 2 2 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Onvoldoende" "Voldoende" "Te goed (niet noemen)" "Weigert" ...
##  $ var164  : num  2 2 2 1 1 1 1 2 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:8] "4" "3" "2" "1" ...
##   .. ..- attr(*, "names")= chr [1:8] "Geen mening (niet noemen)" "Te klein" "Ongeveer juist" "Te groot" ...
##  $ var165  : num  3 3 3 4 5 5 4 4 5 4 ...
##   ..- attr(*, "value.labels")= Named chr [1:10] "6" "5" "4" "3" ...
##   .. ..- attr(*, "names")= chr [1:10] "Geen oordeel (niet noemen)" "Veel kleiner" "Een beetje kleiner" "Blijven zoals nu" ...
##  $ var166  : num  3 3 4 3 5 5 4 3 4 4 ...
##   ..- attr(*, "value.labels")= Named chr [1:10] "6" "5" "4" "3" ...
##   .. ..- attr(*, "names")= chr [1:10] "Geen oordeel (niet noemen)" "Veel kleiner" "Een beetje kleiner" "Blijven zoals nu" ...
##  $ var179  : num  1 1 2 1 1 1 1 1 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:6] "2" "1" "-2" "-3" ...
##   .. ..- attr(*, "names")= chr [1:6] "Nee" "Ja" "Weigert" "Weet niet" ...
##  $ var180  : num  1 1 1 2 1 2 2 1 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:6] "2" "1" "-2" "-3" ...
##   .. ..- attr(*, "names")= chr [1:6] "Nee" "Ja" "Weigert" "Weet niet" ...
##  $ var184  : num  1 1 2 1 2 1 1 1 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:6] "2" "1" "-2" "-3" ...
##   .. ..- attr(*, "names")= chr [1:6] "Nee" "Ja" "Weigert" "Weet niet" ...
##  $ var185  : num  2 1 1 1 2 1 1 1 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:6] "2" "1" "-2" "-3" ...
##   .. ..- attr(*, "names")= chr [1:6] "Nee" "Ja" "Weigert" "Weet niet" ...
##  $ var198a : num  2 1 1 1 1 1 2 2 2 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:6] "2" "1" "-2" "-3" ...
##   .. ..- attr(*, "names")= chr [1:6] "Nee" "Ja" "Weigert" "Weet niet" ...
##  $ var198  : num  -5 3 5 3 1 1 -5 -5 -5 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:11] "7" "6" "5" "4" ...
##   .. ..- attr(*, "names")= chr [1:11] "Ander geloof" "Boeddhistisch" "Islamitisch" "Hindoe" ...
##  $ var201a : num  2 1 1 2 2 1 2 2 2 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:6] "2" "1" "-2" "-3" ...
##   .. ..- attr(*, "names")= chr [1:6] "Nee" "Ja" "Weigert" "Weet niet" ...
##  $ var201b : num  -5 2 4 -5 -5 1 -5 -5 -5 -5 ...
##   ..- attr(*, "value.labels")= Named chr [1:10] "6" "5" "4" "3" ...
##   .. ..- attr(*, "names")= chr [1:10] "Ander kerkgenootschap of levensbeschouwelijke groepering" "Boeddhistisch" "Islamitisch" "Hindoe" ...
##  $ var204  : num  5 4 5 4 5 4 5 5 3 5 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "of nooit?" "minder dan eenmaal per maand," "eens per maand," "eens per 2 weken," ...
##  $ int257  : num  7 3 3 4 6 2 3 5 3 7 ...
##   ..- attr(*, "value.labels")= Named chr [1:11] "7" "6" "5" "4" ...
##   .. ..- attr(*, "names")= chr [1:11] "Buitengewoon ongelovig" "Erg ongelovig" "Enigszins ongelovig" "Noch gelovig, noch ongelovig" ...
##  $ var211  : num  3 2 3 3 3 1 3 2 2 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Nee" "Gedeeltelijk" "Ja" "Weigert" ...
##  $ var223  : num  1 2 1 3 1 1 1 3 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Hangt ervan af" "Moeten niet los van elkaar staan" "Moeten los van elkaar staan" "Weigert" ...
##  $ var1320 : num  1 2 2 2 2 2 2 3 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "of sterk mee oneens?" "enigszins mee oneens," "niet mee eens, niet mee oneens," "enigszins mee eens," ...
##  $ var1321 : num  1 4 2 2 4 2 4 4 2 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "of sterk mee oneens?" "enigszins mee oneens," "niet mee eens, niet mee oneens," "enigszins mee eens," ...
##  $ var1322 : num  3 3 2 2 3 1 1 2 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "of helemaal niet voor u?" "gedeeltelijk voor u," "helemaal voor u," "Weigert" ...
##  $ var1323 : num  3 3 2 3 3 2 3 3 3 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "of zelden of nooit?" "soms," "vaak," "Weigert" ...
##  $ var1324 : num  3 3 2 3 3 3 3 3 3 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Zelden of nooit?" "Soms," "Vaak" "Weigert" ...
##  $ var1325 : num  3 3 3 3 3 2 3 3 3 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "of zelden of nooit?" "soms," "vaak," "Weigert" ...
##  $ var1326 : num  3 3 3 3 3 3 3 3 3 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Zelden of nooit?" "Soms," "Vaak" "Weigert" ...
##  $ var1327 : num  3 3 2 3 3 2 3 3 2 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "of zelden of nooit?" "soms," "vaak," "Weigert" ...
##  $ var1328 : num  3 3 3 3 3 3 3 3 3 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:7] "3" "2" "1" "-2" ...
##   .. ..- attr(*, "names")= chr [1:7] "Zelden of nooit?" "Soms," "Vaak" "Weigert" ...
##  $ var229  : num  3 3 3 8 3 3 3 2 3 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:12] "8" "7" "6" "5" ...
##   .. ..- attr(*, "names")= chr [1:12] "Veel vrienden en kennissen" "Prettig werk" "Een sterk geloof" "Een goed huwelijksleven" ...
##  $ int218  : num  2 2 3 3 2 4 3 3 4 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "Helemaal geen vertrouwen" "Zeer weinig vertrouwen" "Enig vertrouwen" "Veel vertrouwen" ...
##  $ int219  : num  2 2 3 3 3 2 2 2 3 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "Helemaal geen vertrouwen" "Zeer weinig vertrouwen" "Enig vertrouwen" "Veel vertrouwen" ...
##  $ int221  : num  5 2 5 3 3 2 3 3 2 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "Helemaal geen vertrouwen" "Zeer weinig vertrouwen" "Enig vertrouwen" "Veel vertrouwen" ...
##  $ int222  : num  2 2 3 2 4 3 3 2 4 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "Helemaal geen vertrouwen" "Zeer weinig vertrouwen" "Enig vertrouwen" "Veel vertrouwen" ...
##  $ int223  : num  3 3 1 2 3 2 3 2 1 4 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "Helemaal geen vertrouwen" "Zeer weinig vertrouwen" "Enig vertrouwen" "Veel vertrouwen" ...
##  $ int710  : num  4 2 1 3 3 2 3 3 2 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "Helemaal geen vertrouwen" "Zeer weinig vertrouwen" "Enig vertrouwen" "Veel vertrouwen" ...
##  $ int711  : num  4 2 3 2 3 5 3 2 1 4 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "Helemaal geen vertrouwen" "Zeer weinig vertrouwen" "Enig vertrouwen" "Veel vertrouwen" ...
##  $ int712  : num  2 3 3 3 3 2 4 2 4 4 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "Helemaal geen vertrouwen" "Zeer weinig vertrouwen" "Enig vertrouwen" "Veel vertrouwen" ...
##  $ int713  : num  3 3 -3 3 2 4 4 2 4 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "Helemaal geen vertrouwen" "Zeer weinig vertrouwen" "Enig vertrouwen" "Veel vertrouwen" ...
##  $ int714  : num  3 2 -3 3 3 3 4 3 4 4 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "Helemaal geen vertrouwen" "Zeer weinig vertrouwen" "Enig vertrouwen" "Veel vertrouwen" ...
##  $ int715  : num  3 2 5 2 2 3 5 3 3 4 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "Helemaal geen vertrouwen" "Zeer weinig vertrouwen" "Enig vertrouwen" "Veel vertrouwen" ...
##  $ int716  : num  5 3 3 3 2 2 3 3 3 3 ...
##   ..- attr(*, "value.labels")= Named chr [1:9] "5" "4" "3" "2" ...
##   .. ..- attr(*, "names")= chr [1:9] "Helemaal geen vertrouwen" "Zeer weinig vertrouwen" "Enig vertrouwen" "Veel vertrouwen" ...
##  $ var433  : num  2 2 3 3 3 1 5 2 3 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:10] "6" "5" "4" "3" ...
##   .. ..- attr(*, "names")= chr [1:10] "Geen mening" "Helemaal niet mee eens" "Eigenlijk niet mee eens" "Noch mee eens, noch mee oneens" ...
##  $ var439  : num  2 1 5 4 -3 1 1 4 1 5 ...
##   ..- attr(*, "value.labels")= Named chr [1:10] "6" "5" "4" "3" ...
##   .. ..- attr(*, "names")= chr [1:10] "Geen mening" "Helemaal niet mee eens" "Eigenlijk niet mee eens" "Noch mee eens, noch mee oneens" ...
##  $ var1329 : num  2 4 2 4 2 1 2 1 1 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:10] "6" "5" "4" "3" ...
##   .. ..- attr(*, "names")= chr [1:10] "Geen mening" "Helemaal niet mee eens" "Eigenlijk niet mee eens" "Noch mee eens, noch mee oneens" ...
##  $ var1330 : num  5 5 4 3 5 1 1 4 1 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:10] "6" "5" "4" "3" ...
##   .. ..- attr(*, "names")= chr [1:10] "Geen mening" "Helemaal niet mee eens" "Eigenlijk niet mee eens" "Noch mee eens, noch mee oneens" ...
##  $ var445  : num  4 5 2 2 4 4 5 2 3 2 ...
##   ..- attr(*, "value.labels")= Named chr [1:10] "6" "5" "4" "3" ...
##   .. ..- attr(*, "names")= chr [1:10] "Geen mening" "Helemaal niet mee eens" "Eigenlijk niet mee eens" "Noch mee eens, noch mee oneens" ...
##  $ var446  : num  3 5 1 4 2 1 2 3 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:10] "6" "5" "4" "3" ...
##   .. ..- attr(*, "names")= chr [1:10] "Geen mening" "Helemaal niet mee eens" "Eigenlijk niet mee eens" "Noch mee eens, noch mee oneens" ...
##  $ var447  : num  3 5 1 4 2 1 4 3 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:10] "6" "5" "4" "3" ...
##   .. ..- attr(*, "names")= chr [1:10] "Geen mening" "Helemaal niet mee eens" "Eigenlijk niet mee eens" "Noch mee eens, noch mee oneens" ...
##  $ var451  : num  5 5 4 4 4 1 4 5 5 4 ...
##   ..- attr(*, "value.labels")= Named chr [1:10] "6" "5" "4" "3" ...
##   .. ..- attr(*, "names")= chr [1:10] "Geen mening" "Helemaal niet mee eens" "Eigenlijk niet mee eens" "Noch mee eens, noch mee oneens" ...
##  $ var452  : num  2 3 2 2 2 1 4 3 1 1 ...
##   ..- attr(*, "value.labels")= Named chr [1:10] "6" "5" "4" "3" ...
##   .. ..- attr(*, "names")= chr [1:10] "Geen mening" "Helemaal niet mee eens" "Eigenlijk niet mee eens" "Noch mee eens, noch mee oneens" ...
##  $ var1316 : num  5 5 4 4 5 1 2 2 1 5 ...
##   ..- attr(*, "value.labels")= Named chr [1:10] "6" "5" "4" "3" ...
##   .. ..- attr(*, "names")= chr [1:10] "Geen mening" "Helemaal niet mee eens" "Eigenlijk niet mee eens" "Noch mee eens, noch mee oneens" ...
##   [list output truncated]
##  - attr(*, "variable.labels")= Named chr [1:278] "WE_ID" "veilignummer" "Leeftijd op 1-jan-2009" "Geslacht hhpersoon (GBA)" ...
##   ..- attr(*, "names")= chr [1:278] "we_id" "veilignr" "lft1" "geslacht" ...
##  - attr(*, "codepage")= int 1252
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{str}\NormalTok{(cv08_haven)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## tibble [1,963 x 278] (S3: tbl_df/tbl/data.frame)
##  $ we_id   : dbl+lbl [1:1963] 36775330, 36775340, 36775420, 36775440, 36775450, 36775460, 36775480, 367...
##    ..@ label        : chr "WE_ID"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:2] 1e+10 1e+10
##    .. ..- attr(*, "names")= chr [1:2] "Refusal" "Don't Know"
##  $ veilignr: num [1:1963] 8.11e+08 8.11e+08 8.11e+08 8.11e+08 8.11e+08 ...
##   ..- attr(*, "label")= chr "veilignummer"
##   ..- attr(*, "format.spss")= chr "F10.0"
##   ..- attr(*, "display_width")= int 12
##  $ lft1    : dbl+lbl [1:1963] 51, 39, 16, 30, 57, 49, 62, 34, 59, 41, 25, 43, 74, 17, 23, 32, 51, 66, 6...
##    ..@ label        : chr "Leeftijd op 1-jan-2009"
##    ..@ format.spss  : chr "F8.0"
##    ..@ display_width: int 10
##    ..@ labels       : Named num 99
##    .. ..- attr(*, "names")= chr "Onbekend"
##  $ geslacht: chr+lbl [1:1963] M, V, V, M, M, V, M, V, M, M, M, V, V, M, M, V, M, M, V, M, V, M, V, M, V...
##    ..@ label        : chr "Geslacht hhpersoon (GBA)"
##    ..@ format.spss  : chr "A1"
##    ..@ display_width: int 10
##    ..@ labels       : Named chr [1:3] "9" "M" "V"
##    .. ..- attr(*, "names")= chr [1:3] "Onbekend" "Man" "Vrouw"
##  $ allochtn: dbl+lbl [1:1963] 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0...
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:4] 0 1 2 9
##    .. ..- attr(*, "names")= chr [1:4] "geen allochtoon" "allochtoon" "onbekend" "Onbekend"
##  $ lft01   : dbl+lbl [1:1963] 50, 38, 15, 29, 56, 48, 61, 33, 58, 40, 24, 42, 73, 16, 22, 31, 50, 65, 6...
##    ..@ label        : chr "Leeftijd OP op 1 jan. v.h. onderzoekjaar"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:5] 0 1 2 99 125
##    .. ..- attr(*, "names")= chr [1:5] "< één jaar" "één jaar" "twee jaar" "Onbekend" ...
##  $ lftop   : dbl+lbl [1:1963] 51, 39, 16, 29, 57, 49, 62, 34, 59, 41, 25, 43, 74, 17, 22, 32, 51, 66, 6...
##    ..@ label        : chr "Leeftijd OP op datum interview"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:5] 0 1 2 99 125
##    .. ..- attr(*, "names")= chr [1:5] "< één jaar" "één jaar" "twee jaar" "Onbekend" ...
##  $ gewicht : num [1:1963] 8423 6244 13434 8997 8423 ...
##   ..- attr(*, "label")= chr "Persoonsgewicht eindres30"
##   ..- attr(*, "format.spss")= chr "F8.2"
##   ..- attr(*, "display_width")= int 10
##  $ var006n : dbl+lbl [1:1963] 6, 8, 3, 8, 6, 2, 2, 5, 5, 1, 1, 3, 2, 1, 1, 5, 6, 3, 1, 5, 6, 2, 5, 6, 1...
##    ..@ label        : chr "Voltooid opleidingsniveau (uitgebreid) OP, 12-14 jarigen niet standaard op bas.ondw."
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:11] -3 -1 1 2 3 4 5 6 7 8 ...
##    .. ..- attr(*, "names")= chr [1:11] "onbekend" "OP < 12 jr  of volgt actueel bas.ondw." "basisonderwijs" "vmbo" ...
##  $ v040    : dbl+lbl [1:1963] 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2...
##    ..@ label        : chr "Betaald werk?"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:6] -6 -5 -3 -2 1 2
##    .. ..- attr(*, "names")= chr [1:6] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var723  : dbl+lbl [1:1963] -5, 45, -5, 20, -5, -5, 40, 32, 30, 20, 38, 30, -5, -5, 18, 20, 40, -5, -...
##    ..@ label        : chr "Uren werk per week"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:4] -6 -5 -3 -2
##    .. ..- attr(*, "names")= chr [1:4] "Geen opgave" "N.v.t." "Weet niet" "Weigert"
##  $ var723a : dbl+lbl [1:1963] -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -...
##    ..@ label        : chr "Categorie: uren werk per week"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##    .. ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ v202n   : dbl+lbl [1:1963] 4, 1, 7, 1, 3, 2, 1, 1, 1, 1, 1, 1, 5, 7, 1, 1, 1, 5, 2, 1, 2, 1, 5, 1, 5...
##    ..@ label        : chr "positie werkkring (nieuw)"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] 1 2 3 4 5 6 7 8 10
##    .. ..- attr(*, "names")= chr [1:9] "werkt >12 uur" "eigen huishouden" "werkloos" "arbeidsongeschikt" ...
##  $ var1061a: dbl+lbl [1:1963] 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2...
##    ..@ label        : chr "(16) Verricht u vrijwilligerwerk"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:6] -6 -5 -3 -2 1 2
##    .. ..- attr(*, "names")= chr [1:6] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var1061b: dbl+lbl [1:1963] 23, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5,  3,  5, -5, -5,  1, -5, -5, -...
##    ..@ label        : chr "(16) Hoeveel uur per week vrijwilligerwerk?"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:4] -6 -5 -3 -2
##    .. ..- attr(*, "names")= chr [1:4] "Geen opgave" "N.v.t." "Weet niet" "Weigert"
##  $ var1062a: dbl+lbl [1:1963] 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2...
##    ..@ label        : chr "(17) Kosteloos hulp aan zieke of gehandicapte familieleden, kennissen of buren?"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:6] -6 -5 -3 -2 1 2
##    .. ..- attr(*, "names")= chr [1:6] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var1062b: dbl+lbl [1:1963] -5, -5, -5, -5, -5, -5, -5, -5,  3, -5, -5,  2,  5, -5, -5,  1, -5, -5, -...
##    ..@ label        : chr "(17) Hoeveel uur per week kosteloos hulp?"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:4] -6 -5 -3 -2
##    .. ..- attr(*, "names")= chr [1:4] "Geen opgave" "N.v.t." "Weet niet" "Weigert"
##  $ int137n : dbl+lbl [1:1963] -5,  3, -5,  1, -5,  1,  2,  3,  3,  2,  1,  3, -5, -5,  1,  2,  2,  1, -...
##    ..@ label        : chr "S003 Gewenste tijd betaald werk"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##    .. ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int138n : dbl+lbl [1:1963]  3,  3,  3,  3,  2,  3,  3,  2,  3,  3,  3,  2,  3, -5,  3,  2,  1,  3,  ...
##    ..@ label        : chr "S003 Gewenste tijd huishoudelijk werk"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##    .. ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int139n : dbl+lbl [1:1963] -5,  3, -5, -5, -5,  3,  1,  1,  3, -5,  3,  1,  3, -5, -5,  1,  1,  1,  ...
##    ..@ label        : chr "S003 Gewenste tijd gezin"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##    .. ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int140n : dbl+lbl [1:1963] -5,  3,  3,  3,  1,  3,  1,  1,  3,  3,  3,  1,  3, -5,  1,  1,  3,  3,  ...
##    ..@ label        : chr "S003 Gewenste tijd vrienden"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##    .. ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int141n : dbl+lbl [1:1963]  1,  3,  1,  3,  1,  3,  1,  1,  3,  1,  3,  3,  3,  3,  3,  1,  1, -5,  ...
##    ..@ label        : chr "S003 Gewenste tijd vrijetijds-activiteit"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##    .. ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ v401    : dbl+lbl [1:1963] 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 1, 2, 3, 1, 2, 1...
##    ..@ label        : chr "Niveau gezondheid"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var1343 : dbl+lbl [1:1963] 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3...
##    ..@ label        : chr "(199) Ik voel me van andere mensen ge‹soleerd."
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var648  : dbl+lbl [1:1963] 3, 1, 3, 4, 3, 3, 3, 4, 3, 3, 1, 2, 3, 3, 3, 2, 3, 5, 3, 3, 3, 3, 2, 1, 3...
##    ..@ label        : chr "Tevredenheid leven"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var149  : dbl+lbl [1:1963]  2,  1, -3,  3,  2,  2,  2,  2,  1,  2,  1,  2,  2, -3,  2,  1,  2,  3,  ...
##    ..@ label        : chr "Tevredenheid inkomen"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##    .. ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var058  : dbl+lbl [1:1963]  1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  ...
##    ..@ label        : chr "Welvarendheid Nederland"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:6] -6 -5 -3 -2 1 2
##    .. ..- attr(*, "names")= chr [1:6] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var059  : dbl+lbl [1:1963] 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1...
##    ..@ label        : chr "Welvarendheid in eigen huishouden"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:6] -6 -5 -3 -2 1 2
##    .. ..- attr(*, "names")= chr [1:6] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var064  : dbl+lbl [1:1963]  1,  1,  2,  1,  2,  2,  2,  1,  2,  2,  2,  1,  1,  1,  2,  1,  1,  2,  ...
##    ..@ label        : chr "Inzet regering vergroten uw welvaart"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:6] -6 -5 -3 -2 1 2
##    .. ..- attr(*, "names")= chr [1:6] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var365  : dbl+lbl [1:1963]  1,  1,  2,  1,  1,  1,  1,  2,  2,  2,  1,  2,  1,  1,  1,  2,  2,  2,  ...
##    ..@ label        : chr "financieel een onbekommerde oude dag"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:6] -6 -5 -3 -2 1 2
##    .. ..- attr(*, "names")= chr [1:6] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var065  : dbl+lbl [1:1963]  2,  1,  1,  2, -3,  1,  2,  2,  1,  1,  2,  2,  1,  1,  2,  1,  1,  1,  ...
##    ..@ label        : chr "Verwachting crisis met veel werklozen"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:6] -6 -5 -3 -2 1 2
##    .. ..- attr(*, "names")= chr [1:6] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var092  : dbl+lbl [1:1963]  2, -3,  2,  4,  4,  4,  4,  3,  4,  3,  3,  4,  4,  4,  4,  4,  4,  4,  ...
##    ..@ label        : chr "Ontwikkeling opvattingen gedrag en zeden"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var096  : dbl+lbl [1:1963] 3, 3, 2, 3, 3, 1, 2, 2, 1, 1, 2, 4, 3, 1, 2, 3, 2, 2, 1, 1, 2, 1, 3, 2, 1...
##    ..@ label        : chr "Niveau geld voor openbare voorzieningen"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6
##    .. ..- attr(*, "names")= chr [1:10] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int054  : dbl+lbl [1:1963]  4, -3,  3,  3,  1,  1,  2,  3,  2,  1,  1,  1,  2,  2,  2,  2,  3,  1,  ...
##    ..@ label        : chr "Niveau tegenstelling arm en rijk"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##    .. ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int055  : dbl+lbl [1:1963]  3,  3,  3,  2, -3,  1,  2,  3,  3,  2,  2,  3,  3,  3,  3,  2,  3,  2,  ...
##    ..@ label        : chr "Tegenstelling arbeidersklasse en middenklasse"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##    .. ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int056  : dbl+lbl [1:1963]  2,  2,  3,  3,  2,  1,  1,  3,  2,  3,  2,  3,  2,  2,  2,  2,  2,  1,  ...
##    ..@ label        : chr "Tegenstelling werklozen en werkenden"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##    .. ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int057  : dbl+lbl [1:1963]  2,  3,  2,  2,  1,  2,  3,  3,  2,  1,  1,  1,  2,  2,  2,  3,  2,  1,  ...
##    ..@ label        : chr "Tegenstelling werkgevers en werknemers"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##    .. ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int058  : dbl+lbl [1:1963]  3,  3,  2,  2, -3,  1,  2,  3,  4,  2, -3,  1,  2,  3,  2, -3,  3, -3, -...
##    ..@ label        : chr "Tegenstelling platteland en stadsmensen"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##    .. ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int059  : dbl+lbl [1:1963]  2,  3, -3,  3,  3,  1,  1,  2,  4,  2,  1,  1,  2,  2,  2,  2,  2,  2,  ...
##    ..@ label        : chr "Tegenstelling jongeren en ouderen"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##    .. ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int059a : dbl+lbl [1:1963]  3,  2,  2,  2,  3,  1,  2,  2,  3,  2, -3,  1,  2,  2,  2,  2,  2, -3,  ...
##    ..@ label        : chr "Tegenstelling allochtonen en autochtonen"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##    .. ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var571  : dbl+lbl [1:1963]  2,  3,  3,  2,  2,  2,  2,  3,  2,  3,  3,  2,  3,  3,  3,  3,  1,  3,  ...
##    ..@ label        : chr "Verwachting toekomst sociale uitkeringen"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var572  : dbl+lbl [1:1963] -5,  1,  3, -5, -5, -5, -5,  3, -5,  1,  2, -5,  1,  2,  3,  1,  2,  2, -...
##    ..@ label        : chr "Verwachting niveau sociale uitkeringen"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var573  : dbl+lbl [1:1963] 1, 2, 3, 2, 1, 1, 1, 1, 2, 2, 2, 1, 3, 3, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1...
##    ..@ label        : chr "Niveau uitkeringen in huidige economie 1"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var574  : dbl+lbl [1:1963]  3, -5,  3, -5,  2,  3,  3,  2, -5, -5, -5,  1,  3,  2, -5, -5, -5,  3,  ...
##    ..@ label        : chr "Niveau uitkeringen in huidige economie 2"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var576  : dbl+lbl [1:1963] 5, 2, 3, 4, 5, 2, 5, 4, 4, 5, 4, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 2, 2, 2, 4...
##    ..@ label        : chr "Mening toekomst minder sociale zekerheid"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6
##    .. ..- attr(*, "names")= chr [1:10] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var153  : dbl+lbl [1:1963] 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 3, 1, 1, 1, 2...
##    ..@ label        : chr "Tevredenheid sociale voorzieningen"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var154  : dbl+lbl [1:1963]  3,  2,  2,  2,  3,  2,  3,  2,  3,  3, -3,  3,  2,  2, -3,  2,  3,  3,  ...
##    ..@ label        : chr "Niveau Algemene Ouderdomswet (AOW)"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var155  : dbl+lbl [1:1963]  2,  2,  2,  3,  3,  3,  3, -3,  2,  2, -3,  3,  3,  3,  2,  3,  2,  3, -...
##    ..@ label        : chr "Oordeel Wet Werk en Bijstand"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var156  : dbl+lbl [1:1963]  3,  2,  2,  2,  2, -3,  3,  2,  2,  2, -3,  1,  3,  2, -3,  2,  2,  3,  ...
##    ..@ label        : chr "Oordeel Werkloosheidswet (WW)."
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var157  : dbl+lbl [1:1963]  2, -3,  2,  2,  2,  3,  3, -3,  2, -3, -3,  3,  3,  3, -3, -3,  3,  3,  ...
##    ..@ label        : chr "Oordeel Algemene Nabestaandenwet (ANW)."
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var157a : dbl+lbl [1:1963]  3, -3,  2,  2,  3,  3,  3,  2,  2,  2,  3,  1,  3,  3, -3,  3,  2,  3,  ...
##    ..@ label        : chr "Oordeel Arbeidsongeschiktheidswet."
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var154a : dbl+lbl [1:1963] -3, -3,  2,  2,  2,  2,  2,  2,  2,  2,  3,  2,  3,  2, -3,  2,  2, -3, -...
##    ..@ label        : chr "Oordeel Ziektewet."
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var164  : dbl+lbl [1:1963] 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1...
##    ..@ label        : chr "Mate verschil tussen inkomens in NL"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##    .. ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var165  : dbl+lbl [1:1963] 3, 3, 3, 4, 5, 5, 4, 4, 5, 4, 4, 5, 5, 1, 4, 2, 4, 5, 1, 4, 5, 4, 4, 3, 5...
##    ..@ label        : chr "Wens vergroten verschil inkomens"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6
##    .. ..- attr(*, "names")= chr [1:10] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var166  : dbl+lbl [1:1963]  3,  3,  4,  3,  5,  5,  4,  3,  4,  4,  3,  4,  5,  3,  3,  3,  4,  3,  ...
##    ..@ label        : chr "Wens vergroten verschil bezit"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6
##    .. ..- attr(*, "names")= chr [1:10] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var179  : dbl+lbl [1:1963] 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...
##    ..@ label        : chr "M050 Vrij:om te demonstreren"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:6] -6 -5 -3 -2 1 2
##    .. ..- attr(*, "names")= chr [1:6] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var180  : dbl+lbl [1:1963] 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2...
##    ..@ label        : chr "M051 Vrij:openlijk kritiek koningshuis"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:6] -6 -5 -3 -2 1 2
##    .. ..- attr(*, "names")= chr [1:6] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var184  : dbl+lbl [1:1963] 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1...
##    ..@ label        : chr "M054 Vrij:openb schrijven wat men wil"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:6] -6 -5 -3 -2 1 2
##    .. ..- attr(*, "names")= chr [1:6] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var185  : dbl+lbl [1:1963] 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1...
##    ..@ label        : chr "M054 Vrij:openb zeggen wat men wil"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:6] -6 -5 -3 -2 1 2
##    .. ..- attr(*, "names")= chr [1:6] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var198a : dbl+lbl [1:1963] 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1...
##    ..@ label        : chr "Opgevoed met bepaald geloof"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:6] -6 -5 -3 -2 1 2
##    .. ..- attr(*, "names")= chr [1:6] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var198  : dbl+lbl [1:1963] -5,  3,  5,  3,  1,  1, -5, -5, -5,  3,  1, -5,  3,  2, -5,  2,  1,  2,  ...
##    ..@ label        : chr "Geloof opgevoed"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:11] -6 -5 -3 -2 1 2 3 4 5 6 ...
##    .. ..- attr(*, "names")= chr [1:11] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var201a : dbl+lbl [1:1963] 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2...
##    ..@ label        : chr "Rekent zich tot kerkgenootschap"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:6] -6 -5 -3 -2 1 2
##    .. ..- attr(*, "names")= chr [1:6] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var201b : dbl+lbl [1:1963] -5,  2,  4, -5, -5,  1, -5, -5, -5, -5,  1, -5,  2,  2, -5,  6, -5, -5, -...
##    ..@ label        : chr "Welk kerkgenootschap is dat?"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6
##    .. ..- attr(*, "names")= chr [1:10] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var204  : dbl+lbl [1:1963] 5, 4, 5, 4, 5, 4, 5, 5, 3, 5, 4, 5, 1, 1, 5, 1, 5, 5, 5, 5, 1, 5, 5, 5, 5...
##    ..@ label        : chr "Aantal bezoeken kerk afgelopen half jaar"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int257  : dbl+lbl [1:1963] 7, 3, 3, 4, 6, 2, 3, 5, 3, 7, 4, 7, 2, 2, 3, 2, 3, 2, 4, 7, 2, 4, 6, 7, 4...
##    ..@ label        : chr "Mate gelovigheid"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:11] -6 -5 -3 -2 1 2 3 4 5 6 ...
##    .. ..- attr(*, "names")= chr [1:11] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var211  : dbl+lbl [1:1963]  3,  2,  3,  3,  3,  1,  3,  2,  2,  3, -3,  3,  1,  1,  3,  1,  1,  3,  ...
##    ..@ label        : chr "M069 Ziet bijbel als het woord van God"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var223  : dbl+lbl [1:1963] 1, 2, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1...
##    ..@ label        : chr "M068 Politiek los van godsdienst"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var1320 : dbl+lbl [1:1963]  1,  2,  2,  2,  2,  2,  2,  3,  1,  1,  2,  1,  2,  1,  2,  1,  2,  1,  ...
##    ..@ label        : chr "(54) Zin van leven innerlijke ervaring en ontwikkeling eigen vermogens."
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var1321 : dbl+lbl [1:1963] 1, 4, 2, 2, 4, 2, 4, 4, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 4, 2, 5, 2, 2, 4, 1...
##    ..@ label        : chr "(55) Bij beslissingen afgaan op intu‹tie en gevoel."
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var1322 : dbl+lbl [1:1963]  3,  3,  2,  2,  3,  1,  1,  2,  1,  1,  2,  3,  2,  2,  3,  2,  3,  1,  ...
##    ..@ label        : chr "(56) Religie zoek ik zelf bijeen"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var1323 : dbl+lbl [1:1963] 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3...
##    ..@ label        : chr "(57) Praten of mailen over spiritualiteit"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var1324 : dbl+lbl [1:1963] 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3...
##    ..@ label        : chr "(58) Meedoen gespreksgroep over spiritueel onderwerp?"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var1325 : dbl+lbl [1:1963] 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3...
##    ..@ label        : chr "(59) Op internet kijken naar informatie over spiritualiteit"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var1326 : dbl+lbl [1:1963] 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3...
##    ..@ label        : chr "(60) Bezoek beurs etc over spirituele onderwerpen?"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var1327 : dbl+lbl [1:1963] 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3...
##    ..@ label        : chr "(61) Tijdschriften of boeken lezen over spirituele onderwerpen"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var1328 : dbl+lbl [1:1963] 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3...
##    ..@ label        : chr "(62) Deelnemen aan cursus, gericht op spiritualiteit?"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:7] -6 -5 -3 -2 1 2 3
##    .. ..- attr(*, "names")= chr [1:7] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var229  : dbl+lbl [1:1963] 3, 3, 3, 8, 3, 3, 3, 2, 3, 3, 3, 5, 3, 2, 7, 6, 2, 3, 3, 3, 6, 3, 3, 2, 8...
##    ..@ label        : chr "M064 Allerbelangrijkste in het leven"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:12] -6 -5 -3 -2 1 2 3 4 5 6 ...
##    .. ..- attr(*, "names")= chr [1:12] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int218  : dbl+lbl [1:1963] 2, 2, 3, 3, 2, 4, 3, 3, 4, 3, 3, 2, 2, 3, 4, 2, 4, 4, 5, 4, 3, 3, 3, 4, 2...
##    ..@ label        : chr "Mate vertrouwen in regering"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int219  : dbl+lbl [1:1963]  2,  2,  3,  3,  3,  2,  2,  2,  3,  3,  3,  3,  2,  3,  3,  2,  3,  4, -...
##    ..@ label        : chr "Mate vertrouwen in bedrijfsleven"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int221  : dbl+lbl [1:1963]  5,  2,  5,  3,  3,  2,  3,  3,  2,  3,  3,  5,  2,  2,  4,  3,  3, -3, -...
##    ..@ label        : chr "Mate vertrouwen kerken/reli organisaties"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int222  : dbl+lbl [1:1963]  2,  2,  3,  2,  4,  3,  3,  2,  4,  3,  2,  4,  2,  2,  4,  3,  2,  4,  ...
##    ..@ label        : chr "Mate vertrouwen in rechtspraak"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int223  : dbl+lbl [1:1963]  3,  3,  1,  2,  3,  2,  3,  2,  1,  4,  2,  1,  2,  2,  3,  3,  3,  3, -...
##    ..@ label        : chr "Mate vertrouwen in onderwijs"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int710  : dbl+lbl [1:1963] 4, 2, 1, 3, 3, 2, 3, 3, 2, 3, 2, 1, 2, 2, 3, 3, 2, 3, 5, 2, 3, 2, 3, 2, 2...
##    ..@ label        : chr "Mate vertrouwen in gezondheidszorg"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int711  : dbl+lbl [1:1963]  4,  2,  3,  2,  3,  5,  3,  2,  1,  4,  3,  5,  2,  2,  3,  4,  3,  4,  ...
##    ..@ label        : chr "Mate vertrouwen in kranten"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int712  : dbl+lbl [1:1963] 2, 3, 3, 3, 3, 2, 4, 2, 4, 4, 3, 2, 2, 2, 3, 3, 3, 4, 5, 3, 3, 2, 3, 2, 2...
##    ..@ label        : chr "Mate vertrouwen in politie"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int713  : dbl+lbl [1:1963]  3,  3, -3,  3,  2,  4,  4,  2,  4,  3,  3,  3,  2,  2,  4,  3,  3,  4,  ...
##    ..@ label        : chr "Mate vertrouwen in Tweede Kamer"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int714  : dbl+lbl [1:1963]  3,  2, -3,  3,  3,  3,  4,  3,  4,  4,  3,  5,  2,  2,  3,  2,  3,  5,  ...
##    ..@ label        : chr "Mate vertrouwen in ambtenaren"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int715  : dbl+lbl [1:1963]  3,  2,  5,  2,  2,  3,  5,  3,  3,  4, -3,  2,  2,  2,  3,  3,  2, -3,  ...
##    ..@ label        : chr "Mate vertrouwen in Europese Unie"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ int716  : dbl+lbl [1:1963]  5,  3,  3,  3,  2,  2,  3,  3,  3,  3,  3,  2,  2,  3,  2,  4,  3,  3,  ...
##    ..@ label        : chr "Mate vertrouwen in vakbonden"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5
##    .. ..- attr(*, "names")= chr [1:9] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var433  : dbl+lbl [1:1963] 2, 2, 3, 3, 3, 1, 5, 2, 3, 2, 3, 5, 2, 4, 2, 2, 3, 5, 5, 5, 4, 3, 3, 5, 1...
##    ..@ label        : chr "Misdadiger niet straffen maar veranderen"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6
##    .. ..- attr(*, "names")= chr [1:10] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var439  : dbl+lbl [1:1963]  2,  1,  5,  4, -3,  1,  1,  4,  1,  5,  3,  1,  2,  4,  3,  4,  2,  1,  ...
##    ..@ label        : chr "Minder regels, meer sterke leiders"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6
##    .. ..- attr(*, "names")= chr [1:10] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var1329 : dbl+lbl [1:1963] 2, 4, 2, 4, 2, 1, 2, 1, 1, 2, 3, 1, 2, 4, 2, 2, 1, 1, 1, 3, 2, 2, 1, 5, 2...
##    ..@ label        : chr "De vrijheid van meningsuiting mag niet zover gaan dat mensen worden gekwetst in hun religieuze gevoelens."
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6
##    .. ..- attr(*, "names")= chr [1:10] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var1330 : dbl+lbl [1:1963]  5,  5,  4,  3,  5,  1,  1,  4,  1,  2,  3,  5,  2,  4,  3,  3,  2, -3,  ...
##    ..@ label        : chr "(79) Schaam me een Nederlander te zijn."
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6
##    .. ..- attr(*, "names")= chr [1:10] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var445  : dbl+lbl [1:1963] 4, 5, 2, 2, 4, 4, 5, 2, 3, 2, 5, 5, 3, 4, 2, 2, 3, 2, 5, 5, 4, 3, 4, 5, 5...
##    ..@ label        : chr "Seks misdaad niet straffen maar genezen"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6
##    .. ..- attr(*, "names")= chr [1:10] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var446  : dbl+lbl [1:1963] 3, 5, 1, 4, 2, 1, 2, 3, 1, 1, 2, 1, 3, 4, 2, 5, 4, 1, 1, 3, 4, 2, 1, 5, 3...
##    ..@ label        : chr "Onzekerheid wat goed/verkeerd"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6
##    .. ..- attr(*, "names")= chr [1:10] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var447  : dbl+lbl [1:1963] 3, 5, 1, 4, 2, 1, 4, 3, 1, 1, 3, 1, 2, 4, 4, 5, 4, 1, 1, 3, 4, 2, 2, 5, 2...
##    ..@ label        : chr "Steeds anders onduidelijk goed/slecht"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6
##    .. ..- attr(*, "names")= chr [1:10] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var451  : dbl+lbl [1:1963]  5,  5,  4,  4,  4,  1,  4,  5,  5,  4,  3,  5,  2,  4,  4,  3,  5,  2,  ...
##    ..@ label        : chr "Geweld om ideaal te verwezenlijken"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6
##    .. ..- attr(*, "names")= chr [1:10] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var452  : dbl+lbl [1:1963] 2, 3, 2, 2, 2, 1, 4, 3, 1, 1, 5, 3, 2, 2, 2, 2, 5, 1, 4, 3, 2, 3, 2, 5, 2...
##    ..@ label        : chr "Betekenis leven dmv ideaal of taak"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6
##    .. ..- attr(*, "names")= chr [1:10] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##  $ var1316 : dbl+lbl [1:1963]  5,  5,  4,  4,  5,  1,  2,  2,  1,  5,  2,  4,  3,  2,  3,  4,  5, -3,  ...
##    ..@ label        : chr "Geld overheid om sportevenementen binnen te halen"
##    ..@ format.spss  : chr "F10.0"
##    ..@ display_width: int 12
##    ..@ labels       : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6
##    .. ..- attr(*, "names")= chr [1:10] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
##   [list output truncated]
\end{verbatim}

The function \texttt{str()} asks for the structure of an object in your environment. You will see that the original data is stored differently in the three datasets. The different objects (cv08, cv08\_nolab and cv08\_haven) have a different structure. cv08 and cv08\_nolab are `data.frame' objects, the \texttt{haven::read\_spss} function produces a `tibble'.

Let us have quick look at the structure of some variables.

\begin{quote}
To access a variable in a dataset use \texttt{datasetname\$variablename} .

Add to your cheat sheet under operators/symbols: \texttt{\$}
\end{quote}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{str}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{lftop) }\CommentTok{#a factor}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  Factor w/ 81 levels "< één jaar","één jaar",..: 40 28 4 18 46 38 51 23 48 30 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{str}\NormalTok{(cv08_nolab}\OperatorTok{$}\NormalTok{lftop) }\CommentTok{# a numeric variable}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  num [1:1963] 51 39 16 29 57 49 62 34 59 41 ...
##  - attr(*, "value.labels")= Named chr [1:5] "125" "99" "2" "1" ...
##   ..- attr(*, "names")= chr [1:5] "125 jaar" "Onbekend" "twee jaar" "één jaar" ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{str}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{lftop) }\CommentTok{# a 'dbl+lbl' this stands for doubles, or real numbers, which are labeled}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  dbl+lbl [1:1963] 51, 39, 16, 29, 57, 49, 62, 34, 59, 41, 25, 43, 74, 17, 22, 32, 51, 66, 64, 2...
##  @ label        : chr "Leeftijd OP op datum interview"
##  @ format.spss  : chr "F10.0"
##  @ display_width: int 12
##  @ labels       : Named num [1:5] 0 1 2 99 125
##   ..- attr(*, "names")= chr [1:5] "< één jaar" "één jaar" "twee jaar" "Onbekend" ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#next to the data itself, attributes are stored}
\KeywordTok{attributes}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{lftop)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $levels
##  [1] "< één jaar" "één jaar"   "125 jaar"   "16"         "17"         "18"         "19"        
##  [8] "twee jaar"  "20"         "21"         "22"         "23"         "24"         "25"        
## [15] "26"         "27"         "28"         "29"         "30"         "31"         "32"        
## [22] "33"         "34"         "35"         "36"         "37"         "38"         "39"        
## [29] "40"         "41"         "42"         "43"         "44"         "45"         "46"        
## [36] "47"         "48"         "49"         "50"         "51"         "52"         "53"        
## [43] "54"         "55"         "56"         "57"         "58"         "59"         "60"        
## [50] "61"         "62"         "63"         "64"         "65"         "66"         "67"        
## [57] "68"         "69"         "70"         "71"         "72"         "73"         "74"        
## [64] "75"         "76"         "77"         "78"         "79"         "80"         "81"        
## [71] "82"         "83"         "84"         "85"         "86"         "87"         "88"        
## [78] "89"         "90"         "91"         "Onbekend"  
## 
## $class
## [1] "factor"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{attributes}\NormalTok{(cv08_nolab}\OperatorTok{$}\NormalTok{lftop)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $value.labels
##   125 jaar   Onbekend  twee jaar   één jaar < één jaar 
##      "125"       "99"        "2"        "1"        "0"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{attributes}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{lftop)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $label
## [1] "Leeftijd OP op datum interview"
## 
## $format.spss
## [1] "F10.0"
## 
## $display_width
## [1] 12
## 
## $class
## [1] "haven_labelled" "vctrs_vctr"     "double"        
## 
## $labels
## < één jaar   één jaar  twee jaar   Onbekend   125 jaar 
##          0          1          2         99        125
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#to access specific attributes}
\KeywordTok{attr}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{lftop, }\StringTok{"labels"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## < één jaar   één jaar  twee jaar   Onbekend   125 jaar 
##          0          1          2         99        125
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{summary}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{lftop)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## < één jaar   één jaar   125 jaar         16         17         18         19  twee jaar         20 
##          0          0          0         40         37         39         30          0         30 
##         21         22         23         24         25         26         27         28         29 
##         25         25         38         26         22         18         23         29         30 
##         30         31         32         33         34         35         36         37         38 
##         22         28         23         23         24         38         35         37         34 
##         39         40         41         42         43         44         45         46         47 
##         48         45         34         36         39         43         38         41         32 
##         48         49         50         51         52         53         54         55         56 
##         41         45         29         29         43         32         25         27         27 
##         57         58         59         60         61         62         63         64         65 
##         30         44         34         33         36         40         29         27         30 
##         66         67         68         69         70         71         72         73         74 
##         19         24         24         24         23         21         13         15         26 
##         75         76         77         78         79         80         81         82         83 
##         10         14         17         13         13         10          7         10         10 
##         84         85         86         87         88         89         90         91   Onbekend 
##          7          6          3          8          2          3          1          3          4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{summary}\NormalTok{(cv08_nolab}\OperatorTok{$}\NormalTok{lftop)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   16.00   33.00   46.00   46.78   61.00   99.00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{summary}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{lftop)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   16.00   33.00   46.00   46.78   61.00   99.00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{table}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{lftop, }\DataTypeTok{useNA =} \StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##   16   17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32   33   34   35 
##   40   37   39   30   30   25   25   38   26   22   18   23   29   30   22   28   23   23   24   38 
##   36   37   38   39   40   41   42   43   44   45   46   47   48   49   50   51   52   53   54   55 
##   35   37   34   48   45   34   36   39   43   38   41   32   41   45   29   29   43   32   25   27 
##   56   57   58   59   60   61   62   63   64   65   66   67   68   69   70   71   72   73   74   75 
##   27   30   44   34   33   36   40   29   27   30   19   24   24   24   23   21   13   15   26   10 
##   76   77   78   79   80   81   82   83   84   85   86   87   88   89   90   91   99 <NA> 
##   14   17   13   13   10    7   10   10    7    6    3    8    2    3    1    3    4    0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{names}\NormalTok{(cv08_haven)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   [1] "we_id"    "veilignr" "lft1"     "geslacht" "allochtn" "lft01"    "lftop"    "gewicht" 
##   [9] "var006n"  "v040"     "var723"   "var723a"  "v202n"    "var1061a" "var1061b" "var1062a"
##  [17] "var1062b" "int137n"  "int138n"  "int139n"  "int140n"  "int141n"  "v401"     "var1343" 
##  [25] "var648"   "var149"   "var058"   "var059"   "var064"   "var365"   "var065"   "var092"  
##  [33] "var096"   "int054"   "int055"   "int056"   "int057"   "int058"   "int059"   "int059a" 
##  [41] "var571"   "var572"   "var573"   "var574"   "var576"   "var153"   "var154"   "var155"  
##  [49] "var156"   "var157"   "var157a"  "var154a"  "var164"   "var165"   "var166"   "var179"  
##  [57] "var180"   "var184"   "var185"   "var198a"  "var198"   "var201a"  "var201b"  "var204"  
##  [65] "int257"   "var211"   "var223"   "var1320"  "var1321"  "var1322"  "var1323"  "var1324" 
##  [73] "var1325"  "var1326"  "var1327"  "var1328"  "var229"   "int218"   "int219"   "int221"  
##  [81] "int222"   "int223"   "int710"   "int711"   "int712"   "int713"   "int714"   "int715"  
##  [89] "int716"   "var433"   "var439"   "var1329"  "var1330"  "var445"   "var446"   "var447"  
##  [97] "var451"   "var452"   "var1316"  "var1317"  "var1331"  "vw065"    "var491"   "var040"  
## [105] "var1304"  "var274"   "var275"   "var1196"  "var1197"  "var461"   "var273"   "var1262" 
## [113] "var239"   "var318"   "var319"   "var320"   "var1209"  "var1210"  "var599"   "var600"  
## [121] "var408"   "var409"   "var10401" "var10402" "var10403" "var10404" "var10405" "var10406"
## [129] "var10407" "var10408" "var10409" "var10410" "var10411" "var10412" "var10413" "var10414"
## [137] "var10415" "var10416" "var1046a" "var1046b" "var1046c" "var1046d" "var1046e" "var1046f"
## [145] "var1046g" "var1046h" "var1046i" "var1046j" "var1046k" "var1046l" "var1046m" "var1046n"
## [153] "var1046o" "var1046p" "var687"   "var688"   "var689"   "var953"   "var1265"  "var351"  
## [161] "var402"   "var595"   "var972b"  "var972d"  "var972e"  "var972f"  "var972h"  "var972i" 
## [169] "var972k"  "var1039b" "var1039c" "var1039d" "var1039e" "var1039f" "var1039g" "var1039h"
## [177] "var1039i" "var1039j" "var1039l" "var1039m" "var1145a" "var1145b" "var1145c" "var1145d"
## [185] "var1145e" "var1145f" "var1145g" "var1145h" "var1145i" "var1145j" "var1145k" "var1145l"
## [193] "var1145m" "var1145n" "var1145o" "var1145p" "var1146"  "var1163"  "var1335"  "var1336" 
## [201] "var1337"  "var347"   "var544"   "var757bm" "var1318"  "var1332"  "var1333"  "var1334" 
## [209] "var763"   "var766"   "var767"   "var1319"  "var844"   "var846"   "var847"   "var594"  
## [217] "var1017"  "var357"   "var1307"  "var1338"  "var1339"  "var1340"  "var1341"  "var1342" 
## [225] "var516"   "var683b"  "var728b"  "var729b"  "var546"   "var758"   "var759"   "var1031" 
## [233] "var1103"  "var1104"  "var1106"  "var1315a" "var1310"  "var1311"  "var1312"  "var1313" 
## [241] "var1314"  "var900k"  "var900l"  "var548"   "var5504"  "var462b"  "soorthhn" "plaatsin"
## [249] "lft2"     "lft3"     "lft4"     "lft5"     "lft6"     "lft7"     "lft8"     "lft9"    
## [257] "lft10"    "geslac_1" "geslac_2" "geslac_3" "geslac_4" "geslac_5" "geslac_6" "geslac_7"
## [265] "geslac_8" "geslac_9" "lftcatjo" "soortbew" "soi98dop" "isco_op"  "gemgrjj"  "landd"   
## [273] "stede"    "generat"  "typehh"   "plaatshh" "plhh17"   "wperiode"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{summary}\NormalTok{(cv08_haven)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      we_id             veilignr              lft1         geslacht            allochtn     
##  Min.   :36775330   Min.   :811000004   Min.   : 0.00   Length:1963        Min.   :0.0000  
##  1st Qu.:37604540   1st Qu.:812003955   1st Qu.:33.00   Class :character   1st Qu.:0.0000  
##  Median :38724230   Median :902002867   Median :46.00   Mode  :character   Median :0.0000  
##  Mean   :38830177   Mean   :875088135   Mean   :46.56                      Mean   :0.1793  
##  3rd Qu.:40598965   3rd Qu.:904000134   3rd Qu.:60.00                      3rd Qu.:0.0000  
##  Max.   :41199300   Max.   :905010166   Max.   :99.00                      Max.   :9.0000  
##                                                                                            
##      lft01           lftop          gewicht           var006n            v040           var723     
##  Min.   :15.00   Min.   :16.00   Min.   :  955.1   Min.   :-3.000   Min.   :1.000   Min.   :-5.00  
##  1st Qu.:32.00   1st Qu.:33.00   1st Qu.: 5137.2   1st Qu.: 2.000   1st Qu.:1.000   1st Qu.:-5.00  
##  Median :46.00   Median :46.00   Median : 6473.4   Median : 5.000   Median :1.000   Median :20.00  
##  Mean   :46.37   Mean   :46.78   Mean   : 6676.3   Mean   : 3.999   Mean   :1.352   Mean   :18.69  
##  3rd Qu.:60.00   3rd Qu.:61.00   3rd Qu.: 7981.1   3rd Qu.: 6.000   3rd Qu.:2.000   3rd Qu.:38.00  
##  Max.   :99.00   Max.   :99.00   Max.   :20501.2   Max.   : 8.000   Max.   :2.000   Max.   :90.00  
##                                                                                                    
##     var723a           v202n           var1061a        var1061b          var1062a    
##  Min.   :-5.000   Min.   :-3.000   Min.   :1.000   Min.   : -5.000   Min.   :1.000  
##  1st Qu.:-5.000   1st Qu.: 1.000   1st Qu.:1.000   1st Qu.: -5.000   1st Qu.:2.000  
##  Median :-5.000   Median : 1.000   Median :2.000   Median : -5.000   Median :2.000  
##  Mean   :-4.978   Mean   : 2.695   Mean   :1.721   Mean   : -2.074   Mean   :1.773  
##  3rd Qu.:-5.000   3rd Qu.: 5.000   3rd Qu.:2.000   3rd Qu.:  1.000   3rd Qu.:2.000  
##  Max.   : 4.000   Max.   :10.000   Max.   :2.000   Max.   :168.000   Max.   :2.000  
##                                                                                     
##     var1062b          int137n           int138n          int139n           int140n      
##  Min.   : -5.000   Min.   :-5.0000   Min.   :-5.000   Min.   :-5.0000   Min.   :-5.000  
##  1st Qu.: -5.000   1st Qu.: 1.0000   1st Qu.: 2.000   1st Qu.: 1.0000   1st Qu.: 1.000  
##  Median : -5.000   Median : 2.0000   Median : 3.000   Median : 1.0000   Median : 2.000  
##  Mean   : -2.531   Mean   : 0.5797   Mean   : 2.232   Mean   : 0.9103   Mean   : 1.911  
##  3rd Qu.: -5.000   3rd Qu.: 3.0000   3rd Qu.: 3.000   3rd Qu.: 3.0000   3rd Qu.: 3.000  
##  Max.   :168.000   Max.   : 3.0000   Max.   : 3.000   Max.   : 3.0000   Max.   : 3.000  
##                                                                                         
##     int141n            v401          var1343          var648         var149           var058      
##  Min.   :-5.000   Min.   :1.000   Min.   :-3.00   Min.   :1.00   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 1.000   1st Qu.:1.000   1st Qu.: 3.00   1st Qu.:2.00   1st Qu.: 1.000   1st Qu.: 1.000  
##  Median : 1.000   Median :2.000   Median : 3.00   Median :3.00   Median : 1.000   Median : 1.000  
##  Mean   : 1.887   Mean   :1.993   Mean   : 2.86   Mean   :2.58   Mean   : 1.442   Mean   : 1.149  
##  3rd Qu.: 3.000   3rd Qu.:2.000   3rd Qu.: 3.00   3rd Qu.:3.00   3rd Qu.: 2.000   3rd Qu.: 1.000  
##  Max.   : 3.000   Max.   :5.000   Max.   : 3.00   Max.   :5.00   Max.   : 3.000   Max.   : 2.000  
##                                                                                                   
##      var059           var064           var365            var065           var092      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.0000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 1.0000   1st Qu.: 1.000   1st Qu.: 3.000  
##  Median : 1.000   Median : 1.000   Median : 1.0000   Median : 1.000   Median : 4.000  
##  Mean   : 1.083   Mean   : 1.149   Mean   : 0.9409   Mean   : 1.148   Mean   : 3.295  
##  3rd Qu.: 1.000   3rd Qu.: 2.000   3rd Qu.: 2.0000   3rd Qu.: 2.000   3rd Qu.: 4.000  
##  Max.   : 2.000   Max.   : 2.000   Max.   : 2.0000   Max.   : 2.000   Max.   : 4.000  
##                                                                                       
##      var096           int054           int055          int056           int057      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.00   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 1.000   1st Qu.: 2.000   1st Qu.: 2.00   1st Qu.: 2.000   1st Qu.: 2.000  
##  Median : 2.000   Median : 2.000   Median : 3.00   Median : 2.000   Median : 2.000  
##  Mean   : 2.008   Mean   : 1.948   Mean   : 2.43   Mean   : 1.888   Mean   : 1.954  
##  3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 3.00   3rd Qu.: 3.000   3rd Qu.: 3.000  
##  Max.   : 5.000   Max.   : 4.000   Max.   : 4.00   Max.   : 4.000   Max.   : 4.000  
##                                                                                     
##      int058           int059          int059a           var571           var572      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-5.000  
##  1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.:-5.000  
##  Median : 2.000   Median : 2.000   Median : 2.000   Median : 2.000   Median : 1.000  
##  Mean   : 2.065   Mean   : 2.141   Mean   : 1.851   Mean   : 2.326   Mean   :-0.864  
##  3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 2.000  
##  Max.   : 4.000   Max.   : 4.000   Max.   : 4.000   Max.   : 3.000   Max.   : 3.000  
##                                                                                      
##      var573           var574           var576           var153           var154      
##  Min.   :-3.000   Min.   :-5.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 1.000   1st Qu.:-5.000   1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 2.000  
##  Median : 2.000   Median :-5.000   Median : 3.000   Median : 1.000   Median : 2.000  
##  Mean   : 1.615   Mean   :-2.002   Mean   : 2.985   Mean   : 1.319   Mean   : 1.889  
##  3rd Qu.: 2.000   3rd Qu.: 2.000   3rd Qu.: 4.000   3rd Qu.: 2.000   3rd Qu.: 3.000  
##  Max.   : 3.000   Max.   : 3.000   Max.   : 5.000   Max.   : 3.000   Max.   : 3.000  
##                                                                                      
##      var155           var156           var157          var157a          var154a     
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.00  
##  1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.:-3.000   1st Qu.: 2.000   1st Qu.: 2.00  
##  Median : 2.000   Median : 2.000   Median : 2.000   Median : 2.000   Median : 2.00  
##  Mean   : 1.339   Mean   : 1.415   Mean   : 0.566   Mean   : 1.506   Mean   : 1.56  
##  3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 2.00  
##  Max.   : 3.000   Max.   : 3.000   Max.   : 3.000   Max.   : 3.000   Max.   : 3.00  
##                                                                                     
##      var164           var165           var166           var179           var180      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 1.000   1st Qu.: 3.000   1st Qu.: 3.000   1st Qu.: 1.000   1st Qu.: 1.000  
##  Median : 1.000   Median : 4.000   Median : 3.000   Median : 1.000   Median : 1.000  
##  Mean   : 1.271   Mean   : 3.752   Mean   : 3.148   Mean   : 1.061   Mean   : 1.207  
##  3rd Qu.: 2.000   3rd Qu.: 5.000   3rd Qu.: 4.000   3rd Qu.: 1.000   3rd Qu.: 1.000  
##  Max.   : 3.000   Max.   : 5.000   Max.   : 5.000   Max.   : 2.000   Max.   : 2.000  
##                                                                                      
##      var184           var185          var198a          var198           var201a      
##  Min.   :-3.000   Min.   :-3.000   Min.   :1.000   Min.   :-5.0000   Min.   :-3.000  
##  1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.:1.000   1st Qu.:-5.0000   1st Qu.: 1.000  
##  Median : 1.000   Median : 1.000   Median :1.000   Median : 1.0000   Median : 2.000  
##  Mean   : 1.233   Mean   : 1.232   Mean   :1.314   Mean   :-0.2165   Mean   : 1.661  
##  3rd Qu.: 2.000   3rd Qu.: 2.000   3rd Qu.:2.000   3rd Qu.: 2.0000   3rd Qu.: 2.000  
##  Max.   : 2.000   Max.   : 2.000   Max.   :2.000   Max.   : 7.0000   Max.   : 2.000  
##                                                                                      
##     var201b           var204           int257           var211           var223      
##  Min.   :-5.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.:-5.000   1st Qu.: 4.000   1st Qu.: 3.000   1st Qu.: 1.000   1st Qu.: 1.000  
##  Median :-5.000   Median : 5.000   Median : 3.000   Median : 3.000   Median : 1.000  
##  Mean   :-2.512   Mean   : 4.118   Mean   : 3.881   Mean   : 2.235   Mean   : 1.258  
##  3rd Qu.: 1.000   3rd Qu.: 5.000   3rd Qu.: 5.000   3rd Qu.: 3.000   3rd Qu.: 1.000  
##  Max.   : 6.000   Max.   : 5.000   Max.   : 7.000   Max.   : 3.000   Max.   : 3.000  
##                                                                                      
##     var1320          var1321         var1322         var1323          var1324          var1325     
##  Min.   :-3.000   Min.   :-3.00   Min.   :-3.00   Min.   :-3.000   Min.   :-3.000   Min.   :-3.00  
##  1st Qu.: 1.000   1st Qu.: 2.00   1st Qu.: 2.00   1st Qu.: 3.000   1st Qu.: 3.000   1st Qu.: 3.00  
##  Median : 2.000   Median : 2.00   Median : 2.00   Median : 3.000   Median : 3.000   Median : 3.00  
##  Mean   : 1.658   Mean   : 2.61   Mean   : 2.13   Mean   : 2.669   Mean   : 2.821   Mean   : 2.79  
##  3rd Qu.: 2.000   3rd Qu.: 4.00   3rd Qu.: 3.00   3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 3.00  
##  Max.   : 5.000   Max.   : 5.00   Max.   : 3.00   Max.   : 3.000   Max.   : 3.000   Max.   : 3.00  
##                                                                                                    
##     var1326          var1327          var1328           var229           int218      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 3.000   1st Qu.: 3.000   1st Qu.: 3.000   1st Qu.: 3.000   1st Qu.: 3.000  
##  Median : 3.000   Median : 3.000   Median : 3.000   Median : 3.000   Median : 3.000  
##  Mean   : 2.924   Mean   : 2.683   Mean   : 2.909   Mean   : 3.319   Mean   : 2.967  
##  3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 3.000  
##  Max.   : 3.000   Max.   : 3.000   Max.   : 3.000   Max.   : 8.000   Max.   : 5.000  
##                                                                                      
##      int219           int221           int222           int223           int710      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 2.000   1st Qu.: 3.000   1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 2.000  
##  Median : 3.000   Median : 3.000   Median : 3.000   Median : 3.000   Median : 3.000  
##  Mean   : 2.574   Mean   : 3.034   Mean   : 2.685   Mean   : 2.501   Mean   : 2.608  
##  3rd Qu.: 3.000   3rd Qu.: 4.000   3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 3.000  
##  Max.   : 5.000   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000  
##                                                                                      
##      int711           int712          int713           int714           int715      
##  Min.   :-3.000   Min.   :-3.00   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 3.000   1st Qu.: 2.00   1st Qu.: 3.000   1st Qu.: 3.000   1st Qu.: 2.000  
##  Median : 3.000   Median : 3.00   Median : 3.000   Median : 3.000   Median : 3.000  
##  Mean   : 2.827   Mean   : 2.76   Mean   : 2.737   Mean   : 2.829   Mean   : 2.575  
##  3rd Qu.: 4.000   3rd Qu.: 3.00   3rd Qu.: 3.000   3rd Qu.: 4.000   3rd Qu.: 4.000  
##  Max.   : 5.000   Max.   : 5.00   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000  
##                                                                                     
##      int716           var433           var439          var1329          var1330      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 2.000  
##  Median : 3.000   Median : 4.000   Median : 2.000   Median : 2.000   Median : 3.000  
##  Mean   : 2.322   Mean   : 3.331   Mean   : 2.407   Mean   : 2.114   Mean   : 3.163  
##  3rd Qu.: 3.000   3rd Qu.: 5.000   3rd Qu.: 4.000   3rd Qu.: 3.000   3rd Qu.: 5.000  
##  Max.   : 5.000   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000  
##                                                                                      
##      var445           var446           var447           var451           var452      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 3.000   1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 3.000   1st Qu.: 2.000  
##  Median : 4.000   Median : 3.000   Median : 3.000   Median : 4.000   Median : 3.000  
##  Mean   : 3.746   Mean   : 2.706   Mean   : 3.003   Mean   : 3.779   Mean   : 2.788  
##  3rd Qu.: 5.000   3rd Qu.: 4.000   3rd Qu.: 4.000   3rd Qu.: 5.000   3rd Qu.: 4.000  
##  Max.   : 5.000   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000  
##                                                                                      
##     var1316          var1317          var1331           vw065            var491      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 2.000  
##  Median : 3.000   Median : 3.000   Median : 2.000   Median : 1.000   Median : 2.000  
##  Mean   : 2.952   Mean   : 2.862   Mean   : 1.735   Mean   : 1.185   Mean   : 2.665  
##  3rd Qu.: 4.000   3rd Qu.: 4.000   3rd Qu.: 2.000   3rd Qu.: 2.000   3rd Qu.: 3.000  
##  Max.   : 5.000   Max.   : 5.000   Max.   : 4.000   Max.   : 2.000   Max.   : 5.000  
##                                                                                      
##      var040          var1304           var274           var275          var1196      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-5.000   Min.   :-3.000  
##  1st Qu.: 1.000   1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 1.000  
##  Median : 1.000   Median : 2.000   Median : 1.000   Median : 3.000   Median : 1.000  
##  Mean   : 1.803   Mean   : 1.964   Mean   : 1.322   Mean   : 4.462   Mean   : 1.489  
##  3rd Qu.: 2.000   3rd Qu.: 2.000   3rd Qu.: 1.000   3rd Qu.: 8.000   3rd Qu.: 2.000  
##  Max.   : 4.000   Max.   : 4.000   Max.   : 4.000   Max.   :14.000   Max.   : 3.000  
##                                                                                      
##     var1197            var461          var273          var1262           var239      
##  Min.   :-3.0000   Min.   :-3.00   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 1.0000   1st Qu.: 2.00   1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 1.000  
##  Median : 1.0000   Median : 3.00   Median : 2.000   Median : 3.000   Median : 2.000  
##  Mean   : 0.8197   Mean   : 2.33   Mean   : 2.065   Mean   : 2.863   Mean   : 1.614  
##  3rd Qu.: 1.0000   3rd Qu.: 4.00   3rd Qu.: 3.000   3rd Qu.: 4.000   3rd Qu.: 2.000  
##  Max.   : 2.0000   Max.   : 5.00   Max.   : 5.000   Max.   : 5.000   Max.   : 2.000  
##                                                                                      
##      var318           var319           var320          var1209          var1210      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 1.000  
##  Median : 1.000   Median : 2.000   Median : 1.000   Median : 2.000   Median : 2.000  
##  Mean   : 1.435   Mean   : 1.485   Mean   : 1.194   Mean   : 1.952   Mean   : 1.785  
##  3rd Qu.: 2.000   3rd Qu.: 2.000   3rd Qu.: 2.000   3rd Qu.: 3.000   3rd Qu.: 2.000  
##  Max.   : 2.000   Max.   : 2.000   Max.   : 2.000   Max.   : 4.000   Max.   : 4.000  
##                                                                                      
##      var599           var600           var408           var409         var10401        
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Length:1963       
##  1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 1.000   Class :character  
##  Median : 2.000   Median : 2.000   Median : 2.000   Median : 1.000   Mode  :character  
##  Mean   : 1.908   Mean   : 1.759   Mean   : 2.231   Mean   : 1.485                     
##  3rd Qu.: 2.000   3rd Qu.: 2.000   3rd Qu.: 3.000   3rd Qu.: 2.000                     
##  Max.   : 2.000   Max.   : 2.000   Max.   : 3.000   Max.   : 3.000                     
##                                                                                        
##    var10402           var10403           var10404           var10405           var10406        
##  Length:1963        Length:1963        Length:1963        Length:1963        Length:1963       
##  Class :character   Class :character   Class :character   Class :character   Class :character  
##  Mode  :character   Mode  :character   Mode  :character   Mode  :character   Mode  :character  
##                                                                                                
##                                                                                                
##                                                                                                
##                                                                                                
##    var10407           var10408           var10409           var10410           var10411        
##  Length:1963        Length:1963        Length:1963        Length:1963        Length:1963       
##  Class :character   Class :character   Class :character   Class :character   Class :character  
##  Mode  :character   Mode  :character   Mode  :character   Mode  :character   Mode  :character  
##                                                                                                
##                                                                                                
##                                                                                                
##                                                                                                
##    var10412           var10413           var10414           var10415           var10416        
##  Length:1963        Length:1963        Length:1963        Length:1963        Length:1963       
##  Class :character   Class :character   Class :character   Class :character   Class :character  
##  Mode  :character   Mode  :character   Mode  :character   Mode  :character   Mode  :character  
##                                                                                                
##                                                                                                
##                                                                                                
##                                                                                                
##     var1046a         var1046b         var1046c         var1046d         var1046e     
##  Min.   :-4.000   Min.   :-4.000   Min.   :-4.000   Min.   :-4.000   Min.   :-4.000  
##  1st Qu.: 3.000   1st Qu.: 7.000   1st Qu.: 5.000   1st Qu.: 2.000   1st Qu.: 5.000  
##  Median : 6.000   Median :10.000   Median : 9.000   Median : 5.000   Median : 9.000  
##  Mean   : 6.175   Mean   : 9.328   Mean   : 8.621   Mean   : 5.761   Mean   : 8.733  
##  3rd Qu.: 9.000   3rd Qu.:13.000   3rd Qu.:12.000   3rd Qu.: 9.000   3rd Qu.:13.000  
##  Max.   :16.000   Max.   :16.000   Max.   :16.000   Max.   :16.000   Max.   :16.000  
##                                                                                      
##     var1046f        var1046g         var1046h        var1046i         var1046j     
##  Min.   :-4.00   Min.   :-4.000   Min.   :-4.00   Min.   :-4.000   Min.   :-4.000  
##  1st Qu.:12.00   1st Qu.: 7.000   1st Qu.:10.00   1st Qu.: 2.000   1st Qu.: 3.000  
##  Median :15.00   Median :10.000   Median :13.00   Median : 5.000   Median : 5.000  
##  Mean   :13.17   Mean   : 9.357   Mean   :11.66   Mean   : 5.423   Mean   : 5.732  
##  3rd Qu.:16.00   3rd Qu.:13.000   3rd Qu.:15.00   3rd Qu.: 8.000   3rd Qu.: 8.000  
##  Max.   :16.00   Max.   :16.000   Max.   :16.00   Max.   :16.000   Max.   :16.000  
##                                                                                    
##     var1046k         var1046l         var1046m         var1046n         var1046o     
##  Min.   :-4.000   Min.   :-4.000   Min.   :-4.000   Min.   :-4.000   Min.   :-4.000  
##  1st Qu.: 3.000   1st Qu.: 6.000   1st Qu.: 4.000   1st Qu.: 5.000   1st Qu.: 3.000  
##  Median : 6.000   Median :10.000   Median : 6.000   Median : 8.000   Median : 5.000  
##  Mean   : 6.542   Mean   : 9.194   Mean   : 6.552   Mean   : 8.047   Mean   : 5.587  
##  3rd Qu.:10.000   3rd Qu.:13.000   3rd Qu.: 9.000   3rd Qu.:12.000   3rd Qu.: 8.000  
##  Max.   :16.000   Max.   :16.000   Max.   :16.000   Max.   :16.000   Max.   :16.000  
##                                                                                      
##     var1046p         var687           var688            var689           var953      
##  Min.   :-4.00   Min.   :-3.000   Min.   :-5.0000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 8.00   1st Qu.: 1.000   1st Qu.:-5.0000   1st Qu.: 1.000   1st Qu.: 3.000  
##  Median :13.00   Median : 1.000   Median : 1.0000   Median : 1.000   Median : 3.000  
##  Mean   :11.25   Mean   : 1.279   Mean   :-0.1854   Mean   : 1.175   Mean   : 2.593  
##  3rd Qu.:15.00   3rd Qu.: 2.000   3rd Qu.: 2.0000   3rd Qu.: 1.000   3rd Qu.: 3.000  
##  Max.   :16.00   Max.   : 3.000   Max.   : 3.0000   Max.   : 2.000   Max.   : 3.000  
##                                                                                      
##     var1265           var351           var402           var595          var972b      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-2.000  
##  1st Qu.: 1.000   1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 2.000  
##  Median : 2.000   Median : 4.000   Median : 3.000   Median : 2.000   Median : 3.000  
##  Mean   : 1.386   Mean   : 3.356   Mean   : 2.891   Mean   : 2.221   Mean   : 3.118  
##  3rd Qu.: 3.000   3rd Qu.: 5.000   3rd Qu.: 4.000   3rd Qu.: 3.000   3rd Qu.: 4.000  
##  Max.   : 3.000   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000  
##                                                                                      
##     var972d          var972e          var972f          var972h          var972i      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 3.000   1st Qu.: 2.000  
##  Median : 2.000   Median : 2.000   Median : 3.000   Median : 3.000   Median : 2.000  
##  Mean   : 2.343   Mean   : 2.087   Mean   : 2.853   Mean   : 3.324   Mean   : 2.109  
##  3rd Qu.: 3.000   3rd Qu.: 2.000   3rd Qu.: 3.000   3rd Qu.: 4.000   3rd Qu.: 3.000  
##  Max.   : 5.000   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000  
##                                                                                      
##     var972k          var1039b         var1039c        var1039d         var1039e     
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.00   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 2.000   1st Qu.: 3.000   1st Qu.: 3.00   1st Qu.: 3.000   1st Qu.: 3.000  
##  Median : 2.000   Median : 4.000   Median : 3.00   Median : 3.000   Median : 3.000  
##  Mean   : 2.523   Mean   : 3.474   Mean   : 3.42   Mean   : 2.771   Mean   : 2.997  
##  3rd Qu.: 3.000   3rd Qu.: 4.000   3rd Qu.: 4.00   3rd Qu.: 3.000   3rd Qu.: 3.000  
##  Max.   : 5.000   Max.   : 5.000   Max.   : 5.00   Max.   : 5.000   Max.   : 5.000  
##                                                                                     
##     var1039f         var1039g         var1039h        var1039i         var1039j     
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.00   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 3.000   1st Qu.: 3.000   1st Qu.: 3.00   1st Qu.: 3.000   1st Qu.: 3.000  
##  Median : 4.000   Median : 3.000   Median : 4.00   Median : 4.000   Median : 3.000  
##  Mean   : 3.828   Mean   : 3.483   Mean   : 3.24   Mean   : 3.731   Mean   : 3.266  
##  3rd Qu.: 4.000   3rd Qu.: 4.000   3rd Qu.: 4.00   3rd Qu.: 4.000   3rd Qu.: 4.000  
##  Max.   : 5.000   Max.   : 5.000   Max.   : 5.00   Max.   : 5.000   Max.   : 5.000  
##                                                                                     
##     var1039l         var1039m         var1145a         var1145b        var1145c     
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.00   Min.   :-3.000  
##  1st Qu.: 3.000   1st Qu.: 3.000   1st Qu.: 5.000   1st Qu.: 5.00   1st Qu.: 6.000  
##  Median : 3.000   Median : 3.000   Median : 6.000   Median : 6.00   Median : 6.000  
##  Mean   : 3.171   Mean   : 3.127   Mean   : 5.439   Mean   : 5.22   Mean   : 5.628  
##  3rd Qu.: 4.000   3rd Qu.: 4.000   3rd Qu.: 7.000   3rd Qu.: 7.00   3rd Qu.: 7.000  
##  Max.   : 5.000   Max.   : 5.000   Max.   :10.000   Max.   :10.00   Max.   :10.000  
##                                                                                     
##     var1145d         var1145e         var1145f         var1145g         var1145h     
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 5.000   1st Qu.: 5.000   1st Qu.: 5.000   1st Qu.: 5.000   1st Qu.: 5.000  
##  Median : 6.000   Median : 6.000   Median : 6.000   Median : 6.000   Median : 6.000  
##  Mean   : 5.595   Mean   : 5.592   Mean   : 5.938   Mean   : 5.836   Mean   : 5.697  
##  3rd Qu.: 7.000   3rd Qu.: 7.000   3rd Qu.: 7.000   3rd Qu.: 7.000   3rd Qu.: 7.000  
##  Max.   :10.000   Max.   : 9.000   Max.   :10.000   Max.   :10.000   Max.   :10.000  
##                                                                                      
##     var1145i        var1145j         var1145k         var1145l         var1145m     
##  Min.   :-3.00   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 5.00   1st Qu.: 5.000   1st Qu.: 5.000   1st Qu.: 5.000   1st Qu.: 5.000  
##  Median : 6.00   Median : 6.000   Median : 6.000   Median : 6.000   Median : 6.000  
##  Mean   : 5.77   Mean   : 5.428   Mean   : 5.004   Mean   : 5.345   Mean   : 5.311  
##  3rd Qu.: 7.00   3rd Qu.: 7.000   3rd Qu.: 7.000   3rd Qu.: 7.000   3rd Qu.: 7.000  
##  Max.   :10.00   Max.   :10.000   Max.   :10.000   Max.   :10.000   Max.   :10.000  
##                                                                                     
##     var1145n         var1145o         var1145p         var1146          var1163      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 5.000   1st Qu.: 5.000   1st Qu.: 5.000   1st Qu.: 2.000   1st Qu.: 2.000  
##  Median : 6.000   Median : 6.000   Median : 6.000   Median : 2.000   Median : 2.000  
##  Mean   : 5.145   Mean   : 5.347   Mean   : 4.607   Mean   : 2.174   Mean   : 2.094  
##  3rd Qu.: 7.000   3rd Qu.: 7.000   3rd Qu.: 7.000   3rd Qu.: 2.000   3rd Qu.: 3.000  
##  Max.   :10.000   Max.   :10.000   Max.   :10.000   Max.   : 4.000   Max.   : 4.000  
##                                                                                      
##     var1335          var1336          var1337           var347           var544      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 3.000   1st Qu.: 2.000   1st Qu.: 3.000   1st Qu.: 2.000   1st Qu.: 1.000  
##  Median : 4.000   Median : 2.000   Median : 4.000   Median : 2.000   Median : 2.000  
##  Mean   : 3.482   Mean   : 2.065   Mean   : 3.598   Mean   : 2.427   Mean   : 1.584  
##  3rd Qu.: 4.000   3rd Qu.: 2.000   3rd Qu.: 4.000   3rd Qu.: 3.000   3rd Qu.: 2.000  
##  Max.   : 5.000   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000   Max.   : 3.000  
##                                                                                      
##     var757bm         var1318          var1332         var1333          var1334      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.00   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 1.00   1st Qu.: 3.000   1st Qu.: 2.000  
##  Median : 1.000   Median : 1.000   Median : 1.00   Median : 3.000   Median : 3.000  
##  Mean   : 1.164   Mean   : 1.857   Mean   : 1.34   Mean   : 3.221   Mean   : 2.646  
##  3rd Qu.: 2.000   3rd Qu.: 3.000   3rd Qu.: 1.00   3rd Qu.: 4.000   3rd Qu.: 3.000  
##  Max.   : 2.000   Max.   : 3.000   Max.   : 4.00   Max.   : 4.000   Max.   : 4.000  
##                                                                                     
##     var763             var766             var767             var1319           var844      
##  Length:1963        Length:1963        Length:1963        Min.   :-3.000   Min.   :-3.000  
##  Class :character   Class :character   Class :character   1st Qu.: 3.000   1st Qu.: 1.000  
##  Mode  :character   Mode  :character   Mode  :character   Median : 4.000   Median : 2.000  
##                                                           Mean   : 3.875   Mean   : 1.914  
##                                                           3rd Qu.: 5.000   3rd Qu.: 2.000  
##                                                           Max.   : 6.000   Max.   : 5.000  
##                                                                                            
##      var846           var847           var594          var1017           var357      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 3.000   1st Qu.: 2.000   1st Qu.: 2.000  
##  Median : 2.000   Median : 2.000   Median : 4.000   Median : 3.000   Median : 3.000  
##  Mean   : 2.141   Mean   : 1.986   Mean   : 3.312   Mean   : 2.702   Mean   : 2.841  
##  3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 4.000   3rd Qu.: 4.000   3rd Qu.: 4.000  
##  Max.   : 5.000   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000   Max.   : 5.000  
##                                                                                      
##     var1307          var1338          var1339          var1340          var1341      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 2.000   1st Qu.: 2.000  
##  Median : 1.000   Median : 1.000   Median : 1.000   Median : 2.000   Median : 2.000  
##  Mean   : 1.085   Mean   : 1.226   Mean   : 1.133   Mean   : 2.112   Mean   : 1.756  
##  3rd Qu.: 2.000   3rd Qu.: 3.000   3rd Qu.: 2.000   3rd Qu.: 3.000   3rd Qu.: 2.000  
##  Max.   : 3.000   Max.   : 3.000   Max.   : 3.000   Max.   : 3.000   Max.   : 3.000  
##                                                                                      
##     var1342           var516          var683b          var728b          var729b     
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.00  
##  1st Qu.: 1.000   1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 3.000   1st Qu.: 3.00  
##  Median : 1.000   Median : 2.000   Median : 3.000   Median : 3.000   Median : 3.00  
##  Mean   : 1.198   Mean   : 1.853   Mean   : 2.606   Mean   : 2.587   Mean   : 2.71  
##  3rd Qu.: 2.000   3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 3.00  
##  Max.   : 3.000   Max.   : 3.000   Max.   : 3.000   Max.   : 3.000   Max.   : 3.00  
##                                                                                     
##      var546           var758           var759          var1031          var1103      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.000  
##  1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 1.000  
##  Median : 1.000   Median : 1.000   Median : 1.000   Median : 2.000   Median : 2.000  
##  Mean   : 1.618   Mean   : 1.355   Mean   : 1.177   Mean   : 1.625   Mean   : 1.709  
##  3rd Qu.: 3.000   3rd Qu.: 1.000   3rd Qu.: 1.000   3rd Qu.: 2.000   3rd Qu.: 2.000  
##  Max.   : 4.000   Max.   : 4.000   Max.   : 4.000   Max.   : 3.000   Max.   : 4.000  
##                                                                                      
##     var1104          var1106          var1315a         var1310         var1311      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.000   Min.   :-3.00   Min.   :-3.000  
##  1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 2.00   1st Qu.: 2.000  
##  Median : 3.000   Median : 3.000   Median : 3.000   Median : 3.00   Median : 3.000  
##  Mean   : 2.527   Mean   : 2.517   Mean   : 2.208   Mean   : 2.38   Mean   : 2.271  
##  3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 3.000   3rd Qu.: 3.00   3rd Qu.: 3.000  
##  Max.   : 4.000   Max.   : 4.000   Max.   : 4.000   Max.   : 4.00   Max.   : 4.000  
##                                                                                     
##     var1312          var1313          var1314         var900k          var900l      
##  Min.   :-3.000   Min.   :-3.000   Min.   :-3.00   Min.   :-3.000   Min.   :-5.000  
##  1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 1.00   1st Qu.: 2.000   1st Qu.: 2.000  
##  Median : 3.000   Median : 2.000   Median : 2.00   Median : 3.000   Median : 2.000  
##  Mean   : 2.285   Mean   : 1.561   Mean   : 1.42   Mean   : 2.971   Mean   : 2.209  
##  3rd Qu.: 3.000   3rd Qu.: 2.000   3rd Qu.: 3.00   3rd Qu.: 4.000   3rd Qu.: 3.000  
##  Max.   : 4.000   Max.   : 4.000   Max.   : 4.00   Max.   : 5.000   Max.   : 3.000  
##                                                                                     
##      var548          var5504         var462b          soorthhn        plaatsin          lft2      
##  Min.   :-5.000   Min.   :-5.00   Min.   :-10105   Min.   :1.000   Min.   : 1.00   Min.   : 1.00  
##  1st Qu.: 1.000   1st Qu.:-5.00   1st Qu.: 29826   1st Qu.:3.000   1st Qu.: 2.00   1st Qu.:20.00  
##  Median : 2.000   Median :-5.00   Median : 48446   Median :4.000   Median : 4.00   Median :43.00  
##  Mean   : 1.698   Mean   :-2.97   Mean   : 54056   Mean   :3.604   Mean   : 3.94   Mean   :40.02  
##  3rd Qu.: 2.000   3rd Qu.: 1.00   3rd Qu.: 71490   3rd Qu.:5.000   3rd Qu.: 6.00   3rd Qu.:58.00  
##  Max.   : 2.000   Max.   : 2.00   Max.   :317482   Max.   :8.000   Max.   :10.00   Max.   :96.00  
##                                   NA's   :14       NA's   :6       NA's   :6       NA's   :392    
##       lft3            lft4            lft5            lft6            lft7           lft8      
##  Min.   : 1.00   Min.   : 1.00   Min.   : 1.00   Min.   : 1.00   Min.   :  11   Min.   :14.00  
##  1st Qu.:12.00   1st Qu.:11.00   1st Qu.:10.00   1st Qu.: 9.00   1st Qu.:  43   1st Qu.:14.75  
##  Median :22.50   Median :20.00   Median :17.00   Median :16.00   Median :2007   Median :20.00  
##  Mean   :28.03   Mean   :27.03   Mean   :23.59   Mean   :26.12   Mean   :1346   Mean   :26.25  
##  3rd Qu.:46.00   3rd Qu.:45.00   3rd Qu.:43.00   3rd Qu.:43.50   3rd Qu.:2007   3rd Qu.:31.50  
##  Max.   :90.00   Max.   :82.00   Max.   :77.00   Max.   :99.00   Max.   :2007   Max.   :51.00  
##  NA's   :1075    NA's   :1390    NA's   :1787    NA's   :1912    NA's   :1951   NA's   :1959   
##       lft9           lft10        geslac_1           geslac_2           geslac_3        
##  Min.   :15.00   Min.   :12     Length:1963        Length:1963        Length:1963       
##  1st Qu.:19.50   1st Qu.:12     Class :character   Class :character   Class :character  
##  Median :24.00   Median :12     Mode  :character   Mode  :character   Mode  :character  
##  Mean   :30.33   Mean   :12                                                             
##  3rd Qu.:38.00   3rd Qu.:12                                                             
##  Max.   :52.00   Max.   :12                                                             
##  NA's   :1960    NA's   :1962                                                           
##    geslac_4           geslac_5           geslac_6           geslac_7           geslac_8        
##  Length:1963        Length:1963        Length:1963        Length:1963        Length:1963       
##  Class :character   Class :character   Class :character   Class :character   Class :character  
##  Mode  :character   Mode  :character   Mode  :character   Mode  :character   Mode  :character  
##                                                                                                
##                                                                                                
##                                                                                                
##                                                                                                
##    geslac_9           lftcatjo           soortbew            soi98dop        isco_op         
##  Length:1963        Length:1963        Length:1963        Min.   :200123   Length:1963       
##  Class :character   Class :character   Class :character   1st Qu.:338110   Class :character  
##  Mode  :character   Mode  :character   Mode  :character   Median :430168   Mode  :character  
##                                                           Mean   :444655                     
##                                                           3rd Qu.:520799                     
##                                                           Max.   :999900                     
##                                                           NA's   :379                        
##     gemgrjj         landd           stede          generat          typehh         plaatshh     
##  Min.   :1.00   Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   : 1.000  
##  1st Qu.:4.00   1st Qu.:2.000   1st Qu.:2.000   1st Qu.:4.000   1st Qu.:3.000   1st Qu.: 2.000  
##  Median :4.00   Median :3.000   Median :3.000   Median :4.000   Median :4.000   Median : 4.000  
##  Mean   :4.84   Mean   :2.805   Mean   :2.933   Mean   :3.656   Mean   :3.602   Mean   : 3.938  
##  3rd Qu.:6.00   3rd Qu.:3.000   3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:5.000   3rd Qu.: 6.000  
##  Max.   :8.00   Max.   :4.000   Max.   :5.000   Max.   :4.000   Max.   :8.000   Max.   :10.000  
##                                                                 NA's   :6       NA's   :6       
##      plhh17     wperiode     
##  Min.   :1   Min.   :200811  
##  1st Qu.:1   1st Qu.:200812  
##  Median :1   Median :200902  
##  Mean   :1   Mean   :200875  
##  3rd Qu.:1   3rd Qu.:200904  
##  Max.   :1   Max.   :200905  
## 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{head}\NormalTok{(cv08_haven)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 278
##    we_id veilignr  lft1 geslacht allochtn lft01 lftop gewicht var006n    v040   var723  var723a
##   <dbl+>    <dbl> <dbl> <chr+lb> <dbl+lb> <dbl> <dbl>   <dbl> <dbl+l> <dbl+l> <dbl+lb> <dbl+lb>
## 1 3.68e7   8.11e8    51 M [Man]  0 [geen~    50    51   8423. 6 [hbo] 2 [Nee] -5 [N.v~ -5 [N.v~
## 2 3.68e7   8.11e8    39 V [Vrou~ 0 [geen~    38    39   6244. 8 [wo]  1 [Ja]  45       -5 [N.v~
## 3 3.68e7   8.11e8    16 V [Vrou~ 1 [allo~    15    16  13434. 3 [mav~ 2 [Nee] -5 [N.v~ -5 [N.v~
## 4 3.68e7   8.11e8    30 M [Man]  0 [geen~    29    29   8997  8 [wo]  1 [Ja]  20       -5 [N.v~
## 5 3.68e7   8.11e8    57 M [Man]  0 [geen~    56    57   8423. 6 [hbo] 2 [Nee] -5 [N.v~ -5 [N.v~
## 6 3.68e7   8.11e8    49 V [Vrou~ 1 [allo~    48    49   9537. 2 [vmb~ 2 [Nee] -5 [N.v~ -5 [N.v~
## # ... with 266 more variables: v202n <dbl+lbl>, var1061a <dbl+lbl>, var1061b <dbl+lbl>,
## #   var1062a <dbl+lbl>, var1062b <dbl+lbl>, int137n <dbl+lbl>, int138n <dbl+lbl>,
## #   int139n <dbl+lbl>, int140n <dbl+lbl>, int141n <dbl+lbl>, v401 <dbl+lbl>, var1343 <dbl+lbl>,
## #   var648 <dbl+lbl>, var149 <dbl+lbl>, var058 <dbl+lbl>, var059 <dbl+lbl>, var064 <dbl+lbl>,
## #   var365 <dbl+lbl>, var065 <dbl+lbl>, var092 <dbl+lbl>, var096 <dbl+lbl>, int054 <dbl+lbl>,
## #   int055 <dbl+lbl>, int056 <dbl+lbl>, int057 <dbl+lbl>, int058 <dbl+lbl>, int059 <dbl+lbl>,
## #   int059a <dbl+lbl>, var571 <dbl+lbl>, var572 <dbl+lbl>, var573 <dbl+lbl>, var574 <dbl+lbl>,
## #   var576 <dbl+lbl>, var153 <dbl+lbl>, var154 <dbl+lbl>, var155 <dbl+lbl>, var156 <dbl+lbl>,
## #   var157 <dbl+lbl>, var157a <dbl+lbl>, var154a <dbl+lbl>, var164 <dbl+lbl>, var165 <dbl+lbl>,
## #   var166 <dbl+lbl>, var179 <dbl+lbl>, var180 <dbl+lbl>, var184 <dbl+lbl>, var185 <dbl+lbl>,
## #   var198a <dbl+lbl>, var198 <dbl+lbl>, var201a <dbl+lbl>, var201b <dbl+lbl>, var204 <dbl+lbl>,
## #   int257 <dbl+lbl>, var211 <dbl+lbl>, var223 <dbl+lbl>, var1320 <dbl+lbl>, var1321 <dbl+lbl>,
## #   var1322 <dbl+lbl>, var1323 <dbl+lbl>, var1324 <dbl+lbl>, var1325 <dbl+lbl>, var1326 <dbl+lbl>,
## #   var1327 <dbl+lbl>, var1328 <dbl+lbl>, var229 <dbl+lbl>, int218 <dbl+lbl>, int219 <dbl+lbl>,
## #   int221 <dbl+lbl>, int222 <dbl+lbl>, int223 <dbl+lbl>, int710 <dbl+lbl>, int711 <dbl+lbl>,
## #   int712 <dbl+lbl>, int713 <dbl+lbl>, int714 <dbl+lbl>, int715 <dbl+lbl>, int716 <dbl+lbl>,
## #   var433 <dbl+lbl>, var439 <dbl+lbl>, var1329 <dbl+lbl>, var1330 <dbl+lbl>, var445 <dbl+lbl>,
## #   var446 <dbl+lbl>, var447 <dbl+lbl>, var451 <dbl+lbl>, var452 <dbl+lbl>, var1316 <dbl+lbl>,
## #   var1317 <dbl+lbl>, var1331 <dbl+lbl>, vw065 <dbl+lbl>, var491 <dbl+lbl>, var040 <dbl+lbl>,
## #   var1304 <dbl+lbl>, var274 <dbl+lbl>, var275 <dbl+lbl>, var1196 <dbl+lbl>, var1197 <dbl+lbl>,
## #   var461 <dbl+lbl>, var273 <dbl+lbl>, var1262 <dbl+lbl>, ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#fix(cv08_haven) #will produce an error}
\KeywordTok{fix}\NormalTok{(cv08)}
\KeywordTok{View}\NormalTok{(cv08_haven)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
Add to your cheat sheet under \textbf{functions}: \texttt{str(),\ summary(),\ attributes(),\ attr(),\ table(),\ names(),\ head(),\ fix(),\ View()}
\end{quote}

\hypertarget{define-missings}{%
\section{Define missings}\label{define-missings}}

Okay, lets start playing around with our dataset. We are going to have a look at specific variables, define missings, recode some values, etc. I will focus on the dataset created by the haven package.

\hypertarget{r-base}{%
\subsection{R Base}\label{r-base}}

Lets use age as example. This variable is called \textbf{lftop} in CV. First have a look at this variable.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{str}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{lftop)}
\KeywordTok{summary}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{lftop)}
\KeywordTok{attr}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{lftop, }\StringTok{"labels"}\NormalTok{)}
\KeywordTok{table}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{lftop, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  dbl+lbl [1:1963] 51, 39, 16, 29, 57, 49, 62, 34, 59, 41, 25, 43, 74, 17, 22, 32, 51, 66, 64, 2...
##  @ label        : chr "Leeftijd OP op datum interview"
##  @ format.spss  : chr "F10.0"
##  @ display_width: int 12
##  @ labels       : Named num [1:5] 0 1 2 99 125
##   ..- attr(*, "names")= chr [1:5] "< één jaar" "één jaar" "twee jaar" "Onbekend" ...
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   16.00   33.00   46.00   46.78   61.00   99.00 
## < één jaar   één jaar  twee jaar   Onbekend   125 jaar 
##          0          1          2         99        125 
## 
##   16   17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32   33   34   35 
##   40   37   39   30   30   25   25   38   26   22   18   23   29   30   22   28   23   23   24   38 
##   36   37   38   39   40   41   42   43   44   45   46   47   48   49   50   51   52   53   54   55 
##   35   37   34   48   45   34   36   39   43   38   41   32   41   45   29   29   43   32   25   27 
##   56   57   58   59   60   61   62   63   64   65   66   67   68   69   70   71   72   73   74   75 
##   27   30   44   34   33   36   40   29   27   30   19   24   24   24   23   21   13   15   26   10 
##   76   77   78   79   80   81   82   83   84   85   86   87   88   89   90   91   99 <NA> 
##   14   17   13   13   10    7   10   10    7    6    3    8    2    3    1    3    4    0
\end{verbatim}

We have category `onbekend', which should be a missing. Let's copy the original variable in a new one, and attach it to the dataset. Thus not:\\
\texttt{lftop\_new\ \textless{}-\ \ cv08\$lftop}~\\
but:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cv08}\OperatorTok{$}\NormalTok{lftop_new <-}\StringTok{  }\NormalTok{cv08}\OperatorTok{$}\NormalTok{lftop}
\end{Highlighting}
\end{Shaded}

You probably already noticed that to assign values to a new object we use \texttt{\textless{}-} What we now want to do is to replace those values of our new variable \texttt{cv08\$lftop\_new} which have the values \textbf{Onbekend}.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cv08}\OperatorTok{$}\NormalTok{lftop_new[cv08}\OperatorTok{$}\NormalTok{lftop_new}\OperatorTok{==}\StringTok{"Onbekend"}\NormalTok{] <-}\StringTok{  }\OtherTok{NA}
\end{Highlighting}
\end{Shaded}

Dont forget, if you want to understand the code work inside out.

\begin{quote}
Update your cheat sheet! Note that \texttt{==} is a logical operator. What are the other logical operators in R?\\
Note that \texttt{{[}{]}} is used to subset elements from an object (e.g.~dataframe/vector/matrix)\\
Note that \texttt{NA} is used in R to define missing values. It means Not Applicable.
\end{quote}

So did our recode work?

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{table}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{lftop_new, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## < één jaar   één jaar   125 jaar         16         17         18         19  twee jaar         20 
##          0          0          0         40         37         39         30          0         30 
##         21         22         23         24         25         26         27         28         29 
##         25         25         38         26         22         18         23         29         30 
##         30         31         32         33         34         35         36         37         38 
##         22         28         23         23         24         38         35         37         34 
##         39         40         41         42         43         44         45         46         47 
##         48         45         34         36         39         43         38         41         32 
##         48         49         50         51         52         53         54         55         56 
##         41         45         29         29         43         32         25         27         27 
##         57         58         59         60         61         62         63         64         65 
##         30         44         34         33         36         40         29         27         30 
##         66         67         68         69         70         71         72         73         74 
##         19         24         24         24         23         21         13         15         26 
##         75         76         77         78         79         80         81         82         83 
##         10         14         17         13         13         10          7         10         10 
##         84         85         86         87         88         89         90         91   Onbekend 
##          7          6          3          8          2          3          1          3          0 
##       <NA> 
##          4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{levels}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{lftop_new)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "< één jaar" "één jaar"   "125 jaar"   "16"         "17"         "18"         "19"        
##  [8] "twee jaar"  "20"         "21"         "22"         "23"         "24"         "25"        
## [15] "26"         "27"         "28"         "29"         "30"         "31"         "32"        
## [22] "33"         "34"         "35"         "36"         "37"         "38"         "39"        
## [29] "40"         "41"         "42"         "43"         "44"         "45"         "46"        
## [36] "47"         "48"         "49"         "50"         "51"         "52"         "53"        
## [43] "54"         "55"         "56"         "57"         "58"         "59"         "60"        
## [50] "61"         "62"         "63"         "64"         "65"         "66"         "67"        
## [57] "68"         "69"         "70"         "71"         "72"         "73"         "74"        
## [64] "75"         "76"         "77"         "78"         "79"         "80"         "81"        
## [71] "82"         "83"         "84"         "85"         "86"         "87"         "88"        
## [78] "89"         "90"         "91"         "Onbekend"
\end{verbatim}

But we want age as numeric variable not as a factor (categorical).

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{str}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{lftop_new)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  Factor w/ 81 levels "< één jaar","één jaar",..: 40 28 4 18 46 38 51 23 48 30 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cv08}\OperatorTok{$}\NormalTok{agen <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{as.character}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{lftop_new)) }\CommentTok{#how clumsy. we first convert the factor to a string and then to a numeric variable. }
\KeywordTok{table}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{agen, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##   16   17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32   33   34   35 
##   40   37   39   30   30   25   25   38   26   22   18   23   29   30   22   28   23   23   24   38 
##   36   37   38   39   40   41   42   43   44   45   46   47   48   49   50   51   52   53   54   55 
##   35   37   34   48   45   34   36   39   43   38   41   32   41   45   29   29   43   32   25   27 
##   56   57   58   59   60   61   62   63   64   65   66   67   68   69   70   71   72   73   74   75 
##   27   30   44   34   33   36   40   29   27   30   19   24   24   24   23   21   13   15   26   10 
##   76   77   78   79   80   81   82   83   84   85   86   87   88   89   90   91 <NA> 
##   14   17   13   13   10    7   10   10    7    6    3    8    2    3    1    3    4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{str}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{agen)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  num [1:1963] 51 39 16 29 57 49 62 34 59 41 ...
\end{verbatim}

\begin{quote}
Hint: R is case sensitive. Just try to avoid capitals in your variable names. There are people who have set up a whole list of rules how to name and label stuff. Interesting? You can have a look \href{https://style.tidyverse.org/}{here}.\\
I will use all\_lower\_case\_underscore\_seperated.\\
Add to your cheat sheet \texttt{as.character()} and \texttt{as.numeric()}.
\end{quote}

\hypertarget{tidy}{%
\subsection{Tidy}\label{tidy}}

Copy the variable\\
We will `mutate' the original dataset by adding a variable.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cv08_haven <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(cv08_haven, }\DataTypeTok{lftop_new=}\NormalTok{lftop)}
\end{Highlighting}
\end{Shaded}

Replace missings\\
Be aware that the value \textbf{99} is the ``onbekend'' category.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cv08_haven}\OperatorTok{$}\NormalTok{lftop_new <-}\StringTok{ }\KeywordTok{na_if}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{lftop_new, }\DecValTok{99}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Normally you would combine these two steps into one

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cv08_haven <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(cv08_haven, }\DataTypeTok{lftop_new=}\KeywordTok{na_if}\NormalTok{(lftop, }\DecValTok{99}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

check

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{table}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{lftop_new, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##   16   17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32   33   34   35 
##   40   37   39   30   30   25   25   38   26   22   18   23   29   30   22   28   23   23   24   38 
##   36   37   38   39   40   41   42   43   44   45   46   47   48   49   50   51   52   53   54   55 
##   35   37   34   48   45   34   36   39   43   38   41   32   41   45   29   29   43   32   25   27 
##   56   57   58   59   60   61   62   63   64   65   66   67   68   69   70   71   72   73   74   75 
##   27   30   44   34   33   36   40   29   27   30   19   24   24   24   23   21   13   15   26   10 
##   76   77   78   79   80   81   82   83   84   85   86   87   88   89   90   91 <NA> 
##   14   17   13   13   10    7   10   10    7    6    3    8    2    3    1    3    4
\end{verbatim}

An advantage of the tidy way is that it is more intuitive and requires less subsetting.\\
A disadvantage is that you need to know more specific functions.

\begin{quote}
Hint: In your cheat sheet, make a distinction between all the stuff that belongs to R Base and all specific functions, operators, etc. that are part of Tidyverse.\\
How do you know it is part of Tidyverse? Well, if you don't load tidyverse, the code will not work.
\end{quote}

\hypertarget{recoding-variables}{%
\section{Recoding variables}\label{recoding-variables}}

So, we defined a missing value for age. As a second example let us recode the variable education. This one is called \textbf{var006n} in CV08. Lets create a new variable \textbf{educ3} with three levels:\\
1. primary\\
2. secondary\\
3. tertiary

\hypertarget{r-base-1}{%
\subsection{R Base}\label{r-base-1}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{levels}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{var006n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "onbekend"                               "OP < 12 jr  of volgt actueel bas.ondw."
##  [3] "basisonderwijs"                         "vmbo"                                  
##  [5] "mavo"                                   "havo/vwo"                              
##  [7] "mbo"                                    "hbo"                                   
##  [9] "wo"                                     "wo_duplicated_8"                       
## [11] "Onbekend"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{table}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{var006n, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##                               onbekend OP < 12 jr  of volgt actueel bas.ondw. 
##                                      5                                      0 
##                         basisonderwijs                                   vmbo 
##                                    380                                    287 
##                                   mavo                               havo/vwo 
##                                    137                                    106 
##                                    mbo                                    hbo 
##                                    543                                    339 
##                                     wo                        wo_duplicated_8 
##                                      0                                    166 
##                               Onbekend                                   <NA> 
##                                      0                                      0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#lets make it a numeric var first}
\NormalTok{cv08}\OperatorTok{$}\NormalTok{educn <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{var006n)}
\CommentTok{#check}
\KeywordTok{table}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{educn, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##    1    3    4    5    6    7    8   10 <NA> 
##    5  380  287  137  106  543  339  166    0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#start with an empty variable}
\NormalTok{cv08}\OperatorTok{$}\NormalTok{educ3 <-}\StringTok{ }\OtherTok{NA}
\CommentTok{#fill category by category}
\NormalTok{cv08}\OperatorTok{$}\NormalTok{educ3[cv08}\OperatorTok{$}\NormalTok{educn}\OperatorTok{==}\DecValTok{2} \OperatorTok{|}\StringTok{ }\NormalTok{cv08}\OperatorTok{$}\NormalTok{educn}\OperatorTok{==}\DecValTok{3}\NormalTok{] <-}\StringTok{ }\DecValTok{1}
\NormalTok{cv08}\OperatorTok{$}\NormalTok{educ3[cv08}\OperatorTok{$}\NormalTok{educn}\OperatorTok{>}\DecValTok{3} \OperatorTok{&}\StringTok{ }\NormalTok{cv08}\OperatorTok{$}\NormalTok{educn}\OperatorTok{<}\DecValTok{8}\NormalTok{] <-}\StringTok{ }\DecValTok{2}
\NormalTok{cv08}\OperatorTok{$}\NormalTok{educ3[cv08}\OperatorTok{$}\NormalTok{educn}\OperatorTok{>}\DecValTok{7} \OperatorTok{&}\StringTok{ }\NormalTok{cv08}\OperatorTok{$}\NormalTok{educn}\OperatorTok{<}\DecValTok{11}\NormalTok{] <-}\StringTok{ }\DecValTok{3}

\CommentTok{#check}
\KeywordTok{table}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{educ3, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##    1    2    3 <NA> 
##  380 1073  505    5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{prop.table}\NormalTok{(}\KeywordTok{table}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{educ3, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##           1           2           3        <NA> 
## 0.193581253 0.546612328 0.257259297 0.002547122
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#now educ3 is a numeric variable, we want it as factor}
\NormalTok{cv08}\OperatorTok{$}\NormalTok{educ3 <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{educ3)}
\KeywordTok{table}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{educ3, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##    1    2    3 <NA> 
##  380 1073  505    5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{levels}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{educ3) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"primary"}\NormalTok{, }\StringTok{"secondary"}\NormalTok{, }\StringTok{"tertiary"}\NormalTok{)}
\KeywordTok{table}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{educ3, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##   primary secondary  tertiary      <NA> 
##       380      1073       505         5
\end{verbatim}

\begin{quote}
Is this really the first time we encountered the function \texttt{c()}? Well, make sure it is somewhere at the top of your cheat sheet.
\end{quote}

\hypertarget{tidy-1}{%
\subsection{Tidy}\label{tidy-1}}

And now the fun starts. Tidyverse includes a \texttt{dplyr::recode} function, but this function does not work on labeled variables imported via the haven package. Luckily, there is a package that extends the original function, \texttt{labelled}.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#install.packages("labelled")}
\KeywordTok{require}\NormalTok{(labelled) }\CommentTok{#to be able to use the recode function on haven labelled variables}

\CommentTok{#inspect variable}
\KeywordTok{str}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{var006n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  dbl+lbl [1:1963] 6, 8, 3, 8, 6, 2, 2, 5, 5, 1, 1, 3, 2, 1, 1, 5, 6, 3, 1, 5, 6, 2, 5, 6, 1, 3,...
##  @ label        : chr "Voltooid opleidingsniveau (uitgebreid) OP, 12-14 jarigen niet standaard op bas.ondw."
##  @ format.spss  : chr "F10.0"
##  @ display_width: int 12
##  @ labels       : Named num [1:11] -3 -1 1 2 3 4 5 6 7 8 ...
##   ..- attr(*, "names")= chr [1:11] "onbekend" "OP < 12 jr  of volgt actueel bas.ondw." "basisonderwijs" "vmbo" ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{attr}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{var006n, }\StringTok{"labels"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                               onbekend OP < 12 jr  of volgt actueel bas.ondw. 
##                                 -3e+00                                 -1e+00 
##                         basisonderwijs                                   vmbo 
##                                  1e+00                                  2e+00 
##                                   mavo                               havo/vwo 
##                                  3e+00                                  4e+00 
##                                    mbo                                    hbo 
##                                  5e+00                                  6e+00 
##                                     wo                                     wo 
##                                  7e+00                                  8e+00 
##                               Onbekend 
##                                  1e+10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{table}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{var006n, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##   -3    1    2    3    4    5    6    8 <NA> 
##    5  380  287  137  106  543  339  166    0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#recode values, all missings as one value}
\NormalTok{cv08_haven <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(cv08_haven, }\DataTypeTok{educ3=}\KeywordTok{recode}\NormalTok{(var006n, }\StringTok{'-3'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{, }\StringTok{'-1'}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{'1'}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{'2'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{ , }\StringTok{'3'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'4'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'5'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'6'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'7'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'8'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'10'}\NormalTok{=}\StringTok{ }\DecValTok{-9}\NormalTok{), }\DataTypeTok{.keep_value_labels =} \OtherTok{FALSE}\NormalTok{)}

\CommentTok{#replace missing values with NA.}
\NormalTok{cv08_haven <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(cv08_haven, }\DataTypeTok{educ3=}\KeywordTok{na_if}\NormalTok{(educ3, }\DecValTok{-9}\NormalTok{))}

\CommentTok{#make educ3 a factor}
\NormalTok{cv08_haven <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(cv08_haven, }\DataTypeTok{educ3=}\KeywordTok{factor}\NormalTok{(educ3, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{),}
\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"primary"}\NormalTok{, }\StringTok{"secondary"}\NormalTok{, }\StringTok{"tertiary"}\NormalTok{)))}

\CommentTok{#check}
\KeywordTok{table}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{educ3, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##   primary secondary  tertiary      <NA> 
##       380      1073       505         5
\end{verbatim}

Personally, I think this is all quite complicated. But I guess this is a matter of taste.

And advantage of the Tidy way is that you could use the \texttt{\%\textgreater{}\%}, piping, operator. Now, your code does not read from the inside out but from left to right. For many people this is more intuitive. The output of the function on the left is transported to the (first argument of the) function on the right. Thus, in the example below, you see that in the second and third call to mutate I don't have to tell the function which dataset I am using.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cv08_haven <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(cv08_haven, }\DataTypeTok{educ3=}\KeywordTok{recode}\NormalTok{(var006n, }\StringTok{'-3'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{, }\StringTok{'-1'}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{'1'}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{'2'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{ , }\StringTok{'3'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'4'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'5'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'6'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'7'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'8'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'10'}\NormalTok{=}\StringTok{ }\DecValTok{-9}\NormalTok{), }\DataTypeTok{.keep_value_labels =} \OtherTok{FALSE}\NormalTok{) }\OperatorTok{%>%}\StringTok{  }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{educ3=}\KeywordTok{na_if}\NormalTok{(educ3, }\DecValTok{-9}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{educ3=}\KeywordTok{factor}\NormalTok{(educ3, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{), }\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"primary"}\NormalTok{, }\StringTok{"secondary"}\NormalTok{, }\StringTok{"tertiary"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

Perhaps an even tidier way would be:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cv08_haven <-}\StringTok{ }\NormalTok{cv08_haven }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{educ3=}\KeywordTok{recode}\NormalTok{(var006n, }\StringTok{'-3'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{, }\StringTok{'-1'}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{'1'}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{'2'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{ , }\StringTok{'3'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'4'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'5'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'6'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'7'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'8'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'10'}\NormalTok{=}\StringTok{ }\DecValTok{-9}\NormalTok{), }\DataTypeTok{.keep_value_labels =} \OtherTok{FALSE}\NormalTok{) }\OperatorTok{%>%}\StringTok{  }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{educ3=}\KeywordTok{na_if}\NormalTok{(educ3, }\DecValTok{-9}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{educ3=}\KeywordTok{factor}\NormalTok{(educ3, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{), }\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"primary"}\NormalTok{, }\StringTok{"secondary"}\NormalTok{, }\StringTok{"tertiary"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

In the example above, it still may `feel' a little clumsy to have to make a call to the same \texttt{mutate} function three times. Well, this is indeed not necessary.

Thus, the most tidy way is:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cv08_haven <-}\StringTok{ }\NormalTok{cv08_haven }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{educ3=}\KeywordTok{recode}\NormalTok{(var006n, }\StringTok{'-3'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{, }\StringTok{'-1'}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{'1'}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{'2'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{ , }\StringTok{'3'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'4'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'5'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'6'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'7'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'8'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'10'}\NormalTok{=}\StringTok{ }\DecValTok{-9}\NormalTok{, }\DataTypeTok{.keep_value_labels =} \OtherTok{FALSE}\NormalTok{),}
         \DataTypeTok{educ3=}\KeywordTok{na_if}\NormalTok{(educ3, }\DecValTok{-9}\NormalTok{),}
         \DataTypeTok{educ3=}\KeywordTok{factor}\NormalTok{(educ3, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{), }\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"primary"}\NormalTok{, }\StringTok{"secondary"}\NormalTok{, }\StringTok{"tertiary"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\hypertarget{means-and-counting-specific-values}{%
\section{Means and counting specific values}\label{means-and-counting-specific-values}}

\hypertarget{r-base-2}{%
\subsection{R Base}\label{r-base-2}}

Next step. Lets calculate a mean. We will use three questions in CV on polarization. This does not make any theoretical sense of course.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#Step 1: have a look at the vars}
\KeywordTok{summary}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{int055)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                 Geen opgave                      N.v.t.                   Weet niet 
##                           0                           0                          85 
##                     Weigert                  Zeer groot                       Groot 
##                           0                          57                         551 
##               Niet zo groot Helemaal geen tegenstelling 
##                        1213                          57
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{summary}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{int056)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                 Geen opgave                      N.v.t.                   Weet niet 
##                           0                           0                         118 
##                     Weigert                  Zeer groot                       Groot 
##                           0                         258                         987 
##               Niet zo groot Helemaal geen tegenstelling 
##                         571                          29
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{summary}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{int057)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                 Geen opgave                      N.v.t.                   Weet niet 
##                           0                           0                         145 
##                     Weigert                  Zeer groot                       Groot 
##                           0                         213                         803 
##               Niet zo groot Helemaal geen tegenstelling 
##                         756                          46
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#Step 2: make numeric}
\NormalTok{cv08}\OperatorTok{$}\NormalTok{int055n <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{int055)}
\KeywordTok{table}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{int055n, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##    3    5    6    7    8 <NA> 
##   85   57  551 1213   57    0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cv08}\OperatorTok{$}\NormalTok{int056n <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{int056)}
\KeywordTok{table}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{int056n, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##    3    5    6    7    8 <NA> 
##  118  258  987  571   29    0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cv08}\OperatorTok{$}\NormalTok{int057n <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{int057)}
\KeywordTok{table}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{int057n, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##    3    5    6    7    8 <NA> 
##  145  213  803  756   46    0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#Step 3: define missings and recode}
\NormalTok{cv08}\OperatorTok{$}\NormalTok{int055n[cv08}\OperatorTok{$}\NormalTok{int055n}\OperatorTok{<}\DecValTok{5}\NormalTok{] <-}\StringTok{ }\OtherTok{NA}
\NormalTok{cv08}\OperatorTok{$}\NormalTok{int055n <-}\StringTok{ }\NormalTok{cv08}\OperatorTok{$}\NormalTok{int055n  }\OperatorTok{-}\StringTok{ }\DecValTok{4}
\NormalTok{cv08}\OperatorTok{$}\NormalTok{int056n[cv08}\OperatorTok{$}\NormalTok{int056n}\OperatorTok{<}\DecValTok{5}\NormalTok{] <-}\StringTok{ }\OtherTok{NA}
\NormalTok{cv08}\OperatorTok{$}\NormalTok{int056n <-}\StringTok{ }\NormalTok{cv08}\OperatorTok{$}\NormalTok{int056n  }\OperatorTok{-}\StringTok{ }\DecValTok{4}
\NormalTok{cv08}\OperatorTok{$}\NormalTok{int057n[cv08}\OperatorTok{$}\NormalTok{int057n}\OperatorTok{<}\DecValTok{5}\NormalTok{] <-}\StringTok{ }\OtherTok{NA}
\NormalTok{cv08}\OperatorTok{$}\NormalTok{int057n <-}\StringTok{ }\NormalTok{cv08}\OperatorTok{$}\NormalTok{int057n  }\OperatorTok{-}\StringTok{ }\DecValTok{4}

\CommentTok{#Step 4: calculate means. }
\CommentTok{#How does the function mean work in R?}
\KeywordTok{mean}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{int055n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{mean}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{int055n, }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.676251
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{mean}\NormalTok{(}\KeywordTok{c}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{int055n, cv08}\OperatorTok{$}\NormalTok{int056n, cv08}\OperatorTok{$}\NormalTok{int057n), }\DataTypeTok{na.rm =}\NormalTok{ T)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.410756
\end{verbatim}

This is not what we want. What we want is to calculate a mean for each row/respondent. This will do the trick:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{testmeans <-}\StringTok{ }\KeywordTok{rowMeans}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{int055n, cv08}\OperatorTok{$}\NormalTok{int056n, cv08}\OperatorTok{$}\NormalTok{int057n), }\DataTypeTok{na.rm =}\NormalTok{ T)}
\KeywordTok{head}\NormalTok{(testmeans)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.333333 2.666667 2.666667 2.333333 1.500000 1.333333
\end{verbatim}

What we really want is a mean but only if there is a maximum of 1 NA in the three variables.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#lets first count how many missings we have for each respondent}
\NormalTok{nmis <-}\StringTok{ }\KeywordTok{rowSums}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{int055n, cv08}\OperatorTok{$}\NormalTok{int056n, cv08}\OperatorTok{$}\NormalTok{int057n)))}

\CommentTok{# ?is.na}
\CommentTok{# ?rowSums}

\NormalTok{testmeans <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(nmis}\OperatorTok{<}\DecValTok{2}\NormalTok{,testmeans, }\OtherTok{NA}\NormalTok{)}

\CommentTok{#add the calculated means to our dataset}
\NormalTok{cv08}\OperatorTok{$}\NormalTok{int_mean <-}\StringTok{ }\NormalTok{testmeans}

\CommentTok{#Bonus: count specific values}
\CommentTok{#so now we have this, it is easy to find how many times respondents answered 'zeer groot', that is '1'}
\NormalTok{timesZG <-}\StringTok{ }\KeywordTok{rowSums}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(cv08}\OperatorTok{$}\NormalTok{int055n, cv08}\OperatorTok{$}\NormalTok{int056n, cv08}\OperatorTok{$}\NormalTok{int057n)}\OperatorTok{==}\DecValTok{1}\NormalTok{, }\DataTypeTok{na.rm=}\NormalTok{T)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
You need to add a lot of very powerful functions to your cheat sheet: \texttt{mean()}, \texttt{rowMeans()}, \texttt{rowSums}, \texttt{cbind()}, \texttt{is.na()}, \texttt{ifelse().}

Did you also notice that the logicals \textbf{FALSE} and \textbf{TRUE} can be summed? (FALSE equals 0 and TRUE equals 1).
\end{quote}

\hypertarget{tidy-2}{%
\subsection{Tidy}\label{tidy-2}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#Step 1: have a look at the vars}
\KeywordTok{str}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{int055)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  dbl+lbl [1:1963]  3,  3,  3,  2, -3,  1,  2,  3,  3,  2,  2,  3,  3,  3,  3,  2,  3,  2,  3,  ...
##  @ label        : chr "Tegenstelling arbeidersklasse en middenklasse"
##  @ format.spss  : chr "F10.0"
##  @ display_width: int 12
##  @ labels       : Named num [1:8] -6 -5 -3 -2 1 2 3 4
##   ..- attr(*, "names")= chr [1:8] "Geen opgave" "N.v.t." "Weet niet" "Weigert" ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{attr}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{int055, }\StringTok{"labels"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                 Geen opgave                      N.v.t.                   Weet niet 
##                          -6                          -5                          -3 
##                     Weigert                  Zeer groot                       Groot 
##                          -2                           1                           2 
##               Niet zo groot Helemaal geen tegenstelling 
##                           3                           4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{summary}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{int055)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   -3.00    2.00    3.00    2.43    3.00    4.00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{summary}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{int056)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  -3.000   2.000   2.000   1.888   3.000   4.000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{summary}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{int057)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  -3.000   2.000   2.000   1.954   3.000   4.000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{table}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{int055n, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Unknown or uninitialised column: `int055n`.
\end{verbatim}

\begin{verbatim}
## 
## <NA> 
##    0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{table}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{int056, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##   -3    1    2    3    4 <NA> 
##  118  258  987  571   29    0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{table}\NormalTok{(cv08_haven}\OperatorTok{$}\NormalTok{int057, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##   -3    1    2    3    4 <NA> 
##  145  213  803  756   46    0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#Step 2: define missings and recode}
\NormalTok{cv08_haven <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(cv08_haven, }\DataTypeTok{int055n=}\KeywordTok{recode}\NormalTok{(int055, }\StringTok{'-6'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{, }\StringTok{'-5'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{,}\StringTok{'-3'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{,}\StringTok{'-2'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{, }\StringTok{'1'}\NormalTok{=}\DecValTok{4}\NormalTok{, }\StringTok{'2'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{ , }\StringTok{'3'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'4'}\NormalTok{=}\StringTok{ }\DecValTok{1}\NormalTok{), }\DataTypeTok{.keep_value_labels =} \OtherTok{FALSE}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{int055n=}\KeywordTok{na_if}\NormalTok{(int055n, }\DecValTok{-9}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{int055n=}\KeywordTok{labelled}\NormalTok{(int055n, }\KeywordTok{c}\NormalTok{(}\StringTok{"Helemaal geen tegenstelling"}\NormalTok{ =}\StringTok{ }\DecValTok{1}\NormalTok{, }\StringTok{"Niet zo groot"}\NormalTok{ =}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{"Groot"}\NormalTok{=}\DecValTok{3}\NormalTok{, }\StringTok{"Zeer groot"}\NormalTok{=}\DecValTok{4}\NormalTok{)))}

\NormalTok{cv08_haven <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(cv08_haven, }\DataTypeTok{int056n=}\KeywordTok{recode}\NormalTok{(int056, }\StringTok{'-6'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{, }\StringTok{'-5'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{,}\StringTok{'-3'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{,}\StringTok{'-2'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{, }\StringTok{'1'}\NormalTok{=}\DecValTok{4}\NormalTok{, }\StringTok{'2'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{ , }\StringTok{'3'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'4'}\NormalTok{=}\StringTok{ }\DecValTok{1}\NormalTok{), }\DataTypeTok{.keep_value_labels =} \OtherTok{FALSE}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{int056n=}\KeywordTok{na_if}\NormalTok{(int056n, }\DecValTok{-9}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{int056n=}\KeywordTok{labelled}\NormalTok{(int056n, }\KeywordTok{c}\NormalTok{(}\StringTok{"Helemaal geen tegenstelling"}\NormalTok{ =}\StringTok{ }\DecValTok{1}\NormalTok{, }\StringTok{"Niet zo groot"}\NormalTok{ =}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{"Groot"}\NormalTok{=}\DecValTok{3}\NormalTok{, }\StringTok{"Zeer groot"}\NormalTok{=}\DecValTok{4}\NormalTok{)))}

\NormalTok{cv08_haven <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(cv08_haven, }\DataTypeTok{int057n=}\KeywordTok{recode}\NormalTok{(int057, }\StringTok{'-6'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{, }\StringTok{'-5'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{,}\StringTok{'-3'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{,}\StringTok{'-2'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{, }\StringTok{'1'}\NormalTok{=}\DecValTok{4}\NormalTok{, }\StringTok{'2'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{ , }\StringTok{'3'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'4'}\NormalTok{=}\StringTok{ }\DecValTok{1}\NormalTok{), }\DataTypeTok{.keep_value_labels =} \OtherTok{FALSE}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{int057n=}\KeywordTok{na_if}\NormalTok{(int057n, }\DecValTok{-9}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{int057n=}\KeywordTok{labelled}\NormalTok{(int057n, }\KeywordTok{c}\NormalTok{(}\StringTok{"Helemaal geen tegenstelling"}\NormalTok{ =}\StringTok{ }\DecValTok{1}\NormalTok{, }\StringTok{"Niet zo groot"}\NormalTok{ =}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{"Groot"}\NormalTok{=}\DecValTok{3}\NormalTok{, }\StringTok{"Zeer groot"}\NormalTok{=}\DecValTok{4}\NormalTok{)))}


\CommentTok{#Step 3: calculate means. }
\CommentTok{## option 1}
\NormalTok{cv08_haven <-}\StringTok{ }\NormalTok{cv08_haven }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{rowwise}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{int_mean =} \KeywordTok{mean}\NormalTok{(}\KeywordTok{c}\NormalTok{(int055n, int056n, int057n), }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{))}


\CommentTok{## option 2}
\NormalTok{cv08_haven <-}\StringTok{ }\NormalTok{cv08_haven }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{int_mean =} \KeywordTok{rowMeans}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(int055n, int056n, int057n), }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{))}

\CommentTok{#what we really want is a mean but only if there is a maximum of 1 NA in the three variables}

\NormalTok{cv08_haven <-}\StringTok{ }\NormalTok{cv08_haven }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{int_mean_temp =} \KeywordTok{rowMeans}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(int055n, int056n, int057n), }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{),}
         \DataTypeTok{nmis =} \KeywordTok{rowSums}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(int055n, int056n, int057n))), }
         \DataTypeTok{int_mean =} \KeywordTok{ifelse}\NormalTok{(nmis}\OperatorTok{<}\DecValTok{2}\NormalTok{, int_mean_temp, }\OtherTok{NA}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{int_mean_temp, }\OperatorTok{-}\NormalTok{nmis)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
So what are you adding to your cheat sheet? \texttt{rowwise()}, \texttt{select()}.
\end{quote}

\hypertarget{merging-data-files}{%
\section{Merging data files}\label{merging-data-files}}

What you need to know 1: Panel or stacked cross-sections?\\
What you need to know 2: If panel, do you want data in long or wide format?

We need to follow these steps:

\begin{itemize}
\tightlist
\item
  Step1: select variables
\item
  Step2: make consistent
\item
  Step3: perform the actual merging. Make sure to include necessary identifier variables.
\item
  Step4: check your results!!
\end{itemize}

\hypertarget{r-base-3}{%
\subsection{R Base}\label{r-base-3}}

\hypertarget{step1-select-variables}{%
\subsubsection{Step1: select variables}\label{step1-select-variables}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#step 1: selecting the variables you want to keep.}
\CommentTok{#for this tutorial only 6 variables: id, age, sex, educ, health, region (not that R is case sensitive)}
\NormalTok{cv08_sel <-}\StringTok{ }\NormalTok{cv08[,}\KeywordTok{c}\NormalTok{(}\StringTok{"we_id"}\NormalTok{, }\StringTok{"lftop"}\NormalTok{, }\StringTok{"geslacht"}\NormalTok{, }\StringTok{"var006n"}\NormalTok{, }\StringTok{"v401"}\NormalTok{, }\StringTok{"landd"}\NormalTok{)]}
\NormalTok{cv10_sel <-}\StringTok{ }\NormalTok{cv10[,}\KeywordTok{c}\NormalTok{(}\StringTok{"Sleutel"}\NormalTok{, }\StringTok{"var002"}\NormalTok{, }\StringTok{"var001"}\NormalTok{, }\StringTok{"Vltoplop"}\NormalTok{, }\StringTok{"V401"}\NormalTok{, }\StringTok{"Landd"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{quote}
Note that to select rows, you need to set an expression before the ``,'' {[}row,{]} and to select columns, after the ``,'' {[},col{]}. Thus with \texttt{dataset{[}i,j{]}} you will select row \emph{i} and column \emph{j}. You have learned to subset dataframes by using indici (e.g.~\texttt{dataset{[},1:3{]}}), logical expressions (e.g.~\texttt{dataset{[}var1\textgreater{}1,{]})}, and names (e.g.~\texttt{dataset{[},"varname"{]}}).
\end{quote}

\hypertarget{step2-make-consistent}{%
\subsubsection{Step2: make consistent}\label{step2-make-consistent}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#step 2: making the variables similar across individual datasets}
\CommentTok{#step 2a: making names the same}
\KeywordTok{names}\NormalTok{(cv08_sel) <-}\StringTok{ }\KeywordTok{names}\NormalTok{(cv10_sel) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"id"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"sex"}\NormalTok{, }\StringTok{"educ"}\NormalTok{, }\StringTok{"health"}\NormalTok{, }\StringTok{"region"}\NormalTok{)}

\CommentTok{#step 2b: making levels and labels consistent}
\KeywordTok{summary}\NormalTok{(cv08_sel)}
\KeywordTok{summary}\NormalTok{(cv10_sel)}
\CommentTok{#they look very consistent already. but check carefully. }

\CommentTok{#we don't want id to be a factor but numeric. Note that we don't want the factor level values as numbers but the actual labels as numbers. }

\CommentTok{#id}
\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{id <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{as.character}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{id))}
\NormalTok{cv10_sel}\OperatorTok{$}\NormalTok{id <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{as.character}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{id))}

\CommentTok{#age}
\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{age <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{as.character}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{age))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: NAs introduced by coercion
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cv10_sel}\OperatorTok{$}\NormalTok{age <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{as.character}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{age))}

\CommentTok{#sex men}
\KeywordTok{levels}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{sex)}
\KeywordTok{levels}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{sex)}
\KeywordTok{table}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{sex, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\KeywordTok{table}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{sex, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\CommentTok{#lets make it a numeric var first}
\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{sexn <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{sex)}
\KeywordTok{table}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{sexn)}
\CommentTok{#recode into dummy}
\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{men <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{sexn}\OperatorTok{==}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{men <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{sexn}\OperatorTok{==}\DecValTok{1}\NormalTok{, }\OtherTok{NA}\NormalTok{, cv08_sel}\OperatorTok{$}\NormalTok{men)}
\CommentTok{#check}
\KeywordTok{table}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{men, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\CommentTok{#lets make it a numeric var first}
\NormalTok{cv10_sel}\OperatorTok{$}\NormalTok{sexn <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{sex)}
\KeywordTok{table}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{sexn)}
\CommentTok{#recode into dummy}
\NormalTok{cv10_sel}\OperatorTok{$}\NormalTok{men <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{sexn}\OperatorTok{==}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\CommentTok{#check}
\KeywordTok{table}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{men, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}

\CommentTok{#educ educ3}
\KeywordTok{levels}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{educ)}
\KeywordTok{levels}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{educ)}
\KeywordTok{table}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{educ, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\KeywordTok{table}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{educ, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\CommentTok{#lets make it a numeric var first}
\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{educn <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{educ)}
\KeywordTok{table}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{educn)}
\CommentTok{#recode into 3cats: 1 primair, 2 secundair, 3 is tertiair}
\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{educ3 <-}\StringTok{ }\OtherTok{NA}
\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{educ3[cv08_sel}\OperatorTok{$}\NormalTok{educn}\OperatorTok{==}\DecValTok{2} \OperatorTok{|}\StringTok{ }\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{educn}\OperatorTok{==}\DecValTok{3}\NormalTok{] <-}\StringTok{ }\DecValTok{1}
\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{educ3[cv08_sel}\OperatorTok{$}\NormalTok{educn}\OperatorTok{>}\DecValTok{3} \OperatorTok{&}\StringTok{ }\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{educn}\OperatorTok{<}\DecValTok{8}\NormalTok{] <-}\StringTok{ }\DecValTok{2}
\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{educ3[cv08_sel}\OperatorTok{$}\NormalTok{educn}\OperatorTok{>}\DecValTok{7} \OperatorTok{&}\StringTok{ }\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{educn}\OperatorTok{<}\DecValTok{11}\NormalTok{] <-}\StringTok{ }\DecValTok{3}
\CommentTok{#check}
\KeywordTok{table}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{educ3, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\KeywordTok{prop.table}\NormalTok{(}\KeywordTok{table}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{educ3, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{))}

\CommentTok{#lets make it a numeric var first}
\NormalTok{cv10_sel}\OperatorTok{$}\NormalTok{educn <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{educ)}
\KeywordTok{table}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{educn)}
\CommentTok{#recode into 3cats: 1 primair, 2 secundari, 3 is tertiair}
\NormalTok{cv10_sel}\OperatorTok{$}\NormalTok{educ3 <-}\StringTok{ }\OtherTok{NA}
\NormalTok{cv10_sel}\OperatorTok{$}\NormalTok{educ3[cv10_sel}\OperatorTok{$}\NormalTok{educn}\OperatorTok{<}\DecValTok{3}\NormalTok{] <-}\StringTok{ }\DecValTok{1} \CommentTok{#correct?}
\NormalTok{cv10_sel}\OperatorTok{$}\NormalTok{educ3[cv10_sel}\OperatorTok{$}\NormalTok{educn}\OperatorTok{>}\DecValTok{2} \OperatorTok{&}\StringTok{ }\NormalTok{cv10_sel}\OperatorTok{$}\NormalTok{educn}\OperatorTok{<}\DecValTok{6}\NormalTok{] <-}\StringTok{ }\DecValTok{2}
\NormalTok{cv10_sel}\OperatorTok{$}\NormalTok{educ3[cv10_sel}\OperatorTok{$}\NormalTok{educn}\OperatorTok{==}\DecValTok{6}\NormalTok{] <-}\StringTok{ }\DecValTok{3}
\CommentTok{#check}
\KeywordTok{table}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{educ3, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{)}
\KeywordTok{prop.table}\NormalTok{(}\KeywordTok{table}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{educ3, }\DataTypeTok{useNA=}\StringTok{"always"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{step3-merge}{%
\subsubsection{Step3: merge}\label{step3-merge}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#lets add a wave variable}
\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{wave <-}\StringTok{ }\DecValTok{2008}
\NormalTok{cv10_sel}\OperatorTok{$}\NormalTok{wave <-}\StringTok{ }\DecValTok{2010}

\CommentTok{#let make a fake ID, we will use this later when we pretend CV is panel data. }
\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{id2 <-}\StringTok{ }\KeywordTok{rank}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{id)}
\NormalTok{cv10_sel}\OperatorTok{$}\NormalTok{id2 <-}\StringTok{ }\KeywordTok{rank}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{id)}

\CommentTok{#simply place one dataset under the other thus row bind (rbind)}
\CommentTok{#check first if same vars in both datasets.}
\CommentTok{#perhaps clean up first. }

\NormalTok{cv08_sel <-}\StringTok{ }\NormalTok{cv08_sel[,}\KeywordTok{c}\NormalTok{(}\StringTok{"id"}\NormalTok{,}\StringTok{"id2"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"men"}\NormalTok{, }\StringTok{"educ3"}\NormalTok{, }\StringTok{"health"}\NormalTok{, }\StringTok{"region"}\NormalTok{, }\StringTok{"wave"}\NormalTok{)]}
\NormalTok{cv10_sel <-}\StringTok{ }\NormalTok{cv10_sel[,}\KeywordTok{c}\NormalTok{(}\StringTok{"id"}\NormalTok{, }\StringTok{"id2"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"men"}\NormalTok{, }\StringTok{"educ3"}\NormalTok{, }\StringTok{"health"}\NormalTok{, }\StringTok{"region"}\NormalTok{, }\StringTok{"wave"}\NormalTok{)]}

\KeywordTok{summary}\NormalTok{(cv08_sel)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        id                id2              age             men           educ3      
##  Min.   :36775330   Min.   :   1.0   Min.   :16.00   Min.   :0.00   Min.   :1.000  
##  1st Qu.:37604540   1st Qu.: 491.5   1st Qu.:33.00   1st Qu.:0.00   1st Qu.:2.000  
##  Median :38724230   Median : 982.0   Median :46.00   Median :1.00   Median :2.000  
##  Mean   :38830177   Mean   : 982.0   Mean   :46.67   Mean   :0.51   Mean   :2.064  
##  3rd Qu.:40598965   3rd Qu.:1472.5   3rd Qu.:60.00   3rd Qu.:1.00   3rd Qu.:3.000  
##  Max.   :41199300   Max.   :1963.0   Max.   :91.00   Max.   :1.00   Max.   :3.000  
##                                      NA's   :4       NA's   :10     NA's   :5      
##              health                         region         wave     
##  goed,          :1060   Postcode (nog) onbekend:  0   Min.   :2008  
##  zeer goed,     : 504   Noord-Nederland        :220   1st Qu.:2008  
##  gaat wel,      : 320   Oost-Nederland         :416   Median :2008  
##  slecht,        :  67   West-Nederland         :853   Mean   :2008  
##  of zeer slecht?:  12   Zuid-Nederland         :474   3rd Qu.:2008  
##  Geen opgave    :   0                                 Max.   :2008  
##  (Other)        :   0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{summary}\NormalTok{(cv10_sel)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        id                id2              age             men            educ3      
##  Min.   :20131231   Min.   :   1.0   Min.   :16.00   Min.   :0.000   Min.   :1.000  
##  1st Qu.:20131965   1st Qu.: 734.8   1st Qu.:34.00   1st Qu.:0.000   1st Qu.:2.000  
##  Median :20132698   Median :1468.5   Median :48.00   Median :0.000   Median :2.000  
##  Mean   :20132698   Mean   :1468.5   Mean   :48.27   Mean   :0.485   Mean   :2.106  
##  3rd Qu.:20133432   3rd Qu.:2202.2   3rd Qu.:63.00   3rd Qu.:1.000   3rd Qu.:3.000  
##  Max.   :20134166   Max.   :2936.0   Max.   :96.00   Max.   :1.000   Max.   :3.000  
##                                                                      NA's   :3      
##              health                 region          wave     
##  goed,          :1592   Noord-Nederland: 306   Min.   :2010  
##  zeer goed,     : 776   Oost-Nederland : 678   1st Qu.:2010  
##  gaat wel,      : 466   West-Nederland :1263   Median :2010  
##  slecht,        :  79   Zuid-Nederland : 689   Mean   :2010  
##  of zeer slecht?:  22                          3rd Qu.:2010  
##  Weigert        :   1                          Max.   :2010  
##  (Other)        :   0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cv_tot <-}\StringTok{ }\KeywordTok{rbind}\NormalTok{(cv08_sel, cv10_sel)}
\end{Highlighting}
\end{Shaded}

\hypertarget{step4-check}{%
\subsubsection{Step4: check}\label{step4-check}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{summary}\NormalTok{(cv_tot)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        id                id2            age             men            educ3      
##  Min.   :20131231   Min.   :   1   Min.   :16.00   Min.   :0.000   Min.   :1.000  
##  1st Qu.:20132456   1st Qu.: 613   1st Qu.:33.00   1st Qu.:0.000   1st Qu.:2.000  
##  Median :20133680   Median :1225   Median :47.00   Median :0.000   Median :2.000  
##  Mean   :27624666   Mean   :1274   Mean   :47.63   Mean   :0.495   Mean   :2.089  
##  3rd Qu.:37978375   3rd Qu.:1838   3rd Qu.:62.00   3rd Qu.:1.000   3rd Qu.:3.000  
##  Max.   :41199300   Max.   :2936   Max.   :96.00   Max.   :1.000   Max.   :3.000  
##                                    NA's   :4       NA's   :10      NA's   :8      
##              health                         region          wave     
##  goed,          :2652   Postcode (nog) onbekend:   0   Min.   :2008  
##  zeer goed,     :1280   Noord-Nederland        : 526   1st Qu.:2008  
##  gaat wel,      : 786   Oost-Nederland         :1094   Median :2010  
##  slecht,        : 146   West-Nederland         :2116   Mean   :2009  
##  of zeer slecht?:  34   Zuid-Nederland         :1163   3rd Qu.:2010  
##  Weigert        :   1                                  Max.   :2010  
##  (Other)        :   0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{head}\NormalTok{(cv_tot)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         id id2 age men educ3    health         region wave
## 1 36775330   1  51   1     3     goed, West-Nederland 2008
## 2 36775340   2  39   0     3     goed, West-Nederland 2008
## 3 36775420   3  16   0     2     goed, West-Nederland 2008
## 4 36775440   4  29   1     3     goed, West-Nederland 2008
## 5 36775450   5  57   1     3 gaat wel, West-Nederland 2008
## 6 36775460   6  49   0     2     goed, West-Nederland 2008
\end{verbatim}

Okay, lets pretend it was panel data. \texttt{cv\_tot} would then be a panel dataset in long format. But oftentimes, you want a panel dataset in wide format.\\
If you don't know the difference between long and wide format, check the differences between \texttt{cv\_tot} and \texttt{cv\_tot\_panel} after step3b.

\hypertarget{step3b-merge}{%
\subsubsection{Step3b: merge}\label{step3b-merge}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#lets make a panel dataset in wide format}
\NormalTok{cv_tot_panel <-}\StringTok{ }\KeywordTok{merge}\NormalTok{(cv08_sel, cv10_sel, }\DataTypeTok{all=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{by=}\StringTok{"id2"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(cv_tot_panel)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   id2     id.x age.x men.x educ3.x  health.x       region.x wave.x     id.y age.y men.y educ3.y
## 1   1 36775330    51     1       3     goed, West-Nederland   2008 20131231    20     0       2
## 2   2 36775340    39     0       3     goed, West-Nederland   2008 20131232    29     0       3
## 3   3 36775420    16     0       2     goed, West-Nederland   2008 20131233    30     1       2
## 4   4 36775440    29     1       3     goed, West-Nederland   2008 20131234    64     1       2
## 5   5 36775450    57     1       3 gaat wel, West-Nederland   2008 20131235    45     1       1
## 6   6 36775460    49     0       2     goed, West-Nederland   2008 20131236    80     0       2
##     health.y       region.y wave.y
## 1      goed, West-Nederland   2010
## 2 zeer goed, West-Nederland   2010
## 3      goed, West-Nederland   2010
## 4      goed, West-Nederland   2010
## 5      goed, West-Nederland   2010
## 6      goed, West-Nederland   2010
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#rename variables. and when necessary merge again with third wave. not very efficient but it works.}

\CommentTok{#many people prefer the reshape function. (i like doing it myself but here it goes)}
\NormalTok{cv_tot_panel <-}\StringTok{ }\KeywordTok{reshape}\NormalTok{(cv_tot, }\DataTypeTok{timevar=}\StringTok{"wave"}\NormalTok{, }\DataTypeTok{idvar=}\StringTok{"id2"}\NormalTok{, }\DataTypeTok{direction=}\StringTok{"wide"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(cv_tot_panel)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   id2  id.2008 age.2008 men.2008 educ3.2008 health.2008    region.2008  id.2010 age.2010 men.2010
## 1   1 36775330       51        1          3       goed, West-Nederland 20131231       20        0
## 2   2 36775340       39        0          3       goed, West-Nederland 20131232       29        0
## 3   3 36775420       16        0          2       goed, West-Nederland 20131233       30        1
## 4   4 36775440       29        1          3       goed, West-Nederland 20131234       64        1
## 5   5 36775450       57        1          3   gaat wel, West-Nederland 20131235       45        1
## 6   6 36775460       49        0          2       goed, West-Nederland 20131236       80        0
##   educ3.2010 health.2010    region.2010
## 1          2       goed, West-Nederland
## 2          3  zeer goed, West-Nederland
## 3          2       goed, West-Nederland
## 4          2       goed, West-Nederland
## 5          1       goed, West-Nederland
## 6          2       goed, West-Nederland
\end{verbatim}

\hypertarget{tidy-3}{%
\subsection{Tidy}\label{tidy-3}}

\hypertarget{step1-select-variables-1}{%
\subsubsection{Step1: select variables}\label{step1-select-variables-1}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#step 1: selecting the variables you want to keep.}
\CommentTok{#for this tutorial only 6 variables: id, age, sex, educ, health, region (not that R is case sensitive)}
\NormalTok{cv08_sel <-}\StringTok{ }\NormalTok{cv08_haven }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{select}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"we_id"}\NormalTok{, }\StringTok{"lftop"}\NormalTok{, }\StringTok{"geslacht"}\NormalTok{, }\StringTok{"var006n"}\NormalTok{, }\StringTok{"v401"}\NormalTok{, }\StringTok{"landd"}\NormalTok{)) }

\NormalTok{cv10_sel <-}\StringTok{ }\NormalTok{cv10_haven }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"Sleutel"}\NormalTok{, }\StringTok{"var002"}\NormalTok{, }\StringTok{"var001"}\NormalTok{, }\StringTok{"Vltoplop"}\NormalTok{, }\StringTok{"V401"}\NormalTok{, }\StringTok{"Landd"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{step2-make-consistent-1}{%
\subsubsection{Step2: make consistent}\label{step2-make-consistent-1}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#step 2: making the variables similar across individual datasets}
\CommentTok{#step 2a: making names the same}
\KeywordTok{names}\NormalTok{(cv08_sel) <-}\StringTok{ }\KeywordTok{names}\NormalTok{(cv10_sel) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"id"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"sex"}\NormalTok{, }\StringTok{"educ"}\NormalTok{, }\StringTok{"health"}\NormalTok{, }\StringTok{"region"}\NormalTok{)}

\CommentTok{#step 2b: making levels and labels consistent}
\KeywordTok{str}\NormalTok{(cv08_sel)}
\KeywordTok{str}\NormalTok{(cv10_sel)}

\CommentTok{#summary(cv08_sel)}
\CommentTok{#summary(cv10_sel)}

\CommentTok{#they look very consistent already. but check carefully. }
\CommentTok{#id is okay}

\CommentTok{#age: replace 'onbekend'}
\NormalTok{cv08_sel <-}\StringTok{ }\NormalTok{cv08_sel }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{age=}\KeywordTok{na_if}\NormalTok{(age, }\DecValTok{99}\NormalTok{))}
\NormalTok{cv10_sel <-}\StringTok{ }\NormalTok{cv10_sel }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{age=}\KeywordTok{na_if}\NormalTok{(age, }\DecValTok{99}\NormalTok{))}

\CommentTok{#sex: men}
\NormalTok{cv08_sel <-}\StringTok{ }\NormalTok{cv08_sel }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{men=}\KeywordTok{recode}\NormalTok{(sex, }\StringTok{'9'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{, }\StringTok{'M'}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{'V'}\NormalTok{=}\DecValTok{0}\NormalTok{, }\DataTypeTok{.keep_value_labels =} \OtherTok{FALSE}\NormalTok{),}
                                \DataTypeTok{men=}\KeywordTok{na_if}\NormalTok{(men,}\OperatorTok{-}\DecValTok{9}\NormalTok{),}
                                \DataTypeTok{men=}\KeywordTok{labelled}\NormalTok{(men, }\KeywordTok{c}\NormalTok{(}\StringTok{"man"}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{"vrouw"}\NormalTok{=}\DecValTok{0}\NormalTok{)))}
\NormalTok{cv10_sel <-}\StringTok{ }\NormalTok{cv10_sel }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{men=}\KeywordTok{recode}\NormalTok{(sex, }\StringTok{'2'}\NormalTok{=}\DecValTok{0}\NormalTok{, }\DataTypeTok{.keep_value_labels =} \OtherTok{FALSE}\NormalTok{),}
                                \DataTypeTok{men=}\KeywordTok{labelled}\NormalTok{(men, }\KeywordTok{c}\NormalTok{(}\StringTok{"man"}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{"vrouw"}\NormalTok{=}\DecValTok{0}\NormalTok{)))}

\CommentTok{#educ educ3}
\KeywordTok{attr}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{educ, }\StringTok{"labels"}\NormalTok{)}
\KeywordTok{attr}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{educ, }\StringTok{"labels"}\NormalTok{)}

\NormalTok{cv08_sel <-}\StringTok{ }\NormalTok{cv08_sel }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{educ3=}\KeywordTok{recode}\NormalTok{(educ, }\StringTok{'-3'}\NormalTok{=}\OperatorTok{-}\DecValTok{9}\NormalTok{, }\StringTok{'-1'}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{'1'}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{'2'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{ , }\StringTok{'3'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'4'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'5'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'6'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'7'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'8'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'10'}\NormalTok{=}\StringTok{ }\DecValTok{-9}\NormalTok{, }\DataTypeTok{.keep_value_labels =} \OtherTok{FALSE}\NormalTok{),   }
    \DataTypeTok{educ3=}\KeywordTok{na_if}\NormalTok{(educ3, }\DecValTok{-9}\NormalTok{),}
    \DataTypeTok{educ3=}\KeywordTok{factor}\NormalTok{(educ3, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{), }\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"primary"}\NormalTok{, }\StringTok{"secondary"}\NormalTok{, }\StringTok{"tertiary"}\NormalTok{)))}

\NormalTok{cv10_sel <-}\StringTok{ }\NormalTok{cv10_sel }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{educ3=}\KeywordTok{recode}\NormalTok{(educ, }\StringTok{'-1'}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{'1'}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{'2'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{ , }\StringTok{'3'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'4'}\NormalTok{=}\StringTok{ }\DecValTok{2}\NormalTok{, }\StringTok{'5'}\NormalTok{=}\StringTok{ }\DecValTok{3}\NormalTok{, }\StringTok{'10'}\NormalTok{=}\StringTok{ }\DecValTok{-9}\NormalTok{, }\DataTypeTok{.keep_value_labels =} \OtherTok{FALSE}\NormalTok{),   }
    \DataTypeTok{educ3=}\KeywordTok{na_if}\NormalTok{(educ3, }\DecValTok{-9}\NormalTok{),}
    \DataTypeTok{educ3=}\KeywordTok{factor}\NormalTok{(educ3, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{), }\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"primary"}\NormalTok{, }\StringTok{"secondary"}\NormalTok{, }\StringTok{"tertiary"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\hypertarget{step3-merge-1}{%
\subsubsection{Step3: merge}\label{step3-merge-1}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#lets add a wave variable}
\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{wave <-}\StringTok{ }\DecValTok{2008}
\NormalTok{cv10_sel}\OperatorTok{$}\NormalTok{wave <-}\StringTok{ }\DecValTok{2010}

\CommentTok{#let make a fake ID, we will use this later when we pretend CV is panel data. }
\NormalTok{cv08_sel}\OperatorTok{$}\NormalTok{id2 <-}\StringTok{ }\KeywordTok{rank}\NormalTok{(cv08_sel}\OperatorTok{$}\NormalTok{id)}
\NormalTok{cv10_sel}\OperatorTok{$}\NormalTok{id2 <-}\StringTok{ }\KeywordTok{rank}\NormalTok{(cv10_sel}\OperatorTok{$}\NormalTok{id)}

\CommentTok{#simply place one dataset under the other thus row bind (rbind)}
\CommentTok{#check first if same vars in both datasets.}
\CommentTok{#perhaps clean up first. }

\NormalTok{cv08_sel <-}\StringTok{ }\NormalTok{cv08_sel }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{select}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"id"}\NormalTok{,}\StringTok{"id2"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"men"}\NormalTok{, }\StringTok{"educ3"}\NormalTok{, }\StringTok{"health"}\NormalTok{, }\StringTok{"region"}\NormalTok{, }\StringTok{"wave"}\NormalTok{)) }

\NormalTok{cv10_sel <-}\StringTok{ }\NormalTok{cv10_sel }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"id"}\NormalTok{,}\StringTok{"id2"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"men"}\NormalTok{, }\StringTok{"educ3"}\NormalTok{, }\StringTok{"health"}\NormalTok{, }\StringTok{"region"}\NormalTok{, }\StringTok{"wave"}\NormalTok{))}

\NormalTok{cv_tot_tidy <-}\StringTok{ }\NormalTok{cv08_sel }\OperatorTok{%>%}\StringTok{ }\KeywordTok{add_row}\NormalTok{(cv10_sel)}
\end{Highlighting}
\end{Shaded}

\hypertarget{step4-check-1}{%
\subsubsection{Step4: check}\label{step4-check-1}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{summary}\NormalTok{(cv_tot_tidy)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        id                id2            age             men              educ3     
##  Min.   :20131231   Min.   :   1   Min.   :16.00   Min.   :0.000   primary  : 839  
##  1st Qu.:20132456   1st Qu.: 613   1st Qu.:33.00   1st Qu.:0.000   secondary:2777  
##  Median :20133680   Median :1225   Median :47.00   Median :1.000   tertiary :1275  
##  Mean   :27624666   Mean   :1274   Mean   :47.63   Mean   :0.513   NA's     :   8  
##  3rd Qu.:37978375   3rd Qu.:1838   3rd Qu.:62.00   3rd Qu.:1.000                   
##  Max.   :41199300   Max.   :2936   Max.   :96.00   Max.   :1.000                   
##                                    NA's   :4       NA's   :10                      
##      health           region           wave     
##  Min.   :-2.000   Min.   :1.000   Min.   :2008  
##  1st Qu.: 1.000   1st Qu.:2.000   1st Qu.:2008  
##  Median : 2.000   Median :3.000   Median :2010  
##  Mean   : 1.979   Mean   :2.799   Mean   :2009  
##  3rd Qu.: 2.000   3rd Qu.:3.000   3rd Qu.:2010  
##  Max.   : 5.000   Max.   :4.000   Max.   :2010  
## 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{head}\NormalTok{(cv_tot_tidy)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 8
## # Rowwise: 
##          id   id2       age       men educ3            health region  wave
##   <dbl+lbl> <dbl> <dbl+lbl> <dbl+lbl> <fct>         <dbl+lbl>  <dbl> <dbl>
## 1  36775330     1        51 1 [man]   tertiary  2 [goed,]          3  2008
## 2  36775340     2        39 0 [vrouw] tertiary  2 [goed,]          3  2008
## 3  36775420     3        16 0 [vrouw] secondary 2 [goed,]          3  2008
## 4  36775440     4        29 1 [man]   tertiary  2 [goed,]          3  2008
## 5  36775450     5        57 1 [man]   tertiary  3 [gaat wel,]      3  2008
## 6  36775460     6        49 0 [vrouw] secondary 2 [goed,]          3  2008
\end{verbatim}

Okay, lets pretend it was panel data \texttt{cv\_tot} would then be a panel dataset in long format. But oftentimes, you want a panel dataset in wide format.\\
If you don't know the difference between long and wide format, check the differences between \texttt{cv\_tot} and \texttt{cv\_tot\_panel} after step 3b.

\hypertarget{step3b-merge-1}{%
\subsubsection{Step3b: merge}\label{step3b-merge-1}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#lets make a panel dataset in wide format}
\NormalTok{cv_tot_panel_tidy <-}\StringTok{ }\KeywordTok{full_join}\NormalTok{(cv08_sel, cv10_sel, }\DataTypeTok{by=}\StringTok{"id2"}\NormalTok{, }\DataTypeTok{suffix=}\KeywordTok{c}\NormalTok{(}\StringTok{".2008"}\NormalTok{, }\StringTok{".2010"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{aggregate-data}{%
\section{Aggregate data}\label{aggregate-data}}

Lets suppose you want to add the mean age of each region as contextual variable to your data.

\hypertarget{r-base-4}{%
\subsection{R Base}\label{r-base-4}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#step 1. construct dataset with aggregate info}
\NormalTok{age_region <-}\StringTok{ }\KeywordTok{aggregate}\NormalTok{(cv_tot}\OperatorTok{$}\NormalTok{age, }\DataTypeTok{by=}\KeywordTok{list}\NormalTok{(cv_tot}\OperatorTok{$}\NormalTok{region), }\DataTypeTok{FUN=}\NormalTok{mean)}
\KeywordTok{head}\NormalTok{(age_region)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Group.1        x
## 1 Noord-Nederland 47.77567
## 2  Oost-Nederland 48.04113
## 3  West-Nederland       NA
## 4  Zuid-Nederland       NA
\end{verbatim}

Ai, we have missings in age. Luckily the aggregate function can deal with missings.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#step 1. construct dataset with aggregate info}
\NormalTok{age_region <-}\StringTok{ }\KeywordTok{aggregate}\NormalTok{(cv_tot}\OperatorTok{$}\NormalTok{age, }\DataTypeTok{by=}\KeywordTok{list}\NormalTok{(cv_tot}\OperatorTok{$}\NormalTok{region), }\DataTypeTok{FUN=}\NormalTok{mean, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{head}\NormalTok{(age_region)}

\CommentTok{#lets correct variable names}
\KeywordTok{names}\NormalTok{(age_region) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"region"}\NormalTok{,}\StringTok{"age_region"}\NormalTok{)}
\NormalTok{age_region}

\CommentTok{#step 2. match to dataset}
\NormalTok{cv_total <-}\StringTok{ }\KeywordTok{merge}\NormalTok{(cv_tot, age_region, }\DataTypeTok{by=}\StringTok{"region"}\NormalTok{, }\DataTypeTok{all.x=}\OtherTok{TRUE}\NormalTok{)}
\KeywordTok{head}\NormalTok{(cv_total)}
\KeywordTok{tail}\NormalTok{(cv_total)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Group.1        x
## 1 Noord-Nederland 47.77567
## 2  Oost-Nederland 48.04113
## 3  West-Nederland 46.88416
## 4  Zuid-Nederland 48.52500
##            region age_region
## 1 Noord-Nederland   47.77567
## 2  Oost-Nederland   48.04113
## 3  West-Nederland   46.88416
## 4  Zuid-Nederland   48.52500
##            region       id  id2 age men educ3     health wave age_region
## 1 Noord-Nederland 40604110 1728  30   0     3 zeer goed, 2008   47.77567
## 2 Noord-Nederland 37975380  610  41   0     2      goed, 2008   47.77567
## 3 Noord-Nederland 40604300 1741  23   0     2      goed, 2008   47.77567
## 4 Noord-Nederland 38722490  890  49   1     2  gaat wel, 2008   47.77567
## 5 Noord-Nederland 20131654  424  60   0     1      goed, 2010   47.77567
## 6 Noord-Nederland 40604100 1727  18   1     2      goed, 2008   47.77567
##              region       id  id2 age men educ3     health wave age_region
## 4894 Zuid-Nederland 39568320 1429  78   1     2      goed, 2008     48.525
## 4895 Zuid-Nederland 20133708 2478  62   0     2      goed, 2010     48.525
## 4896 Zuid-Nederland 20134032 2802  49   1     2 zeer goed, 2010     48.525
## 4897 Zuid-Nederland 20132436 1206  52   1     1    slecht, 2010     48.525
## 4898 Zuid-Nederland 20131923  693  46   1     2      goed, 2010     48.525
## 4899 Zuid-Nederland 20134031 2801  50   1     2    slecht, 2010     48.525
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{# You can also define your own functions and use these.}

\NormalTok{fmean_narm <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x)\{}\KeywordTok{mean}\NormalTok{(x,}\DataTypeTok{na.rm=}\NormalTok{T)\}}

\NormalTok{age_region_test <-}\StringTok{ }\KeywordTok{aggregate}\NormalTok{(cv_tot}\OperatorTok{$}\NormalTok{age, }\DataTypeTok{by=}\KeywordTok{list}\NormalTok{(cv_tot}\OperatorTok{$}\NormalTok{region), }\DataTypeTok{FUN=}\NormalTok{fmean_narm)}
\KeywordTok{head}\NormalTok{(age_region_test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Group.1        x
## 1 Noord-Nederland 47.77567
## 2  Oost-Nederland 48.04113
## 3  West-Nederland 46.88416
## 4  Zuid-Nederland 48.52500
\end{verbatim}

\hypertarget{tidy-4}{%
\subsection{Tidy}\label{tidy-4}}

** TO DO **

\hypertarget{missing-values}{%
\section{Missing values}\label{missing-values}}

\hypertarget{r-base-5}{%
\subsection{R Base}\label{r-base-5}}

Suppose you want to estimate the following model:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{model1 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(health) }\OperatorTok{~}\StringTok{ }\NormalTok{men }\OperatorTok{+}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{  }\KeywordTok{as.factor}\NormalTok{(educ3) }\OperatorTok{+}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(region), }\DataTypeTok{data=}\NormalTok{cv_total)}
\KeywordTok{summary}\NormalTok{(model1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = as.numeric(health) ~ men + age + as.factor(educ3) + 
##     as.factor(region), data = cv_total)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.8504 -0.5991  0.0100  0.3289  3.2407 
## 
## Coefficients:
##                                   Estimate Std. Error t value Pr(>|t|)    
## (Intercept)                      5.6427632  0.0515902 109.377  < 2e-16 ***
## men                             -0.0155079  0.0211182  -0.734    0.463    
## age                              0.0115217  0.0005858  19.667  < 2e-16 ***
## as.factor(educ3)2               -0.1831809  0.0293149  -6.249 4.49e-10 ***
## as.factor(educ3)3               -0.3248725  0.0330650  -9.825  < 2e-16 ***
## as.factor(region)Oost-Nederland -0.0535139  0.0391705  -1.366    0.172    
## as.factor(region)West-Nederland -0.0152383  0.0360003  -0.423    0.672    
## as.factor(region)Zuid-Nederland  0.0140803  0.0388009   0.363    0.717    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.7371 on 4869 degrees of freedom
##   (22 observations deleted due to missingness)
## Multiple R-squared:  0.09928,    Adjusted R-squared:  0.09799 
## F-statistic: 76.67 on 7 and 4869 DF,  p-value: < 2.2e-16
\end{verbatim}

You see that 22 cases are deleted due to missingness but what happened with your health variable?

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cv_total}\OperatorTok{$}\NormalTok{health[cv_total}\OperatorTok{$}\NormalTok{health}\OperatorTok{==}\StringTok{"Weigert"}\NormalTok{] <-}\StringTok{ }\OtherTok{NA}
\NormalTok{cv_total}\OperatorTok{$}\NormalTok{healthn <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(cv_total}\OperatorTok{$}\NormalTok{health) }\OperatorTok{-}\StringTok{ }\DecValTok{4}
\KeywordTok{table}\NormalTok{(cv_total}\OperatorTok{$}\NormalTok{health, }\DataTypeTok{useNA =} \StringTok{"always"}\NormalTok{)}
\KeywordTok{table}\NormalTok{(cv_total}\OperatorTok{$}\NormalTok{healthn, }\DataTypeTok{useNA =} \StringTok{"always"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##     Geen opgave          N.v.t.       Weet niet         Weigert      zeer goed,           goed, 
##               0               0               0               0            1280            2652 
##       gaat wel,         slecht, of zeer slecht?            <NA> 
##             786             146              34               1 
## 
##    1    2    3    4    5 <NA> 
## 1280 2652  786  146   34    1
\end{verbatim}

Of course we have several options:\\
* listwise deletion. Only use when very few missings
* replace missing values with intuitive values or add missing as a separate category.\\
* impute missing values. A bit complicated but the best option.

\hypertarget{option-1-listwise-deletion}{%
\subsubsection{Option 1: listwise deletion}\label{option-1-listwise-deletion}}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#step1 define all missings}
\KeywordTok{summary}\NormalTok{(cv_total)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                      region           id                id2            age             men       
##  Postcode (nog) onbekend:   0   Min.   :20131231   Min.   :   1   Min.   :16.00   Min.   :0.000  
##  Noord-Nederland        : 526   1st Qu.:20132456   1st Qu.: 613   1st Qu.:33.00   1st Qu.:0.000  
##  Oost-Nederland         :1094   Median :20133680   Median :1225   Median :47.00   Median :0.000  
##  West-Nederland         :2116   Mean   :27624666   Mean   :1274   Mean   :47.63   Mean   :0.495  
##  Zuid-Nederland         :1163   3rd Qu.:37978375   3rd Qu.:1838   3rd Qu.:62.00   3rd Qu.:1.000  
##                                 Max.   :41199300   Max.   :2936   Max.   :96.00   Max.   :1.000  
##                                                                   NA's   :4       NA's   :10     
##      educ3                   health          wave        age_region       healthn    
##  Min.   :1.000   goed,          :2652   Min.   :2008   Min.   :46.88   Min.   :1.00  
##  1st Qu.:2.000   zeer goed,     :1280   1st Qu.:2008   1st Qu.:46.88   1st Qu.:1.00  
##  Median :2.000   gaat wel,      : 786   Median :2010   Median :47.78   Median :2.00  
##  Mean   :2.089   slecht,        : 146   Mean   :2009   Mean   :47.63   Mean   :1.98  
##  3rd Qu.:3.000   of zeer slecht?:  34   3rd Qu.:2010   3rd Qu.:48.04   3rd Qu.:2.00  
##  Max.   :3.000   (Other)        :   0   Max.   :2010   Max.   :48.52   Max.   :5.00  
##  NA's   :8       NA's           :   1                                  NA's   :1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{model2 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(healthn) }\OperatorTok{~}\StringTok{ }\NormalTok{men }\OperatorTok{+}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{  }\KeywordTok{as.factor}\NormalTok{(educ3) }\OperatorTok{+}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(region), }\DataTypeTok{data=}\NormalTok{cv_total)}
\KeywordTok{summary}\NormalTok{(model2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = as.numeric(healthn) ~ men + age + as.factor(educ3) + 
##     as.factor(region), data = cv_total)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.6261 -0.6001  0.0094  0.3288  3.2415 
## 
## Coefficients:
##                                   Estimate Std. Error t value Pr(>|t|)    
## (Intercept)                      1.6429046  0.0515620  31.863  < 2e-16 ***
## men                             -0.0162517  0.0211087  -0.770    0.441    
## age                              0.0115192  0.0005855  19.673  < 2e-16 ***
## as.factor(educ3)2               -0.1831872  0.0292989  -6.252 4.39e-10 ***
## as.factor(educ3)3               -0.3233545  0.0330525  -9.783  < 2e-16 ***
## as.factor(region)Oost-Nederland -0.0535499  0.0391492  -1.368    0.171    
## as.factor(region)West-Nederland -0.0153441  0.0359807  -0.426    0.670    
## as.factor(region)Zuid-Nederland  0.0157006  0.0387850   0.405    0.686    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.7367 on 4868 degrees of freedom
##   (23 observations deleted due to missingness)
## Multiple R-squared:  0.09925,    Adjusted R-squared:  0.09795 
## F-statistic: 76.63 on 7 and 4868 DF,  p-value: < 2.2e-16
\end{verbatim}

You see 23 cases deleted due to missingness

\hypertarget{option-2-replacing-missing-values.}{%
\subsubsection{Option 2: replacing missing values.}\label{option-2-replacing-missing-values.}}

Don't replace missings on dependent variable.\\
For categorical variables add category missing.
For continues/metric variables replace missing with mean value.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{cv_total}\OperatorTok{$}\NormalTok{men2 <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(cv_total}\OperatorTok{$}\NormalTok{men), }\DecValTok{2}\NormalTok{, cv_total}\OperatorTok{$}\NormalTok{men)}
\KeywordTok{summary}\NormalTok{(cv_total}\OperatorTok{$}\NormalTok{men2)}

\NormalTok{cv_total}\OperatorTok{$}\NormalTok{educ3b <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(cv_total}\OperatorTok{$}\NormalTok{educ3), }\DecValTok{4}\NormalTok{, cv_total}\OperatorTok{$}\NormalTok{educ3)}
\KeywordTok{summary}\NormalTok{(cv_total}\OperatorTok{$}\NormalTok{educ3b)}

\NormalTok{cv_total}\OperatorTok{$}\NormalTok{age2 <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(cv_total}\OperatorTok{$}\NormalTok{age), }\KeywordTok{mean}\NormalTok{(cv_total}\OperatorTok{$}\NormalTok{age, }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{), cv_total}\OperatorTok{$}\NormalTok{age)}
\CommentTok{#And lets make a dummy that indicates for whom we replaced missing values. }
\NormalTok{cv_total}\OperatorTok{$}\NormalTok{age_mis <-}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(cv_total}\OperatorTok{$}\NormalTok{age), }\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{)}
\KeywordTok{summary}\NormalTok{(cv_total}\OperatorTok{$}\NormalTok{age2)}
\KeywordTok{table}\NormalTok{(cv_total}\OperatorTok{$}\NormalTok{age_mis)}

\CommentTok{#pay attention, now use categorical variable men2}
\NormalTok{model3 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(healthn }\OperatorTok{~}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(men2) }\OperatorTok{+}\StringTok{ }\NormalTok{age2 }\OperatorTok{+}\StringTok{ }\NormalTok{age_mis }\OperatorTok{+}\StringTok{  }\KeywordTok{as.factor}\NormalTok{(educ3b) }\OperatorTok{+}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(region), }\DataTypeTok{data=}\NormalTok{cv_total)}
\KeywordTok{summary}\NormalTok{(model3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.0000  0.0000  0.0000  0.4981  1.0000  2.0000 
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   1.000   2.000   2.000   2.092   3.000   4.000 
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   16.00   33.50   47.00   47.63   62.00   96.00 
## 
##    0    1 
## 4895    4 
## 
## Call:
## lm(formula = healthn ~ as.factor(men2) + age2 + age_mis + as.factor(educ3b) + 
##     as.factor(region), data = cv_total)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.6200 -0.6013  0.0103  0.3268  3.2422 
## 
## Coefficients:
##                                   Estimate Std. Error t value Pr(>|t|)    
## (Intercept)                      1.6430251  0.0516038  31.839  < 2e-16 ***
## as.factor(men2)1                -0.0186500  0.0211416  -0.882    0.378    
## as.factor(men2)2                -0.2534807  0.2341966  -1.082    0.279    
## age2                             0.0114647  0.0005852  19.592  < 2e-16 ***
## age_mis                          0.1067769  0.3699339   0.289    0.773    
## as.factor(educ3b)2              -0.1786212  0.0293068  -6.095 1.18e-09 ***
## as.factor(educ3b)3              -0.3193546  0.0330785  -9.654  < 2e-16 ***
## as.factor(educ3b)4              -0.4032117  0.2624656  -1.536    0.125    
## as.factor(region)Oost-Nederland -0.0548586  0.0391963  -1.400    0.162    
## as.factor(region)West-Nederland -0.0146274  0.0360252  -0.406    0.685    
## as.factor(region)Zuid-Nederland  0.0157363  0.0388302   0.405    0.685    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.7384 on 4887 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.09797,    Adjusted R-squared:  0.09612 
## F-statistic: 53.08 on 10 and 4887 DF,  p-value: < 2.2e-16
\end{verbatim}

\hypertarget{option-3-impute-missing-values}{%
\subsubsection{Option 3: impute missing values}\label{option-3-impute-missing-values}}

We will use the R package mice (\citet{mice}).

For theory please see:\\
* \url{https://stefvanbuuren.name/Winnipeg}\\
* \url{https://stefvanbuuren.name/Winnipeg/Lectures/Winnipeg.pdf}\\
* For great reading see: \url{https://bookdown.org/mwheymans/bookmi/}

Read the literature, lectures and have a look at all vignettes of the package mice (here). This is not basic stuff!

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#lets start with the original dataset, that is without replacement of the missings}
\NormalTok{cv_total <-}\StringTok{ }\NormalTok{cv_total[,}\KeywordTok{c}\NormalTok{(}\StringTok{"id"}\NormalTok{, }\StringTok{"id2"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"men"}\NormalTok{, }\StringTok{"educ3"}\NormalTok{, }\StringTok{"health"}\NormalTok{, }\StringTok{"region"}\NormalTok{, }\StringTok{"wave"}\NormalTok{)]}
\CommentTok{#define all missings}
\CommentTok{#only for health needs to be redefined}
\NormalTok{cv_total}\OperatorTok{$}\NormalTok{health[cv_total}\OperatorTok{$}\NormalTok{health}\OperatorTok{==}\StringTok{"Weigert"}\NormalTok{] <-}\StringTok{ }\OtherTok{NA}
\NormalTok{cv_total}\OperatorTok{$}\NormalTok{health <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(cv_total}\OperatorTok{$}\NormalTok{health) }\OperatorTok{-}\StringTok{ }\DecValTok{4}

\CommentTok{#multiple imputation}
\CommentTok{#take into account measurement level of variables}
\NormalTok{cv_total}\OperatorTok{$}\NormalTok{men <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(cv_total}\OperatorTok{$}\NormalTok{men)}
\NormalTok{cv_total}\OperatorTok{$}\NormalTok{educ3 <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(cv_total}\OperatorTok{$}\NormalTok{educ3)}

\CommentTok{#check pattern}
\KeywordTok{md.pattern}\NormalTok{(cv_total)}
\end{Highlighting}
\end{Shaded}

\includegraphics{06-Tutorial-CSR_files/figure-latex/mice-1.pdf}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#we do not have real patterns. thus MCAR. This is only seldom the case!!}

\CommentTok{#lets impute}
\KeywordTok{names}\NormalTok{(cv_total)}

\CommentTok{#We do not want to use id id2 and wave to predict the other variables thus we need to tell mice in the predictorMatrix argument. Easiest way is to first estimate and then correct. }

\NormalTok{imp <-}\StringTok{ }\KeywordTok{mice}\NormalTok{(}\DataTypeTok{data=}\NormalTok{cv_total, }\DataTypeTok{method=}\KeywordTok{c}\NormalTok{(}\StringTok{""}\NormalTok{,}\StringTok{""}\NormalTok{, }\StringTok{"cart"}\NormalTok{, }\StringTok{"logreg"}\NormalTok{,    }\StringTok{"polr"}\NormalTok{,  }\StringTok{"cart"}\NormalTok{, }\StringTok{""}\NormalTok{ ,}\StringTok{""}\NormalTok{  ))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Number of logged events: 100
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{attributes}\NormalTok{(imp)}
\NormalTok{pred <-}\StringTok{ }\NormalTok{imp}\OperatorTok{$}\NormalTok{pred}
\NormalTok{pred[,}\StringTok{"id"}\NormalTok{] <-}\StringTok{ }\DecValTok{0}
\NormalTok{pred[,}\StringTok{"id2"}\NormalTok{] <-}\StringTok{ }\DecValTok{0}
\NormalTok{pred[,}\StringTok{"wave"}\NormalTok{] <-}\StringTok{ }\DecValTok{0}
\NormalTok{pred}

\CommentTok{#let us also use a seed, so we have the same data in class. }
\NormalTok{imp <-}\StringTok{ }\KeywordTok{mice}\NormalTok{(}\DataTypeTok{data=}\NormalTok{cv_total, }\DataTypeTok{method=}\KeywordTok{c}\NormalTok{(}\StringTok{""}\NormalTok{,}\StringTok{""}\NormalTok{, }\StringTok{"cart"}\NormalTok{, }\StringTok{"logreg"}\NormalTok{,    }\StringTok{"polr"}\NormalTok{,  }\StringTok{"cart"}\NormalTok{, }\StringTok{""}\NormalTok{ ,}\StringTok{""}\NormalTok{  ), }\DataTypeTok{pred=}\NormalTok{pred, }\DataTypeTok{seed=}\DecValTok{45622}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Number of logged events: 100
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\KeywordTok{summary}\NormalTok{(cv_total)}
\KeywordTok{summary}\NormalTok{(}\KeywordTok{complete}\NormalTok{(imp))}

\KeywordTok{plot}\NormalTok{(imp)}
\end{Highlighting}
\end{Shaded}

\includegraphics{06-Tutorial-CSR_files/figure-latex/mice-2.pdf} \includegraphics{06-Tutorial-CSR_files/figure-latex/mice-3.pdf}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{#in real life: check convergence, check plausible values. see vignette 2 of mice package}

\CommentTok{#and fit model on imputed dataset}
\NormalTok{model_imp <-}\StringTok{ }\KeywordTok{with}\NormalTok{(imp, }\KeywordTok{lm}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(health) }\OperatorTok{~}\StringTok{ }\NormalTok{men }\OperatorTok{+}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{educ3 }\OperatorTok{+}\StringTok{ }\NormalTok{region))}
\NormalTok{pool_model_imp <-}\StringTok{ }\KeywordTok{pool}\NormalTok{(model_imp)}
\KeywordTok{summary}\NormalTok{(pool_model_imp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      id id2 region wave health age educ3 men   
## 4876  1   1      1    1      1   1     1   1  0
## 10    1   1      1    1      1   1     1   0  1
## 8     1   1      1    1      1   1     0   1  1
## 4     1   1      1    1      1   0     1   1  1
## 1     1   1      1    1      0   1     1   1  1
##       0   0      0    0      1   4     8  10 23
## [1] "id"     "id2"    "age"    "men"    "educ3"  "health" "region" "wave"  
## 
##  iter imp variable
##   1   1  age  men  educ3  health
##   1   2  age  men  educ3  health
##   1   3  age  men  educ3  health
##   1   4  age  men  educ3  health
##   1   5  age  men  educ3  health
##   2   1  age  men  educ3  health
##   2   2  age  men  educ3  health
##   2   3  age  men  educ3  health
##   2   4  age  men  educ3  health
##   2   5  age  men  educ3  health
##   3   1  age  men  educ3  health
##   3   2  age  men  educ3  health
##   3   3  age  men  educ3  health
##   3   4  age  men  educ3  health
##   3   5  age  men  educ3  health
##   4   1  age  men  educ3  health
##   4   2  age  men  educ3  health
##   4   3  age  men  educ3  health
##   4   4  age  men  educ3  health
##   4   5  age  men  educ3  health
##   5   1  age  men  educ3  health
##   5   2  age  men  educ3  health
##   5   3  age  men  educ3  health
##   5   4  age  men  educ3  health
##   5   5  age  men  educ3  health
## $names
##  [1] "data"            "imp"             "m"               "where"           "blocks"         
##  [6] "call"            "nmis"            "method"          "predictorMatrix" "visitSequence"  
## [11] "formulas"        "post"            "blots"           "ignore"          "seed"           
## [16] "iteration"       "lastSeedValue"   "chainMean"       "chainVar"        "loggedEvents"   
## [21] "version"         "date"           
## 
## $class
## [1] "mids"
## 
##        id id2 age men educ3 health region wave
## id      0   0   1   1     1      1      1    0
## id2     0   0   1   1     1      1      1    0
## age     0   0   0   1     1      1      1    0
## men     0   0   1   0     1      1      1    0
## educ3   0   0   1   1     0      1      1    0
## health  0   0   1   1     1      0      1    0
## region  0   0   1   1     1      1      0    0
## wave    0   0   1   1     1      1      1    0
## 
##  iter imp variable
##   1   1  age  men  educ3  health
##   1   2  age  men  educ3  health
##   1   3  age  men  educ3  health
##   1   4  age  men  educ3  health
##   1   5  age  men  educ3  health
##   2   1  age  men  educ3  health
##   2   2  age  men  educ3  health
##   2   3  age  men  educ3  health
##   2   4  age  men  educ3  health
##   2   5  age  men  educ3  health
##   3   1  age  men  educ3  health
##   3   2  age  men  educ3  health
##   3   3  age  men  educ3  health
##   3   4  age  men  educ3  health
##   3   5  age  men  educ3  health
##   4   1  age  men  educ3  health
##   4   2  age  men  educ3  health
##   4   3  age  men  educ3  health
##   4   4  age  men  educ3  health
##   4   5  age  men  educ3  health
##   5   1  age  men  educ3  health
##   5   2  age  men  educ3  health
##   5   3  age  men  educ3  health
##   5   4  age  men  educ3  health
##   5   5  age  men  educ3  health
##        id                id2            age          men        educ3          health    
##  Min.   :20131231   Min.   :   1   Min.   :16.00   0   :2469   1   : 839   Min.   :1.00  
##  1st Qu.:20132456   1st Qu.: 613   1st Qu.:33.00   1   :2420   2   :2777   1st Qu.:1.00  
##  Median :20133680   Median :1225   Median :47.00   NA's:  10   3   :1275   Median :2.00  
##  Mean   :27624666   Mean   :1274   Mean   :47.63               NA's:   8   Mean   :1.98  
##  3rd Qu.:37978375   3rd Qu.:1838   3rd Qu.:62.00                           3rd Qu.:2.00  
##  Max.   :41199300   Max.   :2936   Max.   :96.00                           Max.   :5.00  
##                                    NA's   :4                               NA's   :1     
##                      region          wave     
##  Postcode (nog) onbekend:   0   Min.   :2008  
##  Noord-Nederland        : 526   1st Qu.:2008  
##  Oost-Nederland         :1094   Median :2010  
##  West-Nederland         :2116   Mean   :2009  
##  Zuid-Nederland         :1163   3rd Qu.:2010  
##                                 Max.   :2010  
##                                               
##        id                id2            age        men      educ3        health     
##  Min.   :20131231   Min.   :   1   Min.   :16.00   0:2471   1: 842   Min.   :1.000  
##  1st Qu.:20132456   1st Qu.: 613   1st Qu.:33.00   1:2428   2:2779   1st Qu.:1.000  
##  Median :20133680   Median :1225   Median :47.00            3:1278   Median :2.000  
##  Mean   :27624666   Mean   :1274   Mean   :47.62                     Mean   :1.979  
##  3rd Qu.:37978375   3rd Qu.:1838   3rd Qu.:62.00                     3rd Qu.:2.000  
##  Max.   :41199300   Max.   :2936   Max.   :96.00                     Max.   :5.000  
##                      region          wave     
##  Postcode (nog) onbekend:   0   Min.   :2008  
##  Noord-Nederland        : 526   1st Qu.:2008  
##  Oost-Nederland         :1094   Median :2010  
##  West-Nederland         :2116   Mean   :2009  
##  Zuid-Nederland         :1163   3rd Qu.:2010  
##                                 Max.   :2010  
##                   term    estimate    std.error  statistic       df      p.value
## 1          (Intercept)  1.64227489 0.0515381739 31.8652131 4883.812 0.000000e+00
## 2                 men1 -0.01821954 0.0211574583 -0.8611405 4683.712 3.892048e-01
## 3                  age  0.01146351 0.0005846149 19.6086530 4854.560 0.000000e+00
## 4               educ32 -0.17813172 0.0292524289 -6.0894676 4881.477 1.219647e-09
## 5               educ33 -0.31977903 0.0330290911 -9.6817388 4859.881 0.000000e+00
## 6 regionOost-Nederland -0.05554060 0.0391698388 -1.4179430 4888.390 1.562711e-01
## 7 regionWest-Nederland -0.01515412 0.0360044223 -0.4208962 4888.453 6.738494e-01
## 8 regionZuid-Nederland  0.01582036 0.0387973170  0.4077694 4888.453 6.834609e-01
\end{verbatim}

\hypertarget{tidy-5}{%
\subsection{Tidy}\label{tidy-5}}

** TO DO **

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Thank you for reading this tutorial!!}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{variance}{%
\chapter{Covariance and Correlation}\label{variance}}

Social scientists try to explain variance and covariance. It is therefore a good idea to learn by heart the formula for variance and covariance. The sample variance of a random continuous variable X, VAR(X), is as follows:

\[VAR(X)=s_{xx}^2 = s_x^2= \frac{\Sigma^n_{i=1}(X_i-\overline{X})(X_i-\overline{X})}{n-1}= \frac{\Sigma^n_{i=1}(X_i-\overline{X})^2}{n-1}\]\\
The sample standard deviation is given by:

\[STD(X)=\sqrt{s_x^2}=s_x\]

The sample covariance of two random continuous variables X and Y, COV(X,Y) is as follows:

\[COV(X,Y)=s_{xy}^2 = \frac{\Sigma^n_{i=1}(X_i-\overline{X})(Y_i-\overline{Y})}{n-1}\]

The sample correlation coefficient between two random continuous variables X and Y, COR(X,Y), is a covariance on standardized variables (\(z_x=X_{sd}=(X-\overline{X})/s_x\)) and hence:

\[COR(X,Y)=r_{xy} = \frac{s_{xy}^2}{s_x s_y}= \frac{\Sigma^n_i(X_i-\overline{X})(Y_i-\overline{Y})}{\sqrt{\Sigma^n_i(X_i-\overline{X})^2}\sqrt{\Sigma^n_i(Y_i-\overline{Y})^2}}\]
Just to be complete. The population equivalent of the covariance:

\[\sigma _{xy}^2 = \frac{\Sigma^n_i(X_i - \mu_x)(Y_i-\mu_y)}{N},\]
with \(\mu\) the population mean.
And the correlation within the population is:

\[\rho_{xy} = \frac{\sigma_{xy}^2}{\sigma_x \sigma_y}\]

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{references}{%
\chapter*{References}\label{references}}
\addcontentsline{toc}{chapter}{References}

\hypertarget{refs}{}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

  \bibliography{book.bib,packages.bib}

\end{document}
