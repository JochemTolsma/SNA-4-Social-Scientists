# Methods  

<!--- need to add some css styling for button
https://www.w3schools.com/csS/css3_buttons.asp

<style>

.button {
  background-color: #f44336; /* Red */ 
  border: none;
  color: white;
  padding: 15px 32px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 16px;
  margin: 4px 2px;
  cursor: pointer;
}

.button:hover {
  box-shadow: 0 12px 16px 0 rgba(0,0,0,0.24), 0 17px 50px 0 rgba(0,0,0,0.19);
}

.button {border-radius: 12px;}

.button {width: 100%;}

</style>


---> 

<style>

.button1 {
  background-color: #f44336; /* Red */ 
  border: none;
  color: white;
  padding: 15px 32px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 16px;
  margin: 4px 2px;
  cursor: pointer;
}

.button1:hover {
  box-shadow: 0 12px 16px 0 rgba(0,0,0,0.24), 0 17px 50px 0 rgba(0,0,0,0.19);
}

.button1 {border-radius: 12px;}

.button1 {width: 100%;}
</style>


<script>
function myFunction() {

            var btn = document.getElementById("myButton");
            //to make it fancier
            if (btn.value == "Click to hide code") {
                btn.value = "Click to show code";
                btn.innerHTML = "Click to show code";
            }
            else {
                btn.value = "Click to hide code";
                btn.innerHTML = "Click to hide code";
            }
            //this is what you're looking for
            var x = document.getElementById("myDIV");
            if (x.style.display === "none") {
                x.style.display = "block";
            } else {
                x.style.display = "none";
            }
        }

</script>




<!---we need to include this somewhere as general r script---> 

```{r colorize, echo=FALSE, cache=FALSE}
colorize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color,
      x)
  } else x
}
```


```{r globalsettings, echo=FALSE, warning=FALSE}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=100),tidy=TRUE, warning = FALSE, message = FALSE,comment = "#>", cache=TRUE)
options(width = 100)

```



```{r packages, echo=FALSE}
#install if necessary 
if (!require("dplyr", character.only = TRUE)) {install.packages("dplyr", dependencies=TRUE)}
if (!require("haven", character.only = TRUE)) {install.packages("haven", dependencies=TRUE)}
#if (!require("purr", character.only = TRUE)) {install.packages("purr", dependencies=TRUE)}
if (!require("lavaan", character.only = TRUE)) {install.packages("lavaan", dependencies=TRUE)}
if (!require("ggplot2", character.only = TRUE)) {install.packages("ggplot2", dependencies=TRUE)}
if (!require("hrbrthemes", character.only = TRUE)) {install.packages("hrbrthemes", dependencies=TRUE)}
if (!require("patchwork", character.only = TRUE)) {install.packages("patchwork", dependencies=TRUE)}
if (!require("mvtnorm", character.only = TRUE)) {install.packages("mvtnorm", dependencies=TRUE)}
if (!require("plotly", character.only = TRUE)) {install.packages("plotyly", dependencies=TRUE)}
if (!require("plotly", character.only = TRUE)) {install.packages("plotyly", dependencies=TRUE)}
if (!require("future.apply", character.only = TRUE)) {install.packages("future.apply", dependencies=TRUE)}

#load packages.
library(dplyr)
library(haven)
library(purrr)
library(tidyr)
library(lavaan)
library(ggplot2)
library(plotly)
library(ggplot2)
library(hrbrthemes)
hrbrthemes::import_roboto_condensed() 
#loadfonts(device = "win", quiet = TRUE) 
library(patchwork)
library(mvtnorm)
library(future.apply)

```






## Causes  

<!---see!!! 
https://link.springer.com/chapter/10.1007/978-3-319-93227-9_13

https://haozhu233.github.io/kableExtra/awesome_table_in_html.html
---> 

When testing hypotheses on assortative mating many methodological approaches can be used. We may predict the **frequency of specific dyads** in our population with loglinear models and the data we use is commonly structured in a square table like the one below. Loglinear models are, in essence, nothing more than a nice, parsimonious and fancy way to calculate [odds ratio's](\ref(OR)). If we have a small, well filled table of just a few attributes, [loglinear models](\ref(LLM)) are considered to be the golden standard. 

```{r tabledyads, echo=FALSE}
install.packages("kableExtra", repos='http://cran.us.r-project.org')
require(kableExtra)
r1 <- c("", "Wife educ-high", "Wife educ-low")
c1 <- c(350, 200)
c2 <- c(150, 400)
df <- data.frame(c1,c2)
colnames(df)<- c("Wife educ-high", "Wife educ-low")
rownames(df)<- c("Husband educ-high", "Husband educ-low")

#kable(df, caption="Assortative Mating", align="l")

kbl(df, booktabs=TRUE, digits=2, caption="Assortative Mating (dyad frequency)", align = "c") %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  column_spec(1, bold=T) %>%
  row_spec(0, bold=TRUE)
  

```



Another approach is to take the **characteristics of the dyad** (e.g. 1 = intermarriage and 0 = no intermarriage) as the dependent variable. This dependent variable can than be explained by applying (conditional) (multinomial) [logistic regression](\ref(LM)) techniques. In this case, the data is commonly structured in long format and looks something like the table below. 

```{r tabledyads2, echo=FALSE}
require(kableExtra)
set.seed(2362)
c1 <- 1:20
c2 <- sample(c("HIGH", "LOW"), 20, replace=TRUE)
c3 <- runif(20, 18, 45)
c4 <- sample(c("HIGH", "LOW"), 20, replace=TRUE)
c5 <- runif(20, 18, 45)
c6 <- as.numeric(c2==c3)

df <- data.frame(c1,c2, c3, c4, c5, c6)
colnames(df)<- c("dyad_id", "wife educ", "wife age", "husband educ", "husband age", "intermarriage")

#kable(df, caption="Assortative Mating", align="l")

kbl(df, booktabs=TRUE, digits=2, caption="Assortative Mating (dyad characteristic)", align = "c") %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>% 
 scroll_box(width="100%", height = "400px")
  

```


Which methodology is preferred should depend on your hypotheses and on the data you have to your availability. 

> Please be aware that in both approaches we normally do not have information on (the frequency or characteristics of) dyads in which there is no relation between ego and alter. Thus, you may have information on characteristics of me and my wife but you do not have information on all other women (or men) I could have married but didn't. I fished my wife out of the sea but we don't know what the other fish looked like. (Luckily my wife is no scientist and won't read this clarification.)

### Odds Ratio {#OR}  

### Loglinear Model {#LLM}  

### Conditional multinomial logit model {#LM}  

## Consequences 

The method used to explain consequences of dyads depends on our Unit of Analysis. If it is the dyad itself (e.g. mean relationship quality) methods are relatively straightforward, because we may assume that the observations at the dyad-level are independent. We may explain this dyad-characteristic by other characteristics of the dyad (e.g. length of marriage) and by characteristics of each spouse (e.g. working hours men, working hours woman).^[I am assuming that spouses - and egos/alters more generally - can be 'distinguished'. If this is not the case (e.g. homosexual couples), we need different techniques.] That characteristics of the spouses, the covariates, are correlated does not necessarily pose a big problem.^[Except of course if you face issues of multicollinearity.]  
If, on the other hand, the unit of analysis are the partners themselves who make up the dyad, we need to acknowledge that the observations between the partners of the same couple are not independent. In part exactly because partners select and influence each other and share a social context. One solution could be to simply randomly select one partner of each couple or, if partners can be clearly distinguished - for example men and women in heterosexual couples - the different partners could be analyzed separately. A disadvantage of the latter two approaches is, however, that the covariance between the partners cannot be explained anymore, although this may exactly be the focus of our research questions. A more elegant solution, is to take the interdependencies into account and model these explicitly. This can be done within a multi-level framework and within a structural-equation modelling framework. 

## Research questions

When we discussed the methods to analyze causes of homogamy, we were interested in homophily within couples at one point in time and focused on selection as explanans. Now, when we are discussing the consequences of dyads, we are interested in explaining trends in homophily within couples - thus homophily as a consequence of mating - and focus on shared context and influence processes as explanans.  
Naturally, because we are interested in trends in homophily within couples, we focus on dynamic characteristics of the spouses. Thus not, ethnicity, or educational attainment, but, for example, on their political opinions.  

Let us suppose our aim is to write a scientific paper on political opinion homophily within couples. We will formulate the following research questions:

- To what extent can we observe trends in political opinion homophily (or opinion similarity) **within** couples?  
- To what extent can we explain trends in political opinion homophily by influence processes taking place between spouses?  
- To what extent can we explain trends in political opinion homophily by the shared (social) context of the couple?  

Perhaps, you also want to focus in this paper on the influence process itself and formulate a second set of research questions: 

- To what extent are influence process within couples influenced by (or conditional on):  
  - the shared context?    
  - characteristics of the couple?    
  - characteristics of the spouses?  
  
<!--- **Hypothesis 1 Partner influence hypothesis**: Partners opinions will become more similar to one another over time.   
We will introduce the CLPM below. Once you are familiar with this model, you see that we can and should formulate a more precise hypothesis 1.  

**Hypo1 RI-CLPM:** When your partner's opinion is relatively high (compared to your partners average opinion over time) at time T, your own opinion will be relatively high (compared to your own average opinion over time) at time T+1. 

Hypo1 SC-RI-CLPM: Even if we control for structural time trends in political opinions, when your partner's opinion is relatively high (compared to your partners average opinion over time) at time T, your own opinion will be relatively high (compared to your own average opinion over time) at time T+1. 

Hypo1 LT-RI-CLPM: Even if we take into account that...: 
  - the general time trend of men and women will be (positively) associated (i.e. positive covariance of the random slopes);  
  - the mean opinion of your spouse will influence your general time trend (i.e. negative covariance of random intercept of men with random slop of women (and vice versa));
  ...when your partner's opinion is relatively high (compared to your partners average opinion over time) at time T, your own opinion will be relatively high (compared to your own average opinion over time) at time T+1. 


**Hypothesis 2 Male dominance hypothesis**: Women are more influenced by their (male) spouse than men are influenced by their (female) spouse.** 

**Hypothesis 3 Educational dominance hypothesis:** The spouse with the lowest education is more influenced by their partner than the spouse with the highest education.** 

--->

## Data 

We will use the data from the LISS panel.  

<a href="https://www.lissdata.nl/">
  <img src="lisslogo_0.png">
  </a>

More concretely, we will use:  

- 11 waves (2008-2014, 2016-2029)  
- Filter on heterosexual couples (cohabiting and married)
- Filter on couples of which both spouses are older than 25. 

We have already constructed a dataset for you guys and gals to work with which contains information on more than 3000 couples. Don't forget it is a panel data set. This means we have more observations for the same couple (and spouses) over time. Also be aware that our spouses can be clearly distinguished from one another (i.e. husband versus wife).   

Please download this data file to your working directory.

[partner_dataprepped.Rdata](addfiles\partner_dataprepped.Rdata)\

### Variables  


Variables of interest and value labels:

-   education: = highest completed education in years (4-16.5)
-   sex: = 0 = male / 1 = female
-   eu_integration: 0 = eu integration has gone too far / 4 = eu integration should go further
-   immigrants: 0 = immigrants should adjust / 4 immigrants can retain their own culture.
-   euthanasia: 1 = euthanasia should be forbidden / 5 euthanasia should be permitted
-   income_diff: 1 differences in income should increase / 5 differences in income should decrease

For the original variables in Dutch see below: 

<p class= "quote"> **opleiding**  

> Hoogste opleiding met diploma  
> 1 basisonderwijs  
> 2 vmbo  
> 3 havo/vwo  
> 4 mbo  
> 5 hbo  
> 6 wo  
> 7 anders  
> 8 (Nog) geen onderwijs afgerond  
> 9 Volgt nog geen onderwijs  
> Hierbij hebben wij opleiding gecategoriseerd in drie groepen:  
> 1. Laag: basisonderwijs en vmbo  
> 2. Midden: havo/vwo en mbo  
> 3. Hoog: hbo en wo  
> We nemen enkel mensen van 25 jaar en ouder mee. Van hen verwachten we dat ze klaar zijn met hun onderwijscarriere. 

</p>

<p class= "quote"> 
**EU integratie** 

> De Europese integratie is te ver gegaan.  
>  
>  1 Helemaal oneens  
>  2 Oneens   
>  3 Niet eens, niet oneens  
>  4 Eens  
>  5 Helemaal eens  

</p>

<p class= "quote"> 
**Migratie/integratie**

> In Nederland vinden sommigen dat mensen met een migratie achtergrond hier moeten kunnen leven met behoud van de eigen cultuur. Anderen vinden dat zij zich geheel moeten aanpassen aan de Nederlandse cultuur. Waar zou u uzelf plaatsen op een schaal van 1 t/m 5, waarbij 1 behoud van eigen cultuur voor mensen met een migratie achtergrond betekent en 5 dat zij zich geheel moeten aanpassen?  
>  
> 1	behoud van eigen cultuur voor mensen met een migratie achtergrond  
> 2  
> 3	  
> 4	  
> 5	mensen met een migratie achtergrond moeten zich geheel aanpassen  

</p>
---  

## Descriptives

### Preperation 

```{r, echo=TRUE}
#### clean the environment ####.
rm(list=ls())

#### packages ####.
require(tidyverse)

##### Data input ###.
load('addfiles/partner_dataprepped.Rdata')

#clean a little bit. 
rm("partner_df_wide") #we will make a wide file later again. 

partner_df_long <- partner_df_long %>%
  rename("dyad_id" = "nohouse_encr") %>%
  select(-c("hetero", "n", "nomem_encr.m", "positie.m", "nomem_encr.f", "positie.f"))

partner_df_wide <- reshape(partner_df_long,
                           direction = 'wide',
                           idvar = 'dyad_id',
                           timevar = 'time')

```

```{r, echo=FALSE}

##### custom functions ###.
# let us define our polarization function again

fpol <- function(opinions, maxdif=NULL) {
  N <- length(opinions)
  egos <- matrix(opinions, nrow=N, ncol=N, byrow=TRUE)
  alters <- t(egos)
  difference <- if (is.null(maxdif)) { abs(egos - alters) / (range(opinions)[2] - range(opinions)[1])  } else { abs(egos-alters)/maxdif } 
  diag(difference) <- NA
  pol <- var(as.numeric(difference), na.rm=T)
  return(pol)
}

```

Please note that our time variable indicates survey year. We do not want to describe period trends in opinion homophily within couples but lifecourse trends. We will call the latter the *within-trend*. For people familiar with life course research, hopefully you will see the resemblance to the Age-Period-Cohort conundrum. We therefore need to construct a `time_within` variable and add it to our data set.  

`r colorize("Before copying the 'hidden code' below, please try to do this yourself.", "red")` 


<button class=button1 onclick="myFunction()" id="myButton" value="Click To Open Instructions">Only click button after 5 minutes!</button>

<div style="display:none;" id="myDIV">
```{r}
partner_df_long <- partner_df_long %>%
  arrange(dyad_id, time) %>% #let us order the data set
  group_by(dyad_id) %>% #we focus on within dyad-level thus group by dyad
  mutate(start_time = min(time), #determine first wave of participation
         within_time = (time - start_time) + 1, #count passing of time within couples
         n_time = n()) %>% #keep track of number of times couples participated in LISS
  ungroup()
```
</div>

Now we need to think of how we want to operationalize opinion homophily. 

The stronger the political opinion homophily within couples, the larger the spousal correspondence, the larger the association between the opinions of the partners. We discussed covariance and correlations [here](#variance-and-covariance). Would that be an option?    

A different approach would be to operationalize increasing homophily as decreasing absolute opinion dissimilarity between the spouses [@iyengar2018]. 

### Opinion homophily over *within-time*  

Let's have a go. 

```{r trends}
cors <- partner_df_long %>% 
  group_by(within_time)  %>% #we want to see within couple trends. 
  group_map(~ cor.test(x=.x$immigrants.m, y=.x$immigrants.f)$estimate ) %>%
  unlist()

# How to do this in Base R?
# # we subset the data. 
# cor.test(partner_df_long$immigrants.m[partner_df_long$within_time==1], partner_df_long$immigrants.f[partner_df_long$within_time==1])
# 
# #And we could use a loop. 
# cors <- list()
# for (i in 1:11) {
#  cors[[i]] <-  cor.test(partner_df_long$immigrants.m[partner_df_long$within_time==i], partner_df_long$immigrants.f[partner_df_long$within_time==i])
# }


covs <- partner_df_long %>% 
  group_by(within_time)  %>% #we want to see within couple trends. 
  group_map(~ cov(x=.x$immigrants.m, y=.x$immigrants.f, use="complete.obs") ) %>%
  unlist()

partner_df_long %>% 
  mutate(distance = abs(immigrants.m - immigrants.f)) %>%
  group_by(within_time)  %>% #we want to see within couple trends. 
  summarise(mean_dist = mean(distance, na.rm=T)) %>%
  add_column(cors) %>%
  add_column(covs)
```

Whow! Please look at the above results for at least **5 minutes** before you move one. What is your interpretation? Do you observe a (significant) trend? Suppose that the mean distance indeed decreased but that, as a consequence, also the variance in this opinion decreased. What impact would this have for the covariance?    

### Distinguishing period trends from lifecourse trends  

The above results are hard to interpret. In part because we mix up period trends and and within-trends. And although we are interested in influence and shared context effects, we must not forget about (de)selection effects. The couples who survive to reach within-time 11 are probably a selective subgroup of all couples. 

A bit more sophisticated:  

- calculate the (euclidean) distance between all four attitudes.  
- Try to distinguishing period trends from lifecourse trends.  
- Try to take into account of selective sample attrition.^[One of the reasons couples drop out of our data is because of divorce.] 

```{r, results='hide'}
trends <- partner_df_long %>%
  filter(n_time>4) %>% #trying to take selective sample attrition into account. 
  mutate(distance = sqrt((immigrants.m - immigrants.f)^2 + (euthanasia.m - euthanasia.f)^2 + (income_diff.m - income_diff.f)^2 + (eu_integration.m - eu_integration.f)^2 )) %>% #euclidean distance of four political opinions
  group_by(start_time, within_time)  %>% #we want to see within couple trends but need to 'control for' period trends 
  summarise(mean_dist = mean(distance, na.rm=T))

#Put results in a matrix
#?? how to do this the tidy way? 
trends_matrix <- matrix(NA, nrow=11, ncol=11)
for (i in 1:length(trends$start_time)) {
  trends_matrix[trends$start_time[i],trends$within_time[i]] <- trends$mean_dist[i]
}

rownames(trends_matrix) <- c(2008:2014, 2016:2019)
colnames(trends_matrix) <- paste("within_time", 1:11, sep="_")

trends_matrix
```

```{r, echo=FALSE}
require(kableExtra)

df2 <- data.frame(round(trends_matrix,3), row.names = row.names(trends_matrix))

df2[1,1] <- cell_spec(df2[1, 1], "html", color = "red")
df2[2,2] <- cell_spec(df2[2, 2], "html", color = "red")
df2[3,3] <- cell_spec(df2[3, 3], "html", color = "red")
df2[4,4] <- cell_spec(df2[4, 4], "html", color = "red")
df2[5,5] <- cell_spec(df2[5, 5], "html", color = "red")

df2[1,2] <- cell_spec(df2[1, 2], "html", color = "blue")
df2[2,3] <- cell_spec(df2[2, 3], "html", color = "blue")
df2[3,4] <- cell_spec(df2[3, 4], "html", color = "blue")
df2[4,5] <- cell_spec(df2[4, 5], "html", color = "blue")
df2[5,6] <- cell_spec(df2[5, 6], "html", color = "blue")

desc <- df2 %>% 
  kable(escape=FALSE, caption="Trends in spousal correspondance in political attitudes", align = "c" , booktabs=TRUE) %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>% 
 scroll_box(width="100%", height = "400px")

desc
```
\

Follow the same couples over time by following the diagonals (e.g. the blue and red). 

What would you conclude? 

---  

## Analysis 

Even tough the above descriptives do not show convincing time trends, we know that partners may still influence each other. Let us try to test for influence processes.  

>Feel free to re-estimate all models yourself. But it will be way quicker to download all results. 
>
> [results.Rdata](addfiles\results.Rdata)\


### Preperation  

We need to do some additional dataprep. 

```{r, echo=FALSE}
#clean the environment. 
rm(list=ls())

# Data input
load('addfiles/partner_dataprepped.Rdata')

partner_df_wide <- reshape(partner_df_long,
                           direction = 'wide',
                           v.names = names(partner_df_long[2,4:22]),
                           idvar = 'nohouse_encr',
                           timevar = 'time')


```

I know it is a bit cumbersome, but we will make a datafile for each dependent variable separately and will use some shorter names. The data files are stored in a list called `datalist_ori`. 

```{r, echo=TRUE, results='hide'}
datalist_ori <- list()

# dep1: eu_integration

dat <- data.frame(x1=partner_df_wide$eu_integration.m.1)
dat$x2 <- partner_df_wide$eu_integration.m.2
dat$x3 <- partner_df_wide$eu_integration.m.3
dat$x4 <- partner_df_wide$eu_integration.m.4
dat$x5 <- partner_df_wide$eu_integration.m.5
dat$x6 <- partner_df_wide$eu_integration.m.6
dat$x7 <- partner_df_wide$eu_integration.m.7
dat$x8 <- partner_df_wide$eu_integration.m.8
dat$x9 <- partner_df_wide$eu_integration.m.9
dat$x10 <- partner_df_wide$eu_integration.m.10
dat$x11 <- partner_df_wide$eu_integration.m.11

dat$y1 <- partner_df_wide$eu_integration.f.1
dat$y2 <- partner_df_wide$eu_integration.f.2
dat$y3 <- partner_df_wide$eu_integration.f.3
dat$y4 <- partner_df_wide$eu_integration.f.4
dat$y5 <- partner_df_wide$eu_integration.f.5
dat$y6 <- partner_df_wide$eu_integration.f.6
dat$y7 <- partner_df_wide$eu_integration.f.7
dat$y8 <- partner_df_wide$eu_integration.f.8
dat$y9 <- partner_df_wide$eu_integration.f.9
dat$y10 <- partner_df_wide$eu_integration.f.10
dat$y11 <- partner_df_wide$eu_integration.f.11

#treat education as a time stable. And use all available data. 
dat$oplx <- rowMeans(partner_df_wide[,c("oplmet.m.1", "oplmet.m.2",  "oplmet.m.3", "oplmet.m.4", "oplmet.m.5", "oplmet.m.6", "oplmet.m.7",  "oplmet.m.8", "oplmet.m.9", "oplmet.m.10", "oplmet.m.11")], na.rm=T)
dat$oply <- rowMeans(partner_df_wide[,c("oplmet.f.1", "oplmet.f.2",  "oplmet.f.3", "oplmet.f.4", "oplmet.f.5", "oplmet.f.6", "oplmet.f.7",  "oplmet.f.8", "oplmet.f.9", "oplmet.f.10", "oplmet.f.11")], na.rm=T)

#calculate diff in education between men and women
dat$oplxy <- dat$oplx - dat$oply
#table(dat$oplx, dat$oply, useNA = "always")
#hist(dat$oplxy)

#define three groups for multigroup analyses
dat$oplgroup <- ifelse(dat$oplxy > 1, "menhigher", NA)
dat$oplgroup <- ifelse(dat$oplxy < -1, "womenhigher", dat$oplgroup)
dat$oplgroup <- ifelse(dat$oplxy <= 1 & dat$oplxy >= -1, "equal", dat$oplgroup)
#table(dat$oplgroup, useNA = "always")

dat_ori <- dat
datalist_ori[[1]] <- dat_ori

# dep2: immigrants

dat <- data.frame(x1=partner_df_wide$immigrants.m.1)
dat$x2 <- partner_df_wide$immigrants.m.2
dat$x3 <- partner_df_wide$immigrants.m.3
dat$x4 <- partner_df_wide$immigrants.m.4
dat$x5 <- partner_df_wide$immigrants.m.5
dat$x6 <- partner_df_wide$immigrants.m.6
dat$x7 <- partner_df_wide$immigrants.m.7
dat$x8 <- partner_df_wide$immigrants.m.8
dat$x9 <- partner_df_wide$immigrants.m.9
dat$x10 <- partner_df_wide$immigrants.m.10
dat$x11 <- partner_df_wide$immigrants.m.11

dat$y1 <- partner_df_wide$immigrants.f.1
dat$y2 <- partner_df_wide$immigrants.f.2
dat$y3 <- partner_df_wide$immigrants.f.3
dat$y4 <- partner_df_wide$immigrants.f.4
dat$y5 <- partner_df_wide$immigrants.f.5
dat$y6 <- partner_df_wide$immigrants.f.6
dat$y7 <- partner_df_wide$immigrants.f.7
dat$y8 <- partner_df_wide$immigrants.f.8
dat$y9 <- partner_df_wide$immigrants.f.9
dat$y10 <- partner_df_wide$immigrants.f.10
dat$y11 <- partner_df_wide$immigrants.f.11

#treat education as a time stable. And use all available data. 
dat$oplx <- rowMeans(partner_df_wide[,c("oplmet.m.1", "oplmet.m.2",  "oplmet.m.3", "oplmet.m.4", "oplmet.m.5", "oplmet.m.6", "oplmet.m.7",  "oplmet.m.8", "oplmet.m.9", "oplmet.m.10", "oplmet.m.11")], na.rm=T)
dat$oply <- rowMeans(partner_df_wide[,c("oplmet.f.1", "oplmet.f.2",  "oplmet.f.3", "oplmet.f.4", "oplmet.f.5", "oplmet.f.6", "oplmet.f.7",  "oplmet.f.8", "oplmet.f.9", "oplmet.f.10", "oplmet.f.11")], na.rm=T)

#calculate diff in education between men and women
dat$oplxy <- dat$oplx - dat$oply
#table(dat$oplx, dat$oply, useNA = "always")
#hist(dat$oplxy)

#define three groups for multigroup analyses
dat$oplgroup <- ifelse(dat$oplxy > 1, "menhigher", NA)
dat$oplgroup <- ifelse(dat$oplxy < -1, "womenhigher", dat$oplgroup)
dat$oplgroup <- ifelse(dat$oplxy <= 1 & dat$oplxy >= -1, "equal", dat$oplgroup)
#table(dat$oplgroup, useNA = "always")

dat_ori <- dat
datalist_ori[[2]] <- dat_ori

# dep3: euthanasia

dat <- data.frame(x1=partner_df_wide$euthanasia.m.1)
dat$x2 <- partner_df_wide$euthanasia.m.2
dat$x3 <- partner_df_wide$euthanasia.m.3
dat$x4 <- partner_df_wide$euthanasia.m.4
dat$x5 <- partner_df_wide$euthanasia.m.5
dat$x6 <- partner_df_wide$euthanasia.m.6
dat$x7 <- partner_df_wide$euthanasia.m.7
dat$x8 <- partner_df_wide$euthanasia.m.8
dat$x9 <- partner_df_wide$euthanasia.m.9
dat$x10 <- partner_df_wide$euthanasia.m.10
dat$x11 <- partner_df_wide$euthanasia.m.11

dat$y1 <- partner_df_wide$euthanasia.f.1
dat$y2 <- partner_df_wide$euthanasia.f.2
dat$y3 <- partner_df_wide$euthanasia.f.3
dat$y4 <- partner_df_wide$euthanasia.f.4
dat$y5 <- partner_df_wide$euthanasia.f.5
dat$y6 <- partner_df_wide$euthanasia.f.6
dat$y7 <- partner_df_wide$euthanasia.f.7
dat$y8 <- partner_df_wide$euthanasia.f.8
dat$y9 <- partner_df_wide$euthanasia.f.9
dat$y10 <- partner_df_wide$euthanasia.f.10
dat$y11 <- partner_df_wide$euthanasia.f.11

#treat education as a time stable. And use all available data. 
dat$oplx <- rowMeans(partner_df_wide[,c("oplmet.m.1", "oplmet.m.2",  "oplmet.m.3", "oplmet.m.4", "oplmet.m.5", "oplmet.m.6", "oplmet.m.7",  "oplmet.m.8", "oplmet.m.9", "oplmet.m.10", "oplmet.m.11")], na.rm=T)
dat$oply <- rowMeans(partner_df_wide[,c("oplmet.f.1", "oplmet.f.2",  "oplmet.f.3", "oplmet.f.4", "oplmet.f.5", "oplmet.f.6", "oplmet.f.7",  "oplmet.f.8", "oplmet.f.9", "oplmet.f.10", "oplmet.f.11")], na.rm=T)

#calculate diff in education between men and women
dat$oplxy <- dat$oplx - dat$oply
#table(dat$oplx, dat$oply, useNA = "always")
#hist(dat$oplxy)

#define three groups for multigroup analyses
dat$oplgroup <- ifelse(dat$oplxy > 1, "menhigher", NA)
dat$oplgroup <- ifelse(dat$oplxy < -1, "womenhigher", dat$oplgroup)
dat$oplgroup <- ifelse(dat$oplxy <= 1 & dat$oplxy >= -1, "equal", dat$oplgroup)
#table(dat$oplgroup, useNA = "always")

dat_ori <- dat
datalist_ori[[3]] <- dat_ori

# dep4: income_diff

dat <- data.frame(x1=partner_df_wide$income_diff.m.1)
dat$x2 <- partner_df_wide$income_diff.m.2
dat$x3 <- partner_df_wide$income_diff.m.3
dat$x4 <- partner_df_wide$income_diff.m.4
dat$x5 <- partner_df_wide$income_diff.m.5
dat$x6 <- partner_df_wide$income_diff.m.6
dat$x7 <- partner_df_wide$income_diff.m.7
dat$x8 <- partner_df_wide$income_diff.m.8
dat$x9 <- partner_df_wide$income_diff.m.9
dat$x10 <- partner_df_wide$income_diff.m.10
dat$x11 <- partner_df_wide$income_diff.m.11

dat$y1 <- partner_df_wide$income_diff.f.1
dat$y2 <- partner_df_wide$income_diff.f.2
dat$y3 <- partner_df_wide$income_diff.f.3
dat$y4 <- partner_df_wide$income_diff.f.4
dat$y5 <- partner_df_wide$income_diff.f.5
dat$y6 <- partner_df_wide$income_diff.f.6
dat$y7 <- partner_df_wide$income_diff.f.7
dat$y8 <- partner_df_wide$income_diff.f.8
dat$y9 <- partner_df_wide$income_diff.f.9
dat$y10 <- partner_df_wide$income_diff.f.10
dat$y11 <- partner_df_wide$income_diff.f.11

#treat education as a time stable. And use all available data. 
dat$oplx <- rowMeans(partner_df_wide[,c("oplmet.m.1", "oplmet.m.2",  "oplmet.m.3", "oplmet.m.4", "oplmet.m.5", "oplmet.m.6", "oplmet.m.7",  "oplmet.m.8", "oplmet.m.9", "oplmet.m.10", "oplmet.m.11")], na.rm=T)
dat$oply <- rowMeans(partner_df_wide[,c("oplmet.f.1", "oplmet.f.2",  "oplmet.f.3", "oplmet.f.4", "oplmet.f.5", "oplmet.f.6", "oplmet.f.7",  "oplmet.f.8", "oplmet.f.9", "oplmet.f.10", "oplmet.f.11")], na.rm=T)

#calculate diff in education between men and women
dat$oplxy <- dat$oplx - dat$oply
#table(dat$oplx, dat$oply, useNA = "always")
#hist(dat$oplxy)

#define three groups for multigroup analyses
dat$oplgroup <- ifelse(dat$oplxy > 1, "menhigher", NA)
dat$oplgroup <- ifelse(dat$oplxy < -1, "womenhigher", dat$oplgroup)
dat$oplgroup <- ifelse(dat$oplxy <= 1 & dat$oplxy >= -1, "equal", dat$oplgroup)
#table(dat$oplgroup, useNA = "always")

dat_ori <- dat
datalist_ori[[4]] <- dat_ori


```


### Modelling strategy 

1.  takes into account that observations within couples are interdependent;

2.  that can explain the interdependence at the couple level;

3.  focus on changes taking place within couples, not on changes between couples;

4.  clearly distinguishes between:

    i.  Actor effects: stability effects
    ii. Partner effects: influence effects

5.  Is flexible, so we can control, for example, for educational effects.
A model that tickes all the boxes is the Random Intercep Cross-Lagged Panel Model.  


```{r, echo=FALSE, out.width="100%", fig.cap="RI-CLPM"}
knitr::include_graphics("hsem_a_1784738_f0001_oc.jpg")
```
  

Source: [@mulder2020three]

### Robustness
We will compare the results across four different modeling strategies:

1.  Cross-lagged Panel Model (CLPM) (11 waves). This model lumps together between couple effects and within couples effects but it may help us to compare results.
2.  **RI-CLPM (11 waves)**. We will focus on this model!
3.  RI-CLPM + structural time trends (11 waves). This model takes into account that there may also be general period (or structural) trends in the opinions.
4.  RI/RS-CLPM (11 waves). Finally, in this model we take into account that spouses may show different (linear) trends in their opinions for reasons we do not know. It is a random-intercept, random-slope growth curve model for the two spouses combined.

We will test our hypotheses for four different dependent variables:

1.  eu-integration
2.  immigration
3.  euthanasia
4.  income differences\

### Results hypo1  


**Hypo1 RI-CLPM: When your partner's opinion is relatively high (compared to your partners average opinion over time) at time T, your own opinion will be relatively high (compared to your own average opinion over time) at time T+1.** 


#### CLPM  

```{r, eval=FALSE, echo=TRUE}
results <- list()

myModel <- "
  ### control for education
  x1 + x2 + x3 +x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 ~ e*oplx
  y1 + y2 + y3 +y4 + y5 + y6 + y7 + y8 + y9 + y10 + y11 ~ e*oply
  
  ### Estimate the lagged effects
  x2 ~ a*x1 + b*y1
  x3 ~ a*x2 + b*y2
  x4 ~ a*x3 + b*y3
  x5 ~ a*x4 + b*y4
  x6 ~ a*x5 + b*y5
  x7 ~ a*x6 + b*y6
  x8 ~ a*x7 + b*y7
  x9 ~ a*x8 + b*y8
  x10 ~ a*x9 + b*y9
  x11 ~ a*x10 + b*y10
  
  y2 ~ b*x1 + a*y1
  y3 ~ b*x2 + a*y2
  y4 ~ b*x3 + a*y3
  y5 ~ b*x4 + a*y4
  y6 ~ b*x5 + a*y5
  y7 ~ b*x6 + a*y6
  y8 ~ b*x7 + a*y7
  y9 ~ b*x8 + a*y8
  y10 ~ b*x9 + a*y9
  y11 ~ b*x10 + a*y10

  # Estimate the (residual) covariance between the variables
  x1 ~~ y1 # Covariance
  x2 ~~ y2
  x3 ~~ y3
  x4 ~~ y4
  x5 ~~ y5
  x6 ~~ y6
  x7 ~~ y7
  x8 ~~ y8
  x9 ~~ y9
  x10 ~~ y10
  x11 ~~ y11
  
  # Estimate the (residual) variance of the variables.
  x1 ~~ x1 # Variances
  y1 ~~ y1 
  x2 ~~ x2 # Residual variances
  y2 ~~ y2 
  x3 ~~ x3 
  y3 ~~ y3 
  x4 ~~ x4 
  y4 ~~ y4 
  x5 ~~ x5
  y5 ~~ y5
  x6 ~~ x6
  y6 ~~ y6
  x7 ~~ x7
  y7 ~~ y7 
  x8 ~~ x8 
  y8 ~~ y8 
  x9 ~~ x9 
  y9 ~~ y9 
  x10 ~~ x10
  y10 ~~ y10
  x11 ~~ x11
  y11 ~~ y11
  
  #intercepts
  x1 ~ 1
  y1 ~ 1
  x2 ~ 1
  y2 ~ 1
  x3 ~ 1
  y3 ~ 1
  x4 ~ 1
  y4 ~ 1
  x5 ~ 1
  y5 ~ 1
  x6 ~ 1
  y6 ~ 1
  x7 ~ 1
  y7 ~ 1
  x8 ~ 1
  y8 ~ 1
  x9 ~ 1
  y9 ~ 1
  x10 ~ 1
  y10 ~ 1
  x11 ~ 1
  y11 ~ 1
  
  
"

#Estimate models a bit faster:

estimate <- function(x) lavaan(myModel, data=x, missing = "fiml.x", meanstructure = T )
library(future.apply)
plan(multisession)

results_temp <- future_lapply(datalist_ori, estimate)

results[[1]] <- results_temp[[1]]
results[[2]] <- results_temp[[2]]
results[[3]] <- results_temp[[3]]
results[[4]] <- results_temp[[4]]

names(results)[1:4] <-  c("fitm1h1y1", "fitm1h1y2","fitm1h1y3","fitm1h1y4")

save(results, file="results.RData")
```

```{r, results="hold"}

load("addfiles/results.Rdata")

summary(results[[1]])
summary(results[[2]])
summary(results[[3]])
summary(results[[4]])

```

#### RI-CLPM

```{r, eval=FALSE, echo=TRUE}
RICLPM <- '
  # Create between components (random intercepts)
  RIx =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 + 1*x5 + 1*x6 + 1*x7 + 1*x8 + 1*x9 + 1*x10 + 1*x11
  RIy =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 + 1*y5 + 1*y6 + 1*y7 + 1*y8 + 1*y9 + 1*y10 + 1*y11  
  
  RIx ~ e*oplx
  RIy ~ e*oply
  
  # Create within-person centered variables
  wx1 =~ 1*x1
  wx2 =~ 1*x2
  wx3 =~ 1*x3 
  wx4 =~ 1*x4
  wx5 =~ 1*x5
  wx6 =~ 1*x6
  wx7 =~ 1*x7
  wx8 =~ 1*x8 
  wx9 =~ 1*x9
  wx10 =~ 1*x10
  wx11 =~ 1*x11
 
  wy1 =~ 1*y1
  wy2 =~ 1*y2
  wy3 =~ 1*y3
  wy4 =~ 1*y4
  wy5 =~ 1*y5
  wy6 =~ 1*y6
  wy7 =~ 1*y7
  wy8 =~ 1*y8
  wy9 =~ 1*y9
  wy10 =~ 1*y10
  wy11 =~ 1*y11

  # Estimate the lagged effects between the within-person centered variables.
  wx2 ~ a*wx1 + b*wy1
  wx3 ~ a*wx2 + b*wy2
  wx4 ~ a*wx3 + b*wy3
  wx5 ~ a*wx4 + b*wy4
  wx6 ~ a*wx5 + b*wy5
  wx7 ~ a*wx6 + b*wy6
  wx8 ~ a*wx7 + b*wy7
  wx9 ~ a*wx8 + b*wy8
  wx10 ~ a*wx9 + b*wy9
  wx11 ~ a*wx10 + b*wy10
  
  wy2 ~ b*wx1 + a*wy1
  wy3 ~ b*wx2 + a*wy2
  wy4 ~ b*wx3 + a*wy3
  wy5 ~ b*wx4 + a*wy4
  wy6 ~ b*wx5 + a*wy5
  wy7 ~ b*wx6 + a*wy6
  wy8 ~ b*wx7 + a*wy7
  wy9 ~ b*wx8 + a*wy8
  wy10 ~ b*wx9 + a*wy9
  wy11 ~ b*wx10 + a*wy10

  # Estimate the (residual) covariance between the within-person centered variables
  wx1 ~~ wy1 # Covariance
  wx2 ~~ wy2
  wx3 ~~ wy3
  wx4 ~~ wy4
  wx5 ~~ wy5
  wx6 ~~ wy6
  wx7 ~~ wy7
  wx8 ~~ wy8
  wx9 ~~ wy9
  wx10 ~~ wy10
  wx11 ~~ wy11
  
  # Estimate the variance and covariance of the random intercepts. 
  RIx ~~ RIx
  RIy ~~ RIy
  RIx ~~ RIy

  # Estimate the (residual) variance of the within-person centered variables.
  wx1 ~~ wx1 # Variances
  wy1 ~~ wy1 
  wx2 ~~ wx2 # Residual variances
  wy2 ~~ wy2 
  wx3 ~~ wx3 
  wy3 ~~ wy3 
  wx4 ~~ wx4 
  wy4 ~~ wy4 
  wx5 ~~ wx5
  wy5 ~~ wy5
  wx6 ~~ wx6
  wy6 ~~ wy6
  wx7 ~~ wx7
  wy7 ~~ wy7 
  wx8 ~~ wx8 
  wy8 ~~ wy8 
  wx9 ~~ wx9 
  wy9 ~~ wy9 
  wx10 ~~ wx10
  wy10 ~~ wy10
  wx11 ~~ wx11
  wy11 ~~ wy11
'

#Estimate models a bit faster:

estimate <- function(x) lavaan(RICLPM, data=x, missing = "fiml.x", meanstructure = T )
library(future.apply)
plan(multisession)

results_temp <- future_lapply(datalist_ori, estimate)

results[[5]] <- results_temp[[1]]
results[[6]] <- results_temp[[2]]
results[[7]] <- results_temp[[3]]
results[[8]] <- results_temp[[4]]

names(results)[5:8] <- c("fitm2h1y1", "fitm2h1y2","fitm2h1y3","fitm2h1y4")

```

```{r, results="hold"}

load("addfiles/results.Rdata")
summary(results[[5]])
summary(results[[6]])
summary(results[[7]])
summary(results[[8]])


```


#### SC-RI-CLPM

```{r, eval=FALSE, echo=TRUE}
SCCLPM <- '
  # Create between components 
  RIx =~ 1*x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11
  RIy =~ 1*y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9 + y10 + y11  
  
  RIx ~ e*oplx
  RIy ~ e*oply
  
  # Create within-person centered variables
  wx1 =~ 1*x1
  wx2 =~ 1*x2
  wx3 =~ 1*x3 
  wx4 =~ 1*x4
  wx5 =~ 1*x5
  wx6 =~ 1*x6
  wx7 =~ 1*x7
  wx8 =~ 1*x8 
  wx9 =~ 1*x9
  wx10 =~ 1*x10
  wx11 =~ 1*x11
 
  wy1 =~ 1*y1
  wy2 =~ 1*y2
  wy3 =~ 1*y3
  wy4 =~ 1*y4
  wy5 =~ 1*y5
  wy6 =~ 1*y6
  wy7 =~ 1*y7
  wy8 =~ 1*y8
  wy9 =~ 1*y9
  wy10 =~ 1*y10
  wy11 =~ 1*y11

  # Estimate the lagged effects between the within-person centered variables.
  wx2 ~ a*wx1 + b*wy1
  wx3 ~ a*wx2 + b*wy2
  wx4 ~ a*wx3 + b*wy3
  wx5 ~ a*wx4 + b*wy4
  wx6 ~ a*wx5 + b*wy5
  wx7 ~ a*wx6 + b*wy6
  wx8 ~ a*wx7 + b*wy7
  wx9 ~ a*wx8 + b*wy8
  wx10 ~ a*wx9 + b*wy9
  wx11 ~ a*wx10 + b*wy10
  
  wy2 ~ b*wx1 + a*wy1
  wy3 ~ b*wx2 + a*wy2
  wy4 ~ b*wx3 + a*wy3
  wy5 ~ b*wx4 + a*wy4
  wy6 ~ b*wx5 + a*wy5
  wy7 ~ b*wx6 + a*wy6
  wy8 ~ b*wx7 + a*wy7
  wy9 ~ b*wx8 + a*wy8
  wy10 ~ b*wx9 + a*wy9
  wy11 ~ b*wx10 + a*wy10

  # Estimate the (residual) covariance between the within-person centered variables
  wx1 ~~ wy1 # Covariance
  wx2 ~~ wy2
  wx3 ~~ wy3
  wx4 ~~ wy4
  wx5 ~~ wy5
  wx6 ~~ wy6
  wx7 ~~ wy7
  wx8 ~~ wy8
  wx9 ~~ wy9
  wx10 ~~ wy10
  wx11 ~~ wy11
  
  # Estimate the variance and covariance of the random intercepts. 
  RIx ~~ RIx
  RIy ~~ RIy
  RIx ~~ RIy

  # Estimate the (residual) variance of the within-person centered variables.
  wx1 ~~ wx1 # Variances
  wy1 ~~ wy1 
  wx2 ~~ wx2 # Residual variances
  wy2 ~~ wy2 
  wx3 ~~ wx3 
  wy3 ~~ wy3 
  wx4 ~~ wx4 
  wy4 ~~ wy4 
  wx5 ~~ wx5
  wy5 ~~ wy5
  wx6 ~~ wx6
  wy6 ~~ wy6
  wx7 ~~ wx7
  wy7 ~~ wy7 
  wx8 ~~ wx8 
  wy8 ~~ wy8 
  wx9 ~~ wx9 
  wy9 ~~ wy9 
  wx10 ~~ wx10
  wy10 ~~ wy10
  wx11 ~~ wx11
  wy11 ~~ wy11
'

#Estimate models a bit faster:

estimate <- function(x) lavaan(SCCLPM, data=x, missing = "fiml.x", meanstructure = T )
library(future.apply)
plan(multisession)

results_temp <- future_lapply(datalist_ori, estimate)

results[[9]] <- results_temp[[1]]
results[[10]] <- results_temp[[2]]
results[[11]] <- results_temp[[3]]
results[[12]] <- results_temp[[4]]

names(results)[9:12] <- c("fitm3h1y1", "fitm3h1y2","fitm3h1y3","fitm3h1y4")
```

```{r, results="hold"}

load("addfiles/results.Rdata")
summary(results[[9]])
summary(results[[10]])
summary(results[[11]])
summary(results[[12]])


```


#### LT-RI-CLPM

```{r , eval=FALSE, echo=TRUE}

LTRICLPM <- '
  # Create between components (random intercepts)
  RIx =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 + 1*x5 + 1*x6 + 1*x7 + 1*x8 + 1*x9 + 1*x10 + 1*x11
  RIy =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 + 1*y5 + 1*y6 + 1*y7 + 1*y8 + 1*y9 + 1*y10 + 1*y11
  
  RIx ~ e*oplx
  RIy ~ e*oply
  
  #Random slopes
  RIsx =~ 1*x1 + 2*x2 + 3*x3 + 4*x4 + 5*x5 + 6*x6 + 7*x7 + 8*x8 + 9*x9 + 10*x10 + 11*x11
  RIsy =~ 1*y1 + 2*y2 + 3*y3 + 4*y4 + 5*y5 + 6*y6 + 7*y7 + 8*y8 + 9*y9 + 10*y10 + 11*y11
  
  RIsx ~ f*oplx
  RIsy ~ f*oply
  
  # Create within-person centered variables
  wx1 =~ 1*x1
  wx2 =~ 1*x2
  wx3 =~ 1*x3 
  wx4 =~ 1*x4
  wx5 =~ 1*x5
  wx6 =~ 1*x6
  wx7 =~ 1*x7
  wx8 =~ 1*x8 
  wx9 =~ 1*x9
  wx10 =~ 1*x10
  wx11 =~ 1*x11
 
  wy1 =~ 1*y1
  wy2 =~ 1*y2
  wy3 =~ 1*y3
  wy4 =~ 1*y4
  wy5 =~ 1*y5
  wy6 =~ 1*y6
  wy7 =~ 1*y7
  wy8 =~ 1*y8
  wy9 =~ 1*y9
  wy10 =~ 1*y10
  wy11 =~ 1*y11

  # Estimate the lagged effects between the within-person centered variables.
  wx2 ~ a*wx1 + b*wy1
  wx3 ~ a*wx2 + b*wy2
  wx4 ~ a*wx3 + b*wy3
  wx5 ~ a*wx4 + b*wy4
  wx6 ~ a*wx5 + b*wy5
  wx7 ~ a*wx6 + b*wy6
  wx8 ~ a*wx7 + b*wy7
  wx9 ~ a*wx8 + b*wy8
  wx10 ~ a*wx9 + b*wy9
  wx11 ~ a*wx10 + b*wy10
  
  wy2 ~ b*wx1 + a*wy1
  wy3 ~ b*wx2 + a*wy2
  wy4 ~ b*wx3 + a*wy3
  wy5 ~ b*wx4 + a*wy4
  wy6 ~ b*wx5 + a*wy5
  wy7 ~ b*wx6 + a*wy6
  wy8 ~ b*wx7 + a*wy7
  wy9 ~ b*wx8 + a*wy8
  wy10 ~ b*wx9 + a*wy9
  wy11 ~ b*wx10 + a*wy10

  # Estimate the (residual) covariance between the within-person centered variables
  wx1 ~~ wy1 # Covariance
  wx2 ~~ wy2
  wx3 ~~ wy3
  wx4 ~~ wy4
  wx5 ~~ wy5
  wx6 ~~ wy6
  wx7 ~~ wy7
  wx8 ~~ wy8
  wx9 ~~ wy9
  wx10 ~~ wy10
  wx11 ~~ wy11
  
  # Estimate the variance and covariance of the random intercepts and random slopes. 
  RIx ~~ RIx
  RIy ~~ RIy
  RIx ~~ RIy #covariance intercepts: interpretation SELECTION
  RIsx ~~ RIsx
  RIsy ~~ RIsy
  RIsx ~~ RIsy #covariance slopes: interpretation COMMON CONTEXT
  RIx ~~ RIsx #covariance intercept/slope: interpretation regression to the mean
  RIy ~~ RIsy
  RIx ~~ RIsy #cross-covariance: interpretation  INFLUENCE? 
  RIy ~~ RIsx

  # Estimate the (residual) variance of the within-person centered variables.
  wx1 ~~ wx1 # Variances
  wy1 ~~ wy1 
  wx2 ~~ wx2 # Residual variances
  wy2 ~~ wy2 
  wx3 ~~ wx3 
  wy3 ~~ wy3 
  wx4 ~~ wx4 
  wy4 ~~ wy4 
  wx5 ~~ wx5
  wy5 ~~ wy5
  wx6 ~~ wx6
  wy6 ~~ wy6
  wx7 ~~ wx7
  wy7 ~~ wy7 
  wx8 ~~ wx8 
  wy8 ~~ wy8 
  wx9 ~~ wx9 
  wy9 ~~ wy9 
  wx10 ~~ wx10
  wy10 ~~ wy10
  wx11 ~~ wx11
  wy11 ~~ wy11
'


#Estimate models a bit faster:

estimate <- function(x) lavaan(LTRICLPM, data=x, missing = "fiml.x", meanstructure = T )
library(future.apply)
plan(multisession)

results_temp <- future_lapply(datalist_ori, estimate)

results[[13]] <- results_temp[[1]]
results[[14]] <- results_temp[[2]]
results[[15]] <- results_temp[[3]]
results[[16]] <- results_temp[[4]]

names(results)[9:12] <- c("fitm4h1y1", "fitm4h1y2","fitm4h1y3","fitm4h1y4")

save(results, file="results.RData")

```

```{r, results="hold"}

load("addfiles/results.Rdata")

summary(results[[13]])
summary(results[[14]])
summary(results[[15]])
summary(results[[16]])

```

### Summary results hypo1

```{r, results='asis', echo=FALSE}

load("addfiles/results.Rdata")

library(knitr) #for kable/kables
#install.packages("kableExtra", repos='http://cran.us.r-project.org')
library(kableExtra)


#retrieving data to show
#model 1
a <- parameterEstimates(results[[1]])[parameterEstimates(results[[1]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[1]])[parameterEstimates(results[[1]])$label=="b",][1,c(5,6,8)]
m1h1y1 <- rbind(a,b)


a <- parameterEstimates(results[[2]])[parameterEstimates(results[[2]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[2]])[parameterEstimates(results[[2]])$label=="b",][1,c(5,6,8)]
m1h1y2 <- rbind(a,b)

a <- parameterEstimates(results[[3]])[parameterEstimates(results[[3]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[3]])[parameterEstimates(results[[3]])$label=="b",][1,c(5,6,8)]
m1h1y3 <- rbind(a,b)

a <- parameterEstimates(results[[4]])[parameterEstimates(results[[4]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[4]])[parameterEstimates(results[[4]])$label=="b",][1,c(5,6,8)]
m1h1y4 <- rbind(a,b)

#model 2
a <- parameterEstimates(results[[5]])[parameterEstimates(results[[5]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[5]])[parameterEstimates(results[[5]])$label=="b",][1,c(5,6,8)]
m2h1y1 <- rbind(a,b)

a <- parameterEstimates(results[[6]])[parameterEstimates(results[[6]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[6]])[parameterEstimates(results[[6]])$label=="b",][1,c(5,6,8)]
m2h1y2 <- rbind(a,b)

a <- parameterEstimates(results[[7]])[parameterEstimates(results[[7]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[7]])[parameterEstimates(results[[7]])$label=="b",][1,c(5,6,8)]
m2h1y3 <- rbind(a,b)

a <- parameterEstimates(results[[8]])[parameterEstimates(results[[8]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[8]])[parameterEstimates(results[[8]])$label=="b",][1,c(5,6,8)]
m2h1y4 <- rbind(a,b)
#model 3
a <- parameterEstimates(results[[9]])[parameterEstimates(results[[9]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[9]])[parameterEstimates(results[[9]])$label=="b",][1,c(5,6,8)]
m3h1y1 <- rbind(a,b)

a <- parameterEstimates(results[[10]])[parameterEstimates(results[[10]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[10]])[parameterEstimates(results[[10]])$label=="b",][1,c(5,6,8)]
m3h1y2 <- rbind(a,b)

a <- parameterEstimates(results[[11]])[parameterEstimates(results[[11]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[11]])[parameterEstimates(results[[11]])$label=="b",][1,c(5,6,8)]
m3h1y3 <- rbind(a,b)

a <- parameterEstimates(results[[12]])[parameterEstimates(results[[12]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[12]])[parameterEstimates(results[[12]])$label=="b",][1,c(5,6,8)]
m3h1y4 <- rbind(a,b)

#model 4
a <- parameterEstimates(results[[13]])[parameterEstimates(results[[13]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[13]])[parameterEstimates(results[[13]])$label=="b",][1,c(5,6,8)]
m4h1y1 <- rbind(a,b)

a <- parameterEstimates(results[[14]])[parameterEstimates(results[[14]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[14]])[parameterEstimates(results[[14]])$label=="b",][1,c(5,6,8)]
m4h1y2 <- rbind(a,b)

a <- parameterEstimates(results[[15]])[parameterEstimates(results[[15]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[15]])[parameterEstimates(results[[15]])$label=="b",][1,c(5,6,8)]
m4h1y3 <- rbind(a,b)

a <- parameterEstimates(results[[16]])[parameterEstimates(results[[16]])$label=="a",][1,c(5,6,8)]
b <- parameterEstimates(results[[16]])[parameterEstimates(results[[16]])$label=="b",][1,c(5,6,8)]
m4h1y4 <- rbind(a,b)


#combine
#put deps under each other
m1deps <- rbind(m1h1y1, m1h1y2, m1h1y3, m1h1y4)
m2deps <- rbind(m2h1y1, m2h1y2, m2h1y3, m2h1y4)
m3deps <- rbind(m3h1y1, m3h1y2, m3h1y3, m3h1y4)
m4deps <- rbind(m4h1y1, m4h1y2, m4h1y3, m4h1y4)


#put methods next to each other
h1 <- cbind(m1deps, m2deps, m3deps, m4deps)

row.names(h1) <- NULL

paths <- rep(c("stability", "partner-effect"),2)
h1 <- cbind(paths,h1)


hypo1 <- kbl(h1, booktabs=TRUE, digits=2, caption="Results Hypo1", align = "lcccccccccccc") %>%
  add_header_above(c(" ", "CLPM" = 3, "RI-CLPM" = 3, "SC-RI-CLPM" = 3, "LT-RI-CLPM" = 3)) %>%
  pack_rows(index=c("eu-integration"=2, "immigrants"=2, "euthanasia"=2, "income_diff"=2)) %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  column_spec(5:7, color = "white", background = "green")

scroll_box(hypo1, width="100%", height = "400px")

```


### Conclusion hypo1


### Results hypo2 

**Hypo2 RI-CLPM: Women are more influenced by their (male) spouse than men are influenced by their (female) spouse.** 

#### CLPM

```{r, eval=FALSE, echo=TRUE}
myModel <- "
  ### control for education
  x1 + x2 + x3 +x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 ~ ex*oplx
  y1 + y2 + y3 +y4 + y5 + y6 + y7 + y8 + y9 + y10 + y11 ~ ey*oply
  
  ### Estimate the lagged effects
  x2 ~ ax*x1 + bx*y1
  x3 ~ ax*x2 + bx*y2
  x4 ~ ax*x3 + bx*y3
  x5 ~ ax*x4 + bx*y4
  x6 ~ ax*x5 + bx*y5
  x7 ~ ax*x6 + bx*y6
  x8 ~ ax*x7 + bx*y7
  x9 ~ ax*x8 + bx*y8
  x10 ~ ax*x9 + bx*y9
  x11 ~ ax*x10 + bx*y10
  
  y2 ~ by*x1 + ay*y1
  y3 ~ by*x2 + ay*y2
  y4 ~ by*x3 + ay*y3
  y5 ~ by*x4 + ay*y4
  y6 ~ by*x5 + ay*y5
  y7 ~ by*x6 + ay*y6
  y8 ~ by*x7 + ay*y7
  y9 ~ by*x8 + ay*y8
  y10 ~ by*x9 + ay*y9
  y11 ~ by*x10 + ay*y10

  # Estimate the (residual) covariance between the variables
  x1 ~~ y1 # Covariance
  x2 ~~ y2
  x3 ~~ y3
  x4 ~~ y4
  x5 ~~ y5
  x6 ~~ y6
  x7 ~~ y7
  x8 ~~ y8
  x9 ~~ y9
  x10 ~~ y10
  x11 ~~ y11
  
  # Estimate the (residual) variance of the variables.
  x1 ~~ x1 # Variances
  y1 ~~ y1 
  x2 ~~ x2 # Residual variances
  y2 ~~ y2 
  x3 ~~ x3 
  y3 ~~ y3 
  x4 ~~ x4 
  y4 ~~ y4 
  x5 ~~ x5
  y5 ~~ y5
  x6 ~~ x6
  y6 ~~ y6
  x7 ~~ x7
  y7 ~~ y7 
  x8 ~~ x8 
  y8 ~~ y8 
  x9 ~~ x9 
  y9 ~~ y9 
  x10 ~~ x10
  y10 ~~ y10
  x11 ~~ x11
  y11 ~~ y11
  
  #intercepts
  x1 ~ 1
  y1 ~ 1
  x2 ~ 1
  y2 ~ 1
  x3 ~ 1
  y3 ~ 1
  x4 ~ 1
  y4 ~ 1
  x5 ~ 1
  y5 ~ 1
  x6 ~ 1
  y6 ~ 1
  x7 ~ 1
  y7 ~ 1
  x8 ~ 1
  y8 ~ 1
  x9 ~ 1
  y9 ~ 1
  x10 ~ 1
  y10 ~ 1
  x11 ~ 1
  y11 ~ 1
  
  dif1 := ax - ay
  dif2 := bx - by
  dif3 := ex - ey
  
  
"


#Estimate models a bit faster:

estimate <- function(x) lavaan(myModel, data=x, missing = "fiml.x", meanstructure = T )
library(future.apply)
plan(multisession)

results_temp <- future_lapply(datalist_ori, estimate)
summary(results_temp[[1]])
results[[17]] <- results_temp[[1]]
results[[18]] <- results_temp[[2]]
results[[19]] <- results_temp[[3]]
results[[20]] <- results_temp[[4]]

names(results)[17:20] <- c("fitm1h2y1", "fitm1h2y2","fitm1h2y3","fitm1h2y4")


```

```{r, results="hold"}

load("addfiles/results.Rdata")
summary(results[[17]])
summary(results[[18]])
summary(results[[19]])
summary(results[[20]])
```


#### RI-CLPM

```{r, eval=FALSE, echo=TRUE}
RICLPM <- '
  # Create between components (random intercepts)
  RIx =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 + 1*x5 + 1*x6 + 1*x7 + 1*x8 + 1*x9 + 1*x10 + 1*x11
  RIy =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 + 1*y5 + 1*y6 + 1*y7 + 1*y8 + 1*y9 + 1*y10 + 1*y11  
  
  RIx ~ ex*oplx
  RIy ~ ey*oply
  
  # Create within-person centered variables
  wx1 =~ 1*x1
  wx2 =~ 1*x2
  wx3 =~ 1*x3 
  wx4 =~ 1*x4
  wx5 =~ 1*x5
  wx6 =~ 1*x6
  wx7 =~ 1*x7
  wx8 =~ 1*x8 
  wx9 =~ 1*x9
  wx10 =~ 1*x10
  wx11 =~ 1*x11
 
  wy1 =~ 1*y1
  wy2 =~ 1*y2
  wy3 =~ 1*y3
  wy4 =~ 1*y4
  wy5 =~ 1*y5
  wy6 =~ 1*y6
  wy7 =~ 1*y7
  wy8 =~ 1*y8
  wy9 =~ 1*y9
  wy10 =~ 1*y10
  wy11 =~ 1*y11

  # Estimate the lagged effects between the within-person centered variables.
  x2 ~ ax*x1 + bx*y1
  x3 ~ ax*x2 + bx*y2
  x4 ~ ax*x3 + bx*y3
  x5 ~ ax*x4 + bx*y4
  x6 ~ ax*x5 + bx*y5
  x7 ~ ax*x6 + bx*y6
  x8 ~ ax*x7 + bx*y7
  x9 ~ ax*x8 + bx*y8
  x10 ~ ax*x9 + bx*y9
  x11 ~ ax*x10 + bx*y10
  
  y2 ~ by*x1 + ay*y1
  y3 ~ by*x2 + ay*y2
  y4 ~ by*x3 + ay*y3
  y5 ~ by*x4 + ay*y4
  y6 ~ by*x5 + ay*y5
  y7 ~ by*x6 + ay*y6
  y8 ~ by*x7 + ay*y7
  y9 ~ by*x8 + ay*y8
  y10 ~ by*x9 + ay*y9
  y11 ~ by*x10 + ay*y10

  dif1 := ax - ay
  dif2 := bx - by
  dif3 := ex - ey

  # Estimate the (residual) covariance between the within-person centered variables
  wx1 ~~ wy1 # Covariance
  wx2 ~~ wy2
  wx3 ~~ wy3
  wx4 ~~ wy4
  wx5 ~~ wy5
  wx6 ~~ wy6
  wx7 ~~ wy7
  wx8 ~~ wy8
  wx9 ~~ wy9
  wx10 ~~ wy10
  wx11 ~~ wy11
  
  # Estimate the variance and covariance of the random intercepts. 
  RIx ~~ RIx
  RIy ~~ RIy
  RIx ~~ RIy

  # Estimate the (residual) variance of the within-person centered variables.
  wx1 ~~ wx1 # Variances
  wy1 ~~ wy1 
  wx2 ~~ wx2 # Residual variances
  wy2 ~~ wy2 
  wx3 ~~ wx3 
  wy3 ~~ wy3 
  wx4 ~~ wx4 
  wy4 ~~ wy4 
  wx5 ~~ wx5
  wy5 ~~ wy5
  wx6 ~~ wx6
  wy6 ~~ wy6
  wx7 ~~ wx7
  wy7 ~~ wy7 
  wx8 ~~ wx8 
  wy8 ~~ wy8 
  wx9 ~~ wx9 
  wy9 ~~ wy9 
  wx10 ~~ wx10
  wy10 ~~ wy10
  wx11 ~~ wx11
  wy11 ~~ wy11
'


#Estimate models a bit faster:

estimate <- function(x) lavaan(RICLPM, data=x, missing = "fiml.x", meanstructure = T )
library(future.apply)
plan(multisession)

results_temp <- future_lapply(datalist_ori, estimate)
summary(results_temp[[4]])

results[[21]] <- results_temp[[1]]
results[[22]] <- results_temp[[2]]
results[[23]] <- results_temp[[3]]
results[[24]] <- results_temp[[4]]

names(results)[21:24] <- c("fitm2h2y1", "fitm2h2y2","fitm2h2y3","fitm2h2y4")

save(results, file="results.RData")

```

```{r, results="hold"}

load("addfiles/results.Rdata")
summary(results[[21]])
summary(results[[22]])
summary(results[[23]])
summary(results[[24]])

```


#### SC-RI-CLPM

```{r, eval=FALSE, echo=TRUE}

SCCLPM <- '
  # Create between components (random intercepts)
  RIx =~ 1*x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11
  RIy =~ 1*y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9 + y10 + y11  
  
  RIx ~ ex*oplx
  RIy ~ ey*oply
  
  # Create within-person centered variables
  wx1 =~ 1*x1
  wx2 =~ 1*x2
  wx3 =~ 1*x3 
  wx4 =~ 1*x4
  wx5 =~ 1*x5
  wx6 =~ 1*x6
  wx7 =~ 1*x7
  wx8 =~ 1*x8 
  wx9 =~ 1*x9
  wx10 =~ 1*x10
  wx11 =~ 1*x11
 
  wy1 =~ 1*y1
  wy2 =~ 1*y2
  wy3 =~ 1*y3
  wy4 =~ 1*y4
  wy5 =~ 1*y5
  wy6 =~ 1*y6
  wy7 =~ 1*y7
  wy8 =~ 1*y8
  wy9 =~ 1*y9
  wy10 =~ 1*y10
  wy11 =~ 1*y11

  # Estimate the lagged effects between the within-person centered variables.
  x2 ~ ax*x1 + bx*y1
  x3 ~ ax*x2 + bx*y2
  x4 ~ ax*x3 + bx*y3
  x5 ~ ax*x4 + bx*y4
  x6 ~ ax*x5 + bx*y5
  x7 ~ ax*x6 + bx*y6
  x8 ~ ax*x7 + bx*y7
  x9 ~ ax*x8 + bx*y8
  x10 ~ ax*x9 + bx*y9
  x11 ~ ax*x10 + bx*y10
  
  y2 ~ by*x1 + ay*y1
  y3 ~ by*x2 + ay*y2
  y4 ~ by*x3 + ay*y3
  y5 ~ by*x4 + ay*y4
  y6 ~ by*x5 + ay*y5
  y7 ~ by*x6 + ay*y6
  y8 ~ by*x7 + ay*y7
  y9 ~ by*x8 + ay*y8
  y10 ~ by*x9 + ay*y9
  y11 ~ by*x10 + ay*y10

  dif1 := ax - ay
  dif2 := bx - by
  dif3 := ex - ey

  # Estimate the (residual) covariance between the within-person centered variables
  wx1 ~~ wy1 # Covariance
  wx2 ~~ wy2
  wx3 ~~ wy3
  wx4 ~~ wy4
  wx5 ~~ wy5
  wx6 ~~ wy6
  wx7 ~~ wy7
  wx8 ~~ wy8
  wx9 ~~ wy9
  wx10 ~~ wy10
  wx11 ~~ wy11
  
  # Estimate the variance and covariance of the random intercepts. 
  RIx ~~ RIx
  RIy ~~ RIy
  RIx ~~ RIy

  # Estimate the (residual) variance of the within-person centered variables.
  wx1 ~~ wx1 # Variances
  wy1 ~~ wy1 
  wx2 ~~ wx2 # Residual variances
  wy2 ~~ wy2 
  wx3 ~~ wx3 
  wy3 ~~ wy3 
  wx4 ~~ wx4 
  wy4 ~~ wy4 
  wx5 ~~ wx5
  wy5 ~~ wy5
  wx6 ~~ wx6
  wy6 ~~ wy6
  wx7 ~~ wx7
  wy7 ~~ wy7 
  wx8 ~~ wx8 
  wy8 ~~ wy8 
  wx9 ~~ wx9 
  wy9 ~~ wy9 
  wx10 ~~ wx10
  wy10 ~~ wy10
  wx11 ~~ wx11
  wy11 ~~ wy11
'


#Estimate models a bit faster:

estimate <- function(x) lavaan(SCCLPM, data=x, missing = "fiml.x", meanstructure = T )
library(future.apply)
plan(multisession)

results_temp <- future_lapply(datalist_ori, estimate)
summary(results_temp[[4]])

results[[25]] <- results_temp[[1]]
results[[26]] <- results_temp[[2]]
results[[27]] <- results_temp[[3]]
results[[28]] <- results_temp[[4]]

names(results)[25:28] <- c("fitm3h2y1", "fitm3h2y2","fitm3h2y3","fitm3h2y4")

save(results, file="results.RData")

```

```{r, results="hold"}

load("addfiles/results.Rdata")
summary(results[[25]])
summary(results[[26]])
summary(results[[27]])
summary(results[[28]])

```

#### LT-RI-CLPM

```{r, eval=FALSE, echo=TRUE}

LTRICLPM <- '
  # Create between components (random intercepts)
  RIx =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 + 1*x5 + 1*x6 + 1*x7 + 1*x8 + 1*x9 + 1*x10 + 1*x11
  RIy =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 + 1*y5 + 1*y6 + 1*y7 + 1*y8 + 1*y9 + 1*y10 + 1*y11
  
  RIx ~ ex*oplx
  RIy ~ ey*oply
  
  #Random slopes
  RIsx =~ 1*x1 + 2*x2 + 3*x3 + 4*x4 + 5*x5 + 6*x6 + 7*x7 + 8*x8 + 9*x9 + 10*x10 + 11*x11
  RIsy =~ 1*y1 + 2*y2 + 3*y3 + 4*y4 + 5*y5 + 6*y6 + 7*y7 + 8*y8 + 9*y9 + 10*y10 + 11*y11
  
  RIsx ~ fx*oplx
  RIsy ~ fy*oply
  
  # Create within-person centered variables
  wx1 =~ 1*x1
  wx2 =~ 1*x2
  wx3 =~ 1*x3 
  wx4 =~ 1*x4
  wx5 =~ 1*x5
  wx6 =~ 1*x6
  wx7 =~ 1*x7
  wx8 =~ 1*x8 
  wx9 =~ 1*x9
  wx10 =~ 1*x10
  wx11 =~ 1*x11
 
  wy1 =~ 1*y1
  wy2 =~ 1*y2
  wy3 =~ 1*y3
  wy4 =~ 1*y4
  wy5 =~ 1*y5
  wy6 =~ 1*y6
  wy7 =~ 1*y7
  wy8 =~ 1*y8
  wy9 =~ 1*y9
  wy10 =~ 1*y10
  wy11 =~ 1*y11

 # Estimate the lagged effects between the within-person centered variables.
  x2 ~ ax*x1 + bx*y1
  x3 ~ ax*x2 + bx*y2
  x4 ~ ax*x3 + bx*y3
  x5 ~ ax*x4 + bx*y4
  x6 ~ ax*x5 + bx*y5
  x7 ~ ax*x6 + bx*y6
  x8 ~ ax*x7 + bx*y7
  x9 ~ ax*x8 + bx*y8
  x10 ~ ax*x9 + bx*y9
  x11 ~ ax*x10 + bx*y10
  
  y2 ~ by*x1 + ay*y1
  y3 ~ by*x2 + ay*y2
  y4 ~ by*x3 + ay*y3
  y5 ~ by*x4 + ay*y4
  y6 ~ by*x5 + ay*y5
  y7 ~ by*x6 + ay*y6
  y8 ~ by*x7 + ay*y7
  y9 ~ by*x8 + ay*y8
  y10 ~ by*x9 + ay*y9
  y11 ~ by*x10 + ay*y10

  dif1 := ax - ay
  dif2 := bx - by
  dif3 := ex - ey
  dif4 := fx - fy

  # Estimate the (residual) covariance between the within-person centered variables
  wx1 ~~ wy1 # Covariance
  wx2 ~~ wy2
  wx3 ~~ wy3
  wx4 ~~ wy4
  wx5 ~~ wy5
  wx6 ~~ wy6
  wx7 ~~ wy7
  wx8 ~~ wy8
  wx9 ~~ wy9
  wx10 ~~ wy10
  wx11 ~~ wy11
  
  # Estimate the variance and covariance of the random intercepts and random slopes. 
  RIx ~~ RIx
  RIy ~~ RIy
  RIx ~~ RIy #covariance intercepts: interpretation SELECTION
  RIsx ~~ RIsx
  RIsy ~~ RIsy
  RIsx ~~ RIsy #covariance slopes: interpretation COMMON CONTEXT
  RIx ~~ RIsx #covariance intercept/slope: interpretation regression to the mean
  RIy ~~ RIsy
  RIx ~~ RIsy #cross-covariance: interpretation  INFLUENCE? 
  RIy ~~ RIsx

  # Estimate the (residual) variance of the within-person centered variables.
  wx1 ~~ wx1 # Variances
  wy1 ~~ wy1 
  wx2 ~~ wx2 # Residual variances
  wy2 ~~ wy2 
  wx3 ~~ wx3 
  wy3 ~~ wy3 
  wx4 ~~ wx4 
  wy4 ~~ wy4 
  wx5 ~~ wx5
  wy5 ~~ wy5
  wx6 ~~ wx6
  wy6 ~~ wy6
  wx7 ~~ wx7
  wy7 ~~ wy7 
  wx8 ~~ wx8 
  wy8 ~~ wy8 
  wx9 ~~ wx9 
  wy9 ~~ wy9 
  wx10 ~~ wx10
  wy10 ~~ wy10
  wx11 ~~ wx11
  wy11 ~~ wy11
'
#Estimate models a bit faster:

estimate <- function(x) lavaan(LTRICLPM, data=x, missing = "fiml.x", meanstructure = T )
library(future.apply)
plan(multisession)

results_temp <- future_lapply(datalist_ori, estimate)
summary(results_temp[[4]])

results[[29]] <- results_temp[[1]]
results[[30]] <- results_temp[[2]]
results[[31]] <- results_temp[[3]]
results[[32]] <- results_temp[[4]]

names(results)[29:32] <- c("fitm4h2y1", "fitm4h2y2","fitm4h2y3","fitm4h2y4")

save(results, file="results.RData")

```

```{r, results="hold"}

load("addfiles/results.Rdata")
summary(results[[29]])
summary(results[[30]])
summary(results[[31]])
summary(results[[32]])

```


### Summary results hypo2

```{r, results='asis', echo=FALSE}

load("addfiles/results.Rdata")


library(knitr) #for kable/kables
library(kableExtra)


#retrieving data to show
#model 1
ax <- parameterEstimates(results[[17]])[parameterEstimates(results[[17]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[17]])[parameterEstimates(results[[17]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[17]])[parameterEstimates(results[[17]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[17]])[parameterEstimates(results[[17]])$label=="by",][1,c(5,6,8)]
m1h2y1 <- rbind(ax,ay,bx,by)

ax <- parameterEstimates(results[[18]])[parameterEstimates(results[[18]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[18]])[parameterEstimates(results[[18]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[18]])[parameterEstimates(results[[18]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[18]])[parameterEstimates(results[[18]])$label=="by",][1,c(5,6,8)]
m1h2y2 <- rbind(ax,ay,bx,by)

ax <- parameterEstimates(results[[19]])[parameterEstimates(results[[19]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[19]])[parameterEstimates(results[[19]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[19]])[parameterEstimates(results[[19]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[19]])[parameterEstimates(results[[19]])$label=="by",][1,c(5,6,8)]
m1h2y3 <- rbind(ax,ay,bx,by)

ax <- parameterEstimates(results[[20]])[parameterEstimates(results[[20]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[20]])[parameterEstimates(results[[20]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[20]])[parameterEstimates(results[[20]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[20]])[parameterEstimates(results[[20]])$label=="by",][1,c(5,6,8)]
m1h2y4 <- rbind(ax,ay,bx,by)

#model 2
ax <- parameterEstimates(results[[21]])[parameterEstimates(results[[21]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[21]])[parameterEstimates(results[[21]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[21]])[parameterEstimates(results[[21]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[21]])[parameterEstimates(results[[21]])$label=="by",][1,c(5,6,8)]
m2h2y1 <- rbind(ax,ay,bx,by)

ax <- parameterEstimates(results[[22]])[parameterEstimates(results[[22]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[22]])[parameterEstimates(results[[22]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[22]])[parameterEstimates(results[[22]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[22]])[parameterEstimates(results[[22]])$label=="by",][1,c(5,6,8)]
m2h2y2 <- rbind(ax,ay,bx,by)

ax <- parameterEstimates(results[[23]])[parameterEstimates(results[[23]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[23]])[parameterEstimates(results[[23]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[23]])[parameterEstimates(results[[23]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[23]])[parameterEstimates(results[[23]])$label=="by",][1,c(5,6,8)]
m2h2y3 <- rbind(ax,ay,bx,by)

ax <- parameterEstimates(results[[24]])[parameterEstimates(results[[24]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[24]])[parameterEstimates(results[[24]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[24]])[parameterEstimates(results[[24]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[24]])[parameterEstimates(results[[24]])$label=="by",][1,c(5,6,8)]
m2h2y4 <- rbind(ax,ay,bx,by)

#model 3
ax <- parameterEstimates(results[[25]])[parameterEstimates(results[[25]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[25]])[parameterEstimates(results[[25]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[25]])[parameterEstimates(results[[25]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[25]])[parameterEstimates(results[[25]])$label=="by",][1,c(5,6,8)]
m3h2y1 <- rbind(ax,ay,bx,by)

ax <- parameterEstimates(results[[26]])[parameterEstimates(results[[26]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[26]])[parameterEstimates(results[[26]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[26]])[parameterEstimates(results[[26]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[26]])[parameterEstimates(results[[26]])$label=="by",][1,c(5,6,8)]
m3h2y2 <- rbind(ax,ay,bx,by)

ax <- parameterEstimates(results[[27]])[parameterEstimates(results[[27]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[27]])[parameterEstimates(results[[27]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[27]])[parameterEstimates(results[[27]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[27]])[parameterEstimates(results[[27]])$label=="by",][1,c(5,6,8)]
m3h2y3 <- rbind(ax,ay,bx,by)

ax <- parameterEstimates(results[[28]])[parameterEstimates(results[[28]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[28]])[parameterEstimates(results[[28]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[28]])[parameterEstimates(results[[28]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[28]])[parameterEstimates(results[[28]])$label=="by",][1,c(5,6,8)]
m3h2y4 <- rbind(ax,ay,bx,by)

#model 4
ax <- parameterEstimates(results[[29]])[parameterEstimates(results[[29]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[29]])[parameterEstimates(results[[29]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[29]])[parameterEstimates(results[[29]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[29]])[parameterEstimates(results[[29]])$label=="by",][1,c(5,6,8)]
m4h2y1 <- rbind(ax,ay,bx,by)

ax <- parameterEstimates(results[[30]])[parameterEstimates(results[[30]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[30]])[parameterEstimates(results[[30]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[30]])[parameterEstimates(results[[30]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[30]])[parameterEstimates(results[[30]])$label=="by",][1,c(5,6,8)]
m4h2y2 <- rbind(ax,ay,bx,by)

ax <- parameterEstimates(results[[31]])[parameterEstimates(results[[31]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[31]])[parameterEstimates(results[[31]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[31]])[parameterEstimates(results[[31]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[31]])[parameterEstimates(results[[31]])$label=="by",][1,c(5,6,8)]
m4h2y3 <- rbind(ax,ay,bx,by)

ax <- parameterEstimates(results[[32]])[parameterEstimates(results[[32]])$label=="ax",][1,c(5,6,8)]
bx <- parameterEstimates(results[[32]])[parameterEstimates(results[[32]])$label=="bx",][1,c(5,6,8)]
ay <- parameterEstimates(results[[32]])[parameterEstimates(results[[32]])$label=="ay",][1,c(5,6,8)]
by <- parameterEstimates(results[[32]])[parameterEstimates(results[[32]])$label=="by",][1,c(5,6,8)]
m4h2y4 <- rbind(ax,ay,bx,by)

#combine
#put deps under each other
m1deps <- rbind(m1h2y1, m1h2y2, m1h2y3, m1h2y4)
m2deps <- rbind(m2h2y1, m2h2y2, m2h2y3, m2h2y4)
m3deps <- rbind(m3h2y1, m3h2y2, m3h2y3, m3h2y4)
m4deps <- rbind(m4h2y1, m4h2y2, m4h2y3, m4h2y4)

#put methods next to each other
h2 <- cbind(m1deps, m2deps, m3deps, m4deps)
row.names(h2) <- NULL

paths <- rep(c("Men:stability", "Women:stability", "Men:partner-effect", "Women:partner-effect"),2)
h2 <- cbind(paths,h2)


hypo2 <- kbl(h2, booktabs=TRUE, digits=2, caption="Results Hypo2", align = "lcccccccccccc") %>%
  add_header_above(c(" ", "CLPM" = 3, "RI-CLPM" = 3, "SC-RI-CLPM" = 3, "LT-RI-CLPM" = 3)) %>%
  pack_rows(index=c("eu-integration"=4, "immigrants"=4, "euthanasia"=4, "income_diff"=4)) %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  column_spec(5:7, color = "white", background = "green")

hypo2


```

### Conclusion hypo2  

---  

## Assignment

1. Look in the literature for other measures of opinion homophily. Try to apply this measure to construct a similar table as \@ref(descriptives).  
2. Have a look at the detailed results of the RI-CLPM estimated for hypothesis 1. Could you conclude, based on the error-covariance and/or error-correlation between the opinions of the spouses that opinion homophily increased? Motivate your answer.  
3. Have a look at the detailed results of the LT-RI-CLPM and focus on the variance and covariance of the random slopes of the partners. What does this tell you about opinion homophily within partners? Motivate your answer.  
4. You see that sections \@ref(conclusion-hypo1) and \@ref(conclusion-hypo2) are empty. Please fill in the blanks. Motivate your answer and discuss both selection and influence.  
3. You could argue that influence is only possible if people differ initially. Please select couples who are dissimilar at *within-time 1* and do the descriptive and analysis part again. Of course, of course, not for all dependent variables and modelling specifications. Pick one dependent and focus on the **RI-CLPM**.  
4. Please test if influence processes depend on educational attainment. Thus, formulate a hypothesis and test this hypothesis. 


---  


