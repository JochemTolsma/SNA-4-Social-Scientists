[["index.html", "SNASS Social Network Analysis for Social Scientists About the authors", " SNASS Social Network Analysis for Social Scientists Jochem Tolsma Bas hofstra 2021-08-26 About the authors "],["intro.html", "Chapter 1 Introduction 1.1 Overview 1.2 Aim 1.3 Structure 1.4 What makes this course stand out?", " Chapter 1 Introduction 1.1 Overview Sociologists study how societies affect the lives of their members and, vice versa, how individuals shape the societies in which they live. Within societies people make and break relations with specific others and thereby form social networks. Individuals are embedded in many different social networks (e.g. based on friendships, bullying, family relations). Within these social networks individuals influence each others attitudes, behaviors and relations via complex dynamic processes. The attitudes, behaviors and relations of individuals shape, in turn, the societies they live in. They give rise to social phenomena such as inequality, segregation, polarization and cohesion. It is not possible to explain many macro-level social phenomena, let alone to solve many urgent social problems, without taking into account social networks. For example, researchers may be able to deduce hypotheses from an established theory on political opinions of individuals but the same theory is not able to explain when and where political polarization occurs. For this, a social network perspective is necessary. It can thus be no surprise that the study of the causes and consequences of social networks lies at the core of sociology. 1.1.1 Definitions Social Networks A social network is an finite set of actors and the relation(s) defined on this set. The actors are social entities (people, organizations, countries, etc.) whose specific ties (friendship, competition, collaboration, etc.), constitute the network (Wasserman, Faust, and others 1994 : 20). Networks are also called: graphs or sociograms Actors are also called: points, nodes, agents or vertices. Relations are also called: ties, edges or connections. Social Networks is/are no theory nor a method. Social networks are social phenomena with causes and consequences. The size, composition, structure, and evolution of social networks can be explained. Social networks have an impact on individuals (e.g. attitudes and behavior), dyads (e.g. relations), institutions (e.g. efficiency) and societies (e.g. segregation, opinion polarization). Social Network Perspective It is the acknowledgment that individuals are embedded within social networks - no man is an island - and that this has theoretical, data, and methodological consequences. Theoretical consequences: A social network perspective may force to a rethinking of existing hypotheses and may lead to new research questions on the causes and consequences of social networks. Data consequences: To apply a Social Network Perspective, we need data on social networks. Social network data is special in that we need not only information on the social agents (e.g. people, organizations) but also on the ties (or relations) between them. As a consequence, there are many unique practical and ethical aspects related to the collection of network data. Methodological consequences: A social network perspective will make explicit that empirical observations of individuals are not always independent and that the (complex) interdependencies between observations that result from social networks have consequences for many of our traditional research methods which assume independence of observations. It may lead to the development and adoption of new social network analysis techniques. Applying a social network perspective leads to theoretical, data collection, and methodological advancements. Social phenomenon collective human behavior Social problem a social phenomenon which people consider undesired. Polarization Polarization is a social problem and a society is said to be polarized when (sizeable) (and clearly distinguishable) groups in society hold (ever more) opposing, extreme (political) attitudes. 1.2 Aim The intended learning outcomes of the course are: Theoretical knowledge and insight: you will be able to define core concepts related to a social network perspective. You will be able to summarize what a social network perspective in social science research entails. Academic attitude: you develop a positive attitude towards applying a social network perspective in social science research. Research skills: you will be able to apply a social network perspective in social science research. This encompasses that: you will be able to deduce relevant and new social network hypotheses from existing theories. you will be able able to collect and wrangle social network data. you will be able to test these hypotheses with different social network analysis techniques. 1.3 Structure This course is structured along three different dimensions: Type of Social Network: dyad, egonet, socionet (complete network) Causes or Consequences of social networks Implications of applying a social network perspective: Theoretical, Data and Methodological Table. 1.1 Topics discussed within the course Type of Social Network Causes or Consequences Implications Book section Dyads Causes Theory Dyads Causes Method Dyads Consequences Theory Dyads Consequences Method Dyads NA Data Egonets Causes Theory Egonets Causes Method Egonets Consequences Theory Egonets Consequences Method Egonets NA Data Socionet Causes Theory Socionet Causes Method Socionet Consequences Theory Socionet Consequences Method Socionet NA Data Feel free to jump to the section you are most interested in. But there is a clear order in the sections. The best way to accumulate theoretical and methodological knowledge, and to gain the necessary R-skills to successfully apply a social network perspective to your own research is by going through the sections one by. 1.3.1 Type of Social Network Dyads The smallest possible social network is a network between two persons (or, more precisely, between two social agents). A network between two persons is also called a dyad. In the clip below I will introduce you to the the main concepts involved in a dyad. Naturally, the same concepts also play a role in larger social networks. For slides, see here. After having watched the video you should be able to: give a definition of a dyad. explain what is meant by time-varying and time-constant actor attributes and dyad attributes. explain that relations between ego and alter can be classified based on whether relations are directed or undirected and on the level of measurement of the relation (i.e. nominal, ordinal, interval, ratio). be familiar with al the synonyms for networks, agents and relations. provide examples of dyads, and the relations between ego and alter. Egonets We could define an egocentric social network as a set of actors that all have relationships with ego. This definition is quite similar to Marsdens (Marsden 1990) definition: Sets of ties surrounding sampled individual units. To illustrate what is meant by these definitions, let us us consider the following world. And visualize the best-friend-forever relationships in this world. And now sample a random person. The person we sampled, ego, is made red and square in our network. Let us zoom in a little bit. 1.0 degree Lets suppose we had asked this person to name all its best-friend-forevers (BFFs). If we would assume that BFF relations are undirected, then this persons egocentric or 1.0 degree network would look like this: The alters with whom ego is not connected are not part of the egocentric network. And generally, if we collect data we do not have any information on these unconnected alters. 1.5 degree network We may have asked ego - with the question below - whether its BFFs are also BFFs of one another. Please think about the relations between the people you just mentioned. Some of them may be total strangers in the sense that they wouldnt recognize each other if they bumped into each other on the street. Others may be especially close, as close or closer to each other as they are to you. Are they especially close? PROBE: As close or closer to each other as they are to you? It turns out that two alters in egos BFF-network are also BFFs of each other. If we know the relations between the alters in a 1.0 degree network it becomes a 1.5 degree network. See below: In the lower-left corner we see a closed Triad. For more information on Triads jump to this section. 2.0 degree network Perhaps, instead of asking whether there are BFF relations between the BFFs of ego, we could also have used a snowball sampling method and interviewed the alters (or BFFs) of ego. Note that the focal actor (initial sampled unit) remains ego. Thus, if we would have asked egos alters to name their BFFs, we would have discovered the following 2.0 degree network: The newly discovered alters are in light blue. Naturally, we also observe the BFF relation between egos alters appearing. Please note that in a 2.0 degree network the number of alters within the 1.0 degree network of ego will remain the same (assuming that ego did not forget to mention a BFF). 2.X degree network Any ideas about what a 2.5 degree network would look like. To be honest, I dont. Do these networks include all relations between all nodes, or only the relations between the alters in the separate 1.0 degree networks? Perhaps we could call the latter a 2.5 degree network and the former a 2.75 degree network. Socionets A complete, full, or sociocentric network is a network within a sampled context or foci of which we know all nodes and all connections between nodes. The boundaries of the network are thus a priori defined and the contexts in which nodes are present are the sampled units. We may for example sample a classroom, neighborhood, university or country and collect all relations between all nodes within this context. You now have come across a general definition for social networks and specific definitions for dyadic, egocentric and sociocentric social networks. You also know that the social agents within the networks may not necessarily have to be persons but can also be companies, or political parties for example. A network in which the relations between two different type of nodes are present are called multiple-mode networks. Similarly, between one type of node (e.g. persons) we may have information on more than one type of relation. These networks are called multiplex networks. The networks we have considered so far refer to networks of binary relations (yes/no). If the relations can vary in strength, we call the networks a weighted network. Thus, we can have a two-mode, multiplex, weighted, directed network but also a single-mode, uniplex, binary, undirected network. It turns out that many (complete) social networks share certain network characteristics. This is called the small-world phenomena and is discussed in more detail here. But let us start with a teaser. Suppose we live in a world, called Smallworld, of 105 persons (a small world indeed) and have information on all friendship (or trust) relations between its citizens. How could such a network look like? It turns out that (large) social networks of positive relations often have a specific structure. And this structure is called A Small World. Lets have a look at the small world structure of SmallWorld. Play with the small world network of Smallworld. Zoom in and out, turn it around and click on some nodes. How would you describe the structure of the network in Smallworld. Well, I would describe it as a network with a: (1) relatively low density; (2) relatively high degree of clustering and (3) a relatively low average degree of separation (or path length). These three characteristics are defining features of small world networks. But what does density, clustering and path length mean?, and what do we mean with relatively, that does not sound very scientific does it?! Dont you worry, you will learn this during the course. 1.3.2 Causes and Consequences or Selection and Influence Social networks consist of social relations between people. For example friendships, bullying relations or working-together-during-the-course-social-networks relations. The continuous process of making and breaking social relations is also called selection. And the reasons why we make and brake relations with specific persons are important causes for the structures of the social networks we observe. Thus the causes of social networks are strongly related to selection processes. The people with whom we form social relations also influence our attitudes, behaviors and future relations. How we think, behave and with whom we make, break or maintain social relations is for an important part the consequence of the social networks in which we are embedded. Thus the consequences of social networks are strongly related to influence processes (but also to selection processes). Selection and influence processes are firmly entangled. See below for an example. The shapes represent social agents (e.g. individuals). The shape (circle or square) of the social agent is a time-stable characteristic (e.g. sex). The fill of the shape (no fill, pattern fill, solid fill) is a time-varying characteristic (e.g. music taste). The line between the shapes (no line, dashed, solid) signifies the strength of the relationship (e.g. romantic relationship) We could call the selection process Opposite Attracts and we could call the influence process Circle beats square. Let us focus on the selection process first. If there is no tie between the agents, you will notice that a tie will be formed (becomes stronger) between dissimilar agents. When a tie is present between agents, you will notice that a tie will be broken (becomes weaker) when agents are similar with respect to their time-varying characteristic. Let us now focus on the influence process. When a strong tie is present, you will notice that the square agents will assimilate to the time-varying characteristic of the circle agents. We do not know of course the mechanism behind this assimilation (or influence) process. Is it the square who (voluntary) adopts the behavior of the circle or does the circle forces the square to follow suit? 1.3.3 Implications Individuals - or social agents more generally (e.g. institutions, societies) - are part of many different social networks. 1.3.3.1 Theoretical implications A social network perspective may force to a rethinking of existing hypotheses and may lead to new research questions on the causes and consequences of social networks. That individuals are interconnected and hence that observations are (cor)related and characteristics of these observations co-vary is theoretically interesting. It gives rise to a complete new type of research questions. Where normally our research questions refer to describing or explaining the variance between individuals (e.g. why individuals differ) a new set of research questions describe, compare and explain the covariance between individuals. For example, why connected people are more (dis)similar to one another than non-connected others. The social network functions as explanans in these questions. A different set of new research questions takes the social network itself as explanandum. These research questions aim to describe, compare and explain characteristics of social networks (e.g. with respect to size, composition, structure and evolution). 1.3.3.2 Methodological implications That individuals are interconnected and hence that observations are not independent can be seen as a nuisance. That our observations are not independent violates many assumptions of analysis techniques that social scientists commonly apply (e.g. OLS). In order to correctly estimate the effects of interest we need to take these interdependencies into account with social network analysis techniques. 1.3.3.3 Data implications If we want to collect data on social networks, we need not only information on specific focal social agents (egos) but also on its relations with other egos (egos alters) and information on characteristics of these alters. Is it ethical that we collect data on an alter via ego? What do we do if in a school class a pupil does not wish to participate in a study on bullying? Do we delete this child from our bullying networks altogether, thus both as sender and receiver of bullying relations? Collecting data on social networks gives rise to specific ethical issues. If we want to collect data on complete social networks, the sampling unit is no longer an individual but the context in which these ties occur. How do we determine the boundaries of this context and how do we sample these. Collecting network data comes with specific sampling issues. Network data also has a specific format (e.g. an adjacency matrix) and can become very big. How to wrangle these network data objects? Network data oftentimes lead to specific practical data wrangling issues. 1.4 What makes this course stand out? This course is not an introduction to Sociology, Social Networks or Social Network Analysis. It is also not a course in R. I assume you have some intuitive understanding of what social networks are and have opened R or RStudio at one point in your life but both are not necessary prerequisites to follow this course. There are very good (online) introductions to the study of Social Networks, see for example here and here. A good short introduction to R for this course can be found in Chapter A or have a look here for a more thorough introduction to Data Science with R. This course is tailored for research master and PhD students. I will assume that you are interested in and have studied social problems in your academic career and that your research interests fits one of the following broad themes: inequality, cohesion and diversity. For an excellent introduction into sociology see (Van Tubergen 2020). However, up to this point, when you deduced hypotheses from existing theories you did not explicitly acknowledge that individuals are interconnected in social networks. You were neither aware that this may have theoretical consequences for existing hypotheses nor that this gives rise to new research questions. Up to this point, when you tested your hypotheses you assumed that your observations were independent (e.g. OLS) or, at most, that the nonindependence was relatively easy to take into account (e.g. multi-level analysis). In this course you will learn to apply a social network perspective in the study of inequality, cohesion and diversity. You will become able to deduce more precise and new hypotheses. You will become able to test these hypotheses with social network techniques that take into account and explain complex interdependencies. Enjoy!! "],["theory.html", "Chapter 2 Theory 2.1 Causes of dyads 2.2 Consequences of dyads (theory) 2.3 Consequences of dyads (methods)", " Chapter 2 Theory The smallest possible social network is a network between two persons (or, more precisely, between two social agents). A network between two persons is also called a dyad. In the clip below I will introduce you to the the main concepts involved in a dyad. Naturally, the same concepts also play a role in larger social networks. For slides, see here. After having watched the video you should be able to: give a definition of a dyad. explain what is meant by time-varying and time-constant actor attributes and dyad attributes. explain that relations between ego and alter can be classified based on whether relations are directed or undirected and on the level of measurement of the relation (i.e. nominal, ordinal, interval, ratio). be familiar with al the synonyms for networks, agents and relations. provide examples of dyads, and the relations between ego and alter. 2.1 Causes of dyads An important research topic within sociology is assortative mating (or intermarriage) (see: (Kalmijn 1998; Schwartz 2013; Blossfeld 2009)). Scholars in this field try to explain why two people in an exclusive relationship like marriage (or cohabition or best friends) are more similar to one another with respect to defining characteristics (e.g. social class, ethnicity) than two random persons. Assortative mating is a special case of homophily. Assortative mating is an important topic within sociology because it is, next to social mobility, an important indicator of the openness of society. Selection and influence processes are important reasons why partners (ego and alter) within a dyad are more similar than two random persons. We may prefer to marry someone who is similar to us on key social dimensions, share our attitudes and opinions and show similar behavior. Once married we may influence each other and assimilate to one another. A third reason why we observe homophily within couples is that partners are likely to have shared and will share the same social context. With shared social context we mean the shared social and physical environment and shared life experiences. The environment pre-marriage may in part determine characteristics of the pool of potential marriage partners (i.e. the choice set). For example when neighborhoods and schools are segregated along ethnic and educational division lines, the potential marriage partners we meet are likely to be more similar to us than a random person in society at large. The shared social environment post-marriage may exert a similar influence on both partners, consider for example economic recessions effects on different geographic regions. This may impact the job opportunities for both partners similarly (assuming they live in the same house). An example of shared life experiences, would be having children. Please note that causes and consequences of homophily are closely related. A shared social context and partner preferences may predict (or cause) homophily within dyads. But once a dyad is formed, a consequence of this relationship may be that partnes become more similar over time, as a result of a shared environment, influence and (de)selection processes. If you want to disentangle these processes, it is necessarry to have information on the degree of homophily between potential marriage partners would they be randomly assigned to one another, the degree of homophily at the beginning of the union, the degree of homophily within couples after a specific time period. homophily Homophily is the principle that a contact between similar people occurs at a higher rate than among dissimilar people (McPherson, Smith-Lovin, and Cook 2001). You will also come across the terms: - baseline or structural homophily: this is the degree of homophily we observe simply as a result of the composition of the total choice set, the people with whom we can, in principle, form a relationship. - inbreeding homophily: this is the degree of homophily we observe over and above the level of baseline homophily. This may be caused by taste homophily and differences in resources and restrictions (other than set by the total choice set). - taste or choice homophily: the extent of homophily induced by personal preferences. openness of society The openness of society refers to the level of inequality of opportunities within society. The social problem of inequality consists of two sub-problems. The first refers to inequality in outcomes: the unequal distribution of resources (e.g. economic, cultural, social, knowledge, power). The second refers to inquality in opportunities, the association between specific individual or group charactersitics and the likelihood to obtain these resources. Here the opennes of society is clearly linked to the second sub-problem. Where in questions of (inter-generational) social mobility the association between social position of parents and the social position of children is assessed, within the literature on intermarriage the association between the social positions of the two spouses is assessed. Both questions or associations will tell you something about the strenght of class/social position boundaries. 2.1.1 General Theoretical Framework In this section, I would like to introduce a General Theoretical Framework (or micro-macro model) which can be used to explain more or less any social phenomena you are interested in. The GTF can thus also be used to explain the emergence of social networks, and thus also to explain the emergence of dyads, and thus also to explain educational intermarriage. For slides, see here. After having watched the video and after heaving read this page, you should be able to: Understand and summarize the building blocks of the multi-level framework which can be used to explain the emergence of social networks. macro-level (independent) variable(s) social conditions restrictions bridge assumptions (also called social context effects) Theory of Action preferences resources choice-set choice-input choice-output Transformation rules (also called aggregation mechanism) social interdependencies unintended/unforeseen consequences of micro-level behavior macro-level (dependent) variable Provide examples of all building blocks in the context of explaining the emergence of dyads For more background reading on the multi-level framework (aka Coleman-boat, Coleman-bathtub, micro-macro models) see (Coleman 1994) and (Raub, Buskens, and Van Assen 2011, especially paragraph 4.4). The GTF is a framework, not a theory from which you can deduce hypotheses. Before we can do that, we need to fill in the blanks. That is, we need to make the social contexts (bridge assumptions) explicit. We need a Theory of Action. We need to think of the interdependencies and how they impact the aggregation mechanism. So, lets get started Social context effects Characteristics of the social context in which people are embedded (the marco- and meso-level) may impact peoples preferences and resources. Example 1: The level of economic inequality impacts how financial resources are unequally distributed across educational groups within society. Hypo1: In countries with more wealth inequality, the difference between educational groups in economic resources is larger. Example 2: Societal norms may impact your own views and opinions and thus preferences. Hypo2: In countries with more equal gender norms, mens (womens) preferences for a partner with a higher education are stronger (weaker). The special role of restrictions Restrictions or constraints also refer to macro-level characteristics but restrictions do not directly impact preferences and resources (i.e. choice input) but instead influence, or constrain how these preferences and resources lead to choice-output; we have a constrained choice model. Restrictions - in studies on the emergence of social networks - impact the choice-set, the relevant choice-options that a person has. If I would like to marry a grizzly bear but if there are no grizzly bears around which I can marry, I cannot act upon my preferences (commonly the example is about Eskimos but that may be considered more politically incorrect). This is called a structural restriction. A more realistic example would be the distribution of educational degrees within society, which depend on educational expansion and inequality of educational opportunities. Next, to structural restrictions we may also have normative restrictions, the formal and informal rules of institutions. A formal normative restriction would be a law that forbids me to marry a grizzly bear. An informal normative restriction would be a social norm, e.g. my parents who disapprove of my preference to marry a grizzly bear. Please note that social norms may thus impact my preferences directly (a social context effect) and indirectly (act as a restriction). Example1: Preferences for a partner with a similar educational level are more likely to lead to educational homogamy, if educational degrees are more evenly distributed across men and women. In the literature on resources you will see that restrictions are also commonly understood as the absence of resources. I am a stubborn scientists and DO NOT FOLLOW THIS TERMINOLOGY and neither should you. Theory of Action Persons have preferences for a partner with a specific educational-level. Commonly, people prefer higher-educated partners (because of instrumental motives) and people have homomphilic preferences. Preferences may differ between persons with different educational levels and between men and women. Persons also have resources (i.e. economic, cultural, cognitive, social resources) that may affect the search behavior of persons. Example1: persons with more economic resources have more options to meet different people and may thus select a partner from a larger choice-set. Hypo1: persons with more economic resources are more likely to marry a partner that meet their preferences, i.e. a more similar partner. We would like to apply the GTF to explain the emergence of social networks. The networks we observe are the result of people making and breaking social relations. Consequently, a theory of action to explain decision about social relations should explain not only decisions about making new relations (i.e. selection) but also about decision whether or not to maintain or break existing relations (i.e. deselection). When we talk about selection processess, we implicitly mean both selection and deselection. Concretely, if we want to explain the degree of intermarriage within society, we need to take into account both who is marrying whom and who is divorcing whom! Consider the following example. For some people the saying opposite attracts may hold true and they may be unaware of or ignore the social norm not to intermarry. But once married the couple may face unanticipated sanctions of violating the social norm, they may be ostracized. Being faced with this unanticipated consequence of their marriage decision, the couple may subsequently decide to divorce. In this example, the social norm thus not influences the selection process (more precisely, does not moderate the impact of preferences on marriage decisions) but it does influence the deselection process. Our Theory of Action assumes a cost benefit evaluation of some sort, in line with Rational Action Theory. However, social scientists view on humans rationality is different than the view of classical economists. Social scientists speak of restricted or bounded rationality (i.e. a weak rationality assumption); people are not always able to have or process all relevant information to make accurate and correct cost-benefit evaluations. We make questimates about the costs involved in our decision and about the likelihood that our behavior will yield the desired goal. Within sociology, actors goals are not only economic, monatory goals. Actors goals can be physical and social goals (i.e. health, happiness, avoidance of downwards mobility). For a nice paper on Rational Action Theory for Sociologists, see (Goldthorpe 1998). Transformation rules We now almost have all ingredients to explain (or predict) the degree of intermarriage in society. We only need the aggregation mechanisms: the micro-to-macro link. We thereby need to know the macro-level (intended and unintended) consequences of individual actions. That is, we need to know how the marriage market functions. Let us assume the following: Someone takes the initiative. This is determined by chance. The initial choice-set is formed by 5 random partners of the opposite sex (no assumptions about search behavior). Possible partners who are already married are removed from the initial choice-set. The possible partners that remain constitute the (final) choice set. Persons may prefer a partner with a higher education. These preferences may differ between educational levels and between the sexes. Persons choose a partner from their choice set (not marrying is not an option). Possible partners with a higher education have a larger chance to be chosen. How important a partners education is, depends on the preference of the one taking the initiative. The persons who is being proposed to always accepts. We observe no divorces. Resources do not play any role (e.g the higher educated do not have a larger choice set) Educational degrees are either high or low. With the above marriage-market model we have a limited number of ingredients that impact the observed degree of educational intermarriage within society: gender composition within society the distribution of educational degrees in society preferences the number of marriage proposals I hope you see that marriage choices are interdependent. If I marry person A, you no longer can marry person A. These interdependencies make it difficult to predict the macro-level dependent variable, degree of educational homogamy. Given the market model above, can you predict who will marry whom? Well, I can not. You may be a mathematical wizard and able to find a closed solution by some algebra. Another option could be to to make a simplified model and try to simulate the macro-level outcome based purely on our micro-level theory of action and the rules of the marriage market. We call this Agent-Based-Modelling (see ). I programmed a simply ABM based on the above. There are some parameters in the model which you can change. Suppose **%_men=50**: We have an equal gender distribution in society (50% men, 50% women; range: 1-99). **_men_EducHigh=50**: 50% of our male population is higher educated and 50% is lower educated (range: 1-99). **_women_EducHigh=50**: 50% of our female population is higher educated and 50% is lower educated (range: 1-99). pref_men_EH=0: Higher educated men do not have any preference with respect to the educational level of their partner. (range: 0-10) pref_men_EL=0: Lower educated men do not have any preference with respect to the educational level of their partner. (range: 0-10) pref_women_EH=0: Higher educated women do not have any preference with respect to the educational level of their partner. (range: 0-10) pref_women_EL=0: Lower educated women do not have any preference with respect to the educational level of their partner. (range: 0-10) Can you make a guess about the resulting degree of eductional homogamy?? Press update to see if you were correct. Play around with (agent-based simulation) model below. Go to app here 2.1.2 Causes of dyads (methods) When testing hypotheses on assortative mating many methodological approaches can be used. We may predict the frequency of specific dyads in our population with loglinear models and the data we use is commonly structured in a square table like the one below. Loglinear models are, in essence, nothing more than a nice, parsimonious and fancy way to calculate odds ratios. If we have a small, well filled table of just a few attributes, loglinear models are considered to be the golden standard. Table 2.1: Assortative Mating (dyad frequency) Wife educ-high Wife educ-low Husband educ-high 350 150 Husband educ-low 200 400 Another approach is to take the characteristics of the dyad (e.g. 1 = intermarriage and 0 = no intermarriage) as the dependent variable. This dependent variable can than be explained by applying (conditional) (multinomial) logistic regression techniques. In this case, the data is commonly structured in long format and looks something like the table below. Table 2.2: Assortative Mating (dyad characteristic) dyad_id wife educ wife age husband educ husband age intermarriage 1 LOW 30.63 LOW 26.91 0 2 LOW 24.79 LOW 34.61 0 3 HIGH 19.00 HIGH 25.92 0 4 HIGH 29.31 LOW 39.08 0 5 HIGH 25.32 LOW 30.11 0 6 LOW 23.86 LOW 19.01 0 7 HIGH 36.36 LOW 35.34 0 8 LOW 35.58 HIGH 22.64 0 9 LOW 24.24 HIGH 36.36 0 10 LOW 20.27 HIGH 20.79 0 11 HIGH 24.08 LOW 34.20 0 12 HIGH 44.44 LOW 23.97 0 13 LOW 33.40 LOW 25.77 0 14 HIGH 27.86 HIGH 35.55 0 15 LOW 21.97 HIGH 19.44 0 16 HIGH 38.16 LOW 18.42 0 17 HIGH 44.85 HIGH 37.86 0 18 LOW 30.91 LOW 23.21 0 19 HIGH 24.30 HIGH 31.53 0 20 LOW 36.19 LOW 21.50 0 Which methodology is preferred should depend on your hypotheses and on the data you have to your availability. Please be aware that in both approaches we normally do not have information on (the frequency or characteristics of) dyads in which there is no relation between ego and alter. Thus, you may have information on characteristics of me and my wife but you do not have information on all other women (or men) I could have married but didnt. I fished my wife out of the sea but we dont know what the other fish looked like. (Luckily my wife is no scientist and wont read this clarification.) 2.2 Consequences of dyads (theory) Assortative mating, or more generally mating, has consequences for both partners. Just to mention a few: relationship quality; time spend together on culture consumption; divorce rates; number of children; household income; working hours. I hope you see that these concepts all refer to the dyad-level but that you may group these concepts by how they are measured, namely at the dyad-level itself (yes/no divorce, number of children) or at the ego/alter-level and aggregated to the dyad-level (e.g. total working hours of the couple is the sum of the working hours of both individual partners, culture consumption is the consumed culture of both partners (alone and together)). But with both type of concepts, it should be clear that they are the consequence of interdependent actions of both partners (e.g. commonly both partners decide on whether to have and make children). Thus, once again, homophily within couples may be the result of: selection shared context (dyadic) influence But what do we mean with influence? Lets read the following quote. People influence one another, and as the importance and immediacy of a group or individual increases, this influence becomes stronger (Latané, 1981). Forces of influence are especially strong within romantic relationships because these relationships are important, are predicated on mutual acceptance, and involve frequent exposure to the habits of ones partner.\" Bartel et al. (2017) It would say this a quite naive conceptualisation of influence. It is implicitly assumed that partners will match their opinions/behaviors. Thus influence here is convergence. But why should partners characteristics converge over time, why would homophily increase? And, it still does not become clear what the forces of influence are. Let us make a distinction between: positive influence: alters become more similar to each other over time negative influence: alters become more distinct to each other over time positive feedback influence: characteristics develop in same direction over time Now suppose these influence processes are the only reasons why alters change (i.e. the ceteris paribus condition). How could dyad similarity develop over time. Figure 2.1: Positive influence With [positive influence]2.1 actors will become more similar to each other over time. Figure 2.2: Negative influence With [negative influence]2.2 actors will become more distinct to each other over time. Figure 2.3: Positive feedback influence With [positive feedback]2.3 actors will develop in the same direction. Naturally, we need to be aware that other mechanisms may also explain these trends. For example, with respect [the figure above]2.3, a shared environment may also explain a shared trend. More concretely, when a couple gets children, both spouses may become happier over time. There are several forces of positive influence mechanisms: information: We may exchange new effective information and arguments with our alters. persuasion (and dissuasion): we may convince, force or pressure our alters to become similar to us. contagion: this can be taken quite literally, like how the flu spreads but also more metaphorically like how (health) behaviors like drinking, smoking, sporting spread (because our alters increase the opportunities for these behaviors). assimilation: we may mimic our alters because of a psychological need for similarity, because we think this will be good for our identity / social status, etc. The literature is not very clear and consistent about different type of incluence processes and which influence mechanisms are at play. You will thus also see that authors use socialisation when talking about (positive) influence processes. There are several forces of negative influence mechanisms: information: We may exchange new counter-effective information and arguments with our alters. This would especially become relevant whey we dont like or belief the source of information and arguments. persuasion (and dissuasion): we may convince, force or pressure our alters to become dissimilar to us. polarisation: we may distance ourselves from our alters because of a psychological need for distinctiveness. This would especially become relevant when we are already distinct on key social dimensions. There are several forces of positive feedback influence mechanisms: confirmation: information and arguments are repeated and existing opinions and behaviors of both alters reinforced. competition: we may have a psychological need to be better/higher/more than our alter. The crucial difference between the positive feedback mechanisms and the positive influence mechanisms are that as a result of the former homophily between the alters does not necessarily change. Note that positive feedback could entail increasing and decreasing the opinion or behavior. 2.3 Consequences of dyads (methods) The method used to explain consequences of dyads depends on our Unit of Analysis. If it is the dyad itself (e.g. mean relationship quality) methods are relatively straightforward, because we may assume that the observations at the dyad-level are independent. If, on the other hand, the unit of analysis are the partners themselves that make up the dyad, we need to acknowledge that the observations between the partners of the same couple are not independent. In part exactly because partners select and influence each other and share a social context. One solution could be to simply randomly select one partner of each couple or, if partners can be clearly distinguished - for example men and women in heterosexual couples - the different partners could be analyzed separately. A disadvantage of the latter two approaches is, however, that the covariance between the partners cannot be explained anymore, although this may exactly be the focus of our research questions. A more elegant solution, is to take the interdependencies into account and model these explicitly. This can be done within a multi-level framework and within a structural-equation modelling framework. When we discussed the methods to analyze causes of homogamy, we were interested in homophily within couples at one point in time and focus on selection as explanans. Now, when we discuss the consequences of dyads, we are interested in explaining trends in homophily within couples and focus on shared context and influence processes as explanans. "],["methods.html", "Chapter 3 Methods 3.1 Causes 3.2 Consequences 3.3 Dyadic Influence: Mechanisms 3.4 Expectations 3.5 Data 3.6 Analysis 3.7 Modelling strategy 3.8 Results Hypo1 3.9 Results Hypo2", " Chapter 3 Methods 3.1 Causes 3.1.1 Odds Ratio 3.1.2 Loglinear Model 3.1.3 Conditional multinomial logit model 3.2 Consequences PARTNERS AND POLITICS - When do we listen to our partners political opinion? Embed from Getty Images In this part of the book, we will demonstrate the Cross-Lagged Panel Model (CLPM) and how to apply it to assess whether partners influence each other opinions. Relevance Why would influence processes between couples be relevant. Well, for many reasons. But influence processes that take place within couples may explain (in part): Political polarization within society. Opinion homophily within couples. Political polarization between groups (e.g. couples) may be the result of: selection common context influence Homophily within couples may be the result of: selection common context dyadic influence Let us briefly discuss these three common causes and demonstrate how the resulting homophily within couples could contribute to polarization at the society level. 3.2.1 Selection We will start with a fictive population of unmarried persons. Some political opinion is distributed as follows within society. Figure 3.1: Distribution of opinions within population But these individuals want to get married. Who do they pick. Well, we discussed the marriage market here. Marriage Market: Constrained Decisions with whom to marry (or cohabit). Let us assume that the opinion did not yet change but that bachelors prefer, to some extent, a partner with a similar political opinion. What does the political opinion distribution look like for the mean political opinion of the couples. Well, the preference for a partner with similar political opinions was definitely not strong enough to substantially change the opinion distribution.1 Please go to the common context tab. 3.2.2 Common context What is a common context? Some examples: Shared life experiences: having kids poverty Shared environment: pollution housing poverty Suppose these life events are more likely for some couples than others. More specifically, assume that the occurrence of life events is associated with the mean political opinion of the couple (at time T). The life event consequently influences the mean political opinion of the couple (at time T+1). We now clearly observe polarization between couples. However, if we go back to the individual-level again, we do not (clearly) observe polarization between individuals. In order to also observe (pronounced) polarization between individuals, there needs to be some influence between partners 3.2.3 Dyadic Influence Why would partners influence each other? Well, we discussed influence here. Dyadic (positive) influence: information persuasion need for similarity 3.3 Dyadic Influence: Mechanisms What happens within the couple? Or phrased otherwise, what could dyadic influence look like? No change (no influence) Common trend (commen context and/or dyadic influence) Convergence (assimilation) Mimic change after shocks 3.4 Expectations Now, let us try to formulate several hypotheses on influence processes taking place within couples. Naturally, these hypotheses should be derived from existing (and established) theories. But the aim here is not to teach you how to derive hypotheses but to test hypotheses on dyadic influence. People influence one another, and as the importance and immediacy of a group or individual increases, this influence becomes stronger (Latané, 1981). Forces of influence are especially strong within romantic relationships because these relationships are important, are predicated on mutual acceptance, and involve frequent exposure to the habits of ones partner. Bartel et al. (2017) Naive conceptualisation of influence. It is assumed that partners will match their opinions/behaviors. Thus influence here is convergence and reaction to shocks. Hypothesis 1 Partner influence hypothesis: Partners opinions will become more similar to one another over time. We will introduce the CLPM below. Once you are familiar with this model, you see that we can and should formulate a more precise hypothesis 1. Hypo1 RI-CLPM: When your partners opinion is relatively high (compared to your partners average opinion over time) at time T, your own opinion will be relatively high (compared to your own average opinion over time) at time T+1. Hypothesis 2 Male dominance hypothesis: Women are more influenced by their (male) spouse than men are influenced by their (female) spouse.** Hypothesis 3 Educational dominance hypothesis: The spouse with the lowest education is more influenced by their partner than the spouse with the highest education.** 3.5 Data We will use: 11 waves (2008-2014, 2016-2020) More than 3000 heterosexual couples (cohabiting and married) Older than 25 We have already constructed a dataset for you guys and gals to work with. Please download this data file to your working directory. partner_dataprepped.Rdata 3.5.1 Variables Variables of interest and value labels: Education: = highest completed education in years (4-16.5) sex: = 0 = male / 1 = female eu_integration: 0 = eu integration has gone too far / 4 = eu integration should go further immigrants: 0 = immigrants should adjust / 4 immigrants can retain their own culture. euthanasia: 1 = euthanasia should be forbidden / 5 euthanasia should be permitted income: 1 differences in income should increase / 5 differences in income should decrease opleiding Hoogste opleiding met diploma 1 basisonderwijs 2 vmbo 3 havo/vwo 4 mbo 5 hbo 6 wo 7 anders 8 (Nog) geen onderwijs afgerond 9 Volgt nog geen onderwijs Hierbij hebben wij opleiding gecategoriseerd in drie groepen: 1. Laag: basisonderwijs en vmbo 2. Midden: havo/vwo en mbo 3. Hoog: hbo en wo We nemen enkel mensen van 25 jaar en ouder mee. Van hen verwachten we dat ze klaar zijn met hun onderwijscarriere. EU integratie De Europese integratie is te ver gegaan. 1 Helemaal oneens 2 Oneens 3 Niet eens, niet oneens 4 Eens 5 Helemaal eens Migratie/integratie In Nederland vinden sommigen dat mensen met een migratie achtergrond hier moeten kunnen leven met behoud van de eigen cultuur. Anderen vinden dat zij zich geheel moeten aanpassen aan de Nederlandse cultuur. Waar zou u uzelf plaatsen op een schaal van 1 t/m 5, waarbij 1 behoud van eigen cultuur voor mensen met een migratie achtergrond betekent en 5 dat zij zich geheel moeten aanpassen? 1 behoud van eigen cultuur voor mensen met een migratie achtergrond 2 3 4 5 mensen met een migratie achtergrond moeten zich geheel aanpassen 3.5.2 Descriptives TO DO 3.6 Analysis As always, make sure to start properly. See here. We need to do some additional dataprep. Have a look at the dataset. It is in long format but we will need a wide format. I know it is a bit cumbersome, but we will make a datafile for each dependent variable separately and will use some shorter names. The data files are stored in a list called datalist_ori. datalist_ori &lt;- list() # dep1: eu_integration dat &lt;- data.frame(x1 = partner_df_wide$eu_integration.m.1) dat$x2 &lt;- partner_df_wide$eu_integration.m.2 dat$x3 &lt;- partner_df_wide$eu_integration.m.3 dat$x4 &lt;- partner_df_wide$eu_integration.m.4 dat$x5 &lt;- partner_df_wide$eu_integration.m.5 dat$x6 &lt;- partner_df_wide$eu_integration.m.6 dat$x7 &lt;- partner_df_wide$eu_integration.m.7 dat$x8 &lt;- partner_df_wide$eu_integration.m.8 dat$x9 &lt;- partner_df_wide$eu_integration.m.9 dat$x10 &lt;- partner_df_wide$eu_integration.m.10 dat$x11 &lt;- partner_df_wide$eu_integration.m.11 dat$y1 &lt;- partner_df_wide$eu_integration.f.1 dat$y2 &lt;- partner_df_wide$eu_integration.f.2 dat$y3 &lt;- partner_df_wide$eu_integration.f.3 dat$y4 &lt;- partner_df_wide$eu_integration.f.4 dat$y5 &lt;- partner_df_wide$eu_integration.f.5 dat$y6 &lt;- partner_df_wide$eu_integration.f.6 dat$y7 &lt;- partner_df_wide$eu_integration.f.7 dat$y8 &lt;- partner_df_wide$eu_integration.f.8 dat$y9 &lt;- partner_df_wide$eu_integration.f.9 dat$y10 &lt;- partner_df_wide$eu_integration.f.10 dat$y11 &lt;- partner_df_wide$eu_integration.f.11 # treat education as a time stable. And use all available data. dat$oplx &lt;- rowMeans(partner_df_wide[, c(&quot;oplmet.m.1&quot;, &quot;oplmet.m.2&quot;, &quot;oplmet.m.3&quot;, &quot;oplmet.m.4&quot;, &quot;oplmet.m.5&quot;, &quot;oplmet.m.6&quot;, &quot;oplmet.m.7&quot;, &quot;oplmet.m.8&quot;, &quot;oplmet.m.9&quot;, &quot;oplmet.m.10&quot;, &quot;oplmet.m.11&quot;)], na.rm = T) dat$oply &lt;- rowMeans(partner_df_wide[, c(&quot;oplmet.f.1&quot;, &quot;oplmet.f.2&quot;, &quot;oplmet.f.3&quot;, &quot;oplmet.f.4&quot;, &quot;oplmet.f.5&quot;, &quot;oplmet.f.6&quot;, &quot;oplmet.f.7&quot;, &quot;oplmet.f.8&quot;, &quot;oplmet.f.9&quot;, &quot;oplmet.f.10&quot;, &quot;oplmet.f.11&quot;)], na.rm = T) # calculate diff in education between men and women dat$oplxy &lt;- dat$oplx - dat$oply # table(dat$oplx, dat$oply, useNA = &#39;always&#39;) hist(dat$oplxy) # define three groups for multigroup analyses dat$oplgroup &lt;- ifelse(dat$oplxy &gt; 1, &quot;menhigher&quot;, NA) dat$oplgroup &lt;- ifelse(dat$oplxy &lt; -1, &quot;womenhigher&quot;, dat$oplgroup) dat$oplgroup &lt;- ifelse(dat$oplxy &lt;= 1 &amp; dat$oplxy &gt;= -1, &quot;equal&quot;, dat$oplgroup) # table(dat$oplgroup, useNA = &#39;always&#39;) dat_ori &lt;- dat datalist_ori[[1]] &lt;- dat_ori # dep2: immigrants dat &lt;- data.frame(x1 = partner_df_wide$immigrants.m.1) dat$x2 &lt;- partner_df_wide$immigrants.m.2 dat$x3 &lt;- partner_df_wide$immigrants.m.3 dat$x4 &lt;- partner_df_wide$immigrants.m.4 dat$x5 &lt;- partner_df_wide$immigrants.m.5 dat$x6 &lt;- partner_df_wide$immigrants.m.6 dat$x7 &lt;- partner_df_wide$immigrants.m.7 dat$x8 &lt;- partner_df_wide$immigrants.m.8 dat$x9 &lt;- partner_df_wide$immigrants.m.9 dat$x10 &lt;- partner_df_wide$immigrants.m.10 dat$x11 &lt;- partner_df_wide$immigrants.m.11 dat$y1 &lt;- partner_df_wide$immigrants.f.1 dat$y2 &lt;- partner_df_wide$immigrants.f.2 dat$y3 &lt;- partner_df_wide$immigrants.f.3 dat$y4 &lt;- partner_df_wide$immigrants.f.4 dat$y5 &lt;- partner_df_wide$immigrants.f.5 dat$y6 &lt;- partner_df_wide$immigrants.f.6 dat$y7 &lt;- partner_df_wide$immigrants.f.7 dat$y8 &lt;- partner_df_wide$immigrants.f.8 dat$y9 &lt;- partner_df_wide$immigrants.f.9 dat$y10 &lt;- partner_df_wide$immigrants.f.10 dat$y11 &lt;- partner_df_wide$immigrants.f.11 # treat education as a time stable. And use all available data. dat$oplx &lt;- rowMeans(partner_df_wide[, c(&quot;oplmet.m.1&quot;, &quot;oplmet.m.2&quot;, &quot;oplmet.m.3&quot;, &quot;oplmet.m.4&quot;, &quot;oplmet.m.5&quot;, &quot;oplmet.m.6&quot;, &quot;oplmet.m.7&quot;, &quot;oplmet.m.8&quot;, &quot;oplmet.m.9&quot;, &quot;oplmet.m.10&quot;, &quot;oplmet.m.11&quot;)], na.rm = T) dat$oply &lt;- rowMeans(partner_df_wide[, c(&quot;oplmet.f.1&quot;, &quot;oplmet.f.2&quot;, &quot;oplmet.f.3&quot;, &quot;oplmet.f.4&quot;, &quot;oplmet.f.5&quot;, &quot;oplmet.f.6&quot;, &quot;oplmet.f.7&quot;, &quot;oplmet.f.8&quot;, &quot;oplmet.f.9&quot;, &quot;oplmet.f.10&quot;, &quot;oplmet.f.11&quot;)], na.rm = T) # calculate diff in education between men and women dat$oplxy &lt;- dat$oplx - dat$oply # table(dat$oplx, dat$oply, useNA = &#39;always&#39;) hist(dat$oplxy) # define three groups for multigroup analyses dat$oplgroup &lt;- ifelse(dat$oplxy &gt; 1, &quot;menhigher&quot;, NA) dat$oplgroup &lt;- ifelse(dat$oplxy &lt; -1, &quot;womenhigher&quot;, dat$oplgroup) dat$oplgroup &lt;- ifelse(dat$oplxy &lt;= 1 &amp; dat$oplxy &gt;= -1, &quot;equal&quot;, dat$oplgroup) # table(dat$oplgroup, useNA = &#39;always&#39;) dat_ori &lt;- dat datalist_ori[[2]] &lt;- dat_ori # dep3: euthanasia dat &lt;- data.frame(x1 = partner_df_wide$euthanasia.m.1) dat$x2 &lt;- partner_df_wide$euthanasia.m.2 dat$x3 &lt;- partner_df_wide$euthanasia.m.3 dat$x4 &lt;- partner_df_wide$euthanasia.m.4 dat$x5 &lt;- partner_df_wide$euthanasia.m.5 dat$x6 &lt;- partner_df_wide$euthanasia.m.6 dat$x7 &lt;- partner_df_wide$euthanasia.m.7 dat$x8 &lt;- partner_df_wide$euthanasia.m.8 dat$x9 &lt;- partner_df_wide$euthanasia.m.9 dat$x10 &lt;- partner_df_wide$euthanasia.m.10 dat$x11 &lt;- partner_df_wide$euthanasia.m.11 dat$y1 &lt;- partner_df_wide$euthanasia.f.1 dat$y2 &lt;- partner_df_wide$euthanasia.f.2 dat$y3 &lt;- partner_df_wide$euthanasia.f.3 dat$y4 &lt;- partner_df_wide$euthanasia.f.4 dat$y5 &lt;- partner_df_wide$euthanasia.f.5 dat$y6 &lt;- partner_df_wide$euthanasia.f.6 dat$y7 &lt;- partner_df_wide$euthanasia.f.7 dat$y8 &lt;- partner_df_wide$euthanasia.f.8 dat$y9 &lt;- partner_df_wide$euthanasia.f.9 dat$y10 &lt;- partner_df_wide$euthanasia.f.10 dat$y11 &lt;- partner_df_wide$euthanasia.f.11 # treat education as a time stable. And use all available data. dat$oplx &lt;- rowMeans(partner_df_wide[, c(&quot;oplmet.m.1&quot;, &quot;oplmet.m.2&quot;, &quot;oplmet.m.3&quot;, &quot;oplmet.m.4&quot;, &quot;oplmet.m.5&quot;, &quot;oplmet.m.6&quot;, &quot;oplmet.m.7&quot;, &quot;oplmet.m.8&quot;, &quot;oplmet.m.9&quot;, &quot;oplmet.m.10&quot;, &quot;oplmet.m.11&quot;)], na.rm = T) dat$oply &lt;- rowMeans(partner_df_wide[, c(&quot;oplmet.f.1&quot;, &quot;oplmet.f.2&quot;, &quot;oplmet.f.3&quot;, &quot;oplmet.f.4&quot;, &quot;oplmet.f.5&quot;, &quot;oplmet.f.6&quot;, &quot;oplmet.f.7&quot;, &quot;oplmet.f.8&quot;, &quot;oplmet.f.9&quot;, &quot;oplmet.f.10&quot;, &quot;oplmet.f.11&quot;)], na.rm = T) # calculate diff in education between men and women dat$oplxy &lt;- dat$oplx - dat$oply # table(dat$oplx, dat$oply, useNA = &#39;always&#39;) hist(dat$oplxy) # define three groups for multigroup analyses dat$oplgroup &lt;- ifelse(dat$oplxy &gt; 1, &quot;menhigher&quot;, NA) dat$oplgroup &lt;- ifelse(dat$oplxy &lt; -1, &quot;womenhigher&quot;, dat$oplgroup) dat$oplgroup &lt;- ifelse(dat$oplxy &lt;= 1 &amp; dat$oplxy &gt;= -1, &quot;equal&quot;, dat$oplgroup) # table(dat$oplgroup, useNA = &#39;always&#39;) dat_ori &lt;- dat datalist_ori[[3]] &lt;- dat_ori # dep4: income_diff dat &lt;- data.frame(x1 = partner_df_wide$income_diff.m.1) dat$x2 &lt;- partner_df_wide$income_diff.m.2 dat$x3 &lt;- partner_df_wide$income_diff.m.3 dat$x4 &lt;- partner_df_wide$income_diff.m.4 dat$x5 &lt;- partner_df_wide$income_diff.m.5 dat$x6 &lt;- partner_df_wide$income_diff.m.6 dat$x7 &lt;- partner_df_wide$income_diff.m.7 dat$x8 &lt;- partner_df_wide$income_diff.m.8 dat$x9 &lt;- partner_df_wide$income_diff.m.9 dat$x10 &lt;- partner_df_wide$income_diff.m.10 dat$x11 &lt;- partner_df_wide$income_diff.m.11 dat$y1 &lt;- partner_df_wide$income_diff.f.1 dat$y2 &lt;- partner_df_wide$income_diff.f.2 dat$y3 &lt;- partner_df_wide$income_diff.f.3 dat$y4 &lt;- partner_df_wide$income_diff.f.4 dat$y5 &lt;- partner_df_wide$income_diff.f.5 dat$y6 &lt;- partner_df_wide$income_diff.f.6 dat$y7 &lt;- partner_df_wide$income_diff.f.7 dat$y8 &lt;- partner_df_wide$income_diff.f.8 dat$y9 &lt;- partner_df_wide$income_diff.f.9 dat$y10 &lt;- partner_df_wide$income_diff.f.10 dat$y11 &lt;- partner_df_wide$income_diff.f.11 # treat education as a time stable. And use all available data. dat$oplx &lt;- rowMeans(partner_df_wide[, c(&quot;oplmet.m.1&quot;, &quot;oplmet.m.2&quot;, &quot;oplmet.m.3&quot;, &quot;oplmet.m.4&quot;, &quot;oplmet.m.5&quot;, &quot;oplmet.m.6&quot;, &quot;oplmet.m.7&quot;, &quot;oplmet.m.8&quot;, &quot;oplmet.m.9&quot;, &quot;oplmet.m.10&quot;, &quot;oplmet.m.11&quot;)], na.rm = T) dat$oply &lt;- rowMeans(partner_df_wide[, c(&quot;oplmet.f.1&quot;, &quot;oplmet.f.2&quot;, &quot;oplmet.f.3&quot;, &quot;oplmet.f.4&quot;, &quot;oplmet.f.5&quot;, &quot;oplmet.f.6&quot;, &quot;oplmet.f.7&quot;, &quot;oplmet.f.8&quot;, &quot;oplmet.f.9&quot;, &quot;oplmet.f.10&quot;, &quot;oplmet.f.11&quot;)], na.rm = T) # calculate diff in education between men and women dat$oplxy &lt;- dat$oplx - dat$oply # table(dat$oplx, dat$oply, useNA = &#39;always&#39;) hist(dat$oplxy) # define three groups for multigroup analyses dat$oplgroup &lt;- ifelse(dat$oplxy &gt; 1, &quot;menhigher&quot;, NA) dat$oplgroup &lt;- ifelse(dat$oplxy &lt; -1, &quot;womenhigher&quot;, dat$oplgroup) dat$oplgroup &lt;- ifelse(dat$oplxy &lt;= 1 &amp; dat$oplxy &gt;= -1, &quot;equal&quot;, dat$oplgroup) # table(dat$oplgroup, useNA = &#39;always&#39;) dat_ori &lt;- dat datalist_ori[[4]] &lt;- dat_ori 3.7 Modelling strategy Actor effects: stability effects Partner effects: influence effects Controlling for education. Figure 3.2: RI-CLPM Source: (Mulder and Hamaker 2020)(https://www.tandfonline.com/doi/full/10.1080/10705511.2020.1784738) We will compare the results across four different modeling strategies: Cross-lagged Panel Model (CLPM) (11 waves) RI-CLPM (11 waves) RI-CLPM + structural time trends (11 waves) RI/RS-CLPM (11 waves) 3.7.1 Robustness We will test our hypotheses for four different dependent variables: eu-integration immigration euthanasia income differences Feel free to re-estimate all models yourself. But it will be way quicker to download all results. results.Rdata 3.8 Results Hypo1 Hypo1 RI-CLPM: When your partners opinion is relatively high (compared to your partners average opinion over time) at time T, your own opinion will be relatively high (compared to your own average opinion over time) at time T+1. 3.8.1 CLPM results &lt;- list() myModel &lt;- &quot; ### control for education x1 + x2 + x3 +x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 ~ e*oplx y1 + y2 + y3 +y4 + y5 + y6 + y7 + y8 + y9 + y10 + y11 ~ e*oply ### Estimate the lagged effects x2 ~ a*x1 + b*y1 x3 ~ a*x2 + b*y2 x4 ~ a*x3 + b*y3 x5 ~ a*x4 + b*y4 x6 ~ a*x5 + b*y5 x7 ~ a*x6 + b*y6 x8 ~ a*x7 + b*y7 x9 ~ a*x8 + b*y8 x10 ~ a*x9 + b*y9 x11 ~ a*x10 + b*y10 y2 ~ b*x1 + a*y1 y3 ~ b*x2 + a*y2 y4 ~ b*x3 + a*y3 y5 ~ b*x4 + a*y4 y6 ~ b*x5 + a*y5 y7 ~ b*x6 + a*y6 y8 ~ b*x7 + a*y7 y9 ~ b*x8 + a*y8 y10 ~ b*x9 + a*y9 y11 ~ b*x10 + a*y10 # Estimate the (residual) covariance between the variables x1 ~~ y1 # Covariance x2 ~~ y2 x3 ~~ y3 x4 ~~ y4 x5 ~~ y5 x6 ~~ y6 x7 ~~ y7 x8 ~~ y8 x9 ~~ y9 x10 ~~ y10 x11 ~~ y11 # Estimate the (residual) variance of the variables. x1 ~~ x1 # Variances y1 ~~ y1 x2 ~~ x2 # Residual variances y2 ~~ y2 x3 ~~ x3 y3 ~~ y3 x4 ~~ x4 y4 ~~ y4 x5 ~~ x5 y5 ~~ y5 x6 ~~ x6 y6 ~~ y6 x7 ~~ x7 y7 ~~ y7 x8 ~~ x8 y8 ~~ y8 x9 ~~ x9 y9 ~~ y9 x10 ~~ x10 y10 ~~ y10 x11 ~~ x11 y11 ~~ y11 #intercepts x1 ~ 1 y1 ~ 1 x2 ~ 1 y2 ~ 1 x3 ~ 1 y3 ~ 1 x4 ~ 1 y4 ~ 1 x5 ~ 1 y5 ~ 1 x6 ~ 1 y6 ~ 1 x7 ~ 1 y7 ~ 1 x8 ~ 1 y8 ~ 1 x9 ~ 1 y9 ~ 1 x10 ~ 1 y10 ~ 1 x11 ~ 1 y11 ~ 1 &quot; # Estimate models a bit faster: estimate &lt;- function(x) lavaan(myModel, data = x, missing = &quot;fiml.x&quot;, meanstructure = T) library(future.apply) plan(multisession) results_temp &lt;- future_lapply(datalist_ori, estimate) results[[1]] &lt;- results_temp[[1]] results[[2]] &lt;- results_temp[[2]] results[[3]] &lt;- results_temp[[3]] results[[4]] &lt;- results_temp[[4]] names(results)[1:4] &lt;- c(&quot;fitm1h1y1&quot;, &quot;fitm1h1y2&quot;, &quot;fitm1h1y3&quot;, &quot;fitm1h1y4&quot;) save(results, file = &quot;results.RData&quot;) load(&quot;addfiles/results.Rdata&quot;) summary(results[[1]]) summary(results[[2]]) summary(results[[3]]) summary(results[[4]]) #&gt; lavaan 0.6-7 ended normally after 31 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 117 #&gt; Number of equality constraints 59 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1415 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 3353.035 #&gt; Degrees of freedom 261 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; x1 ~ #&gt; oplx (e) 0.039 0.002 22.760 0.000 #&gt; x2 ~ #&gt; oplx (e) 0.039 0.002 22.760 0.000 #&gt; x3 ~ #&gt; oplx (e) 0.039 0.002 22.760 0.000 #&gt; x4 ~ #&gt; oplx (e) 0.039 0.002 22.760 0.000 #&gt; x5 ~ #&gt; oplx (e) 0.039 0.002 22.760 0.000 #&gt; x6 ~ #&gt; oplx (e) 0.039 0.002 22.760 0.000 #&gt; x7 ~ #&gt; oplx (e) 0.039 0.002 22.760 0.000 #&gt; x8 ~ #&gt; oplx (e) 0.039 0.002 22.760 0.000 #&gt; x9 ~ #&gt; oplx (e) 0.039 0.002 22.760 0.000 #&gt; x10 ~ #&gt; oplx (e) 0.039 0.002 22.760 0.000 #&gt; x11 ~ #&gt; oplx (e) 0.039 0.002 22.760 0.000 #&gt; y1 ~ #&gt; oply (e) 0.039 0.002 22.760 0.000 #&gt; y2 ~ #&gt; oply (e) 0.039 0.002 22.760 0.000 #&gt; y3 ~ #&gt; oply (e) 0.039 0.002 22.760 0.000 #&gt; y4 ~ #&gt; oply (e) 0.039 0.002 22.760 0.000 #&gt; y5 ~ #&gt; oply (e) 0.039 0.002 22.760 0.000 #&gt; y6 ~ #&gt; oply (e) 0.039 0.002 22.760 0.000 #&gt; y7 ~ #&gt; oply (e) 0.039 0.002 22.760 0.000 #&gt; y8 ~ #&gt; oply (e) 0.039 0.002 22.760 0.000 #&gt; y9 ~ #&gt; oply (e) 0.039 0.002 22.760 0.000 #&gt; y10 ~ #&gt; oply (e) 0.039 0.002 22.760 0.000 #&gt; y11 ~ #&gt; oply (e) 0.039 0.002 22.760 0.000 #&gt; x2 ~ #&gt; x1 (a) 0.572 0.005 114.096 0.000 #&gt; y1 (b) 0.150 0.005 29.318 0.000 #&gt; x3 ~ #&gt; x2 (a) 0.572 0.005 114.096 0.000 #&gt; y2 (b) 0.150 0.005 29.318 0.000 #&gt; x4 ~ #&gt; x3 (a) 0.572 0.005 114.096 0.000 #&gt; y3 (b) 0.150 0.005 29.318 0.000 #&gt; x5 ~ #&gt; x4 (a) 0.572 0.005 114.096 0.000 #&gt; y4 (b) 0.150 0.005 29.318 0.000 #&gt; x6 ~ #&gt; x5 (a) 0.572 0.005 114.096 0.000 #&gt; y5 (b) 0.150 0.005 29.318 0.000 #&gt; x7 ~ #&gt; x6 (a) 0.572 0.005 114.096 0.000 #&gt; y6 (b) 0.150 0.005 29.318 0.000 #&gt; x8 ~ #&gt; x7 (a) 0.572 0.005 114.096 0.000 #&gt; y7 (b) 0.150 0.005 29.318 0.000 #&gt; x9 ~ #&gt; x8 (a) 0.572 0.005 114.096 0.000 #&gt; y8 (b) 0.150 0.005 29.318 0.000 #&gt; x10 ~ #&gt; x9 (a) 0.572 0.005 114.096 0.000 #&gt; y9 (b) 0.150 0.005 29.318 0.000 #&gt; x11 ~ #&gt; x10 (a) 0.572 0.005 114.096 0.000 #&gt; y10 (b) 0.150 0.005 29.318 0.000 #&gt; y2 ~ #&gt; x1 (b) 0.150 0.005 29.318 0.000 #&gt; y1 (a) 0.572 0.005 114.096 0.000 #&gt; y3 ~ #&gt; x2 (b) 0.150 0.005 29.318 0.000 #&gt; y2 (a) 0.572 0.005 114.096 0.000 #&gt; y4 ~ #&gt; x3 (b) 0.150 0.005 29.318 0.000 #&gt; y3 (a) 0.572 0.005 114.096 0.000 #&gt; y5 ~ #&gt; x4 (b) 0.150 0.005 29.318 0.000 #&gt; y4 (a) 0.572 0.005 114.096 0.000 #&gt; y6 ~ #&gt; x5 (b) 0.150 0.005 29.318 0.000 #&gt; y5 (a) 0.572 0.005 114.096 0.000 #&gt; y7 ~ #&gt; x6 (b) 0.150 0.005 29.318 0.000 #&gt; y6 (a) 0.572 0.005 114.096 0.000 #&gt; y8 ~ #&gt; x7 (b) 0.150 0.005 29.318 0.000 #&gt; y7 (a) 0.572 0.005 114.096 0.000 #&gt; y9 ~ #&gt; x8 (b) 0.150 0.005 29.318 0.000 #&gt; y8 (a) 0.572 0.005 114.096 0.000 #&gt; y10 ~ #&gt; x9 (b) 0.150 0.005 29.318 0.000 #&gt; y9 (a) 0.572 0.005 114.096 0.000 #&gt; y11 ~ #&gt; x10 (b) 0.150 0.005 29.318 0.000 #&gt; y10 (a) 0.572 0.005 114.096 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 ~~ #&gt; .y1 0.410 0.030 13.695 0.000 #&gt; .x2 ~~ #&gt; .y2 0.121 0.021 5.706 0.000 #&gt; .x3 ~~ #&gt; .y3 0.118 0.020 5.806 0.000 #&gt; .x4 ~~ #&gt; .y4 0.152 0.022 7.063 0.000 #&gt; .x5 ~~ #&gt; .y5 0.147 0.025 5.937 0.000 #&gt; .x6 ~~ #&gt; .y6 0.110 0.020 5.561 0.000 #&gt; .x7 ~~ #&gt; .y7 0.105 0.018 5.991 0.000 #&gt; .x8 ~~ #&gt; .y8 0.112 0.021 5.242 0.000 #&gt; .x9 ~~ #&gt; .y9 0.119 0.022 5.444 0.000 #&gt; .x10 ~~ #&gt; .y10 0.078 0.023 3.335 0.001 #&gt; .x11 ~~ #&gt; .y11 0.130 0.024 5.493 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 1.133 0.034 33.382 0.000 #&gt; .y1 1.087 0.031 35.251 0.000 #&gt; .x2 0.089 0.031 2.898 0.004 #&gt; .y2 0.072 0.029 2.469 0.014 #&gt; .x3 0.016 0.031 0.509 0.611 #&gt; .y3 0.007 0.028 0.245 0.806 #&gt; .x4 -0.285 0.031 -9.066 0.000 #&gt; .y4 -0.326 0.029 -11.062 0.000 #&gt; .x5 0.107 0.032 3.285 0.001 #&gt; .y5 -0.082 0.030 -2.748 0.006 #&gt; .x6 -0.190 0.030 -6.311 0.000 #&gt; .y6 -0.150 0.029 -5.257 0.000 #&gt; .x7 -0.187 0.029 -6.370 0.000 #&gt; .y7 -0.185 0.028 -6.666 0.000 #&gt; .x8 -0.017 0.031 -0.564 0.573 #&gt; .y8 -0.032 0.029 -1.094 0.274 #&gt; .x9 -0.169 0.031 -5.452 0.000 #&gt; .y9 -0.112 0.030 -3.758 0.000 #&gt; .x10 0.041 0.032 1.282 0.200 #&gt; .y10 0.077 0.031 2.492 0.013 #&gt; .x11 0.033 0.033 0.992 0.321 #&gt; .y11 0.029 0.031 0.948 0.343 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 1.384 0.046 30.338 0.000 #&gt; .y1 1.007 0.034 29.508 0.000 #&gt; .x2 0.824 0.031 27.005 0.000 #&gt; .y2 0.685 0.026 26.343 0.000 #&gt; .x3 0.781 0.030 26.387 0.000 #&gt; .y3 0.595 0.023 25.454 0.000 #&gt; .x4 0.814 0.032 25.716 0.000 #&gt; .y4 0.639 0.026 25.011 0.000 #&gt; .x5 0.945 0.037 25.737 0.000 #&gt; .y5 0.694 0.028 25.003 0.000 #&gt; .x6 0.709 0.027 25.842 0.000 #&gt; .y6 0.581 0.023 24.975 0.000 #&gt; .x7 0.646 0.025 25.635 0.000 #&gt; .y7 0.523 0.021 25.036 0.000 #&gt; .x8 0.754 0.030 25.271 0.000 #&gt; .y8 0.626 0.025 24.953 0.000 #&gt; .x9 0.753 0.029 25.582 0.000 #&gt; .y9 0.646 0.026 24.747 0.000 #&gt; .x10 0.766 0.032 24.282 0.000 #&gt; .y10 0.651 0.028 23.475 0.000 #&gt; .x11 0.796 0.033 24.016 0.000 #&gt; .y11 0.620 0.027 22.840 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 26 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 117 #&gt; Number of equality constraints 59 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1230 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 4312.762 #&gt; Degrees of freedom 261 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; x1 ~ #&gt; oplx (e) 0.026 0.001 18.920 0.000 #&gt; x2 ~ #&gt; oplx (e) 0.026 0.001 18.920 0.000 #&gt; x3 ~ #&gt; oplx (e) 0.026 0.001 18.920 0.000 #&gt; x4 ~ #&gt; oplx (e) 0.026 0.001 18.920 0.000 #&gt; x5 ~ #&gt; oplx (e) 0.026 0.001 18.920 0.000 #&gt; x6 ~ #&gt; oplx (e) 0.026 0.001 18.920 0.000 #&gt; x7 ~ #&gt; oplx (e) 0.026 0.001 18.920 0.000 #&gt; x8 ~ #&gt; oplx (e) 0.026 0.001 18.920 0.000 #&gt; x9 ~ #&gt; oplx (e) 0.026 0.001 18.920 0.000 #&gt; x10 ~ #&gt; oplx (e) 0.026 0.001 18.920 0.000 #&gt; x11 ~ #&gt; oplx (e) 0.026 0.001 18.920 0.000 #&gt; y1 ~ #&gt; oply (e) 0.026 0.001 18.920 0.000 #&gt; y2 ~ #&gt; oply (e) 0.026 0.001 18.920 0.000 #&gt; y3 ~ #&gt; oply (e) 0.026 0.001 18.920 0.000 #&gt; y4 ~ #&gt; oply (e) 0.026 0.001 18.920 0.000 #&gt; y5 ~ #&gt; oply (e) 0.026 0.001 18.920 0.000 #&gt; y6 ~ #&gt; oply (e) 0.026 0.001 18.920 0.000 #&gt; y7 ~ #&gt; oply (e) 0.026 0.001 18.920 0.000 #&gt; y8 ~ #&gt; oply (e) 0.026 0.001 18.920 0.000 #&gt; y9 ~ #&gt; oply (e) 0.026 0.001 18.920 0.000 #&gt; y10 ~ #&gt; oply (e) 0.026 0.001 18.920 0.000 #&gt; y11 ~ #&gt; oply (e) 0.026 0.001 18.920 0.000 #&gt; x2 ~ #&gt; x1 (a) 0.570 0.005 117.122 0.000 #&gt; y1 (b) 0.164 0.005 32.553 0.000 #&gt; x3 ~ #&gt; x2 (a) 0.570 0.005 117.122 0.000 #&gt; y2 (b) 0.164 0.005 32.553 0.000 #&gt; x4 ~ #&gt; x3 (a) 0.570 0.005 117.122 0.000 #&gt; y3 (b) 0.164 0.005 32.553 0.000 #&gt; x5 ~ #&gt; x4 (a) 0.570 0.005 117.122 0.000 #&gt; y4 (b) 0.164 0.005 32.553 0.000 #&gt; x6 ~ #&gt; x5 (a) 0.570 0.005 117.122 0.000 #&gt; y5 (b) 0.164 0.005 32.553 0.000 #&gt; x7 ~ #&gt; x6 (a) 0.570 0.005 117.122 0.000 #&gt; y6 (b) 0.164 0.005 32.553 0.000 #&gt; x8 ~ #&gt; x7 (a) 0.570 0.005 117.122 0.000 #&gt; y7 (b) 0.164 0.005 32.553 0.000 #&gt; x9 ~ #&gt; x8 (a) 0.570 0.005 117.122 0.000 #&gt; y8 (b) 0.164 0.005 32.553 0.000 #&gt; x10 ~ #&gt; x9 (a) 0.570 0.005 117.122 0.000 #&gt; y9 (b) 0.164 0.005 32.553 0.000 #&gt; x11 ~ #&gt; x10 (a) 0.570 0.005 117.122 0.000 #&gt; y10 (b) 0.164 0.005 32.553 0.000 #&gt; y2 ~ #&gt; x1 (b) 0.164 0.005 32.553 0.000 #&gt; y1 (a) 0.570 0.005 117.122 0.000 #&gt; y3 ~ #&gt; x2 (b) 0.164 0.005 32.553 0.000 #&gt; y2 (a) 0.570 0.005 117.122 0.000 #&gt; y4 ~ #&gt; x3 (b) 0.164 0.005 32.553 0.000 #&gt; y3 (a) 0.570 0.005 117.122 0.000 #&gt; y5 ~ #&gt; x4 (b) 0.164 0.005 32.553 0.000 #&gt; y4 (a) 0.570 0.005 117.122 0.000 #&gt; y6 ~ #&gt; x5 (b) 0.164 0.005 32.553 0.000 #&gt; y5 (a) 0.570 0.005 117.122 0.000 #&gt; y7 ~ #&gt; x6 (b) 0.164 0.005 32.553 0.000 #&gt; y6 (a) 0.570 0.005 117.122 0.000 #&gt; y8 ~ #&gt; x7 (b) 0.164 0.005 32.553 0.000 #&gt; y7 (a) 0.570 0.005 117.122 0.000 #&gt; y9 ~ #&gt; x8 (b) 0.164 0.005 32.553 0.000 #&gt; y8 (a) 0.570 0.005 117.122 0.000 #&gt; y10 ~ #&gt; x9 (b) 0.164 0.005 32.553 0.000 #&gt; y9 (a) 0.570 0.005 117.122 0.000 #&gt; y11 ~ #&gt; x10 (b) 0.164 0.005 32.553 0.000 #&gt; y10 (a) 0.570 0.005 117.122 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 ~~ #&gt; .y1 0.383 0.023 16.619 0.000 #&gt; .x2 ~~ #&gt; .y2 0.101 0.015 6.622 0.000 #&gt; .x3 ~~ #&gt; .y3 0.104 0.015 6.806 0.000 #&gt; .x4 ~~ #&gt; .y4 0.071 0.014 5.067 0.000 #&gt; .x5 ~~ #&gt; .y5 0.086 0.014 6.103 0.000 #&gt; .x6 ~~ #&gt; .y6 0.074 0.014 5.391 0.000 #&gt; .x7 ~~ #&gt; .y7 0.055 0.014 4.035 0.000 #&gt; .x8 ~~ #&gt; .y8 0.075 0.015 5.121 0.000 #&gt; .x9 ~~ #&gt; .y9 0.040 0.015 2.684 0.007 #&gt; .x10 ~~ #&gt; .y10 0.089 0.015 5.887 0.000 #&gt; .x11 ~~ #&gt; .y11 0.102 0.015 6.774 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.892 0.028 32.245 0.000 #&gt; .y1 0.953 0.027 35.963 0.000 #&gt; .x2 0.026 0.025 1.038 0.299 #&gt; .y2 0.057 0.024 2.331 0.020 #&gt; .x3 -0.002 0.025 -0.089 0.929 #&gt; .y3 0.068 0.024 2.803 0.005 #&gt; .x4 -0.001 0.024 -0.058 0.953 #&gt; .y4 0.039 0.024 1.593 0.111 #&gt; .x5 -0.003 0.025 -0.140 0.888 #&gt; .y5 0.039 0.024 1.599 0.110 #&gt; .x6 -0.005 0.025 -0.192 0.848 #&gt; .y6 0.039 0.024 1.656 0.098 #&gt; .x7 0.018 0.025 0.708 0.479 #&gt; .y7 0.065 0.024 2.701 0.007 #&gt; .x8 -0.048 0.025 -1.921 0.055 #&gt; .y8 0.002 0.025 0.097 0.923 #&gt; .x9 -0.058 0.025 -2.280 0.023 #&gt; .y9 0.018 0.025 0.725 0.468 #&gt; .x10 0.103 0.026 3.933 0.000 #&gt; .y10 0.127 0.025 5.052 0.000 #&gt; .x11 -0.011 0.026 -0.420 0.675 #&gt; .y11 0.053 0.026 2.085 0.037 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.945 0.031 30.290 0.000 #&gt; .y1 0.870 0.029 30.158 0.000 #&gt; .x2 0.567 0.021 27.155 0.000 #&gt; .y2 0.551 0.020 27.179 0.000 #&gt; .x3 0.548 0.021 26.526 0.000 #&gt; .y3 0.504 0.019 26.218 0.000 #&gt; .x4 0.462 0.018 25.877 0.000 #&gt; .y4 0.485 0.019 25.485 0.000 #&gt; .x5 0.478 0.019 25.817 0.000 #&gt; .y5 0.462 0.018 25.165 0.000 #&gt; .x6 0.506 0.019 26.234 0.000 #&gt; .y6 0.442 0.017 26.326 0.000 #&gt; .x7 0.489 0.019 25.936 0.000 #&gt; .y7 0.450 0.017 26.082 0.000 #&gt; .x8 0.479 0.019 25.456 0.000 #&gt; .y8 0.483 0.019 25.545 0.000 #&gt; .x9 0.502 0.019 25.775 0.000 #&gt; .y9 0.506 0.020 25.464 0.000 #&gt; .x10 0.512 0.021 24.658 0.000 #&gt; .y10 0.454 0.019 24.272 0.000 #&gt; .x11 0.492 0.020 24.435 0.000 #&gt; .y11 0.451 0.019 24.036 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 74 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 117 #&gt; Number of equality constraints 59 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1290 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 5151.101 #&gt; Degrees of freedom 261 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; x1 ~ #&gt; oplx (e) 0.004 0.001 3.326 0.001 #&gt; x2 ~ #&gt; oplx (e) 0.004 0.001 3.326 0.001 #&gt; x3 ~ #&gt; oplx (e) 0.004 0.001 3.326 0.001 #&gt; x4 ~ #&gt; oplx (e) 0.004 0.001 3.326 0.001 #&gt; x5 ~ #&gt; oplx (e) 0.004 0.001 3.326 0.001 #&gt; x6 ~ #&gt; oplx (e) 0.004 0.001 3.326 0.001 #&gt; x7 ~ #&gt; oplx (e) 0.004 0.001 3.326 0.001 #&gt; x8 ~ #&gt; oplx (e) 0.004 0.001 3.326 0.001 #&gt; x9 ~ #&gt; oplx (e) 0.004 0.001 3.326 0.001 #&gt; x10 ~ #&gt; oplx (e) 0.004 0.001 3.326 0.001 #&gt; x11 ~ #&gt; oplx (e) 0.004 0.001 3.326 0.001 #&gt; y1 ~ #&gt; oply (e) 0.004 0.001 3.326 0.001 #&gt; y2 ~ #&gt; oply (e) 0.004 0.001 3.326 0.001 #&gt; y3 ~ #&gt; oply (e) 0.004 0.001 3.326 0.001 #&gt; y4 ~ #&gt; oply (e) 0.004 0.001 3.326 0.001 #&gt; y5 ~ #&gt; oply (e) 0.004 0.001 3.326 0.001 #&gt; y6 ~ #&gt; oply (e) 0.004 0.001 3.326 0.001 #&gt; y7 ~ #&gt; oply (e) 0.004 0.001 3.326 0.001 #&gt; y8 ~ #&gt; oply (e) 0.004 0.001 3.326 0.001 #&gt; y9 ~ #&gt; oply (e) 0.004 0.001 3.326 0.001 #&gt; y10 ~ #&gt; oply (e) 0.004 0.001 3.326 0.001 #&gt; y11 ~ #&gt; oply (e) 0.004 0.001 3.326 0.001 #&gt; x2 ~ #&gt; x1 (a) 0.680 0.004 158.832 0.000 #&gt; y1 (b) 0.182 0.004 41.580 0.000 #&gt; x3 ~ #&gt; x2 (a) 0.680 0.004 158.832 0.000 #&gt; y2 (b) 0.182 0.004 41.580 0.000 #&gt; x4 ~ #&gt; x3 (a) 0.680 0.004 158.832 0.000 #&gt; y3 (b) 0.182 0.004 41.580 0.000 #&gt; x5 ~ #&gt; x4 (a) 0.680 0.004 158.832 0.000 #&gt; y4 (b) 0.182 0.004 41.580 0.000 #&gt; x6 ~ #&gt; x5 (a) 0.680 0.004 158.832 0.000 #&gt; y5 (b) 0.182 0.004 41.580 0.000 #&gt; x7 ~ #&gt; x6 (a) 0.680 0.004 158.832 0.000 #&gt; y6 (b) 0.182 0.004 41.580 0.000 #&gt; x8 ~ #&gt; x7 (a) 0.680 0.004 158.832 0.000 #&gt; y7 (b) 0.182 0.004 41.580 0.000 #&gt; x9 ~ #&gt; x8 (a) 0.680 0.004 158.832 0.000 #&gt; y8 (b) 0.182 0.004 41.580 0.000 #&gt; x10 ~ #&gt; x9 (a) 0.680 0.004 158.832 0.000 #&gt; y9 (b) 0.182 0.004 41.580 0.000 #&gt; x11 ~ #&gt; x10 (a) 0.680 0.004 158.832 0.000 #&gt; y10 (b) 0.182 0.004 41.580 0.000 #&gt; y2 ~ #&gt; x1 (b) 0.182 0.004 41.580 0.000 #&gt; y1 (a) 0.680 0.004 158.832 0.000 #&gt; y3 ~ #&gt; x2 (b) 0.182 0.004 41.580 0.000 #&gt; y2 (a) 0.680 0.004 158.832 0.000 #&gt; y4 ~ #&gt; x3 (b) 0.182 0.004 41.580 0.000 #&gt; y3 (a) 0.680 0.004 158.832 0.000 #&gt; y5 ~ #&gt; x4 (b) 0.182 0.004 41.580 0.000 #&gt; y4 (a) 0.680 0.004 158.832 0.000 #&gt; y6 ~ #&gt; x5 (b) 0.182 0.004 41.580 0.000 #&gt; y5 (a) 0.680 0.004 158.832 0.000 #&gt; y7 ~ #&gt; x6 (b) 0.182 0.004 41.580 0.000 #&gt; y6 (a) 0.680 0.004 158.832 0.000 #&gt; y8 ~ #&gt; x7 (b) 0.182 0.004 41.580 0.000 #&gt; y7 (a) 0.680 0.004 158.832 0.000 #&gt; y9 ~ #&gt; x8 (b) 0.182 0.004 41.580 0.000 #&gt; y8 (a) 0.680 0.004 158.832 0.000 #&gt; y10 ~ #&gt; x9 (b) 0.182 0.004 41.580 0.000 #&gt; y9 (a) 0.680 0.004 158.832 0.000 #&gt; y11 ~ #&gt; x10 (b) 0.182 0.004 41.580 0.000 #&gt; y10 (a) 0.680 0.004 158.832 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 ~~ #&gt; .y1 0.658 0.029 22.943 0.000 #&gt; .x2 ~~ #&gt; .y2 0.081 0.012 6.912 0.000 #&gt; .x3 ~~ #&gt; .y3 0.086 0.011 7.800 0.000 #&gt; .x4 ~~ #&gt; .y4 0.086 0.011 7.867 0.000 #&gt; .x5 ~~ #&gt; .y5 0.077 0.010 7.447 0.000 #&gt; .x6 ~~ #&gt; .y6 0.066 0.009 7.440 0.000 #&gt; .x7 ~~ #&gt; .y7 0.057 0.009 6.176 0.000 #&gt; .x8 ~~ #&gt; .y8 0.063 0.010 6.072 0.000 #&gt; .x9 ~~ #&gt; .y9 0.074 0.010 7.093 0.000 #&gt; .x10 ~~ #&gt; .y10 0.096 0.013 7.554 0.000 #&gt; .x11 ~~ #&gt; .y11 0.101 0.012 8.407 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 4.256 0.026 161.422 0.000 #&gt; .y1 4.274 0.026 161.379 0.000 #&gt; .x2 0.559 0.027 20.780 0.000 #&gt; .y2 0.587 0.026 22.511 0.000 #&gt; .x3 0.537 0.026 20.488 0.000 #&gt; .y3 0.529 0.027 19.968 0.000 #&gt; .x4 0.579 0.026 22.213 0.000 #&gt; .y4 0.601 0.027 22.523 0.000 #&gt; .x5 0.567 0.026 21.500 0.000 #&gt; .y5 0.581 0.026 22.174 0.000 #&gt; .x6 0.569 0.026 21.651 0.000 #&gt; .y6 0.572 0.025 22.816 0.000 #&gt; .x7 0.587 0.026 22.663 0.000 #&gt; .y7 0.587 0.026 22.866 0.000 #&gt; .x8 0.570 0.026 21.537 0.000 #&gt; .y8 0.575 0.027 21.666 0.000 #&gt; .x9 0.509 0.027 18.825 0.000 #&gt; .y9 0.535 0.026 20.449 0.000 #&gt; .x10 0.543 0.028 19.517 0.000 #&gt; .y10 0.544 0.027 20.026 0.000 #&gt; .x11 0.597 0.028 21.710 0.000 #&gt; .y11 0.600 0.027 21.817 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 1.060 0.034 31.095 0.000 #&gt; .y1 1.113 0.036 30.875 0.000 #&gt; .x2 0.440 0.016 26.862 0.000 #&gt; .y2 0.392 0.015 26.637 0.000 #&gt; .x3 0.359 0.014 26.181 0.000 #&gt; .y3 0.408 0.016 25.925 0.000 #&gt; .x4 0.338 0.013 26.091 0.000 #&gt; .y4 0.403 0.016 25.781 0.000 #&gt; .x5 0.339 0.013 25.647 0.000 #&gt; .y5 0.347 0.014 25.241 0.000 #&gt; .x6 0.344 0.013 26.462 0.000 #&gt; .y6 0.272 0.011 25.709 0.000 #&gt; .x7 0.308 0.012 25.948 0.000 #&gt; .y7 0.308 0.012 25.196 0.000 #&gt; .x8 0.325 0.013 25.093 0.000 #&gt; .y8 0.351 0.014 24.731 0.000 #&gt; .x9 0.367 0.015 25.327 0.000 #&gt; .y9 0.321 0.013 25.158 0.000 #&gt; .x10 0.394 0.017 23.697 0.000 #&gt; .y10 0.360 0.015 23.902 0.000 #&gt; .x11 0.362 0.015 24.067 0.000 #&gt; .y11 0.367 0.015 23.792 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 48 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 117 #&gt; Number of equality constraints 59 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1309 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 4211.139 #&gt; Degrees of freedom 261 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; x1 ~ #&gt; oplx (e) -0.017 0.001 -11.913 0.000 #&gt; x2 ~ #&gt; oplx (e) -0.017 0.001 -11.913 0.000 #&gt; x3 ~ #&gt; oplx (e) -0.017 0.001 -11.913 0.000 #&gt; x4 ~ #&gt; oplx (e) -0.017 0.001 -11.913 0.000 #&gt; x5 ~ #&gt; oplx (e) -0.017 0.001 -11.913 0.000 #&gt; x6 ~ #&gt; oplx (e) -0.017 0.001 -11.913 0.000 #&gt; x7 ~ #&gt; oplx (e) -0.017 0.001 -11.913 0.000 #&gt; x8 ~ #&gt; oplx (e) -0.017 0.001 -11.913 0.000 #&gt; x9 ~ #&gt; oplx (e) -0.017 0.001 -11.913 0.000 #&gt; x10 ~ #&gt; oplx (e) -0.017 0.001 -11.913 0.000 #&gt; x11 ~ #&gt; oplx (e) -0.017 0.001 -11.913 0.000 #&gt; y1 ~ #&gt; oply (e) -0.017 0.001 -11.913 0.000 #&gt; y2 ~ #&gt; oply (e) -0.017 0.001 -11.913 0.000 #&gt; y3 ~ #&gt; oply (e) -0.017 0.001 -11.913 0.000 #&gt; y4 ~ #&gt; oply (e) -0.017 0.001 -11.913 0.000 #&gt; y5 ~ #&gt; oply (e) -0.017 0.001 -11.913 0.000 #&gt; y6 ~ #&gt; oply (e) -0.017 0.001 -11.913 0.000 #&gt; y7 ~ #&gt; oply (e) -0.017 0.001 -11.913 0.000 #&gt; y8 ~ #&gt; oply (e) -0.017 0.001 -11.913 0.000 #&gt; y9 ~ #&gt; oply (e) -0.017 0.001 -11.913 0.000 #&gt; y10 ~ #&gt; oply (e) -0.017 0.001 -11.913 0.000 #&gt; y11 ~ #&gt; oply (e) -0.017 0.001 -11.913 0.000 #&gt; x2 ~ #&gt; x1 (a) 0.576 0.005 117.622 0.000 #&gt; y1 (b) 0.146 0.005 28.545 0.000 #&gt; x3 ~ #&gt; x2 (a) 0.576 0.005 117.622 0.000 #&gt; y2 (b) 0.146 0.005 28.545 0.000 #&gt; x4 ~ #&gt; x3 (a) 0.576 0.005 117.622 0.000 #&gt; y3 (b) 0.146 0.005 28.545 0.000 #&gt; x5 ~ #&gt; x4 (a) 0.576 0.005 117.622 0.000 #&gt; y4 (b) 0.146 0.005 28.545 0.000 #&gt; x6 ~ #&gt; x5 (a) 0.576 0.005 117.622 0.000 #&gt; y5 (b) 0.146 0.005 28.545 0.000 #&gt; x7 ~ #&gt; x6 (a) 0.576 0.005 117.622 0.000 #&gt; y6 (b) 0.146 0.005 28.545 0.000 #&gt; x8 ~ #&gt; x7 (a) 0.576 0.005 117.622 0.000 #&gt; y7 (b) 0.146 0.005 28.545 0.000 #&gt; x9 ~ #&gt; x8 (a) 0.576 0.005 117.622 0.000 #&gt; y8 (b) 0.146 0.005 28.545 0.000 #&gt; x10 ~ #&gt; x9 (a) 0.576 0.005 117.622 0.000 #&gt; y9 (b) 0.146 0.005 28.545 0.000 #&gt; x11 ~ #&gt; x10 (a) 0.576 0.005 117.622 0.000 #&gt; y10 (b) 0.146 0.005 28.545 0.000 #&gt; y2 ~ #&gt; x1 (b) 0.146 0.005 28.545 0.000 #&gt; y1 (a) 0.576 0.005 117.622 0.000 #&gt; y3 ~ #&gt; x2 (b) 0.146 0.005 28.545 0.000 #&gt; y2 (a) 0.576 0.005 117.622 0.000 #&gt; y4 ~ #&gt; x3 (b) 0.146 0.005 28.545 0.000 #&gt; y3 (a) 0.576 0.005 117.622 0.000 #&gt; y5 ~ #&gt; x4 (b) 0.146 0.005 28.545 0.000 #&gt; y4 (a) 0.576 0.005 117.622 0.000 #&gt; y6 ~ #&gt; x5 (b) 0.146 0.005 28.545 0.000 #&gt; y5 (a) 0.576 0.005 117.622 0.000 #&gt; y7 ~ #&gt; x6 (b) 0.146 0.005 28.545 0.000 #&gt; y6 (a) 0.576 0.005 117.622 0.000 #&gt; y8 ~ #&gt; x7 (b) 0.146 0.005 28.545 0.000 #&gt; y7 (a) 0.576 0.005 117.622 0.000 #&gt; y9 ~ #&gt; x8 (b) 0.146 0.005 28.545 0.000 #&gt; y8 (a) 0.576 0.005 117.622 0.000 #&gt; y10 ~ #&gt; x9 (b) 0.146 0.005 28.545 0.000 #&gt; y9 (a) 0.576 0.005 117.622 0.000 #&gt; y11 ~ #&gt; x10 (b) 0.146 0.005 28.545 0.000 #&gt; y10 (a) 0.576 0.005 117.622 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 ~~ #&gt; .y1 0.421 0.025 16.651 0.000 #&gt; .x2 ~~ #&gt; .y2 0.140 0.016 8.804 0.000 #&gt; .x3 ~~ #&gt; .y3 0.099 0.016 6.283 0.000 #&gt; .x4 ~~ #&gt; .y4 0.110 0.017 6.538 0.000 #&gt; .x5 ~~ #&gt; .y5 0.062 0.014 4.389 0.000 #&gt; .x6 ~~ #&gt; .y6 0.132 0.016 8.277 0.000 #&gt; .x7 ~~ #&gt; .y7 0.092 0.014 6.442 0.000 #&gt; .x8 ~~ #&gt; .y8 0.084 0.016 5.379 0.000 #&gt; .x9 ~~ #&gt; .y9 0.103 0.017 6.144 0.000 #&gt; .x10 ~~ #&gt; .y10 0.094 0.017 5.492 0.000 #&gt; .x11 ~~ #&gt; .y11 0.069 0.017 3.957 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 3.856 0.029 130.976 0.000 #&gt; .y1 4.007 0.027 146.050 0.000 #&gt; .x2 1.238 0.035 35.035 0.000 #&gt; .y2 1.350 0.034 39.374 0.000 #&gt; .x3 1.210 0.035 34.432 0.000 #&gt; .y3 1.249 0.035 35.770 0.000 #&gt; .x4 1.210 0.036 34.057 0.000 #&gt; .y4 1.294 0.035 37.093 0.000 #&gt; .x5 1.328 0.035 38.257 0.000 #&gt; .y5 1.345 0.034 39.097 0.000 #&gt; .x6 1.135 0.036 31.683 0.000 #&gt; .y6 1.215 0.035 34.565 0.000 #&gt; .x7 1.227 0.035 35.149 0.000 #&gt; .y7 1.269 0.034 37.270 0.000 #&gt; .x8 1.276 0.036 35.898 0.000 #&gt; .y8 1.323 0.035 37.776 0.000 #&gt; .x9 1.262 0.036 35.163 0.000 #&gt; .y9 1.286 0.036 36.048 0.000 #&gt; .x10 1.252 0.036 34.580 0.000 #&gt; .y10 1.253 0.036 34.746 0.000 #&gt; .x11 1.303 0.037 35.598 0.000 #&gt; .y11 1.283 0.036 35.215 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 1.095 0.036 30.386 0.000 #&gt; .y1 0.910 0.030 30.280 0.000 #&gt; .x2 0.608 0.022 27.022 0.000 #&gt; .y2 0.541 0.020 27.090 0.000 #&gt; .x3 0.541 0.021 26.339 0.000 #&gt; .y3 0.555 0.021 26.223 0.000 #&gt; .x4 0.565 0.022 25.748 0.000 #&gt; .y4 0.532 0.021 25.544 0.000 #&gt; .x5 0.468 0.018 25.316 0.000 #&gt; .y5 0.471 0.019 25.266 0.000 #&gt; .x6 0.562 0.021 26.194 0.000 #&gt; .y6 0.532 0.020 26.158 0.000 #&gt; .x7 0.502 0.019 25.972 0.000 #&gt; .y7 0.444 0.017 25.676 0.000 #&gt; .x8 0.535 0.021 25.603 0.000 #&gt; .y8 0.505 0.020 25.362 0.000 #&gt; .x9 0.552 0.021 25.758 0.000 #&gt; .y9 0.542 0.021 25.218 0.000 #&gt; .x10 0.532 0.022 24.556 0.000 #&gt; .y10 0.531 0.022 24.152 0.000 #&gt; .x11 0.543 0.022 24.310 0.000 #&gt; .y11 0.525 0.022 23.738 0.000 3.8.2 RI-CLPM RICLPM &lt;- &#39; # Create between components (random intercepts) RIx =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 + 1*x5 + 1*x6 + 1*x7 + 1*x8 + 1*x9 + 1*x10 + 1*x11 RIy =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 + 1*y5 + 1*y6 + 1*y7 + 1*y8 + 1*y9 + 1*y10 + 1*y11 RIx ~ e*oplx RIy ~ e*oply # Create within-person centered variables wx1 =~ 1*x1 wx2 =~ 1*x2 wx3 =~ 1*x3 wx4 =~ 1*x4 wx5 =~ 1*x5 wx6 =~ 1*x6 wx7 =~ 1*x7 wx8 =~ 1*x8 wx9 =~ 1*x9 wx10 =~ 1*x10 wx11 =~ 1*x11 wy1 =~ 1*y1 wy2 =~ 1*y2 wy3 =~ 1*y3 wy4 =~ 1*y4 wy5 =~ 1*y5 wy6 =~ 1*y6 wy7 =~ 1*y7 wy8 =~ 1*y8 wy9 =~ 1*y9 wy10 =~ 1*y10 wy11 =~ 1*y11 # Estimate the lagged effects between the within-person centered variables. wx2 ~ a*wx1 + b*wy1 wx3 ~ a*wx2 + b*wy2 wx4 ~ a*wx3 + b*wy3 wx5 ~ a*wx4 + b*wy4 wx6 ~ a*wx5 + b*wy5 wx7 ~ a*wx6 + b*wy6 wx8 ~ a*wx7 + b*wy7 wx9 ~ a*wx8 + b*wy8 wx10 ~ a*wx9 + b*wy9 wx11 ~ a*wx10 + b*wy10 wy2 ~ b*wx1 + a*wy1 wy3 ~ b*wx2 + a*wy2 wy4 ~ b*wx3 + a*wy3 wy5 ~ b*wx4 + a*wy4 wy6 ~ b*wx5 + a*wy5 wy7 ~ b*wx6 + a*wy6 wy8 ~ b*wx7 + a*wy7 wy9 ~ b*wx8 + a*wy8 wy10 ~ b*wx9 + a*wy9 wy11 ~ b*wx10 + a*wy10 # Estimate the (residual) covariance between the within-person centered variables wx1 ~~ wy1 # Covariance wx2 ~~ wy2 wx3 ~~ wy3 wx4 ~~ wy4 wx5 ~~ wy5 wx6 ~~ wy6 wx7 ~~ wy7 wx8 ~~ wy8 wx9 ~~ wy9 wx10 ~~ wy10 wx11 ~~ wy11 # Estimate the variance and covariance of the random intercepts. RIx ~~ RIx RIy ~~ RIy RIx ~~ RIy # Estimate the (residual) variance of the within-person centered variables. wx1 ~~ wx1 # Variances wy1 ~~ wy1 wx2 ~~ wx2 # Residual variances wy2 ~~ wy2 wx3 ~~ wx3 wy3 ~~ wy3 wx4 ~~ wx4 wy4 ~~ wy4 wx5 ~~ wx5 wy5 ~~ wy5 wx6 ~~ wx6 wy6 ~~ wy6 wx7 ~~ wx7 wy7 ~~ wy7 wx8 ~~ wx8 wy8 ~~ wy8 wx9 ~~ wx9 wy9 ~~ wy9 wx10 ~~ wx10 wy10 ~~ wy10 wx11 ~~ wx11 wy11 ~~ wy11 &#39; #Estimate models a bit faster: estimate &lt;- function(x) lavaan(RICLPM, data=x, missing = &quot;fiml.x&quot;, meanstructure = T ) library(future.apply) plan(multisession) results_temp &lt;- future_lapply(datalist_ori, estimate) results[[5]] &lt;- results_temp[[1]] results[[6]] &lt;- results_temp[[2]] results[[7]] &lt;- results_temp[[3]] results[[8]] &lt;- results_temp[[4]] names(results)[5:8] &lt;- c(&quot;fitm2h1y1&quot;, &quot;fitm2h1y2&quot;,&quot;fitm2h1y3&quot;,&quot;fitm2h1y4&quot;) load(&quot;addfiles/results.Rdata&quot;) summary(results[[5]]) summary(results[[6]]) summary(results[[7]]) summary(results[[8]]) #&gt; lavaan 0.6-7 ended normally after 42 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 78 #&gt; Number of equality constraints 39 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1415 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 1632.289 #&gt; Degrees of freedom 280 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (e) 0.122 0.001 107.040 0.000 #&gt; RIy ~ #&gt; oply (e) 0.122 0.001 107.040 0.000 #&gt; wx2 ~ #&gt; wx1 (a) 0.203 0.008 24.374 0.000 #&gt; wy1 (b) 0.075 0.009 8.629 0.000 #&gt; wx3 ~ #&gt; wx2 (a) 0.203 0.008 24.374 0.000 #&gt; wy2 (b) 0.075 0.009 8.629 0.000 #&gt; wx4 ~ #&gt; wx3 (a) 0.203 0.008 24.374 0.000 #&gt; wy3 (b) 0.075 0.009 8.629 0.000 #&gt; wx5 ~ #&gt; wx4 (a) 0.203 0.008 24.374 0.000 #&gt; wy4 (b) 0.075 0.009 8.629 0.000 #&gt; wx6 ~ #&gt; wx5 (a) 0.203 0.008 24.374 0.000 #&gt; wy5 (b) 0.075 0.009 8.629 0.000 #&gt; wx7 ~ #&gt; wx6 (a) 0.203 0.008 24.374 0.000 #&gt; wy6 (b) 0.075 0.009 8.629 0.000 #&gt; wx8 ~ #&gt; wx7 (a) 0.203 0.008 24.374 0.000 #&gt; wy7 (b) 0.075 0.009 8.629 0.000 #&gt; wx9 ~ #&gt; wx8 (a) 0.203 0.008 24.374 0.000 #&gt; wy8 (b) 0.075 0.009 8.629 0.000 #&gt; wx10 ~ #&gt; wx9 (a) 0.203 0.008 24.374 0.000 #&gt; wy9 (b) 0.075 0.009 8.629 0.000 #&gt; wx11 ~ #&gt; wx10 (a) 0.203 0.008 24.374 0.000 #&gt; wy10 (b) 0.075 0.009 8.629 0.000 #&gt; wy2 ~ #&gt; wx1 (b) 0.075 0.009 8.629 0.000 #&gt; wy1 (a) 0.203 0.008 24.374 0.000 #&gt; wy3 ~ #&gt; wx2 (b) 0.075 0.009 8.629 0.000 #&gt; wy2 (a) 0.203 0.008 24.374 0.000 #&gt; wy4 ~ #&gt; wx3 (b) 0.075 0.009 8.629 0.000 #&gt; wy3 (a) 0.203 0.008 24.374 0.000 #&gt; wy5 ~ #&gt; wx4 (b) 0.075 0.009 8.629 0.000 #&gt; wy4 (a) 0.203 0.008 24.374 0.000 #&gt; wy6 ~ #&gt; wx5 (b) 0.075 0.009 8.629 0.000 #&gt; wy5 (a) 0.203 0.008 24.374 0.000 #&gt; wy7 ~ #&gt; wx6 (b) 0.075 0.009 8.629 0.000 #&gt; wy6 (a) 0.203 0.008 24.374 0.000 #&gt; wy8 ~ #&gt; wx7 (b) 0.075 0.009 8.629 0.000 #&gt; wy7 (a) 0.203 0.008 24.374 0.000 #&gt; wy9 ~ #&gt; wx8 (b) 0.075 0.009 8.629 0.000 #&gt; wy8 (a) 0.203 0.008 24.374 0.000 #&gt; wy10 ~ #&gt; wx9 (b) 0.075 0.009 8.629 0.000 #&gt; wy9 (a) 0.203 0.008 24.374 0.000 #&gt; wy11 ~ #&gt; wx10 (b) 0.075 0.009 8.629 0.000 #&gt; wy10 (a) 0.203 0.008 24.374 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.120 0.022 5.386 0.000 #&gt; .wx2 ~~ #&gt; .wy2 0.118 0.020 5.771 0.000 #&gt; .wx3 ~~ #&gt; .wy3 0.121 0.019 6.356 0.000 #&gt; .wx4 ~~ #&gt; .wy4 0.115 0.019 6.072 0.000 #&gt; .wx5 ~~ #&gt; .wy5 0.104 0.022 4.757 0.000 #&gt; .wx6 ~~ #&gt; .wy6 0.073 0.017 4.381 0.000 #&gt; .wx7 ~~ #&gt; .wy7 0.100 0.016 6.324 0.000 #&gt; .wx8 ~~ #&gt; .wy8 0.083 0.018 4.541 0.000 #&gt; .wx9 ~~ #&gt; .wy9 0.102 0.019 5.241 0.000 #&gt; .wx10 ~~ #&gt; .wy10 0.043 0.020 2.127 0.033 #&gt; .wx11 ~~ #&gt; .wy11 0.101 0.021 4.850 0.000 #&gt; .RIx ~~ #&gt; .RIy 0.354 0.017 21.005 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; .wx2 0.000 #&gt; .wx3 0.000 #&gt; .wx4 0.000 #&gt; .wx5 0.000 #&gt; .wx6 0.000 #&gt; .wx7 0.000 #&gt; .wx8 0.000 #&gt; .wx9 0.000 #&gt; .wx10 0.000 #&gt; .wx11 0.000 #&gt; wy1 0.000 #&gt; .wy2 0.000 #&gt; .wy3 0.000 #&gt; .wy4 0.000 #&gt; .wy5 0.000 #&gt; .wy6 0.000 #&gt; .wy7 0.000 #&gt; .wy8 0.000 #&gt; .wy9 0.000 #&gt; .wy10 0.000 #&gt; .wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 0.757 0.025 30.317 0.000 #&gt; .RIy 0.488 0.018 27.518 0.000 #&gt; wx1 0.717 0.031 22.848 0.000 #&gt; wy1 0.618 0.027 22.504 0.000 #&gt; .wx2 0.712 0.029 24.248 0.000 #&gt; .wy2 0.588 0.025 23.509 0.000 #&gt; .wx3 0.614 0.026 23.815 0.000 #&gt; .wy3 0.533 0.023 23.030 0.000 #&gt; .wx4 0.604 0.027 22.679 0.000 #&gt; .wy4 0.490 0.022 21.934 0.000 #&gt; .wx5 0.758 0.032 24.016 0.000 #&gt; .wy5 0.567 0.024 23.286 0.000 #&gt; .wx6 0.510 0.022 22.955 0.000 #&gt; .wy6 0.432 0.019 22.186 0.000 #&gt; .wx7 0.488 0.021 22.844 0.000 #&gt; .wy7 0.444 0.020 22.585 0.000 #&gt; .wx8 0.546 0.024 23.023 0.000 #&gt; .wy8 0.505 0.022 22.795 0.000 #&gt; .wx9 0.604 0.026 23.063 0.000 #&gt; .wy9 0.510 0.023 22.176 0.000 #&gt; .wx10 0.562 0.026 21.674 0.000 #&gt; .wy10 0.511 0.024 21.292 0.000 #&gt; .wx11 0.612 0.028 21.517 0.000 #&gt; .wy11 0.519 0.025 20.641 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 39 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 78 #&gt; Number of equality constraints 39 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1230 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 833.630 #&gt; Degrees of freedom 280 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (e) 0.104 0.001 103.001 0.000 #&gt; RIy ~ #&gt; oply (e) 0.104 0.001 103.001 0.000 #&gt; wx2 ~ #&gt; wx1 (a) 0.102 0.008 12.802 0.000 #&gt; wy1 (b) 0.030 0.008 3.548 0.000 #&gt; wx3 ~ #&gt; wx2 (a) 0.102 0.008 12.802 0.000 #&gt; wy2 (b) 0.030 0.008 3.548 0.000 #&gt; wx4 ~ #&gt; wx3 (a) 0.102 0.008 12.802 0.000 #&gt; wy3 (b) 0.030 0.008 3.548 0.000 #&gt; wx5 ~ #&gt; wx4 (a) 0.102 0.008 12.802 0.000 #&gt; wy4 (b) 0.030 0.008 3.548 0.000 #&gt; wx6 ~ #&gt; wx5 (a) 0.102 0.008 12.802 0.000 #&gt; wy5 (b) 0.030 0.008 3.548 0.000 #&gt; wx7 ~ #&gt; wx6 (a) 0.102 0.008 12.802 0.000 #&gt; wy6 (b) 0.030 0.008 3.548 0.000 #&gt; wx8 ~ #&gt; wx7 (a) 0.102 0.008 12.802 0.000 #&gt; wy7 (b) 0.030 0.008 3.548 0.000 #&gt; wx9 ~ #&gt; wx8 (a) 0.102 0.008 12.802 0.000 #&gt; wy8 (b) 0.030 0.008 3.548 0.000 #&gt; wx10 ~ #&gt; wx9 (a) 0.102 0.008 12.802 0.000 #&gt; wy9 (b) 0.030 0.008 3.548 0.000 #&gt; wx11 ~ #&gt; wx10 (a) 0.102 0.008 12.802 0.000 #&gt; wy10 (b) 0.030 0.008 3.548 0.000 #&gt; wy2 ~ #&gt; wx1 (b) 0.030 0.008 3.548 0.000 #&gt; wy1 (a) 0.102 0.008 12.802 0.000 #&gt; wy3 ~ #&gt; wx2 (b) 0.030 0.008 3.548 0.000 #&gt; wy2 (a) 0.102 0.008 12.802 0.000 #&gt; wy4 ~ #&gt; wx3 (b) 0.030 0.008 3.548 0.000 #&gt; wy3 (a) 0.102 0.008 12.802 0.000 #&gt; wy5 ~ #&gt; wx4 (b) 0.030 0.008 3.548 0.000 #&gt; wy4 (a) 0.102 0.008 12.802 0.000 #&gt; wy6 ~ #&gt; wx5 (b) 0.030 0.008 3.548 0.000 #&gt; wy5 (a) 0.102 0.008 12.802 0.000 #&gt; wy7 ~ #&gt; wx6 (b) 0.030 0.008 3.548 0.000 #&gt; wy6 (a) 0.102 0.008 12.802 0.000 #&gt; wy8 ~ #&gt; wx7 (b) 0.030 0.008 3.548 0.000 #&gt; wy7 (a) 0.102 0.008 12.802 0.000 #&gt; wy9 ~ #&gt; wx8 (b) 0.030 0.008 3.548 0.000 #&gt; wy8 (a) 0.102 0.008 12.802 0.000 #&gt; wy10 ~ #&gt; wx9 (b) 0.030 0.008 3.548 0.000 #&gt; wy9 (a) 0.102 0.008 12.802 0.000 #&gt; wy11 ~ #&gt; wx10 (b) 0.030 0.008 3.548 0.000 #&gt; wy10 (a) 0.102 0.008 12.802 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.052 0.013 4.087 0.000 #&gt; .wx2 ~~ #&gt; .wy2 0.047 0.013 3.720 0.000 #&gt; .wx3 ~~ #&gt; .wy3 0.030 0.011 2.687 0.007 #&gt; .wx4 ~~ #&gt; .wy4 0.045 0.011 4.062 0.000 #&gt; .wx5 ~~ #&gt; .wy5 0.044 0.011 4.057 0.000 #&gt; .wx6 ~~ #&gt; .wy6 0.026 0.011 2.404 0.016 #&gt; .wx7 ~~ #&gt; .wy7 0.034 0.011 2.992 0.003 #&gt; .wx8 ~~ #&gt; .wy8 0.032 0.011 2.834 0.005 #&gt; .wx9 ~~ #&gt; .wy9 0.012 0.013 0.959 0.337 #&gt; .wx10 ~~ #&gt; .wy10 0.048 0.013 3.688 0.000 #&gt; .wx11 ~~ #&gt; .wy11 0.062 0.013 4.865 0.000 #&gt; .RIx ~~ #&gt; .RIy 0.308 0.013 23.781 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; .wx2 0.000 #&gt; .wx3 0.000 #&gt; .wx4 0.000 #&gt; .wx5 0.000 #&gt; .wx6 0.000 #&gt; .wx7 0.000 #&gt; .wx8 0.000 #&gt; .wx9 0.000 #&gt; .wx10 0.000 #&gt; .wx11 0.000 #&gt; wy1 0.000 #&gt; .wy2 0.000 #&gt; .wy3 0.000 #&gt; .wy4 0.000 #&gt; .wy5 0.000 #&gt; .wy6 0.000 #&gt; .wy7 0.000 #&gt; .wy8 0.000 #&gt; .wy9 0.000 #&gt; .wy10 0.000 #&gt; .wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 0.535 0.017 32.040 0.000 #&gt; .RIy 0.500 0.016 31.781 0.000 #&gt; wx1 0.449 0.019 23.866 0.000 #&gt; wy1 0.374 0.016 23.272 0.000 #&gt; .wx2 0.406 0.017 24.105 0.000 #&gt; .wy2 0.428 0.017 24.616 0.000 #&gt; .wx3 0.353 0.015 23.825 0.000 #&gt; .wy3 0.319 0.014 23.389 0.000 #&gt; .wx4 0.327 0.014 22.780 0.000 #&gt; .wy4 0.328 0.014 22.674 0.000 #&gt; .wx5 0.329 0.014 23.605 0.000 #&gt; .wy5 0.337 0.014 23.534 0.000 #&gt; .wx6 0.355 0.015 23.698 0.000 #&gt; .wy6 0.308 0.013 23.315 0.000 #&gt; .wx7 0.352 0.015 23.524 0.000 #&gt; .wy7 0.332 0.014 23.601 0.000 #&gt; .wx8 0.327 0.014 22.999 0.000 #&gt; .wy8 0.331 0.014 23.197 0.000 #&gt; .wx9 0.374 0.016 23.077 0.000 #&gt; .wy9 0.376 0.016 22.787 0.000 #&gt; .wx10 0.375 0.017 22.119 0.000 #&gt; .wy10 0.343 0.016 21.618 0.000 #&gt; .wx11 0.363 0.017 21.477 0.000 #&gt; .wy11 0.329 0.016 20.681 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 57 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 78 #&gt; Number of equality constraints 39 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1290 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 5881.742 #&gt; Degrees of freedom 280 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (e) 0.334 0.002 181.923 0.000 #&gt; RIy ~ #&gt; oply (e) 0.334 0.002 181.923 0.000 #&gt; wx2 ~ #&gt; wx1 (a) 0.116 0.008 14.473 0.000 #&gt; wy1 (b) 0.042 0.008 4.918 0.000 #&gt; wx3 ~ #&gt; wx2 (a) 0.116 0.008 14.473 0.000 #&gt; wy2 (b) 0.042 0.008 4.918 0.000 #&gt; wx4 ~ #&gt; wx3 (a) 0.116 0.008 14.473 0.000 #&gt; wy3 (b) 0.042 0.008 4.918 0.000 #&gt; wx5 ~ #&gt; wx4 (a) 0.116 0.008 14.473 0.000 #&gt; wy4 (b) 0.042 0.008 4.918 0.000 #&gt; wx6 ~ #&gt; wx5 (a) 0.116 0.008 14.473 0.000 #&gt; wy5 (b) 0.042 0.008 4.918 0.000 #&gt; wx7 ~ #&gt; wx6 (a) 0.116 0.008 14.473 0.000 #&gt; wy6 (b) 0.042 0.008 4.918 0.000 #&gt; wx8 ~ #&gt; wx7 (a) 0.116 0.008 14.473 0.000 #&gt; wy7 (b) 0.042 0.008 4.918 0.000 #&gt; wx9 ~ #&gt; wx8 (a) 0.116 0.008 14.473 0.000 #&gt; wy8 (b) 0.042 0.008 4.918 0.000 #&gt; wx10 ~ #&gt; wx9 (a) 0.116 0.008 14.473 0.000 #&gt; wy9 (b) 0.042 0.008 4.918 0.000 #&gt; wx11 ~ #&gt; wx10 (a) 0.116 0.008 14.473 0.000 #&gt; wy10 (b) 0.042 0.008 4.918 0.000 #&gt; wy2 ~ #&gt; wx1 (b) 0.042 0.008 4.918 0.000 #&gt; wy1 (a) 0.116 0.008 14.473 0.000 #&gt; wy3 ~ #&gt; wx2 (b) 0.042 0.008 4.918 0.000 #&gt; wy2 (a) 0.116 0.008 14.473 0.000 #&gt; wy4 ~ #&gt; wx3 (b) 0.042 0.008 4.918 0.000 #&gt; wy3 (a) 0.116 0.008 14.473 0.000 #&gt; wy5 ~ #&gt; wx4 (b) 0.042 0.008 4.918 0.000 #&gt; wy4 (a) 0.116 0.008 14.473 0.000 #&gt; wy6 ~ #&gt; wx5 (b) 0.042 0.008 4.918 0.000 #&gt; wy5 (a) 0.116 0.008 14.473 0.000 #&gt; wy7 ~ #&gt; wx6 (b) 0.042 0.008 4.918 0.000 #&gt; wy6 (a) 0.116 0.008 14.473 0.000 #&gt; wy8 ~ #&gt; wx7 (b) 0.042 0.008 4.918 0.000 #&gt; wy7 (a) 0.116 0.008 14.473 0.000 #&gt; wy9 ~ #&gt; wx8 (b) 0.042 0.008 4.918 0.000 #&gt; wy8 (a) 0.116 0.008 14.473 0.000 #&gt; wy10 ~ #&gt; wx9 (b) 0.042 0.008 4.918 0.000 #&gt; wy9 (a) 0.116 0.008 14.473 0.000 #&gt; wy11 ~ #&gt; wx10 (b) 0.042 0.008 4.918 0.000 #&gt; wy10 (a) 0.116 0.008 14.473 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.067 0.011 6.180 0.000 #&gt; .wx2 ~~ #&gt; .wy2 0.036 0.009 4.073 0.000 #&gt; .wx3 ~~ #&gt; .wy3 0.068 0.009 7.443 0.000 #&gt; .wx4 ~~ #&gt; .wy4 0.029 0.008 3.608 0.000 #&gt; .wx5 ~~ #&gt; .wy5 0.040 0.008 5.196 0.000 #&gt; .wx6 ~~ #&gt; .wy6 0.036 0.007 5.156 0.000 #&gt; .wx7 ~~ #&gt; .wy7 0.034 0.007 4.786 0.000 #&gt; .wx8 ~~ #&gt; .wy8 0.027 0.008 3.461 0.001 #&gt; .wx9 ~~ #&gt; .wy9 0.034 0.008 4.181 0.000 #&gt; .wx10 ~~ #&gt; .wy10 0.063 0.010 6.040 0.000 #&gt; .wx11 ~~ #&gt; .wy11 0.068 0.009 7.155 0.000 #&gt; .RIx ~~ #&gt; .RIy 1.081 0.039 27.517 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; .wx2 0.000 #&gt; .wx3 0.000 #&gt; .wx4 0.000 #&gt; .wx5 0.000 #&gt; .wx6 0.000 #&gt; .wx7 0.000 #&gt; .wx8 0.000 #&gt; .wx9 0.000 #&gt; .wx10 0.000 #&gt; .wx11 0.000 #&gt; wy1 0.000 #&gt; .wy2 0.000 #&gt; .wy3 0.000 #&gt; .wy4 0.000 #&gt; .wy5 0.000 #&gt; .wy6 0.000 #&gt; .wy7 0.000 #&gt; .wy8 0.000 #&gt; .wy9 0.000 #&gt; .wy10 0.000 #&gt; .wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 1.608 0.043 37.197 0.000 #&gt; .RIy 1.738 0.048 36.494 0.000 #&gt; wx1 0.318 0.015 21.885 0.000 #&gt; wy1 0.333 0.015 22.559 0.000 #&gt; .wx2 0.295 0.013 22.916 0.000 #&gt; .wy2 0.245 0.011 22.343 0.000 #&gt; .wx3 0.264 0.011 23.389 0.000 #&gt; .wy3 0.306 0.013 23.763 0.000 #&gt; .wx4 0.219 0.010 22.181 0.000 #&gt; .wy4 0.246 0.011 22.427 0.000 #&gt; .wx5 0.249 0.011 22.940 0.000 #&gt; .wy5 0.206 0.009 22.655 0.000 #&gt; .wx6 0.219 0.010 22.441 0.000 #&gt; .wy6 0.182 0.008 21.994 0.000 #&gt; .wx7 0.210 0.009 22.603 0.000 #&gt; .wy7 0.204 0.009 22.442 0.000 #&gt; .wx8 0.218 0.010 22.064 0.000 #&gt; .wy8 0.229 0.010 22.744 0.000 #&gt; .wx9 0.248 0.011 22.330 0.000 #&gt; .wy9 0.210 0.010 22.063 0.000 #&gt; .wx10 0.280 0.013 21.647 0.000 #&gt; .wy10 0.266 0.012 21.498 0.000 #&gt; .wx11 0.257 0.012 20.889 0.000 #&gt; .wy11 0.243 0.012 20.488 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 51 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 78 #&gt; Number of equality constraints 39 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1309 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 6298.286 #&gt; Degrees of freedom 280 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (e) 0.286 0.002 160.481 0.000 #&gt; RIy ~ #&gt; oply (e) 0.286 0.002 160.481 0.000 #&gt; wx2 ~ #&gt; wx1 (a) 0.121 0.008 14.959 0.000 #&gt; wy1 (b) 0.007 0.009 0.845 0.398 #&gt; wx3 ~ #&gt; wx2 (a) 0.121 0.008 14.959 0.000 #&gt; wy2 (b) 0.007 0.009 0.845 0.398 #&gt; wx4 ~ #&gt; wx3 (a) 0.121 0.008 14.959 0.000 #&gt; wy3 (b) 0.007 0.009 0.845 0.398 #&gt; wx5 ~ #&gt; wx4 (a) 0.121 0.008 14.959 0.000 #&gt; wy4 (b) 0.007 0.009 0.845 0.398 #&gt; wx6 ~ #&gt; wx5 (a) 0.121 0.008 14.959 0.000 #&gt; wy5 (b) 0.007 0.009 0.845 0.398 #&gt; wx7 ~ #&gt; wx6 (a) 0.121 0.008 14.959 0.000 #&gt; wy6 (b) 0.007 0.009 0.845 0.398 #&gt; wx8 ~ #&gt; wx7 (a) 0.121 0.008 14.959 0.000 #&gt; wy7 (b) 0.007 0.009 0.845 0.398 #&gt; wx9 ~ #&gt; wx8 (a) 0.121 0.008 14.959 0.000 #&gt; wy8 (b) 0.007 0.009 0.845 0.398 #&gt; wx10 ~ #&gt; wx9 (a) 0.121 0.008 14.959 0.000 #&gt; wy9 (b) 0.007 0.009 0.845 0.398 #&gt; wx11 ~ #&gt; wx10 (a) 0.121 0.008 14.959 0.000 #&gt; wy10 (b) 0.007 0.009 0.845 0.398 #&gt; wy2 ~ #&gt; wx1 (b) 0.007 0.009 0.845 0.398 #&gt; wy1 (a) 0.121 0.008 14.959 0.000 #&gt; wy3 ~ #&gt; wx2 (b) 0.007 0.009 0.845 0.398 #&gt; wy2 (a) 0.121 0.008 14.959 0.000 #&gt; wy4 ~ #&gt; wx3 (b) 0.007 0.009 0.845 0.398 #&gt; wy3 (a) 0.121 0.008 14.959 0.000 #&gt; wy5 ~ #&gt; wx4 (b) 0.007 0.009 0.845 0.398 #&gt; wy4 (a) 0.121 0.008 14.959 0.000 #&gt; wy6 ~ #&gt; wx5 (b) 0.007 0.009 0.845 0.398 #&gt; wy5 (a) 0.121 0.008 14.959 0.000 #&gt; wy7 ~ #&gt; wx6 (b) 0.007 0.009 0.845 0.398 #&gt; wy6 (a) 0.121 0.008 14.959 0.000 #&gt; wy8 ~ #&gt; wx7 (b) 0.007 0.009 0.845 0.398 #&gt; wy7 (a) 0.121 0.008 14.959 0.000 #&gt; wy9 ~ #&gt; wx8 (b) 0.007 0.009 0.845 0.398 #&gt; wy8 (a) 0.121 0.008 14.959 0.000 #&gt; wy10 ~ #&gt; wx9 (b) 0.007 0.009 0.845 0.398 #&gt; wy9 (a) 0.121 0.008 14.959 0.000 #&gt; wy11 ~ #&gt; wx10 (b) 0.007 0.009 0.845 0.398 #&gt; wy10 (a) 0.121 0.008 14.959 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.111 0.017 6.646 0.000 #&gt; .wx2 ~~ #&gt; .wy2 0.045 0.013 3.333 0.001 #&gt; .wx3 ~~ #&gt; .wy3 0.062 0.013 4.765 0.000 #&gt; .wx4 ~~ #&gt; .wy4 0.034 0.013 2.656 0.008 #&gt; .wx5 ~~ #&gt; .wy5 0.019 0.012 1.558 0.119 #&gt; .wx6 ~~ #&gt; .wy6 0.056 0.013 4.396 0.000 #&gt; .wx7 ~~ #&gt; .wy7 0.052 0.012 4.483 0.000 #&gt; .wx8 ~~ #&gt; .wy8 0.042 0.013 3.257 0.001 #&gt; .wx9 ~~ #&gt; .wy9 0.037 0.014 2.730 0.006 #&gt; .wx10 ~~ #&gt; .wy10 0.049 0.014 3.365 0.001 #&gt; .wx11 ~~ #&gt; .wy11 0.051 0.016 3.186 0.001 #&gt; .RIx ~~ #&gt; .RIy 0.999 0.036 27.380 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; .wx2 0.000 #&gt; .wx3 0.000 #&gt; .wx4 0.000 #&gt; .wx5 0.000 #&gt; .wx6 0.000 #&gt; .wx7 0.000 #&gt; .wx8 0.000 #&gt; .wx9 0.000 #&gt; .wx10 0.000 #&gt; .wx11 0.000 #&gt; wy1 0.000 #&gt; .wy2 0.000 #&gt; .wy3 0.000 #&gt; .wy4 0.000 #&gt; .wy5 0.000 #&gt; .wy6 0.000 #&gt; .wy7 0.000 #&gt; .wy8 0.000 #&gt; .wy9 0.000 #&gt; .wy10 0.000 #&gt; .wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 1.570 0.043 36.219 0.000 #&gt; .RIy 1.488 0.043 34.746 0.000 #&gt; wx1 0.513 0.023 22.698 0.000 #&gt; wy1 0.493 0.022 22.602 0.000 #&gt; .wx2 0.409 0.018 22.994 0.000 #&gt; .wy2 0.406 0.018 22.862 0.000 #&gt; .wx3 0.398 0.017 23.436 0.000 #&gt; .wy3 0.416 0.018 23.277 0.000 #&gt; .wx4 0.379 0.017 22.322 0.000 #&gt; .wy4 0.337 0.015 21.761 0.000 #&gt; .wx5 0.348 0.015 22.775 0.000 #&gt; .wy5 0.359 0.016 22.819 0.000 #&gt; .wx6 0.383 0.017 23.183 0.000 #&gt; .wy6 0.369 0.016 22.899 0.000 #&gt; .wx7 0.365 0.016 22.978 0.000 #&gt; .wy7 0.312 0.014 22.275 0.000 #&gt; .wx8 0.362 0.016 22.679 0.000 #&gt; .wy8 0.395 0.017 22.813 0.000 #&gt; .wx9 0.390 0.017 22.479 0.000 #&gt; .wy9 0.390 0.017 22.308 0.000 #&gt; .wx10 0.377 0.018 21.329 0.000 #&gt; .wy10 0.400 0.019 21.140 0.000 #&gt; .wx11 0.454 0.021 21.540 0.000 #&gt; .wy11 0.385 0.019 20.250 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 3.8.3 SC-RI-CLPM SCCLPM &lt;- &#39; # Create between components RIx =~ 1*x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 RIy =~ 1*y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9 + y10 + y11 RIx ~ e*oplx RIy ~ e*oply # Create within-person centered variables wx1 =~ 1*x1 wx2 =~ 1*x2 wx3 =~ 1*x3 wx4 =~ 1*x4 wx5 =~ 1*x5 wx6 =~ 1*x6 wx7 =~ 1*x7 wx8 =~ 1*x8 wx9 =~ 1*x9 wx10 =~ 1*x10 wx11 =~ 1*x11 wy1 =~ 1*y1 wy2 =~ 1*y2 wy3 =~ 1*y3 wy4 =~ 1*y4 wy5 =~ 1*y5 wy6 =~ 1*y6 wy7 =~ 1*y7 wy8 =~ 1*y8 wy9 =~ 1*y9 wy10 =~ 1*y10 wy11 =~ 1*y11 # Estimate the lagged effects between the within-person centered variables. wx2 ~ a*wx1 + b*wy1 wx3 ~ a*wx2 + b*wy2 wx4 ~ a*wx3 + b*wy3 wx5 ~ a*wx4 + b*wy4 wx6 ~ a*wx5 + b*wy5 wx7 ~ a*wx6 + b*wy6 wx8 ~ a*wx7 + b*wy7 wx9 ~ a*wx8 + b*wy8 wx10 ~ a*wx9 + b*wy9 wx11 ~ a*wx10 + b*wy10 wy2 ~ b*wx1 + a*wy1 wy3 ~ b*wx2 + a*wy2 wy4 ~ b*wx3 + a*wy3 wy5 ~ b*wx4 + a*wy4 wy6 ~ b*wx5 + a*wy5 wy7 ~ b*wx6 + a*wy6 wy8 ~ b*wx7 + a*wy7 wy9 ~ b*wx8 + a*wy8 wy10 ~ b*wx9 + a*wy9 wy11 ~ b*wx10 + a*wy10 # Estimate the (residual) covariance between the within-person centered variables wx1 ~~ wy1 # Covariance wx2 ~~ wy2 wx3 ~~ wy3 wx4 ~~ wy4 wx5 ~~ wy5 wx6 ~~ wy6 wx7 ~~ wy7 wx8 ~~ wy8 wx9 ~~ wy9 wx10 ~~ wy10 wx11 ~~ wy11 # Estimate the variance and covariance of the random intercepts. RIx ~~ RIx RIy ~~ RIy RIx ~~ RIy # Estimate the (residual) variance of the within-person centered variables. wx1 ~~ wx1 # Variances wy1 ~~ wy1 wx2 ~~ wx2 # Residual variances wy2 ~~ wy2 wx3 ~~ wx3 wy3 ~~ wy3 wx4 ~~ wx4 wy4 ~~ wy4 wx5 ~~ wx5 wy5 ~~ wy5 wx6 ~~ wx6 wy6 ~~ wy6 wx7 ~~ wx7 wy7 ~~ wy7 wx8 ~~ wx8 wy8 ~~ wy8 wx9 ~~ wx9 wy9 ~~ wy9 wx10 ~~ wx10 wy10 ~~ wy10 wx11 ~~ wx11 wy11 ~~ wy11 &#39; #Estimate models a bit faster: estimate &lt;- function(x) lavaan(SCCLPM, data=x, missing = &quot;fiml.x&quot;, meanstructure = T ) library(future.apply) plan(multisession) results_temp &lt;- future_lapply(datalist_ori, estimate) results[[9]] &lt;- results_temp[[1]] results[[10]] &lt;- results_temp[[2]] results[[11]] &lt;- results_temp[[3]] results[[12]] &lt;- results_temp[[4]] names(results)[9:12] &lt;- c(&quot;fitm3h1y1&quot;, &quot;fitm3h1y2&quot;,&quot;fitm3h1y3&quot;,&quot;fitm3h1y4&quot;) load(&quot;addfiles/results.Rdata&quot;) summary(results[[9]]) summary(results[[10]]) summary(results[[11]]) summary(results[[12]]) #&gt; lavaan 0.6-7 ended normally after 51 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 98 #&gt; Number of equality constraints 39 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1415 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 1184.580 #&gt; Degrees of freedom 260 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.032 0.015 70.760 0.000 #&gt; x3 1.046 0.015 68.405 0.000 #&gt; x4 0.917 0.015 59.630 0.000 #&gt; x5 1.028 0.017 60.851 0.000 #&gt; x6 0.936 0.015 61.616 0.000 #&gt; x7 0.876 0.014 60.474 0.000 #&gt; x8 0.919 0.015 60.197 0.000 #&gt; x9 0.871 0.016 56.165 0.000 #&gt; x10 0.944 0.016 58.963 0.000 #&gt; x11 0.996 0.017 58.689 0.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.045 0.015 69.564 0.000 #&gt; y3 1.059 0.016 66.061 0.000 #&gt; y4 0.908 0.016 57.240 0.000 #&gt; y5 0.919 0.016 56.258 0.000 #&gt; y6 0.908 0.015 58.915 0.000 #&gt; y7 0.863 0.015 57.729 0.000 #&gt; y8 0.895 0.016 56.765 0.000 #&gt; y9 0.899 0.016 55.775 0.000 #&gt; y10 0.975 0.017 58.061 0.000 #&gt; y11 1.022 0.018 57.752 0.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (e) 0.127 0.002 79.687 0.000 #&gt; RIy ~ #&gt; oply (e) 0.127 0.002 79.687 0.000 #&gt; wx2 ~ #&gt; wx1 (a) 0.203 0.008 24.247 0.000 #&gt; wy1 (b) 0.071 0.009 8.002 0.000 #&gt; wx3 ~ #&gt; wx2 (a) 0.203 0.008 24.247 0.000 #&gt; wy2 (b) 0.071 0.009 8.002 0.000 #&gt; wx4 ~ #&gt; wx3 (a) 0.203 0.008 24.247 0.000 #&gt; wy3 (b) 0.071 0.009 8.002 0.000 #&gt; wx5 ~ #&gt; wx4 (a) 0.203 0.008 24.247 0.000 #&gt; wy4 (b) 0.071 0.009 8.002 0.000 #&gt; wx6 ~ #&gt; wx5 (a) 0.203 0.008 24.247 0.000 #&gt; wy5 (b) 0.071 0.009 8.002 0.000 #&gt; wx7 ~ #&gt; wx6 (a) 0.203 0.008 24.247 0.000 #&gt; wy6 (b) 0.071 0.009 8.002 0.000 #&gt; wx8 ~ #&gt; wx7 (a) 0.203 0.008 24.247 0.000 #&gt; wy7 (b) 0.071 0.009 8.002 0.000 #&gt; wx9 ~ #&gt; wx8 (a) 0.203 0.008 24.247 0.000 #&gt; wy8 (b) 0.071 0.009 8.002 0.000 #&gt; wx10 ~ #&gt; wx9 (a) 0.203 0.008 24.247 0.000 #&gt; wy9 (b) 0.071 0.009 8.002 0.000 #&gt; wx11 ~ #&gt; wx10 (a) 0.203 0.008 24.247 0.000 #&gt; wy10 (b) 0.071 0.009 8.002 0.000 #&gt; wy2 ~ #&gt; wx1 (b) 0.071 0.009 8.002 0.000 #&gt; wy1 (a) 0.203 0.008 24.247 0.000 #&gt; wy3 ~ #&gt; wx2 (b) 0.071 0.009 8.002 0.000 #&gt; wy2 (a) 0.203 0.008 24.247 0.000 #&gt; wy4 ~ #&gt; wx3 (b) 0.071 0.009 8.002 0.000 #&gt; wy3 (a) 0.203 0.008 24.247 0.000 #&gt; wy5 ~ #&gt; wx4 (b) 0.071 0.009 8.002 0.000 #&gt; wy4 (a) 0.203 0.008 24.247 0.000 #&gt; wy6 ~ #&gt; wx5 (b) 0.071 0.009 8.002 0.000 #&gt; wy5 (a) 0.203 0.008 24.247 0.000 #&gt; wy7 ~ #&gt; wx6 (b) 0.071 0.009 8.002 0.000 #&gt; wy6 (a) 0.203 0.008 24.247 0.000 #&gt; wy8 ~ #&gt; wx7 (b) 0.071 0.009 8.002 0.000 #&gt; wy7 (a) 0.203 0.008 24.247 0.000 #&gt; wy9 ~ #&gt; wx8 (b) 0.071 0.009 8.002 0.000 #&gt; wy8 (a) 0.203 0.008 24.247 0.000 #&gt; wy10 ~ #&gt; wx9 (b) 0.071 0.009 8.002 0.000 #&gt; wy9 (a) 0.203 0.008 24.247 0.000 #&gt; wy11 ~ #&gt; wx10 (b) 0.071 0.009 8.002 0.000 #&gt; wy10 (a) 0.203 0.008 24.247 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.105 0.022 4.761 0.000 #&gt; .wx2 ~~ #&gt; .wy2 0.090 0.020 4.528 0.000 #&gt; .wx3 ~~ #&gt; .wy3 0.088 0.018 4.821 0.000 #&gt; .wx4 ~~ #&gt; .wy4 0.103 0.018 5.617 0.000 #&gt; .wx5 ~~ #&gt; .wy5 0.103 0.021 4.820 0.000 #&gt; .wx6 ~~ #&gt; .wy6 0.072 0.017 4.327 0.000 #&gt; .wx7 ~~ #&gt; .wy7 0.087 0.015 5.705 0.000 #&gt; .wx8 ~~ #&gt; .wy8 0.082 0.018 4.524 0.000 #&gt; .wx9 ~~ #&gt; .wy9 0.098 0.019 5.111 0.000 #&gt; .wx10 ~~ #&gt; .wy10 0.038 0.020 1.893 0.058 #&gt; .wx11 ~~ #&gt; .wy11 0.088 0.020 4.313 0.000 #&gt; .RIx ~~ #&gt; .RIy 0.376 0.019 19.861 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; .wx2 0.000 #&gt; .wx3 0.000 #&gt; .wx4 0.000 #&gt; .wx5 0.000 #&gt; .wx6 0.000 #&gt; .wx7 0.000 #&gt; .wx8 0.000 #&gt; .wx9 0.000 #&gt; .wx10 0.000 #&gt; .wx11 0.000 #&gt; wy1 0.000 #&gt; .wy2 0.000 #&gt; .wy3 0.000 #&gt; .wy4 0.000 #&gt; .wy5 0.000 #&gt; .wy6 0.000 #&gt; .wy7 0.000 #&gt; .wy8 0.000 #&gt; .wy9 0.000 #&gt; .wy10 0.000 #&gt; .wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 0.806 0.031 26.229 0.000 #&gt; .RIy 0.520 0.021 24.305 0.000 #&gt; wx1 0.696 0.031 22.335 0.000 #&gt; wy1 0.601 0.027 21.922 0.000 #&gt; .wx2 0.681 0.029 23.590 0.000 #&gt; .wy2 0.555 0.024 22.682 0.000 #&gt; .wx3 0.575 0.025 22.989 0.000 #&gt; .wy3 0.491 0.022 22.059 0.000 #&gt; .wx4 0.605 0.026 23.151 0.000 #&gt; .wy4 0.488 0.022 22.431 0.000 #&gt; .wx5 0.711 0.031 23.224 0.000 #&gt; .wy5 0.573 0.024 23.432 0.000 #&gt; .wx6 0.520 0.022 23.228 0.000 #&gt; .wy6 0.438 0.019 22.472 0.000 #&gt; .wx7 0.489 0.021 23.403 0.000 #&gt; .wy7 0.441 0.019 23.043 0.000 #&gt; .wx8 0.553 0.024 23.131 0.000 #&gt; .wy8 0.508 0.022 23.022 0.000 #&gt; .wx9 0.604 0.026 23.489 0.000 #&gt; .wy9 0.516 0.023 22.406 0.000 #&gt; .wx10 0.564 0.026 21.577 0.000 #&gt; .wy10 0.502 0.024 20.981 0.000 #&gt; .wx11 0.597 0.028 21.051 0.000 #&gt; .wy11 0.495 0.025 20.035 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 44 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 98 #&gt; Number of equality constraints 39 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1230 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 745.392 #&gt; Degrees of freedom 260 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 0.014 70.278 0.000 #&gt; x3 1.005 0.015 69.049 0.000 #&gt; x4 1.008 0.015 67.174 0.000 #&gt; x5 1.018 0.015 68.283 0.000 #&gt; x6 1.003 0.015 65.205 0.000 #&gt; x7 1.018 0.015 66.017 0.000 #&gt; x8 0.977 0.015 65.373 0.000 #&gt; x9 0.952 0.016 61.324 0.000 #&gt; x10 1.015 0.016 62.772 0.000 #&gt; x11 0.991 0.016 61.377 0.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.040 0.015 69.260 0.000 #&gt; y3 1.072 0.015 71.615 0.000 #&gt; y4 1.071 0.016 67.625 0.000 #&gt; y5 1.077 0.016 68.626 0.000 #&gt; y6 1.069 0.016 68.829 0.000 #&gt; y7 1.069 0.016 67.652 0.000 #&gt; y8 1.032 0.016 65.732 0.000 #&gt; y9 1.020 0.016 61.914 0.000 #&gt; y10 1.054 0.017 63.867 0.000 #&gt; y11 1.062 0.017 63.216 0.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (e) 0.102 0.001 80.150 0.000 #&gt; RIy ~ #&gt; oply (e) 0.102 0.001 80.150 0.000 #&gt; wx2 ~ #&gt; wx1 (a) 0.101 0.008 12.700 0.000 #&gt; wy1 (b) 0.028 0.008 3.362 0.001 #&gt; wx3 ~ #&gt; wx2 (a) 0.101 0.008 12.700 0.000 #&gt; wy2 (b) 0.028 0.008 3.362 0.001 #&gt; wx4 ~ #&gt; wx3 (a) 0.101 0.008 12.700 0.000 #&gt; wy3 (b) 0.028 0.008 3.362 0.001 #&gt; wx5 ~ #&gt; wx4 (a) 0.101 0.008 12.700 0.000 #&gt; wy4 (b) 0.028 0.008 3.362 0.001 #&gt; wx6 ~ #&gt; wx5 (a) 0.101 0.008 12.700 0.000 #&gt; wy5 (b) 0.028 0.008 3.362 0.001 #&gt; wx7 ~ #&gt; wx6 (a) 0.101 0.008 12.700 0.000 #&gt; wy6 (b) 0.028 0.008 3.362 0.001 #&gt; wx8 ~ #&gt; wx7 (a) 0.101 0.008 12.700 0.000 #&gt; wy7 (b) 0.028 0.008 3.362 0.001 #&gt; wx9 ~ #&gt; wx8 (a) 0.101 0.008 12.700 0.000 #&gt; wy8 (b) 0.028 0.008 3.362 0.001 #&gt; wx10 ~ #&gt; wx9 (a) 0.101 0.008 12.700 0.000 #&gt; wy9 (b) 0.028 0.008 3.362 0.001 #&gt; wx11 ~ #&gt; wx10 (a) 0.101 0.008 12.700 0.000 #&gt; wy10 (b) 0.028 0.008 3.362 0.001 #&gt; wy2 ~ #&gt; wx1 (b) 0.028 0.008 3.362 0.001 #&gt; wy1 (a) 0.101 0.008 12.700 0.000 #&gt; wy3 ~ #&gt; wx2 (b) 0.028 0.008 3.362 0.001 #&gt; wy2 (a) 0.101 0.008 12.700 0.000 #&gt; wy4 ~ #&gt; wx3 (b) 0.028 0.008 3.362 0.001 #&gt; wy3 (a) 0.101 0.008 12.700 0.000 #&gt; wy5 ~ #&gt; wx4 (b) 0.028 0.008 3.362 0.001 #&gt; wy4 (a) 0.101 0.008 12.700 0.000 #&gt; wy6 ~ #&gt; wx5 (b) 0.028 0.008 3.362 0.001 #&gt; wy5 (a) 0.101 0.008 12.700 0.000 #&gt; wy7 ~ #&gt; wx6 (b) 0.028 0.008 3.362 0.001 #&gt; wy6 (a) 0.101 0.008 12.700 0.000 #&gt; wy8 ~ #&gt; wx7 (b) 0.028 0.008 3.362 0.001 #&gt; wy7 (a) 0.101 0.008 12.700 0.000 #&gt; wy9 ~ #&gt; wx8 (b) 0.028 0.008 3.362 0.001 #&gt; wy8 (a) 0.101 0.008 12.700 0.000 #&gt; wy10 ~ #&gt; wx9 (b) 0.028 0.008 3.362 0.001 #&gt; wy9 (a) 0.101 0.008 12.700 0.000 #&gt; wy11 ~ #&gt; wx10 (b) 0.028 0.008 3.362 0.001 #&gt; wy10 (a) 0.101 0.008 12.700 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.050 0.013 3.930 0.000 #&gt; .wx2 ~~ #&gt; .wy2 0.047 0.013 3.703 0.000 #&gt; .wx3 ~~ #&gt; .wy3 0.030 0.011 2.673 0.008 #&gt; .wx4 ~~ #&gt; .wy4 0.043 0.011 3.898 0.000 #&gt; .wx5 ~~ #&gt; .wy5 0.043 0.011 3.948 0.000 #&gt; .wx6 ~~ #&gt; .wy6 0.026 0.011 2.376 0.017 #&gt; .wx7 ~~ #&gt; .wy7 0.032 0.011 2.881 0.004 #&gt; .wx8 ~~ #&gt; .wy8 0.030 0.011 2.717 0.007 #&gt; .wx9 ~~ #&gt; .wy9 0.010 0.013 0.761 0.447 #&gt; .wx10 ~~ #&gt; .wy10 0.045 0.013 3.478 0.001 #&gt; .wx11 ~~ #&gt; .wy11 0.062 0.013 4.871 0.000 #&gt; .RIx ~~ #&gt; .RIy 0.297 0.013 22.520 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; .wx2 0.000 #&gt; .wx3 0.000 #&gt; .wx4 0.000 #&gt; .wx5 0.000 #&gt; .wx6 0.000 #&gt; .wx7 0.000 #&gt; .wx8 0.000 #&gt; .wx9 0.000 #&gt; .wx10 0.000 #&gt; .wx11 0.000 #&gt; wy1 0.000 #&gt; .wy2 0.000 #&gt; .wy3 0.000 #&gt; .wy4 0.000 #&gt; .wy5 0.000 #&gt; .wy6 0.000 #&gt; .wy7 0.000 #&gt; .wy8 0.000 #&gt; .wy9 0.000 #&gt; .wy10 0.000 #&gt; .wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 0.535 0.019 27.861 0.000 #&gt; .RIy 0.451 0.017 27.154 0.000 #&gt; wx1 0.448 0.019 23.890 0.000 #&gt; wy1 0.387 0.017 23.322 0.000 #&gt; .wx2 0.407 0.017 23.992 0.000 #&gt; .wy2 0.428 0.017 24.549 0.000 #&gt; .wx3 0.352 0.015 23.687 0.000 #&gt; .wy3 0.315 0.014 23.088 0.000 #&gt; .wx4 0.326 0.014 22.627 0.000 #&gt; .wy4 0.325 0.014 22.443 0.000 #&gt; .wx5 0.327 0.014 23.360 0.000 #&gt; .wy5 0.333 0.014 23.306 0.000 #&gt; .wx6 0.355 0.015 23.631 0.000 #&gt; .wy6 0.306 0.013 23.113 0.000 #&gt; .wx7 0.349 0.015 23.310 0.000 #&gt; .wy7 0.330 0.014 23.423 0.000 #&gt; .wx8 0.328 0.014 23.096 0.000 #&gt; .wy8 0.333 0.014 23.284 0.000 #&gt; .wx9 0.374 0.016 23.256 0.000 #&gt; .wy9 0.377 0.016 22.894 0.000 #&gt; .wx10 0.370 0.017 21.778 0.000 #&gt; .wy10 0.343 0.016 21.456 0.000 #&gt; .wx11 0.365 0.017 21.452 0.000 #&gt; .wy11 0.326 0.016 20.501 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 94 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 98 #&gt; Number of equality constraints 39 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1290 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 5754.776 #&gt; Degrees of freedom 260 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 0.995 0.004 241.929 0.000 #&gt; x3 0.993 0.004 232.141 0.000 #&gt; x4 1.001 0.004 231.154 0.000 #&gt; x5 1.003 0.004 227.019 0.000 #&gt; x6 1.008 0.004 231.190 0.000 #&gt; x7 1.013 0.004 233.021 0.000 #&gt; x8 1.016 0.004 228.624 0.000 #&gt; x9 1.008 0.005 218.153 0.000 #&gt; x10 1.004 0.005 208.323 0.000 #&gt; x11 1.014 0.005 208.580 0.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.015 0.004 251.843 0.000 #&gt; y3 1.011 0.005 221.550 0.000 #&gt; y4 1.023 0.005 224.154 0.000 #&gt; y5 1.028 0.004 234.838 0.000 #&gt; y6 1.030 0.004 237.318 0.000 #&gt; y7 1.033 0.004 232.516 0.000 #&gt; y8 1.035 0.005 224.870 0.000 #&gt; y9 1.028 0.005 224.226 0.000 #&gt; y10 1.024 0.005 208.550 0.000 #&gt; y11 1.034 0.005 208.052 0.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (e) 0.330 0.002 168.741 0.000 #&gt; RIy ~ #&gt; oply (e) 0.330 0.002 168.741 0.000 #&gt; wx2 ~ #&gt; wx1 (a) 0.112 0.008 14.014 0.000 #&gt; wy1 (b) 0.037 0.008 4.430 0.000 #&gt; wx3 ~ #&gt; wx2 (a) 0.112 0.008 14.014 0.000 #&gt; wy2 (b) 0.037 0.008 4.430 0.000 #&gt; wx4 ~ #&gt; wx3 (a) 0.112 0.008 14.014 0.000 #&gt; wy3 (b) 0.037 0.008 4.430 0.000 #&gt; wx5 ~ #&gt; wx4 (a) 0.112 0.008 14.014 0.000 #&gt; wy4 (b) 0.037 0.008 4.430 0.000 #&gt; wx6 ~ #&gt; wx5 (a) 0.112 0.008 14.014 0.000 #&gt; wy5 (b) 0.037 0.008 4.430 0.000 #&gt; wx7 ~ #&gt; wx6 (a) 0.112 0.008 14.014 0.000 #&gt; wy6 (b) 0.037 0.008 4.430 0.000 #&gt; wx8 ~ #&gt; wx7 (a) 0.112 0.008 14.014 0.000 #&gt; wy7 (b) 0.037 0.008 4.430 0.000 #&gt; wx9 ~ #&gt; wx8 (a) 0.112 0.008 14.014 0.000 #&gt; wy8 (b) 0.037 0.008 4.430 0.000 #&gt; wx10 ~ #&gt; wx9 (a) 0.112 0.008 14.014 0.000 #&gt; wy9 (b) 0.037 0.008 4.430 0.000 #&gt; wx11 ~ #&gt; wx10 (a) 0.112 0.008 14.014 0.000 #&gt; wy10 (b) 0.037 0.008 4.430 0.000 #&gt; wy2 ~ #&gt; wx1 (b) 0.037 0.008 4.430 0.000 #&gt; wy1 (a) 0.112 0.008 14.014 0.000 #&gt; wy3 ~ #&gt; wx2 (b) 0.037 0.008 4.430 0.000 #&gt; wy2 (a) 0.112 0.008 14.014 0.000 #&gt; wy4 ~ #&gt; wx3 (b) 0.037 0.008 4.430 0.000 #&gt; wy3 (a) 0.112 0.008 14.014 0.000 #&gt; wy5 ~ #&gt; wx4 (b) 0.037 0.008 4.430 0.000 #&gt; wy4 (a) 0.112 0.008 14.014 0.000 #&gt; wy6 ~ #&gt; wx5 (b) 0.037 0.008 4.430 0.000 #&gt; wy5 (a) 0.112 0.008 14.014 0.000 #&gt; wy7 ~ #&gt; wx6 (b) 0.037 0.008 4.430 0.000 #&gt; wy6 (a) 0.112 0.008 14.014 0.000 #&gt; wy8 ~ #&gt; wx7 (b) 0.037 0.008 4.430 0.000 #&gt; wy7 (a) 0.112 0.008 14.014 0.000 #&gt; wy9 ~ #&gt; wx8 (b) 0.037 0.008 4.430 0.000 #&gt; wy8 (a) 0.112 0.008 14.014 0.000 #&gt; wy10 ~ #&gt; wx9 (b) 0.037 0.008 4.430 0.000 #&gt; wy9 (a) 0.112 0.008 14.014 0.000 #&gt; wy11 ~ #&gt; wx10 (b) 0.037 0.008 4.430 0.000 #&gt; wy10 (a) 0.112 0.008 14.014 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.063 0.011 5.802 0.000 #&gt; .wx2 ~~ #&gt; .wy2 0.035 0.009 3.985 0.000 #&gt; .wx3 ~~ #&gt; .wy3 0.066 0.009 7.321 0.000 #&gt; .wx4 ~~ #&gt; .wy4 0.029 0.008 3.610 0.000 #&gt; .wx5 ~~ #&gt; .wy5 0.040 0.008 5.149 0.000 #&gt; .wx6 ~~ #&gt; .wy6 0.035 0.007 5.062 0.000 #&gt; .wx7 ~~ #&gt; .wy7 0.032 0.007 4.544 0.000 #&gt; .wx8 ~~ #&gt; .wy8 0.024 0.008 3.085 0.002 #&gt; .wx9 ~~ #&gt; .wy9 0.034 0.008 4.193 0.000 #&gt; .wx10 ~~ #&gt; .wy10 0.062 0.010 6.033 0.000 #&gt; .wx11 ~~ #&gt; .wy11 0.066 0.009 6.958 0.000 #&gt; .RIx ~~ #&gt; .RIy 1.057 0.038 27.498 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; .wx2 0.000 #&gt; .wx3 0.000 #&gt; .wx4 0.000 #&gt; .wx5 0.000 #&gt; .wx6 0.000 #&gt; .wx7 0.000 #&gt; .wx8 0.000 #&gt; .wx9 0.000 #&gt; .wx10 0.000 #&gt; .wx11 0.000 #&gt; wy1 0.000 #&gt; .wy2 0.000 #&gt; .wy3 0.000 #&gt; .wy4 0.000 #&gt; .wy5 0.000 #&gt; .wy6 0.000 #&gt; .wy7 0.000 #&gt; .wy8 0.000 #&gt; .wy9 0.000 #&gt; .wy10 0.000 #&gt; .wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 1.603 0.044 36.255 0.000 #&gt; .RIy 1.651 0.046 35.668 0.000 #&gt; wx1 0.316 0.014 21.886 0.000 #&gt; wy1 0.332 0.015 22.517 0.000 #&gt; .wx2 0.294 0.013 22.946 0.000 #&gt; .wy2 0.244 0.011 22.349 0.000 #&gt; .wx3 0.262 0.011 23.429 0.000 #&gt; .wy3 0.304 0.013 23.807 0.000 #&gt; .wx4 0.219 0.010 22.197 0.000 #&gt; .wy4 0.245 0.011 22.431 0.000 #&gt; .wx5 0.249 0.011 22.961 0.000 #&gt; .wy5 0.204 0.009 22.632 0.000 #&gt; .wx6 0.219 0.010 22.422 0.000 #&gt; .wy6 0.180 0.008 21.944 0.000 #&gt; .wx7 0.209 0.009 22.518 0.000 #&gt; .wy7 0.202 0.009 22.378 0.000 #&gt; .wx8 0.215 0.010 21.933 0.000 #&gt; .wy8 0.226 0.010 22.647 0.000 #&gt; .wx9 0.248 0.011 22.337 0.000 #&gt; .wy9 0.210 0.010 22.065 0.000 #&gt; .wx10 0.279 0.013 21.674 0.000 #&gt; .wy10 0.266 0.012 21.520 0.000 #&gt; .wx11 0.255 0.012 20.788 0.000 #&gt; .wy11 0.240 0.012 20.376 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 67 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 98 #&gt; Number of equality constraints 39 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1309 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 6116.744 #&gt; Degrees of freedom 260 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 0.991 0.006 172.616 0.000 #&gt; x3 0.989 0.006 162.821 0.000 #&gt; x4 0.989 0.006 157.453 0.000 #&gt; x5 1.016 0.006 164.159 0.000 #&gt; x6 0.988 0.006 157.004 0.000 #&gt; x7 0.992 0.006 158.043 0.000 #&gt; x8 1.003 0.006 157.073 0.000 #&gt; x9 1.012 0.007 152.846 0.000 #&gt; x10 1.013 0.007 151.056 0.000 #&gt; x11 1.024 0.007 142.513 0.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.041 0.006 175.131 0.000 #&gt; y3 1.031 0.006 160.421 0.000 #&gt; y4 1.041 0.006 162.313 0.000 #&gt; y5 1.056 0.006 163.112 0.000 #&gt; y6 1.035 0.007 158.293 0.000 #&gt; y7 1.030 0.006 162.578 0.000 #&gt; y8 1.040 0.007 154.358 0.000 #&gt; y9 1.039 0.007 151.676 0.000 #&gt; y10 1.033 0.007 147.337 0.000 #&gt; y11 1.036 0.007 144.519 0.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (e) 0.281 0.002 142.213 0.000 #&gt; RIy ~ #&gt; oply (e) 0.281 0.002 142.213 0.000 #&gt; wx2 ~ #&gt; wx1 (a) 0.119 0.008 14.812 0.000 #&gt; wy1 (b) 0.009 0.009 1.067 0.286 #&gt; wx3 ~ #&gt; wx2 (a) 0.119 0.008 14.812 0.000 #&gt; wy2 (b) 0.009 0.009 1.067 0.286 #&gt; wx4 ~ #&gt; wx3 (a) 0.119 0.008 14.812 0.000 #&gt; wy3 (b) 0.009 0.009 1.067 0.286 #&gt; wx5 ~ #&gt; wx4 (a) 0.119 0.008 14.812 0.000 #&gt; wy4 (b) 0.009 0.009 1.067 0.286 #&gt; wx6 ~ #&gt; wx5 (a) 0.119 0.008 14.812 0.000 #&gt; wy5 (b) 0.009 0.009 1.067 0.286 #&gt; wx7 ~ #&gt; wx6 (a) 0.119 0.008 14.812 0.000 #&gt; wy6 (b) 0.009 0.009 1.067 0.286 #&gt; wx8 ~ #&gt; wx7 (a) 0.119 0.008 14.812 0.000 #&gt; wy7 (b) 0.009 0.009 1.067 0.286 #&gt; wx9 ~ #&gt; wx8 (a) 0.119 0.008 14.812 0.000 #&gt; wy8 (b) 0.009 0.009 1.067 0.286 #&gt; wx10 ~ #&gt; wx9 (a) 0.119 0.008 14.812 0.000 #&gt; wy9 (b) 0.009 0.009 1.067 0.286 #&gt; wx11 ~ #&gt; wx10 (a) 0.119 0.008 14.812 0.000 #&gt; wy10 (b) 0.009 0.009 1.067 0.286 #&gt; wy2 ~ #&gt; wx1 (b) 0.009 0.009 1.067 0.286 #&gt; wy1 (a) 0.119 0.008 14.812 0.000 #&gt; wy3 ~ #&gt; wx2 (b) 0.009 0.009 1.067 0.286 #&gt; wy2 (a) 0.119 0.008 14.812 0.000 #&gt; wy4 ~ #&gt; wx3 (b) 0.009 0.009 1.067 0.286 #&gt; wy3 (a) 0.119 0.008 14.812 0.000 #&gt; wy5 ~ #&gt; wx4 (b) 0.009 0.009 1.067 0.286 #&gt; wy4 (a) 0.119 0.008 14.812 0.000 #&gt; wy6 ~ #&gt; wx5 (b) 0.009 0.009 1.067 0.286 #&gt; wy5 (a) 0.119 0.008 14.812 0.000 #&gt; wy7 ~ #&gt; wx6 (b) 0.009 0.009 1.067 0.286 #&gt; wy6 (a) 0.119 0.008 14.812 0.000 #&gt; wy8 ~ #&gt; wx7 (b) 0.009 0.009 1.067 0.286 #&gt; wy7 (a) 0.119 0.008 14.812 0.000 #&gt; wy9 ~ #&gt; wx8 (b) 0.009 0.009 1.067 0.286 #&gt; wy8 (a) 0.119 0.008 14.812 0.000 #&gt; wy10 ~ #&gt; wx9 (b) 0.009 0.009 1.067 0.286 #&gt; wy9 (a) 0.119 0.008 14.812 0.000 #&gt; wy11 ~ #&gt; wx10 (b) 0.009 0.009 1.067 0.286 #&gt; wy10 (a) 0.119 0.008 14.812 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.099 0.017 5.902 0.000 #&gt; .wx2 ~~ #&gt; .wy2 0.047 0.013 3.526 0.000 #&gt; .wx3 ~~ #&gt; .wy3 0.063 0.013 4.792 0.000 #&gt; .wx4 ~~ #&gt; .wy4 0.037 0.013 2.841 0.005 #&gt; .wx5 ~~ #&gt; .wy5 0.009 0.012 0.756 0.450 #&gt; .wx6 ~~ #&gt; .wy6 0.057 0.013 4.538 0.000 #&gt; .wx7 ~~ #&gt; .wy7 0.053 0.012 4.517 0.000 #&gt; .wx8 ~~ #&gt; .wy8 0.042 0.013 3.259 0.001 #&gt; .wx9 ~~ #&gt; .wy9 0.037 0.014 2.714 0.007 #&gt; .wx10 ~~ #&gt; .wy10 0.050 0.014 3.474 0.001 #&gt; .wx11 ~~ #&gt; .wy11 0.048 0.016 3.034 0.002 #&gt; .RIx ~~ #&gt; .RIy 0.979 0.036 27.320 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; .wx2 0.000 #&gt; .wx3 0.000 #&gt; .wx4 0.000 #&gt; .wx5 0.000 #&gt; .wx6 0.000 #&gt; .wx7 0.000 #&gt; .wx8 0.000 #&gt; .wx9 0.000 #&gt; .wx10 0.000 #&gt; .wx11 0.000 #&gt; wy1 0.000 #&gt; .wy2 0.000 #&gt; .wy3 0.000 #&gt; .wy4 0.000 #&gt; .wy5 0.000 #&gt; .wy6 0.000 #&gt; .wy7 0.000 #&gt; .wy8 0.000 #&gt; .wy9 0.000 #&gt; .wy10 0.000 #&gt; .wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 1.575 0.045 34.743 0.000 #&gt; .RIy 1.372 0.041 33.292 0.000 #&gt; wx1 0.511 0.023 22.541 0.000 #&gt; wy1 0.511 0.023 22.456 0.000 #&gt; .wx2 0.410 0.018 23.033 0.000 #&gt; .wy2 0.398 0.017 22.725 0.000 #&gt; .wx3 0.398 0.017 23.489 0.000 #&gt; .wy3 0.417 0.018 23.305 0.000 #&gt; .wx4 0.379 0.017 22.390 0.000 #&gt; .wy4 0.335 0.015 21.696 0.000 #&gt; .wx5 0.341 0.015 22.554 0.000 #&gt; .wy5 0.348 0.015 22.574 0.000 #&gt; .wx6 0.381 0.016 23.268 0.000 #&gt; .wy6 0.371 0.016 22.940 0.000 #&gt; .wx7 0.364 0.016 23.035 0.000 #&gt; .wy7 0.313 0.014 22.330 0.000 #&gt; .wx8 0.361 0.016 22.670 0.000 #&gt; .wy8 0.394 0.017 22.772 0.000 #&gt; .wx9 0.387 0.017 22.395 0.000 #&gt; .wy9 0.389 0.017 22.283 0.000 #&gt; .wx10 0.375 0.018 21.249 0.000 #&gt; .wy10 0.400 0.019 21.157 0.000 #&gt; .wx11 0.443 0.021 21.352 0.000 #&gt; .wy11 0.384 0.019 20.226 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 3.8.4 LT-RI-CLPM LTRICLPM &lt;- &#39; # Create between components (random intercepts) RIx =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 + 1*x5 + 1*x6 + 1*x7 + 1*x8 + 1*x9 + 1*x10 + 1*x11 RIy =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 + 1*y5 + 1*y6 + 1*y7 + 1*y8 + 1*y9 + 1*y10 + 1*y11 RIx ~ e*oplx RIy ~ e*oply #Random slopes RIsx =~ 1*x1 + 2*x2 + 3*x3 + 4*x4 + 5*x5 + 6*x6 + 7*x7 + 8*x8 + 9*x9 + 10*x10 + 11*x11 RIsy =~ 1*y1 + 2*y2 + 3*y3 + 4*y4 + 5*y5 + 6*y6 + 7*y7 + 8*y8 + 9*y9 + 10*y10 + 11*y11 RIsx ~ f*oplx RIsy ~ f*oply # Create within-person centered variables wx1 =~ 1*x1 wx2 =~ 1*x2 wx3 =~ 1*x3 wx4 =~ 1*x4 wx5 =~ 1*x5 wx6 =~ 1*x6 wx7 =~ 1*x7 wx8 =~ 1*x8 wx9 =~ 1*x9 wx10 =~ 1*x10 wx11 =~ 1*x11 wy1 =~ 1*y1 wy2 =~ 1*y2 wy3 =~ 1*y3 wy4 =~ 1*y4 wy5 =~ 1*y5 wy6 =~ 1*y6 wy7 =~ 1*y7 wy8 =~ 1*y8 wy9 =~ 1*y9 wy10 =~ 1*y10 wy11 =~ 1*y11 # Estimate the lagged effects between the within-person centered variables. wx2 ~ a*wx1 + b*wy1 wx3 ~ a*wx2 + b*wy2 wx4 ~ a*wx3 + b*wy3 wx5 ~ a*wx4 + b*wy4 wx6 ~ a*wx5 + b*wy5 wx7 ~ a*wx6 + b*wy6 wx8 ~ a*wx7 + b*wy7 wx9 ~ a*wx8 + b*wy8 wx10 ~ a*wx9 + b*wy9 wx11 ~ a*wx10 + b*wy10 wy2 ~ b*wx1 + a*wy1 wy3 ~ b*wx2 + a*wy2 wy4 ~ b*wx3 + a*wy3 wy5 ~ b*wx4 + a*wy4 wy6 ~ b*wx5 + a*wy5 wy7 ~ b*wx6 + a*wy6 wy8 ~ b*wx7 + a*wy7 wy9 ~ b*wx8 + a*wy8 wy10 ~ b*wx9 + a*wy9 wy11 ~ b*wx10 + a*wy10 # Estimate the (residual) covariance between the within-person centered variables wx1 ~~ wy1 # Covariance wx2 ~~ wy2 wx3 ~~ wy3 wx4 ~~ wy4 wx5 ~~ wy5 wx6 ~~ wy6 wx7 ~~ wy7 wx8 ~~ wy8 wx9 ~~ wy9 wx10 ~~ wy10 wx11 ~~ wy11 # Estimate the variance and covariance of the random intercepts and random slopes. RIx ~~ RIx RIy ~~ RIy RIx ~~ RIy #covariance intercepts: interpretation SELECTION RIsx ~~ RIsx RIsy ~~ RIsy RIsx ~~ RIsy #covariance slopes: interpretation COMMON CONTEXT RIx ~~ RIsx #covariance intercept/slope: interpretation regression to the mean RIy ~~ RIsy RIx ~~ RIsy #cross-covariance: interpretation INFLUENCE? RIy ~~ RIsx # Estimate the (residual) variance of the within-person centered variables. wx1 ~~ wx1 # Variances wy1 ~~ wy1 wx2 ~~ wx2 # Residual variances wy2 ~~ wy2 wx3 ~~ wx3 wy3 ~~ wy3 wx4 ~~ wx4 wy4 ~~ wy4 wx5 ~~ wx5 wy5 ~~ wy5 wx6 ~~ wx6 wy6 ~~ wy6 wx7 ~~ wx7 wy7 ~~ wy7 wx8 ~~ wx8 wy8 ~~ wy8 wx9 ~~ wx9 wy9 ~~ wy9 wx10 ~~ wx10 wy10 ~~ wy10 wx11 ~~ wx11 wy11 ~~ wy11 &#39; #Estimate models a bit faster: estimate &lt;- function(x) lavaan(LTRICLPM, data=x, missing = &quot;fiml.x&quot;, meanstructure = T ) library(future.apply) plan(multisession) results_temp &lt;- future_lapply(datalist_ori, estimate) results[[13]] &lt;- results_temp[[1]] results[[14]] &lt;- results_temp[[2]] results[[15]] &lt;- results_temp[[3]] results[[16]] &lt;- results_temp[[4]] names(results)[9:12] &lt;- c(&quot;fitm4h1y1&quot;, &quot;fitm4h1y2&quot;,&quot;fitm4h1y3&quot;,&quot;fitm4h1y4&quot;) save(results, file=&quot;results.RData&quot;) load(&quot;addfiles/results.Rdata&quot;) summary(results[[13]]) summary(results[[14]]) summary(results[[15]]) summary(results[[16]]) #&gt; lavaan 0.6-7 ended normally after 86 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 87 #&gt; Number of equality constraints 40 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1415 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 1387.507 #&gt; Degrees of freedom 272 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; RIsx =~ #&gt; x1 1.000 #&gt; x2 2.000 #&gt; x3 3.000 #&gt; x4 4.000 #&gt; x5 5.000 #&gt; x6 6.000 #&gt; x7 7.000 #&gt; x8 8.000 #&gt; x9 9.000 #&gt; x10 10.000 #&gt; x11 11.000 #&gt; RIsy =~ #&gt; y1 1.000 #&gt; y2 2.000 #&gt; y3 3.000 #&gt; y4 4.000 #&gt; y5 5.000 #&gt; y6 6.000 #&gt; y7 7.000 #&gt; y8 8.000 #&gt; y9 9.000 #&gt; y10 10.000 #&gt; y11 11.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (e) 0.132 0.001 91.424 0.000 #&gt; RIy ~ #&gt; oply (e) 0.132 0.001 91.424 0.000 #&gt; RIsx ~ #&gt; oplx (f) -0.002 0.000 -9.935 0.000 #&gt; RIsy ~ #&gt; oply (f) -0.002 0.000 -9.935 0.000 #&gt; wx2 ~ #&gt; wx1 (a) 0.145 0.010 14.885 0.000 #&gt; wy1 (b) 0.058 0.010 5.674 0.000 #&gt; wx3 ~ #&gt; wx2 (a) 0.145 0.010 14.885 0.000 #&gt; wy2 (b) 0.058 0.010 5.674 0.000 #&gt; wx4 ~ #&gt; wx3 (a) 0.145 0.010 14.885 0.000 #&gt; wy3 (b) 0.058 0.010 5.674 0.000 #&gt; wx5 ~ #&gt; wx4 (a) 0.145 0.010 14.885 0.000 #&gt; wy4 (b) 0.058 0.010 5.674 0.000 #&gt; wx6 ~ #&gt; wx5 (a) 0.145 0.010 14.885 0.000 #&gt; wy5 (b) 0.058 0.010 5.674 0.000 #&gt; wx7 ~ #&gt; wx6 (a) 0.145 0.010 14.885 0.000 #&gt; wy6 (b) 0.058 0.010 5.674 0.000 #&gt; wx8 ~ #&gt; wx7 (a) 0.145 0.010 14.885 0.000 #&gt; wy7 (b) 0.058 0.010 5.674 0.000 #&gt; wx9 ~ #&gt; wx8 (a) 0.145 0.010 14.885 0.000 #&gt; wy8 (b) 0.058 0.010 5.674 0.000 #&gt; wx10 ~ #&gt; wx9 (a) 0.145 0.010 14.885 0.000 #&gt; wy9 (b) 0.058 0.010 5.674 0.000 #&gt; wx11 ~ #&gt; wx10 (a) 0.145 0.010 14.885 0.000 #&gt; wy10 (b) 0.058 0.010 5.674 0.000 #&gt; wy2 ~ #&gt; wx1 (b) 0.058 0.010 5.674 0.000 #&gt; wy1 (a) 0.145 0.010 14.885 0.000 #&gt; wy3 ~ #&gt; wx2 (b) 0.058 0.010 5.674 0.000 #&gt; wy2 (a) 0.145 0.010 14.885 0.000 #&gt; wy4 ~ #&gt; wx3 (b) 0.058 0.010 5.674 0.000 #&gt; wy3 (a) 0.145 0.010 14.885 0.000 #&gt; wy5 ~ #&gt; wx4 (b) 0.058 0.010 5.674 0.000 #&gt; wy4 (a) 0.145 0.010 14.885 0.000 #&gt; wy6 ~ #&gt; wx5 (b) 0.058 0.010 5.674 0.000 #&gt; wy5 (a) 0.145 0.010 14.885 0.000 #&gt; wy7 ~ #&gt; wx6 (b) 0.058 0.010 5.674 0.000 #&gt; wy6 (a) 0.145 0.010 14.885 0.000 #&gt; wy8 ~ #&gt; wx7 (b) 0.058 0.010 5.674 0.000 #&gt; wy7 (a) 0.145 0.010 14.885 0.000 #&gt; wy9 ~ #&gt; wx8 (b) 0.058 0.010 5.674 0.000 #&gt; wy8 (a) 0.145 0.010 14.885 0.000 #&gt; wy10 ~ #&gt; wx9 (b) 0.058 0.010 5.674 0.000 #&gt; wy9 (a) 0.145 0.010 14.885 0.000 #&gt; wy11 ~ #&gt; wx10 (b) 0.058 0.010 5.674 0.000 #&gt; wy10 (a) 0.145 0.010 14.885 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.093 0.023 4.098 0.000 #&gt; .wx2 ~~ #&gt; .wy2 0.090 0.020 4.521 0.000 #&gt; .wx3 ~~ #&gt; .wy3 0.110 0.019 5.912 0.000 #&gt; .wx4 ~~ #&gt; .wy4 0.111 0.019 5.894 0.000 #&gt; .wx5 ~~ #&gt; .wy5 0.095 0.021 4.460 0.000 #&gt; .wx6 ~~ #&gt; .wy6 0.065 0.016 4.046 0.000 #&gt; .wx7 ~~ #&gt; .wy7 0.083 0.015 5.458 0.000 #&gt; .wx8 ~~ #&gt; .wy8 0.072 0.018 4.054 0.000 #&gt; .wx9 ~~ #&gt; .wy9 0.080 0.019 4.260 0.000 #&gt; .wx10 ~~ #&gt; .wy10 0.047 0.021 2.275 0.023 #&gt; .wx11 ~~ #&gt; .wy11 0.110 0.022 4.958 0.000 #&gt; .RIx ~~ #&gt; .RIy 0.294 0.027 10.860 0.000 #&gt; .RIsx ~~ #&gt; .RIsy 0.001 0.000 2.509 0.012 #&gt; .RIx ~~ #&gt; .RIsx -0.014 0.004 -3.372 0.001 #&gt; .RIy ~~ #&gt; .RIsy -0.005 0.003 -1.453 0.146 #&gt; .RIx ~~ #&gt; .RIsy 0.003 0.003 0.762 0.446 #&gt; .RIy ~~ #&gt; .RIsx 0.003 0.003 0.931 0.352 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; .RIsx 0.000 #&gt; .RIsy 0.000 #&gt; wx1 0.000 #&gt; .wx2 0.000 #&gt; .wx3 0.000 #&gt; .wx4 0.000 #&gt; .wx5 0.000 #&gt; .wx6 0.000 #&gt; .wx7 0.000 #&gt; .wx8 0.000 #&gt; .wx9 0.000 #&gt; .wx10 0.000 #&gt; .wx11 0.000 #&gt; wy1 0.000 #&gt; .wy2 0.000 #&gt; .wy3 0.000 #&gt; .wy4 0.000 #&gt; .wy5 0.000 #&gt; .wy6 0.000 #&gt; .wy7 0.000 #&gt; .wy8 0.000 #&gt; .wy9 0.000 #&gt; .wy10 0.000 #&gt; .wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 0.775 0.040 19.367 0.000 #&gt; .RIy 0.483 0.031 15.779 0.000 #&gt; .RIsx 0.005 0.001 7.510 0.000 #&gt; .RIsy 0.002 0.000 4.589 0.000 #&gt; wx1 0.613 0.031 19.513 0.000 #&gt; wy1 0.566 0.028 20.232 0.000 #&gt; .wx2 0.648 0.028 22.850 0.000 #&gt; .wy2 0.545 0.024 22.400 0.000 #&gt; .wx3 0.577 0.025 23.074 0.000 #&gt; .wy3 0.509 0.023 22.501 0.000 #&gt; .wx4 0.588 0.026 22.408 0.000 #&gt; .wy4 0.481 0.022 21.760 0.000 #&gt; .wx5 0.730 0.031 23.908 0.000 #&gt; .wy5 0.557 0.024 23.263 0.000 #&gt; .wx6 0.498 0.022 22.911 0.000 #&gt; .wy6 0.417 0.019 22.078 0.000 #&gt; .wx7 0.460 0.021 22.404 0.000 #&gt; .wy7 0.427 0.019 22.272 0.000 #&gt; .wx8 0.516 0.023 22.410 0.000 #&gt; .wy8 0.485 0.022 22.333 0.000 #&gt; .wx9 0.551 0.025 21.848 0.000 #&gt; .wy9 0.474 0.022 21.162 0.000 #&gt; .wx10 0.516 0.026 19.884 0.000 #&gt; .wy10 0.491 0.025 19.977 0.000 #&gt; .wx11 0.563 0.029 19.152 0.000 #&gt; .wy11 0.504 0.027 18.572 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 122 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 87 #&gt; Number of equality constraints 40 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1230 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 753.109 #&gt; Degrees of freedom 272 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; RIsx =~ #&gt; x1 1.000 #&gt; x2 2.000 #&gt; x3 3.000 #&gt; x4 4.000 #&gt; x5 5.000 #&gt; x6 6.000 #&gt; x7 7.000 #&gt; x8 8.000 #&gt; x9 9.000 #&gt; x10 10.000 #&gt; x11 11.000 #&gt; RIsy =~ #&gt; y1 1.000 #&gt; y2 2.000 #&gt; y3 3.000 #&gt; y4 4.000 #&gt; y5 5.000 #&gt; y6 6.000 #&gt; y7 7.000 #&gt; y8 8.000 #&gt; y9 9.000 #&gt; y10 10.000 #&gt; y11 11.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (e) 0.103 0.001 80.062 0.000 #&gt; RIy ~ #&gt; oply (e) 0.103 0.001 80.062 0.000 #&gt; RIsx ~ #&gt; oplx (f) 0.000 0.000 1.452 0.146 #&gt; RIsy ~ #&gt; oply (f) 0.000 0.000 1.452 0.146 #&gt; wx2 ~ #&gt; wx1 (a) 0.066 0.009 7.261 0.000 #&gt; wy1 (b) 0.015 0.009 1.542 0.123 #&gt; wx3 ~ #&gt; wx2 (a) 0.066 0.009 7.261 0.000 #&gt; wy2 (b) 0.015 0.009 1.542 0.123 #&gt; wx4 ~ #&gt; wx3 (a) 0.066 0.009 7.261 0.000 #&gt; wy3 (b) 0.015 0.009 1.542 0.123 #&gt; wx5 ~ #&gt; wx4 (a) 0.066 0.009 7.261 0.000 #&gt; wy4 (b) 0.015 0.009 1.542 0.123 #&gt; wx6 ~ #&gt; wx5 (a) 0.066 0.009 7.261 0.000 #&gt; wy5 (b) 0.015 0.009 1.542 0.123 #&gt; wx7 ~ #&gt; wx6 (a) 0.066 0.009 7.261 0.000 #&gt; wy6 (b) 0.015 0.009 1.542 0.123 #&gt; wx8 ~ #&gt; wx7 (a) 0.066 0.009 7.261 0.000 #&gt; wy7 (b) 0.015 0.009 1.542 0.123 #&gt; wx9 ~ #&gt; wx8 (a) 0.066 0.009 7.261 0.000 #&gt; wy8 (b) 0.015 0.009 1.542 0.123 #&gt; wx10 ~ #&gt; wx9 (a) 0.066 0.009 7.261 0.000 #&gt; wy9 (b) 0.015 0.009 1.542 0.123 #&gt; wx11 ~ #&gt; wx10 (a) 0.066 0.009 7.261 0.000 #&gt; wy10 (b) 0.015 0.009 1.542 0.123 #&gt; wy2 ~ #&gt; wx1 (b) 0.015 0.009 1.542 0.123 #&gt; wy1 (a) 0.066 0.009 7.261 0.000 #&gt; wy3 ~ #&gt; wx2 (b) 0.015 0.009 1.542 0.123 #&gt; wy2 (a) 0.066 0.009 7.261 0.000 #&gt; wy4 ~ #&gt; wx3 (b) 0.015 0.009 1.542 0.123 #&gt; wy3 (a) 0.066 0.009 7.261 0.000 #&gt; wy5 ~ #&gt; wx4 (b) 0.015 0.009 1.542 0.123 #&gt; wy4 (a) 0.066 0.009 7.261 0.000 #&gt; wy6 ~ #&gt; wx5 (b) 0.015 0.009 1.542 0.123 #&gt; wy5 (a) 0.066 0.009 7.261 0.000 #&gt; wy7 ~ #&gt; wx6 (b) 0.015 0.009 1.542 0.123 #&gt; wy6 (a) 0.066 0.009 7.261 0.000 #&gt; wy8 ~ #&gt; wx7 (b) 0.015 0.009 1.542 0.123 #&gt; wy7 (a) 0.066 0.009 7.261 0.000 #&gt; wy9 ~ #&gt; wx8 (b) 0.015 0.009 1.542 0.123 #&gt; wy8 (a) 0.066 0.009 7.261 0.000 #&gt; wy10 ~ #&gt; wx9 (b) 0.015 0.009 1.542 0.123 #&gt; wy9 (a) 0.066 0.009 7.261 0.000 #&gt; wy11 ~ #&gt; wx10 (b) 0.015 0.009 1.542 0.123 #&gt; wy10 (a) 0.066 0.009 7.261 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.030 0.013 2.313 0.021 #&gt; .wx2 ~~ #&gt; .wy2 0.041 0.013 3.195 0.001 #&gt; .wx3 ~~ #&gt; .wy3 0.020 0.011 1.832 0.067 #&gt; .wx4 ~~ #&gt; .wy4 0.039 0.011 3.589 0.000 #&gt; .wx5 ~~ #&gt; .wy5 0.041 0.011 3.808 0.000 #&gt; .wx6 ~~ #&gt; .wy6 0.024 0.011 2.233 0.026 #&gt; .wx7 ~~ #&gt; .wy7 0.032 0.011 2.814 0.005 #&gt; .wx8 ~~ #&gt; .wy8 0.027 0.011 2.402 0.016 #&gt; .wx9 ~~ #&gt; .wy9 0.009 0.013 0.744 0.457 #&gt; .wx10 ~~ #&gt; .wy10 0.038 0.013 2.986 0.003 #&gt; .wx11 ~~ #&gt; .wy11 0.052 0.013 3.997 0.000 #&gt; .RIx ~~ #&gt; .RIy 0.379 0.021 18.233 0.000 #&gt; .RIsx ~~ #&gt; .RIsy 0.001 0.000 3.498 0.000 #&gt; .RIx ~~ #&gt; .RIsx -0.011 0.002 -4.796 0.000 #&gt; .RIy ~~ #&gt; .RIsy -0.014 0.002 -6.106 0.000 #&gt; .RIx ~~ #&gt; .RIsy -0.010 0.002 -4.812 0.000 #&gt; .RIy ~~ #&gt; .RIsx -0.006 0.002 -3.087 0.002 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; .RIsx 0.000 #&gt; .RIsy 0.000 #&gt; wx1 0.000 #&gt; .wx2 0.000 #&gt; .wx3 0.000 #&gt; .wx4 0.000 #&gt; .wx5 0.000 #&gt; .wx6 0.000 #&gt; .wx7 0.000 #&gt; .wx8 0.000 #&gt; .wx9 0.000 #&gt; .wx10 0.000 #&gt; .wx11 0.000 #&gt; wy1 0.000 #&gt; .wy2 0.000 #&gt; .wy3 0.000 #&gt; .wy4 0.000 #&gt; .wy5 0.000 #&gt; .wy6 0.000 #&gt; .wy7 0.000 #&gt; .wy8 0.000 #&gt; .wy9 0.000 #&gt; .wy10 0.000 #&gt; .wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 0.619 0.027 23.131 0.000 #&gt; .RIy 0.613 0.026 23.241 0.000 #&gt; .RIsx 0.001 0.000 5.094 0.000 #&gt; .RIsy 0.002 0.000 5.690 0.000 #&gt; wx1 0.410 0.019 21.642 0.000 #&gt; wy1 0.332 0.016 20.354 0.000 #&gt; .wx2 0.389 0.017 22.962 0.000 #&gt; .wy2 0.410 0.017 23.591 0.000 #&gt; .wx3 0.338 0.015 23.049 0.000 #&gt; .wy3 0.304 0.013 22.542 0.000 #&gt; .wx4 0.317 0.014 22.420 0.000 #&gt; .wy4 0.318 0.014 22.330 0.000 #&gt; .wx5 0.325 0.014 23.514 0.000 #&gt; .wy5 0.332 0.014 23.431 0.000 #&gt; .wx6 0.350 0.015 23.649 0.000 #&gt; .wy6 0.304 0.013 23.244 0.000 #&gt; .wx7 0.348 0.015 23.436 0.000 #&gt; .wy7 0.327 0.014 23.469 0.000 #&gt; .wx8 0.318 0.014 22.681 0.000 #&gt; .wy8 0.322 0.014 22.854 0.000 #&gt; .wx9 0.365 0.016 22.530 0.000 #&gt; .wy9 0.364 0.016 22.194 0.000 #&gt; .wx10 0.352 0.017 20.833 0.000 #&gt; .wy10 0.322 0.016 20.438 0.000 #&gt; .wx11 0.342 0.017 19.837 0.000 #&gt; .wy11 0.304 0.016 18.850 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 107 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 87 #&gt; Number of equality constraints 40 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1290 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 5704.541 #&gt; Degrees of freedom 272 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; RIsx =~ #&gt; x1 1.000 #&gt; x2 2.000 #&gt; x3 3.000 #&gt; x4 4.000 #&gt; x5 5.000 #&gt; x6 6.000 #&gt; x7 7.000 #&gt; x8 8.000 #&gt; x9 9.000 #&gt; x10 10.000 #&gt; x11 11.000 #&gt; RIsy =~ #&gt; y1 1.000 #&gt; y2 2.000 #&gt; y3 3.000 #&gt; y4 4.000 #&gt; y5 5.000 #&gt; y6 6.000 #&gt; y7 7.000 #&gt; y8 8.000 #&gt; y9 9.000 #&gt; y10 10.000 #&gt; y11 11.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (e) 0.330 0.002 166.688 0.000 #&gt; RIy ~ #&gt; oply (e) 0.330 0.002 166.688 0.000 #&gt; RIsx ~ #&gt; oplx (f) 0.001 0.000 6.280 0.000 #&gt; RIsy ~ #&gt; oply (f) 0.001 0.000 6.280 0.000 #&gt; wx2 ~ #&gt; wx1 (a) 0.060 0.009 6.641 0.000 #&gt; wy1 (b) 0.033 0.009 3.485 0.000 #&gt; wx3 ~ #&gt; wx2 (a) 0.060 0.009 6.641 0.000 #&gt; wy2 (b) 0.033 0.009 3.485 0.000 #&gt; wx4 ~ #&gt; wx3 (a) 0.060 0.009 6.641 0.000 #&gt; wy3 (b) 0.033 0.009 3.485 0.000 #&gt; wx5 ~ #&gt; wx4 (a) 0.060 0.009 6.641 0.000 #&gt; wy4 (b) 0.033 0.009 3.485 0.000 #&gt; wx6 ~ #&gt; wx5 (a) 0.060 0.009 6.641 0.000 #&gt; wy5 (b) 0.033 0.009 3.485 0.000 #&gt; wx7 ~ #&gt; wx6 (a) 0.060 0.009 6.641 0.000 #&gt; wy6 (b) 0.033 0.009 3.485 0.000 #&gt; wx8 ~ #&gt; wx7 (a) 0.060 0.009 6.641 0.000 #&gt; wy7 (b) 0.033 0.009 3.485 0.000 #&gt; wx9 ~ #&gt; wx8 (a) 0.060 0.009 6.641 0.000 #&gt; wy8 (b) 0.033 0.009 3.485 0.000 #&gt; wx10 ~ #&gt; wx9 (a) 0.060 0.009 6.641 0.000 #&gt; wy9 (b) 0.033 0.009 3.485 0.000 #&gt; wx11 ~ #&gt; wx10 (a) 0.060 0.009 6.641 0.000 #&gt; wy10 (b) 0.033 0.009 3.485 0.000 #&gt; wy2 ~ #&gt; wx1 (b) 0.033 0.009 3.485 0.000 #&gt; wy1 (a) 0.060 0.009 6.641 0.000 #&gt; wy3 ~ #&gt; wx2 (b) 0.033 0.009 3.485 0.000 #&gt; wy2 (a) 0.060 0.009 6.641 0.000 #&gt; wy4 ~ #&gt; wx3 (b) 0.033 0.009 3.485 0.000 #&gt; wy3 (a) 0.060 0.009 6.641 0.000 #&gt; wy5 ~ #&gt; wx4 (b) 0.033 0.009 3.485 0.000 #&gt; wy4 (a) 0.060 0.009 6.641 0.000 #&gt; wy6 ~ #&gt; wx5 (b) 0.033 0.009 3.485 0.000 #&gt; wy5 (a) 0.060 0.009 6.641 0.000 #&gt; wy7 ~ #&gt; wx6 (b) 0.033 0.009 3.485 0.000 #&gt; wy6 (a) 0.060 0.009 6.641 0.000 #&gt; wy8 ~ #&gt; wx7 (b) 0.033 0.009 3.485 0.000 #&gt; wy7 (a) 0.060 0.009 6.641 0.000 #&gt; wy9 ~ #&gt; wx8 (b) 0.033 0.009 3.485 0.000 #&gt; wy8 (a) 0.060 0.009 6.641 0.000 #&gt; wy10 ~ #&gt; wx9 (b) 0.033 0.009 3.485 0.000 #&gt; wy9 (a) 0.060 0.009 6.641 0.000 #&gt; wy11 ~ #&gt; wx10 (b) 0.033 0.009 3.485 0.000 #&gt; wy10 (a) 0.060 0.009 6.641 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.054 0.011 5.038 0.000 #&gt; .wx2 ~~ #&gt; .wy2 0.029 0.009 3.278 0.001 #&gt; .wx3 ~~ #&gt; .wy3 0.062 0.009 7.003 0.000 #&gt; .wx4 ~~ #&gt; .wy4 0.028 0.008 3.525 0.000 #&gt; .wx5 ~~ #&gt; .wy5 0.038 0.008 5.017 0.000 #&gt; .wx6 ~~ #&gt; .wy6 0.035 0.007 5.156 0.000 #&gt; .wx7 ~~ #&gt; .wy7 0.031 0.007 4.500 0.000 #&gt; .wx8 ~~ #&gt; .wy8 0.024 0.008 3.157 0.002 #&gt; .wx9 ~~ #&gt; .wy9 0.031 0.008 3.942 0.000 #&gt; .wx10 ~~ #&gt; .wy10 0.060 0.010 5.887 0.000 #&gt; .wx11 ~~ #&gt; .wy11 0.055 0.009 5.812 0.000 #&gt; .RIx ~~ #&gt; .RIy 1.116 0.045 24.683 0.000 #&gt; .RIsx ~~ #&gt; .RIsy 0.000 0.000 2.880 0.004 #&gt; .RIx ~~ #&gt; .RIsx -0.007 0.003 -2.606 0.009 #&gt; .RIy ~~ #&gt; .RIsy -0.011 0.003 -3.935 0.000 #&gt; .RIx ~~ #&gt; .RIsy -0.006 0.003 -2.150 0.032 #&gt; .RIy ~~ #&gt; .RIsx -0.003 0.003 -0.893 0.372 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; .RIsx 0.000 #&gt; .RIsy 0.000 #&gt; wx1 0.000 #&gt; .wx2 0.000 #&gt; .wx3 0.000 #&gt; .wx4 0.000 #&gt; .wx5 0.000 #&gt; .wx6 0.000 #&gt; .wx7 0.000 #&gt; .wx8 0.000 #&gt; .wx9 0.000 #&gt; .wx10 0.000 #&gt; .wx11 0.000 #&gt; wy1 0.000 #&gt; .wy2 0.000 #&gt; .wy3 0.000 #&gt; .wy4 0.000 #&gt; .wy5 0.000 #&gt; .wy6 0.000 #&gt; .wy7 0.000 #&gt; .wy8 0.000 #&gt; .wy9 0.000 #&gt; .wy10 0.000 #&gt; .wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 1.647 0.051 32.469 0.000 #&gt; .RIy 1.823 0.056 32.345 0.000 #&gt; .RIsx 0.002 0.000 6.807 0.000 #&gt; .RIsy 0.002 0.000 7.292 0.000 #&gt; wx1 0.285 0.014 19.984 0.000 #&gt; wy1 0.294 0.014 20.516 0.000 #&gt; .wx2 0.272 0.013 21.496 0.000 #&gt; .wy2 0.224 0.011 20.538 0.000 #&gt; .wx3 0.247 0.011 22.437 0.000 #&gt; .wy3 0.290 0.013 23.006 0.000 #&gt; .wx4 0.212 0.010 21.773 0.000 #&gt; .wy4 0.237 0.011 22.066 0.000 #&gt; .wx5 0.242 0.011 22.814 0.000 #&gt; .wy5 0.196 0.009 22.359 0.000 #&gt; .wx6 0.214 0.010 22.380 0.000 #&gt; .wy6 0.179 0.008 21.978 0.000 #&gt; .wx7 0.205 0.009 22.465 0.000 #&gt; .wy7 0.198 0.009 22.261 0.000 #&gt; .wx8 0.211 0.010 21.711 0.000 #&gt; .wy8 0.217 0.010 22.304 0.000 #&gt; .wx9 0.233 0.011 21.420 0.000 #&gt; .wy9 0.197 0.009 21.021 0.000 #&gt; .wx10 0.263 0.013 20.555 0.000 #&gt; .wy10 0.250 0.012 20.312 0.000 #&gt; .wx11 0.225 0.012 18.348 0.000 #&gt; .wy11 0.209 0.012 17.768 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 83 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 87 #&gt; Number of equality constraints 40 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1309 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 6137.986 #&gt; Degrees of freedom 272 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; RIsx =~ #&gt; x1 1.000 #&gt; x2 2.000 #&gt; x3 3.000 #&gt; x4 4.000 #&gt; x5 5.000 #&gt; x6 6.000 #&gt; x7 7.000 #&gt; x8 8.000 #&gt; x9 9.000 #&gt; x10 10.000 #&gt; x11 11.000 #&gt; RIsy =~ #&gt; y1 1.000 #&gt; y2 2.000 #&gt; y3 3.000 #&gt; y4 4.000 #&gt; y5 5.000 #&gt; y6 6.000 #&gt; y7 7.000 #&gt; y8 8.000 #&gt; y9 9.000 #&gt; y10 10.000 #&gt; y11 11.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (e) 0.282 0.002 139.133 0.000 #&gt; RIy ~ #&gt; oply (e) 0.282 0.002 139.133 0.000 #&gt; RIsx ~ #&gt; oplx (f) 0.001 0.000 4.139 0.000 #&gt; RIsy ~ #&gt; oply (f) 0.001 0.000 4.139 0.000 #&gt; wx2 ~ #&gt; wx1 (a) 0.066 0.009 7.091 0.000 #&gt; wy1 (b) 0.009 0.010 0.933 0.351 #&gt; wx3 ~ #&gt; wx2 (a) 0.066 0.009 7.091 0.000 #&gt; wy2 (b) 0.009 0.010 0.933 0.351 #&gt; wx4 ~ #&gt; wx3 (a) 0.066 0.009 7.091 0.000 #&gt; wy3 (b) 0.009 0.010 0.933 0.351 #&gt; wx5 ~ #&gt; wx4 (a) 0.066 0.009 7.091 0.000 #&gt; wy4 (b) 0.009 0.010 0.933 0.351 #&gt; wx6 ~ #&gt; wx5 (a) 0.066 0.009 7.091 0.000 #&gt; wy5 (b) 0.009 0.010 0.933 0.351 #&gt; wx7 ~ #&gt; wx6 (a) 0.066 0.009 7.091 0.000 #&gt; wy6 (b) 0.009 0.010 0.933 0.351 #&gt; wx8 ~ #&gt; wx7 (a) 0.066 0.009 7.091 0.000 #&gt; wy7 (b) 0.009 0.010 0.933 0.351 #&gt; wx9 ~ #&gt; wx8 (a) 0.066 0.009 7.091 0.000 #&gt; wy8 (b) 0.009 0.010 0.933 0.351 #&gt; wx10 ~ #&gt; wx9 (a) 0.066 0.009 7.091 0.000 #&gt; wy9 (b) 0.009 0.010 0.933 0.351 #&gt; wx11 ~ #&gt; wx10 (a) 0.066 0.009 7.091 0.000 #&gt; wy10 (b) 0.009 0.010 0.933 0.351 #&gt; wy2 ~ #&gt; wx1 (b) 0.009 0.010 0.933 0.351 #&gt; wy1 (a) 0.066 0.009 7.091 0.000 #&gt; wy3 ~ #&gt; wx2 (b) 0.009 0.010 0.933 0.351 #&gt; wy2 (a) 0.066 0.009 7.091 0.000 #&gt; wy4 ~ #&gt; wx3 (b) 0.009 0.010 0.933 0.351 #&gt; wy3 (a) 0.066 0.009 7.091 0.000 #&gt; wy5 ~ #&gt; wx4 (b) 0.009 0.010 0.933 0.351 #&gt; wy4 (a) 0.066 0.009 7.091 0.000 #&gt; wy6 ~ #&gt; wx5 (b) 0.009 0.010 0.933 0.351 #&gt; wy5 (a) 0.066 0.009 7.091 0.000 #&gt; wy7 ~ #&gt; wx6 (b) 0.009 0.010 0.933 0.351 #&gt; wy6 (a) 0.066 0.009 7.091 0.000 #&gt; wy8 ~ #&gt; wx7 (b) 0.009 0.010 0.933 0.351 #&gt; wy7 (a) 0.066 0.009 7.091 0.000 #&gt; wy9 ~ #&gt; wx8 (b) 0.009 0.010 0.933 0.351 #&gt; wy8 (a) 0.066 0.009 7.091 0.000 #&gt; wy10 ~ #&gt; wx9 (b) 0.009 0.010 0.933 0.351 #&gt; wy9 (a) 0.066 0.009 7.091 0.000 #&gt; wy11 ~ #&gt; wx10 (b) 0.009 0.010 0.933 0.351 #&gt; wy10 (a) 0.066 0.009 7.091 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.105 0.016 6.436 0.000 #&gt; .wx2 ~~ #&gt; .wy2 0.046 0.013 3.430 0.001 #&gt; .wx3 ~~ #&gt; .wy3 0.058 0.013 4.500 0.000 #&gt; .wx4 ~~ #&gt; .wy4 0.032 0.013 2.539 0.011 #&gt; .wx5 ~~ #&gt; .wy5 0.020 0.012 1.665 0.096 #&gt; .wx6 ~~ #&gt; .wy6 0.054 0.012 4.325 0.000 #&gt; .wx7 ~~ #&gt; .wy7 0.052 0.012 4.510 0.000 #&gt; .wx8 ~~ #&gt; .wy8 0.040 0.013 3.189 0.001 #&gt; .wx9 ~~ #&gt; .wy9 0.036 0.013 2.678 0.007 #&gt; .wx10 ~~ #&gt; .wy10 0.041 0.014 2.892 0.004 #&gt; .wx11 ~~ #&gt; .wy11 0.047 0.016 2.978 0.003 #&gt; .RIx ~~ #&gt; .RIy 1.042 0.046 22.479 0.000 #&gt; .RIsx ~~ #&gt; .RIsy 0.000 0.000 0.823 0.410 #&gt; .RIx ~~ #&gt; .RIsx -0.019 0.004 -5.360 0.000 #&gt; .RIy ~~ #&gt; .RIsy -0.021 0.004 -5.550 0.000 #&gt; .RIx ~~ #&gt; .RIsy -0.008 0.003 -2.453 0.014 #&gt; .RIy ~~ #&gt; .RIsx 0.001 0.003 0.233 0.816 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; .RIsx 0.000 #&gt; .RIsy 0.000 #&gt; wx1 0.000 #&gt; .wx2 0.000 #&gt; .wx3 0.000 #&gt; .wx4 0.000 #&gt; .wx5 0.000 #&gt; .wx6 0.000 #&gt; .wx7 0.000 #&gt; .wx8 0.000 #&gt; .wx9 0.000 #&gt; .wx10 0.000 #&gt; .wx11 0.000 #&gt; wy1 0.000 #&gt; .wy2 0.000 #&gt; .wy3 0.000 #&gt; .wy4 0.000 #&gt; .wy5 0.000 #&gt; .wy6 0.000 #&gt; .wy7 0.000 #&gt; .wy8 0.000 #&gt; .wy9 0.000 #&gt; .wy10 0.000 #&gt; .wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 1.718 0.057 30.394 0.000 #&gt; .RIy 1.656 0.057 28.874 0.000 #&gt; .RIsx 0.002 0.000 7.151 0.000 #&gt; .RIsy 0.002 0.000 6.694 0.000 #&gt; wx1 0.448 0.022 20.478 0.000 #&gt; wy1 0.432 0.021 20.173 0.000 #&gt; .wx2 0.378 0.018 21.405 0.000 #&gt; .wy2 0.382 0.018 21.484 0.000 #&gt; .wx3 0.377 0.017 22.562 0.000 #&gt; .wy3 0.396 0.018 22.493 0.000 #&gt; .wx4 0.358 0.016 21.777 0.000 #&gt; .wy4 0.323 0.015 21.294 0.000 #&gt; .wx5 0.344 0.015 22.653 0.000 #&gt; .wy5 0.354 0.016 22.753 0.000 #&gt; .wx6 0.372 0.016 23.082 0.000 #&gt; .wy6 0.358 0.016 22.781 0.000 #&gt; .wx7 0.364 0.016 22.894 0.000 #&gt; .wy7 0.306 0.014 22.140 0.000 #&gt; .wx8 0.346 0.016 22.265 0.000 #&gt; .wy8 0.379 0.017 22.438 0.000 #&gt; .wx9 0.369 0.017 21.651 0.000 #&gt; .wy9 0.369 0.017 21.490 0.000 #&gt; .wx10 0.341 0.017 19.631 0.000 #&gt; .wy10 0.372 0.019 19.741 0.000 #&gt; .wx11 0.405 0.021 19.525 0.000 #&gt; .wy11 0.349 0.019 18.242 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 3.8.5 Summary results hypo1 load(&quot;addfiles/results.Rdata&quot;) library(knitr) #for kable/kables library(kableExtra) # retrieving data to show model 1 a &lt;- parameterEstimates(results[[1]])[parameterEstimates(results[[1]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[1]])[parameterEstimates(results[[1]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m1h1y1 &lt;- rbind(a, b) a &lt;- parameterEstimates(results[[2]])[parameterEstimates(results[[2]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[2]])[parameterEstimates(results[[2]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m1h1y2 &lt;- rbind(a, b) a &lt;- parameterEstimates(results[[3]])[parameterEstimates(results[[3]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[3]])[parameterEstimates(results[[3]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m1h1y3 &lt;- rbind(a, b) a &lt;- parameterEstimates(results[[4]])[parameterEstimates(results[[4]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[4]])[parameterEstimates(results[[4]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m1h1y4 &lt;- rbind(a, b) # model 2 a &lt;- parameterEstimates(results[[5]])[parameterEstimates(results[[5]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[5]])[parameterEstimates(results[[5]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m2h1y1 &lt;- rbind(a, b) a &lt;- parameterEstimates(results[[6]])[parameterEstimates(results[[6]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[6]])[parameterEstimates(results[[6]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m2h1y2 &lt;- rbind(a, b) a &lt;- parameterEstimates(results[[7]])[parameterEstimates(results[[7]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[7]])[parameterEstimates(results[[7]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m2h1y3 &lt;- rbind(a, b) a &lt;- parameterEstimates(results[[8]])[parameterEstimates(results[[8]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[8]])[parameterEstimates(results[[8]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m2h1y4 &lt;- rbind(a, b) # model 3 a &lt;- parameterEstimates(results[[9]])[parameterEstimates(results[[9]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[9]])[parameterEstimates(results[[9]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m3h1y1 &lt;- rbind(a, b) a &lt;- parameterEstimates(results[[10]])[parameterEstimates(results[[10]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[10]])[parameterEstimates(results[[10]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m3h1y2 &lt;- rbind(a, b) a &lt;- parameterEstimates(results[[11]])[parameterEstimates(results[[11]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[11]])[parameterEstimates(results[[11]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m3h1y3 &lt;- rbind(a, b) a &lt;- parameterEstimates(results[[12]])[parameterEstimates(results[[12]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[12]])[parameterEstimates(results[[12]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m3h1y4 &lt;- rbind(a, b) # model 4 a &lt;- parameterEstimates(results[[13]])[parameterEstimates(results[[13]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[13]])[parameterEstimates(results[[13]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m4h1y1 &lt;- rbind(a, b) a &lt;- parameterEstimates(results[[14]])[parameterEstimates(results[[14]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[14]])[parameterEstimates(results[[14]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m4h1y2 &lt;- rbind(a, b) a &lt;- parameterEstimates(results[[15]])[parameterEstimates(results[[15]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[15]])[parameterEstimates(results[[15]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m4h1y3 &lt;- rbind(a, b) a &lt;- parameterEstimates(results[[16]])[parameterEstimates(results[[16]])$label == &quot;a&quot;, ][1, c(5, 6, 8)] b &lt;- parameterEstimates(results[[16]])[parameterEstimates(results[[16]])$label == &quot;b&quot;, ][1, c(5, 6, 8)] m4h1y4 &lt;- rbind(a, b) # combine put deps under each other m1deps &lt;- rbind(m1h1y1, m1h1y2, m1h1y3, m1h1y4) m2deps &lt;- rbind(m2h1y1, m2h1y2, m2h1y3, m2h1y4) m3deps &lt;- rbind(m3h1y1, m3h1y2, m3h1y3, m3h1y4) m4deps &lt;- rbind(m4h1y1, m4h1y2, m4h1y3, m4h1y4) # put methods next to each other h1 &lt;- cbind(m1deps, m2deps, m3deps, m4deps) row.names(h1) &lt;- NULL paths &lt;- rep(c(&quot;stability&quot;, &quot;partner-effect&quot;), 2) h1 &lt;- cbind(paths, h1) hypo1 &lt;- kbl(h1, booktabs = TRUE, digits = 2, caption = &quot;Results Hypo1&quot;, align = &quot;lcccccccccccc&quot;) %&gt;% add_header_above(c(&quot; &quot;, CLPM = 3, `RI-CLPM` = 3, `SC-RI-CLPM` = 3, `LT-RI-CLPM` = 3)) %&gt;% pack_rows(index = c(`eu-integration` = 2, immigrants = 2, euthanasia = 2, income_diff = 2)) %&gt;% kable_classic(full_width = F, html_font = &quot;Cambria&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) %&gt;% column_spec(5:7, color = &quot;white&quot;, background = &quot;green&quot;) hypo1 Table 3.1: Results Hypo1 CLPM RI-CLPM SC-RI-CLPM LT-RI-CLPM paths est se pvalue est se pvalue est se pvalue est se pvalue eu-integration stability 0.57 0.01 0 0.20 0.01 0.0 0.20 0.01 0.00 0.14 0.01 0.00 partner-effect 0.15 0.01 0 0.08 0.01 0.0 0.07 0.01 0.00 0.06 0.01 0.00 immigrants stability 0.57 0.00 0 0.10 0.01 0.0 0.10 0.01 0.00 0.07 0.01 0.00 partner-effect 0.16 0.01 0 0.03 0.01 0.0 0.03 0.01 0.00 0.01 0.01 0.12 euthanasia stability 0.68 0.00 0 0.12 0.01 0.0 0.11 0.01 0.00 0.06 0.01 0.00 partner-effect 0.18 0.00 0 0.04 0.01 0.0 0.04 0.01 0.00 0.03 0.01 0.00 income_diff stability 0.58 0.00 0 0.12 0.01 0.0 0.12 0.01 0.00 0.07 0.01 0.00 partner-effect 0.15 0.01 0 0.01 0.01 0.4 0.01 0.01 0.29 0.01 0.01 0.35 3.8.6 Conclusion hypo1 3.9 Results Hypo2 Hypo2 RI-CLPM: Women are more influenced by their (male) spouse than men are influenced by their (female) spouse. 3.9.1 CLPM myModel &lt;- &quot; ### control for education x1 + x2 + x3 +x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 ~ ex*oplx y1 + y2 + y3 +y4 + y5 + y6 + y7 + y8 + y9 + y10 + y11 ~ ey*oply ### Estimate the lagged effects x2 ~ ax*x1 + bx*y1 x3 ~ ax*x2 + bx*y2 x4 ~ ax*x3 + bx*y3 x5 ~ ax*x4 + bx*y4 x6 ~ ax*x5 + bx*y5 x7 ~ ax*x6 + bx*y6 x8 ~ ax*x7 + bx*y7 x9 ~ ax*x8 + bx*y8 x10 ~ ax*x9 + bx*y9 x11 ~ ax*x10 + bx*y10 y2 ~ by*x1 + ay*y1 y3 ~ by*x2 + ay*y2 y4 ~ by*x3 + ay*y3 y5 ~ by*x4 + ay*y4 y6 ~ by*x5 + ay*y5 y7 ~ by*x6 + ay*y6 y8 ~ by*x7 + ay*y7 y9 ~ by*x8 + ay*y8 y10 ~ by*x9 + ay*y9 y11 ~ by*x10 + ay*y10 # Estimate the (residual) covariance between the variables x1 ~~ y1 # Covariance x2 ~~ y2 x3 ~~ y3 x4 ~~ y4 x5 ~~ y5 x6 ~~ y6 x7 ~~ y7 x8 ~~ y8 x9 ~~ y9 x10 ~~ y10 x11 ~~ y11 # Estimate the (residual) variance of the variables. x1 ~~ x1 # Variances y1 ~~ y1 x2 ~~ x2 # Residual variances y2 ~~ y2 x3 ~~ x3 y3 ~~ y3 x4 ~~ x4 y4 ~~ y4 x5 ~~ x5 y5 ~~ y5 x6 ~~ x6 y6 ~~ y6 x7 ~~ x7 y7 ~~ y7 x8 ~~ x8 y8 ~~ y8 x9 ~~ x9 y9 ~~ y9 x10 ~~ x10 y10 ~~ y10 x11 ~~ x11 y11 ~~ y11 #intercepts x1 ~ 1 y1 ~ 1 x2 ~ 1 y2 ~ 1 x3 ~ 1 y3 ~ 1 x4 ~ 1 y4 ~ 1 x5 ~ 1 y5 ~ 1 x6 ~ 1 y6 ~ 1 x7 ~ 1 y7 ~ 1 x8 ~ 1 y8 ~ 1 x9 ~ 1 y9 ~ 1 x10 ~ 1 y10 ~ 1 x11 ~ 1 y11 ~ 1 dif1 := ax - ay dif2 := bx - by dif3 := ex - ey &quot; # Estimate models a bit faster: estimate &lt;- function(x) lavaan(myModel, data = x, missing = &quot;fiml.x&quot;, meanstructure = T) library(future.apply) plan(multisession) results_temp &lt;- future_lapply(datalist_ori, estimate) summary(results_temp[[1]]) results[[17]] &lt;- results_temp[[1]] results[[18]] &lt;- results_temp[[2]] results[[19]] &lt;- results_temp[[3]] results[[20]] &lt;- results_temp[[4]] names(results)[17:20] &lt;- c(&quot;fitm1h2y1&quot;, &quot;fitm1h2y2&quot;, &quot;fitm1h2y3&quot;, &quot;fitm1h2y4&quot;) load(&quot;addfiles/results.Rdata&quot;) summary(results[[17]]) summary(results[[18]]) summary(results[[19]]) summary(results[[20]]) #&gt; lavaan 0.6-7 ended normally after 39 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 117 #&gt; Number of equality constraints 56 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1415 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 3233.567 #&gt; Degrees of freedom 258 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; x1 ~ #&gt; oplx (ex) 0.043 0.002 17.477 0.000 #&gt; x2 ~ #&gt; oplx (ex) 0.043 0.002 17.477 0.000 #&gt; x3 ~ #&gt; oplx (ex) 0.043 0.002 17.477 0.000 #&gt; x4 ~ #&gt; oplx (ex) 0.043 0.002 17.477 0.000 #&gt; x5 ~ #&gt; oplx (ex) 0.043 0.002 17.477 0.000 #&gt; x6 ~ #&gt; oplx (ex) 0.043 0.002 17.477 0.000 #&gt; x7 ~ #&gt; oplx (ex) 0.043 0.002 17.477 0.000 #&gt; x8 ~ #&gt; oplx (ex) 0.043 0.002 17.477 0.000 #&gt; x9 ~ #&gt; oplx (ex) 0.043 0.002 17.477 0.000 #&gt; x10 ~ #&gt; oplx (ex) 0.043 0.002 17.477 0.000 #&gt; x11 ~ #&gt; oplx (ex) 0.043 0.002 17.477 0.000 #&gt; y1 ~ #&gt; oply (ey) 0.036 0.002 15.163 0.000 #&gt; y2 ~ #&gt; oply (ey) 0.036 0.002 15.163 0.000 #&gt; y3 ~ #&gt; oply (ey) 0.036 0.002 15.163 0.000 #&gt; y4 ~ #&gt; oply (ey) 0.036 0.002 15.163 0.000 #&gt; y5 ~ #&gt; oply (ey) 0.036 0.002 15.163 0.000 #&gt; y6 ~ #&gt; oply (ey) 0.036 0.002 15.163 0.000 #&gt; y7 ~ #&gt; oply (ey) 0.036 0.002 15.163 0.000 #&gt; y8 ~ #&gt; oply (ey) 0.036 0.002 15.163 0.000 #&gt; y9 ~ #&gt; oply (ey) 0.036 0.002 15.163 0.000 #&gt; y10 ~ #&gt; oply (ey) 0.036 0.002 15.163 0.000 #&gt; y11 ~ #&gt; oply (ey) 0.036 0.002 15.163 0.000 #&gt; x2 ~ #&gt; x1 (ax) 0.605 0.007 86.610 0.000 #&gt; y1 (bx) 0.163 0.009 18.854 0.000 #&gt; x3 ~ #&gt; x2 (ax) 0.605 0.007 86.610 0.000 #&gt; y2 (bx) 0.163 0.009 18.854 0.000 #&gt; x4 ~ #&gt; x3 (ax) 0.605 0.007 86.610 0.000 #&gt; y3 (bx) 0.163 0.009 18.854 0.000 #&gt; x5 ~ #&gt; x4 (ax) 0.605 0.007 86.610 0.000 #&gt; y4 (bx) 0.163 0.009 18.854 0.000 #&gt; x6 ~ #&gt; x5 (ax) 0.605 0.007 86.610 0.000 #&gt; y5 (bx) 0.163 0.009 18.854 0.000 #&gt; x7 ~ #&gt; x6 (ax) 0.605 0.007 86.610 0.000 #&gt; y6 (bx) 0.163 0.009 18.854 0.000 #&gt; x8 ~ #&gt; x7 (ax) 0.605 0.007 86.610 0.000 #&gt; y7 (bx) 0.163 0.009 18.854 0.000 #&gt; x9 ~ #&gt; x8 (ax) 0.605 0.007 86.610 0.000 #&gt; y8 (bx) 0.163 0.009 18.854 0.000 #&gt; x10 ~ #&gt; x9 (ax) 0.605 0.007 86.610 0.000 #&gt; y9 (bx) 0.163 0.009 18.854 0.000 #&gt; x11 ~ #&gt; x10 (ax) 0.605 0.007 86.610 0.000 #&gt; y10 (bx) 0.163 0.009 18.854 0.000 #&gt; y2 ~ #&gt; x1 (by) 0.151 0.007 23.192 0.000 #&gt; y1 (ay) 0.525 0.008 67.181 0.000 #&gt; y3 ~ #&gt; x2 (by) 0.151 0.007 23.192 0.000 #&gt; y2 (ay) 0.525 0.008 67.181 0.000 #&gt; y4 ~ #&gt; x3 (by) 0.151 0.007 23.192 0.000 #&gt; y3 (ay) 0.525 0.008 67.181 0.000 #&gt; y5 ~ #&gt; x4 (by) 0.151 0.007 23.192 0.000 #&gt; y4 (ay) 0.525 0.008 67.181 0.000 #&gt; y6 ~ #&gt; x5 (by) 0.151 0.007 23.192 0.000 #&gt; y5 (ay) 0.525 0.008 67.181 0.000 #&gt; y7 ~ #&gt; x6 (by) 0.151 0.007 23.192 0.000 #&gt; y6 (ay) 0.525 0.008 67.181 0.000 #&gt; y8 ~ #&gt; x7 (by) 0.151 0.007 23.192 0.000 #&gt; y7 (ay) 0.525 0.008 67.181 0.000 #&gt; y9 ~ #&gt; x8 (by) 0.151 0.007 23.192 0.000 #&gt; y8 (ay) 0.525 0.008 67.181 0.000 #&gt; y10 ~ #&gt; x9 (by) 0.151 0.007 23.192 0.000 #&gt; y9 (ay) 0.525 0.008 67.181 0.000 #&gt; y11 ~ #&gt; x10 (by) 0.151 0.007 23.192 0.000 #&gt; y10 (ay) 0.525 0.008 67.181 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 ~~ #&gt; .y1 0.410 0.030 13.668 0.000 #&gt; .x2 ~~ #&gt; .y2 0.123 0.021 5.822 0.000 #&gt; .x3 ~~ #&gt; .y3 0.119 0.020 5.841 0.000 #&gt; .x4 ~~ #&gt; .y4 0.154 0.022 7.146 0.000 #&gt; .x5 ~~ #&gt; .y5 0.146 0.025 5.956 0.000 #&gt; .x6 ~~ #&gt; .y6 0.112 0.020 5.655 0.000 #&gt; .x7 ~~ #&gt; .y7 0.104 0.018 5.963 0.000 #&gt; .x8 ~~ #&gt; .y8 0.114 0.021 5.336 0.000 #&gt; .x9 ~~ #&gt; .y9 0.119 0.022 5.476 0.000 #&gt; .x10 ~~ #&gt; .y10 0.081 0.023 3.487 0.000 #&gt; .x11 ~~ #&gt; .y11 0.131 0.024 5.568 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 1.087 0.040 27.297 0.000 #&gt; .y1 1.125 0.036 31.131 0.000 #&gt; .x2 -0.030 0.037 -0.818 0.413 #&gt; .y2 0.179 0.034 5.266 0.000 #&gt; .x3 -0.107 0.037 -2.916 0.004 #&gt; .y3 0.118 0.034 3.499 0.000 #&gt; .x4 -0.408 0.038 -10.870 0.000 #&gt; .y4 -0.216 0.034 -6.268 0.000 #&gt; .x5 -0.001 0.038 -0.039 0.969 #&gt; .y5 0.015 0.035 0.418 0.676 #&gt; .x6 -0.304 0.036 -8.390 0.000 #&gt; .y6 -0.054 0.034 -1.600 0.110 #&gt; .x7 -0.295 0.036 -8.238 0.000 #&gt; .y7 -0.089 0.033 -2.666 0.008 #&gt; .x8 -0.124 0.037 -3.329 0.001 #&gt; .y8 0.062 0.035 1.785 0.074 #&gt; .x9 -0.278 0.037 -7.464 0.000 #&gt; .y9 -0.013 0.035 -0.376 0.707 #&gt; .x10 -0.067 0.038 -1.745 0.081 #&gt; .y10 0.177 0.036 4.925 0.000 #&gt; .x11 -0.083 0.039 -2.115 0.034 #&gt; .y11 0.137 0.036 3.769 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 1.375 0.045 30.425 0.000 #&gt; .y1 1.013 0.034 29.369 0.000 #&gt; .x2 0.825 0.030 27.054 0.000 #&gt; .y2 0.679 0.026 26.286 0.000 #&gt; .x3 0.775 0.029 26.359 0.000 #&gt; .y3 0.599 0.024 25.470 0.000 #&gt; .x4 0.809 0.031 25.775 0.000 #&gt; .y4 0.642 0.026 24.959 0.000 #&gt; .x5 0.922 0.036 25.674 0.000 #&gt; .y5 0.703 0.028 25.034 0.000 #&gt; .x6 0.703 0.027 25.881 0.000 #&gt; .y6 0.584 0.023 24.937 0.000 #&gt; .x7 0.637 0.025 25.650 0.000 #&gt; .y7 0.532 0.021 24.981 0.000 #&gt; .x8 0.741 0.029 25.230 0.000 #&gt; .y8 0.628 0.025 24.978 0.000 #&gt; .x9 0.744 0.029 25.613 0.000 #&gt; .y9 0.648 0.026 24.738 0.000 #&gt; .x10 0.757 0.031 24.217 0.000 #&gt; .y10 0.651 0.028 23.538 0.000 #&gt; .x11 0.787 0.033 23.979 0.000 #&gt; .y11 0.625 0.027 22.882 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 0.080 0.011 7.385 0.000 #&gt; dif2 0.012 0.011 1.097 0.273 #&gt; dif3 0.007 0.003 2.106 0.035 #&gt; #&gt; lavaan 0.6-7 ended normally after 38 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 117 #&gt; Number of equality constraints 56 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1230 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 4304.782 #&gt; Degrees of freedom 258 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; x1 ~ #&gt; oplx (ex) 0.024 0.002 12.493 0.000 #&gt; x2 ~ #&gt; oplx (ex) 0.024 0.002 12.493 0.000 #&gt; x3 ~ #&gt; oplx (ex) 0.024 0.002 12.493 0.000 #&gt; x4 ~ #&gt; oplx (ex) 0.024 0.002 12.493 0.000 #&gt; x5 ~ #&gt; oplx (ex) 0.024 0.002 12.493 0.000 #&gt; x6 ~ #&gt; oplx (ex) 0.024 0.002 12.493 0.000 #&gt; x7 ~ #&gt; oplx (ex) 0.024 0.002 12.493 0.000 #&gt; x8 ~ #&gt; oplx (ex) 0.024 0.002 12.493 0.000 #&gt; x9 ~ #&gt; oplx (ex) 0.024 0.002 12.493 0.000 #&gt; x10 ~ #&gt; oplx (ex) 0.024 0.002 12.493 0.000 #&gt; x11 ~ #&gt; oplx (ex) 0.024 0.002 12.493 0.000 #&gt; y1 ~ #&gt; oply (ey) 0.029 0.002 14.613 0.000 #&gt; y2 ~ #&gt; oply (ey) 0.029 0.002 14.613 0.000 #&gt; y3 ~ #&gt; oply (ey) 0.029 0.002 14.613 0.000 #&gt; y4 ~ #&gt; oply (ey) 0.029 0.002 14.613 0.000 #&gt; y5 ~ #&gt; oply (ey) 0.029 0.002 14.613 0.000 #&gt; y6 ~ #&gt; oply (ey) 0.029 0.002 14.613 0.000 #&gt; y7 ~ #&gt; oply (ey) 0.029 0.002 14.613 0.000 #&gt; y8 ~ #&gt; oply (ey) 0.029 0.002 14.613 0.000 #&gt; y9 ~ #&gt; oply (ey) 0.029 0.002 14.613 0.000 #&gt; y10 ~ #&gt; oply (ey) 0.029 0.002 14.613 0.000 #&gt; y11 ~ #&gt; oply (ey) 0.029 0.002 14.613 0.000 #&gt; x2 ~ #&gt; x1 (ax) 0.569 0.007 79.995 0.000 #&gt; y1 (bx) 0.176 0.007 23.736 0.000 #&gt; x3 ~ #&gt; x2 (ax) 0.569 0.007 79.995 0.000 #&gt; y2 (bx) 0.176 0.007 23.736 0.000 #&gt; x4 ~ #&gt; x3 (ax) 0.569 0.007 79.995 0.000 #&gt; y3 (bx) 0.176 0.007 23.736 0.000 #&gt; x5 ~ #&gt; x4 (ax) 0.569 0.007 79.995 0.000 #&gt; y4 (bx) 0.176 0.007 23.736 0.000 #&gt; x6 ~ #&gt; x5 (ax) 0.569 0.007 79.995 0.000 #&gt; y5 (bx) 0.176 0.007 23.736 0.000 #&gt; x7 ~ #&gt; x6 (ax) 0.569 0.007 79.995 0.000 #&gt; y6 (bx) 0.176 0.007 23.736 0.000 #&gt; x8 ~ #&gt; x7 (ax) 0.569 0.007 79.995 0.000 #&gt; y7 (bx) 0.176 0.007 23.736 0.000 #&gt; x9 ~ #&gt; x8 (ax) 0.569 0.007 79.995 0.000 #&gt; y8 (bx) 0.176 0.007 23.736 0.000 #&gt; x10 ~ #&gt; x9 (ax) 0.569 0.007 79.995 0.000 #&gt; y9 (bx) 0.176 0.007 23.736 0.000 #&gt; x11 ~ #&gt; x10 (ax) 0.569 0.007 79.995 0.000 #&gt; y10 (bx) 0.176 0.007 23.736 0.000 #&gt; y2 ~ #&gt; x1 (by) 0.152 0.007 21.425 0.000 #&gt; y1 (ay) 0.572 0.007 79.358 0.000 #&gt; y3 ~ #&gt; x2 (by) 0.152 0.007 21.425 0.000 #&gt; y2 (ay) 0.572 0.007 79.358 0.000 #&gt; y4 ~ #&gt; x3 (by) 0.152 0.007 21.425 0.000 #&gt; y3 (ay) 0.572 0.007 79.358 0.000 #&gt; y5 ~ #&gt; x4 (by) 0.152 0.007 21.425 0.000 #&gt; y4 (ay) 0.572 0.007 79.358 0.000 #&gt; y6 ~ #&gt; x5 (by) 0.152 0.007 21.425 0.000 #&gt; y5 (ay) 0.572 0.007 79.358 0.000 #&gt; y7 ~ #&gt; x6 (by) 0.152 0.007 21.425 0.000 #&gt; y6 (ay) 0.572 0.007 79.358 0.000 #&gt; y8 ~ #&gt; x7 (by) 0.152 0.007 21.425 0.000 #&gt; y7 (ay) 0.572 0.007 79.358 0.000 #&gt; y9 ~ #&gt; x8 (by) 0.152 0.007 21.425 0.000 #&gt; y8 (ay) 0.572 0.007 79.358 0.000 #&gt; y10 ~ #&gt; x9 (by) 0.152 0.007 21.425 0.000 #&gt; y9 (ay) 0.572 0.007 79.358 0.000 #&gt; y11 ~ #&gt; x10 (by) 0.152 0.007 21.425 0.000 #&gt; y10 (ay) 0.572 0.007 79.358 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 ~~ #&gt; .y1 0.383 0.023 16.611 0.000 #&gt; .x2 ~~ #&gt; .y2 0.101 0.015 6.608 0.000 #&gt; .x3 ~~ #&gt; .y3 0.104 0.015 6.808 0.000 #&gt; .x4 ~~ #&gt; .y4 0.071 0.014 5.063 0.000 #&gt; .x5 ~~ #&gt; .y5 0.086 0.014 6.086 0.000 #&gt; .x6 ~~ #&gt; .y6 0.073 0.014 5.334 0.000 #&gt; .x7 ~~ #&gt; .y7 0.055 0.014 4.040 0.000 #&gt; .x8 ~~ #&gt; .y8 0.075 0.015 5.110 0.000 #&gt; .x9 ~~ #&gt; .y9 0.041 0.015 2.712 0.007 #&gt; .x10 ~~ #&gt; .y10 0.089 0.015 5.882 0.000 #&gt; .x11 ~~ #&gt; .y11 0.101 0.015 6.750 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.917 0.032 28.541 0.000 #&gt; .y1 0.927 0.031 30.028 0.000 #&gt; .x2 0.038 0.030 1.266 0.206 #&gt; .y2 0.043 0.029 1.499 0.134 #&gt; .x3 0.009 0.030 0.313 0.754 #&gt; .y3 0.054 0.029 1.898 0.058 #&gt; .x4 0.010 0.029 0.330 0.741 #&gt; .y4 0.025 0.029 0.873 0.382 #&gt; .x5 0.008 0.030 0.266 0.790 #&gt; .y5 0.025 0.029 0.871 0.384 #&gt; .x6 0.007 0.030 0.222 0.825 #&gt; .y6 0.025 0.028 0.893 0.372 #&gt; .x7 0.029 0.030 0.976 0.329 #&gt; .y7 0.050 0.028 1.765 0.078 #&gt; .x8 -0.036 0.030 -1.210 0.226 #&gt; .y8 -0.012 0.029 -0.406 0.685 #&gt; .x9 -0.046 0.030 -1.500 0.134 #&gt; .y9 0.004 0.030 0.124 0.902 #&gt; .x10 0.115 0.031 3.711 0.000 #&gt; .y10 0.112 0.030 3.768 0.000 #&gt; .x11 0.001 0.031 0.017 0.986 #&gt; .y11 0.039 0.030 1.313 0.189 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.946 0.031 30.278 0.000 #&gt; .y1 0.869 0.029 30.124 0.000 #&gt; .x2 0.567 0.021 27.152 0.000 #&gt; .y2 0.551 0.020 27.172 0.000 #&gt; .x3 0.548 0.021 26.509 0.000 #&gt; .y3 0.504 0.019 26.222 0.000 #&gt; .x4 0.460 0.018 25.860 0.000 #&gt; .y4 0.485 0.019 25.470 0.000 #&gt; .x5 0.477 0.019 25.760 0.000 #&gt; .y5 0.463 0.018 25.114 0.000 #&gt; .x6 0.505 0.019 26.222 0.000 #&gt; .y6 0.442 0.017 26.327 0.000 #&gt; .x7 0.488 0.019 25.910 0.000 #&gt; .y7 0.451 0.017 26.076 0.000 #&gt; .x8 0.479 0.019 25.427 0.000 #&gt; .y8 0.484 0.019 25.571 0.000 #&gt; .x9 0.501 0.019 25.754 0.000 #&gt; .y9 0.506 0.020 25.472 0.000 #&gt; .x10 0.511 0.021 24.631 0.000 #&gt; .y10 0.454 0.019 24.284 0.000 #&gt; .x11 0.492 0.020 24.422 0.000 #&gt; .y11 0.451 0.019 24.049 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 -0.003 0.010 -0.301 0.763 #&gt; dif2 0.024 0.010 2.265 0.024 #&gt; dif3 -0.004 0.003 -1.575 0.115 #&gt; #&gt; lavaan 0.6-7 ended normally after 68 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 117 #&gt; Number of equality constraints 56 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1290 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 5137.978 #&gt; Degrees of freedom 258 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; x1 ~ #&gt; oplx (ex) 0.004 0.002 2.542 0.011 #&gt; x2 ~ #&gt; oplx (ex) 0.004 0.002 2.542 0.011 #&gt; x3 ~ #&gt; oplx (ex) 0.004 0.002 2.542 0.011 #&gt; x4 ~ #&gt; oplx (ex) 0.004 0.002 2.542 0.011 #&gt; x5 ~ #&gt; oplx (ex) 0.004 0.002 2.542 0.011 #&gt; x6 ~ #&gt; oplx (ex) 0.004 0.002 2.542 0.011 #&gt; x7 ~ #&gt; oplx (ex) 0.004 0.002 2.542 0.011 #&gt; x8 ~ #&gt; oplx (ex) 0.004 0.002 2.542 0.011 #&gt; x9 ~ #&gt; oplx (ex) 0.004 0.002 2.542 0.011 #&gt; x10 ~ #&gt; oplx (ex) 0.004 0.002 2.542 0.011 #&gt; x11 ~ #&gt; oplx (ex) 0.004 0.002 2.542 0.011 #&gt; y1 ~ #&gt; oply (ey) 0.004 0.002 2.244 0.025 #&gt; y2 ~ #&gt; oply (ey) 0.004 0.002 2.244 0.025 #&gt; y3 ~ #&gt; oply (ey) 0.004 0.002 2.244 0.025 #&gt; y4 ~ #&gt; oply (ey) 0.004 0.002 2.244 0.025 #&gt; y5 ~ #&gt; oply (ey) 0.004 0.002 2.244 0.025 #&gt; y6 ~ #&gt; oply (ey) 0.004 0.002 2.244 0.025 #&gt; y7 ~ #&gt; oply (ey) 0.004 0.002 2.244 0.025 #&gt; y8 ~ #&gt; oply (ey) 0.004 0.002 2.244 0.025 #&gt; y9 ~ #&gt; oply (ey) 0.004 0.002 2.244 0.025 #&gt; y10 ~ #&gt; oply (ey) 0.004 0.002 2.244 0.025 #&gt; y11 ~ #&gt; oply (ey) 0.004 0.002 2.244 0.025 #&gt; x2 ~ #&gt; x1 (ax) 0.663 0.007 101.002 0.000 #&gt; y1 (bx) 0.192 0.007 29.543 0.000 #&gt; x3 ~ #&gt; x2 (ax) 0.663 0.007 101.002 0.000 #&gt; y2 (bx) 0.192 0.007 29.543 0.000 #&gt; x4 ~ #&gt; x3 (ax) 0.663 0.007 101.002 0.000 #&gt; y3 (bx) 0.192 0.007 29.543 0.000 #&gt; x5 ~ #&gt; x4 (ax) 0.663 0.007 101.002 0.000 #&gt; y4 (bx) 0.192 0.007 29.543 0.000 #&gt; x6 ~ #&gt; x5 (ax) 0.663 0.007 101.002 0.000 #&gt; y5 (bx) 0.192 0.007 29.543 0.000 #&gt; x7 ~ #&gt; x6 (ax) 0.663 0.007 101.002 0.000 #&gt; y6 (bx) 0.192 0.007 29.543 0.000 #&gt; x8 ~ #&gt; x7 (ax) 0.663 0.007 101.002 0.000 #&gt; y7 (bx) 0.192 0.007 29.543 0.000 #&gt; x9 ~ #&gt; x8 (ax) 0.663 0.007 101.002 0.000 #&gt; y8 (bx) 0.192 0.007 29.543 0.000 #&gt; x10 ~ #&gt; x9 (ax) 0.663 0.007 101.002 0.000 #&gt; y9 (bx) 0.192 0.007 29.543 0.000 #&gt; x11 ~ #&gt; x10 (ax) 0.663 0.007 101.002 0.000 #&gt; y10 (bx) 0.192 0.007 29.543 0.000 #&gt; y2 ~ #&gt; x1 (by) 0.172 0.007 25.776 0.000 #&gt; y1 (ay) 0.697 0.006 109.007 0.000 #&gt; y3 ~ #&gt; x2 (by) 0.172 0.007 25.776 0.000 #&gt; y2 (ay) 0.697 0.006 109.007 0.000 #&gt; y4 ~ #&gt; x3 (by) 0.172 0.007 25.776 0.000 #&gt; y3 (ay) 0.697 0.006 109.007 0.000 #&gt; y5 ~ #&gt; x4 (by) 0.172 0.007 25.776 0.000 #&gt; y4 (ay) 0.697 0.006 109.007 0.000 #&gt; y6 ~ #&gt; x5 (by) 0.172 0.007 25.776 0.000 #&gt; y5 (ay) 0.697 0.006 109.007 0.000 #&gt; y7 ~ #&gt; x6 (by) 0.172 0.007 25.776 0.000 #&gt; y6 (ay) 0.697 0.006 109.007 0.000 #&gt; y8 ~ #&gt; x7 (by) 0.172 0.007 25.776 0.000 #&gt; y7 (ay) 0.697 0.006 109.007 0.000 #&gt; y9 ~ #&gt; x8 (by) 0.172 0.007 25.776 0.000 #&gt; y8 (ay) 0.697 0.006 109.007 0.000 #&gt; y10 ~ #&gt; x9 (by) 0.172 0.007 25.776 0.000 #&gt; y9 (ay) 0.697 0.006 109.007 0.000 #&gt; y11 ~ #&gt; x10 (by) 0.172 0.007 25.776 0.000 #&gt; y10 (ay) 0.697 0.006 109.007 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 ~~ #&gt; .y1 0.659 0.029 22.944 0.000 #&gt; .x2 ~~ #&gt; .y2 0.081 0.012 6.888 0.000 #&gt; .x3 ~~ #&gt; .y3 0.086 0.011 7.794 0.000 #&gt; .x4 ~~ #&gt; .y4 0.086 0.011 7.827 0.000 #&gt; .x5 ~~ #&gt; .y5 0.078 0.010 7.479 0.000 #&gt; .x6 ~~ #&gt; .y6 0.066 0.009 7.415 0.000 #&gt; .x7 ~~ #&gt; .y7 0.056 0.009 6.178 0.000 #&gt; .x8 ~~ #&gt; .y8 0.062 0.010 6.021 0.000 #&gt; .x9 ~~ #&gt; .y9 0.075 0.011 7.104 0.000 #&gt; .x10 ~~ #&gt; .y10 0.096 0.013 7.549 0.000 #&gt; .x11 ~~ #&gt; .y11 0.101 0.012 8.429 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 4.254 0.029 144.503 0.000 #&gt; .y1 4.277 0.029 145.918 0.000 #&gt; .x2 0.588 0.033 17.686 0.000 #&gt; .y2 0.563 0.032 17.659 0.000 #&gt; .x3 0.566 0.033 17.314 0.000 #&gt; .y3 0.505 0.032 15.659 0.000 #&gt; .x4 0.608 0.033 18.669 0.000 #&gt; .y4 0.576 0.032 17.810 0.000 #&gt; .x5 0.596 0.033 18.115 0.000 #&gt; .y5 0.556 0.032 17.357 0.000 #&gt; .x6 0.599 0.033 18.210 0.000 #&gt; .y6 0.547 0.031 17.557 0.000 #&gt; .x7 0.617 0.033 18.895 0.000 #&gt; .y7 0.562 0.032 17.722 0.000 #&gt; .x8 0.600 0.033 18.089 0.000 #&gt; .y8 0.551 0.033 16.924 0.000 #&gt; .x9 0.539 0.034 16.020 0.000 #&gt; .y9 0.510 0.032 15.819 0.000 #&gt; .x10 0.572 0.034 16.738 0.000 #&gt; .y10 0.519 0.033 15.711 0.000 #&gt; .x11 0.627 0.034 18.473 0.000 #&gt; .y11 0.575 0.033 17.293 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 1.062 0.034 31.012 0.000 #&gt; .y1 1.112 0.036 30.945 0.000 #&gt; .x2 0.440 0.016 26.796 0.000 #&gt; .y2 0.392 0.015 26.698 0.000 #&gt; .x3 0.361 0.014 26.107 0.000 #&gt; .y3 0.406 0.016 25.958 0.000 #&gt; .x4 0.339 0.013 26.022 0.000 #&gt; .y4 0.402 0.016 25.847 0.000 #&gt; .x5 0.340 0.013 25.598 0.000 #&gt; .y5 0.346 0.014 25.297 0.000 #&gt; .x6 0.344 0.013 26.425 0.000 #&gt; .y6 0.271 0.011 25.766 0.000 #&gt; .x7 0.308 0.012 25.913 0.000 #&gt; .y7 0.306 0.012 25.227 0.000 #&gt; .x8 0.325 0.013 25.062 0.000 #&gt; .y8 0.349 0.014 24.754 0.000 #&gt; .x9 0.369 0.015 25.268 0.000 #&gt; .y9 0.320 0.013 25.193 0.000 #&gt; .x10 0.395 0.017 23.634 0.000 #&gt; .y10 0.358 0.015 23.933 0.000 #&gt; .x11 0.362 0.015 24.042 0.000 #&gt; .y11 0.367 0.015 23.806 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 -0.034 0.010 -3.489 0.000 #&gt; dif2 0.020 0.010 2.051 0.040 #&gt; dif3 0.000 0.002 0.218 0.827 #&gt; #&gt; lavaan 0.6-7 ended normally after 54 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 117 #&gt; Number of equality constraints 56 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1309 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 4146.492 #&gt; Degrees of freedom 258 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; x1 ~ #&gt; oplx (ex) -0.020 0.002 -10.112 0.000 #&gt; x2 ~ #&gt; oplx (ex) -0.020 0.002 -10.112 0.000 #&gt; x3 ~ #&gt; oplx (ex) -0.020 0.002 -10.112 0.000 #&gt; x4 ~ #&gt; oplx (ex) -0.020 0.002 -10.112 0.000 #&gt; x5 ~ #&gt; oplx (ex) -0.020 0.002 -10.112 0.000 #&gt; x6 ~ #&gt; oplx (ex) -0.020 0.002 -10.112 0.000 #&gt; x7 ~ #&gt; oplx (ex) -0.020 0.002 -10.112 0.000 #&gt; x8 ~ #&gt; oplx (ex) -0.020 0.002 -10.112 0.000 #&gt; x9 ~ #&gt; oplx (ex) -0.020 0.002 -10.112 0.000 #&gt; x10 ~ #&gt; oplx (ex) -0.020 0.002 -10.112 0.000 #&gt; x11 ~ #&gt; oplx (ex) -0.020 0.002 -10.112 0.000 #&gt; y1 ~ #&gt; oply (ey) -0.014 0.002 -6.762 0.000 #&gt; y2 ~ #&gt; oply (ey) -0.014 0.002 -6.762 0.000 #&gt; y3 ~ #&gt; oply (ey) -0.014 0.002 -6.762 0.000 #&gt; y4 ~ #&gt; oply (ey) -0.014 0.002 -6.762 0.000 #&gt; y5 ~ #&gt; oply (ey) -0.014 0.002 -6.762 0.000 #&gt; y6 ~ #&gt; oply (ey) -0.014 0.002 -6.762 0.000 #&gt; y7 ~ #&gt; oply (ey) -0.014 0.002 -6.762 0.000 #&gt; y8 ~ #&gt; oply (ey) -0.014 0.002 -6.762 0.000 #&gt; y9 ~ #&gt; oply (ey) -0.014 0.002 -6.762 0.000 #&gt; y10 ~ #&gt; oply (ey) -0.014 0.002 -6.762 0.000 #&gt; y11 ~ #&gt; oply (ey) -0.014 0.002 -6.762 0.000 #&gt; x2 ~ #&gt; x1 (ax) 0.606 0.007 87.759 0.000 #&gt; y1 (bx) 0.143 0.008 18.295 0.000 #&gt; x3 ~ #&gt; x2 (ax) 0.606 0.007 87.759 0.000 #&gt; y2 (bx) 0.143 0.008 18.295 0.000 #&gt; x4 ~ #&gt; x3 (ax) 0.606 0.007 87.759 0.000 #&gt; y3 (bx) 0.143 0.008 18.295 0.000 #&gt; x5 ~ #&gt; x4 (ax) 0.606 0.007 87.759 0.000 #&gt; y4 (bx) 0.143 0.008 18.295 0.000 #&gt; x6 ~ #&gt; x5 (ax) 0.606 0.007 87.759 0.000 #&gt; y5 (bx) 0.143 0.008 18.295 0.000 #&gt; x7 ~ #&gt; x6 (ax) 0.606 0.007 87.759 0.000 #&gt; y6 (bx) 0.143 0.008 18.295 0.000 #&gt; x8 ~ #&gt; x7 (ax) 0.606 0.007 87.759 0.000 #&gt; y7 (bx) 0.143 0.008 18.295 0.000 #&gt; x9 ~ #&gt; x8 (ax) 0.606 0.007 87.759 0.000 #&gt; y8 (bx) 0.143 0.008 18.295 0.000 #&gt; x10 ~ #&gt; x9 (ax) 0.606 0.007 87.759 0.000 #&gt; y9 (bx) 0.143 0.008 18.295 0.000 #&gt; x11 ~ #&gt; x10 (ax) 0.606 0.007 87.759 0.000 #&gt; y10 (bx) 0.143 0.008 18.295 0.000 #&gt; y2 ~ #&gt; x1 (by) 0.152 0.007 21.574 0.000 #&gt; y1 (ay) 0.539 0.008 71.026 0.000 #&gt; y3 ~ #&gt; x2 (by) 0.152 0.007 21.574 0.000 #&gt; y2 (ay) 0.539 0.008 71.026 0.000 #&gt; y4 ~ #&gt; x3 (by) 0.152 0.007 21.574 0.000 #&gt; y3 (ay) 0.539 0.008 71.026 0.000 #&gt; y5 ~ #&gt; x4 (by) 0.152 0.007 21.574 0.000 #&gt; y4 (ay) 0.539 0.008 71.026 0.000 #&gt; y6 ~ #&gt; x5 (by) 0.152 0.007 21.574 0.000 #&gt; y5 (ay) 0.539 0.008 71.026 0.000 #&gt; y7 ~ #&gt; x6 (by) 0.152 0.007 21.574 0.000 #&gt; y6 (ay) 0.539 0.008 71.026 0.000 #&gt; y8 ~ #&gt; x7 (by) 0.152 0.007 21.574 0.000 #&gt; y7 (ay) 0.539 0.008 71.026 0.000 #&gt; y9 ~ #&gt; x8 (by) 0.152 0.007 21.574 0.000 #&gt; y8 (ay) 0.539 0.008 71.026 0.000 #&gt; y10 ~ #&gt; x9 (by) 0.152 0.007 21.574 0.000 #&gt; y9 (ay) 0.539 0.008 71.026 0.000 #&gt; y11 ~ #&gt; x10 (by) 0.152 0.007 21.574 0.000 #&gt; y10 (ay) 0.539 0.008 71.026 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 ~~ #&gt; .y1 0.421 0.025 16.634 0.000 #&gt; .x2 ~~ #&gt; .y2 0.140 0.016 8.814 0.000 #&gt; .x3 ~~ #&gt; .y3 0.099 0.016 6.276 0.000 #&gt; .x4 ~~ #&gt; .y4 0.111 0.017 6.581 0.000 #&gt; .x5 ~~ #&gt; .y5 0.064 0.014 4.462 0.000 #&gt; .x6 ~~ #&gt; .y6 0.133 0.016 8.390 0.000 #&gt; .x7 ~~ #&gt; .y7 0.091 0.014 6.399 0.000 #&gt; .x8 ~~ #&gt; .y8 0.085 0.016 5.396 0.000 #&gt; .x9 ~~ #&gt; .y9 0.102 0.017 6.129 0.000 #&gt; .x10 ~~ #&gt; .y10 0.093 0.017 5.451 0.000 #&gt; .x11 ~~ #&gt; .y11 0.071 0.017 4.076 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 3.891 0.034 115.721 0.000 #&gt; .y1 3.968 0.032 123.603 0.000 #&gt; .x2 1.174 0.045 26.127 0.000 #&gt; .y2 1.431 0.043 33.089 0.000 #&gt; .x3 1.144 0.045 25.458 0.000 #&gt; .y3 1.332 0.044 30.327 0.000 #&gt; .x4 1.145 0.045 25.352 0.000 #&gt; .y4 1.375 0.044 31.356 0.000 #&gt; .x5 1.262 0.045 28.302 0.000 #&gt; .y5 1.425 0.043 32.801 0.000 #&gt; .x6 1.065 0.046 23.342 0.000 #&gt; .y6 1.296 0.044 29.325 0.000 #&gt; .x7 1.163 0.045 26.035 0.000 #&gt; .y7 1.349 0.043 31.216 0.000 #&gt; .x8 1.211 0.045 26.754 0.000 #&gt; .y8 1.402 0.044 31.804 0.000 #&gt; .x9 1.196 0.046 26.224 0.000 #&gt; .y9 1.366 0.045 30.539 0.000 #&gt; .x10 1.185 0.046 25.819 0.000 #&gt; .y10 1.332 0.045 29.538 0.000 #&gt; .x11 1.237 0.046 26.737 0.000 #&gt; .y11 1.361 0.045 30.067 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 1.090 0.036 30.464 0.000 #&gt; .y1 0.914 0.030 30.174 0.000 #&gt; .x2 0.606 0.022 27.077 0.000 #&gt; .y2 0.539 0.020 27.048 0.000 #&gt; .x3 0.536 0.020 26.341 0.000 #&gt; .y3 0.559 0.021 26.210 0.000 #&gt; .x4 0.560 0.022 25.830 0.000 #&gt; .y4 0.534 0.021 25.457 0.000 #&gt; .x5 0.463 0.018 25.301 0.000 #&gt; .y5 0.479 0.019 25.243 0.000 #&gt; .x6 0.555 0.021 26.217 0.000 #&gt; .y6 0.534 0.020 26.107 0.000 #&gt; .x7 0.495 0.019 26.004 0.000 #&gt; .y7 0.447 0.017 25.646 0.000 #&gt; .x8 0.532 0.021 25.615 0.000 #&gt; .y8 0.508 0.020 25.372 0.000 #&gt; .x9 0.548 0.021 25.808 0.000 #&gt; .y9 0.542 0.022 25.161 0.000 #&gt; .x10 0.529 0.022 24.542 0.000 #&gt; .y10 0.533 0.022 24.184 0.000 #&gt; .x11 0.543 0.022 24.296 0.000 #&gt; .y11 0.522 0.022 23.746 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 0.067 0.011 6.294 0.000 #&gt; dif2 -0.009 0.011 -0.803 0.422 #&gt; dif3 -0.006 0.003 -2.275 0.023 3.9.2 RI-CLPM RICLPM &lt;- &#39; # Create between components (random intercepts) RIx =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 + 1*x5 + 1*x6 + 1*x7 + 1*x8 + 1*x9 + 1*x10 + 1*x11 RIy =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 + 1*y5 + 1*y6 + 1*y7 + 1*y8 + 1*y9 + 1*y10 + 1*y11 RIx ~ ex*oplx RIy ~ ey*oply # Create within-person centered variables wx1 =~ 1*x1 wx2 =~ 1*x2 wx3 =~ 1*x3 wx4 =~ 1*x4 wx5 =~ 1*x5 wx6 =~ 1*x6 wx7 =~ 1*x7 wx8 =~ 1*x8 wx9 =~ 1*x9 wx10 =~ 1*x10 wx11 =~ 1*x11 wy1 =~ 1*y1 wy2 =~ 1*y2 wy3 =~ 1*y3 wy4 =~ 1*y4 wy5 =~ 1*y5 wy6 =~ 1*y6 wy7 =~ 1*y7 wy8 =~ 1*y8 wy9 =~ 1*y9 wy10 =~ 1*y10 wy11 =~ 1*y11 # Estimate the lagged effects between the within-person centered variables. x2 ~ ax*x1 + bx*y1 x3 ~ ax*x2 + bx*y2 x4 ~ ax*x3 + bx*y3 x5 ~ ax*x4 + bx*y4 x6 ~ ax*x5 + bx*y5 x7 ~ ax*x6 + bx*y6 x8 ~ ax*x7 + bx*y7 x9 ~ ax*x8 + bx*y8 x10 ~ ax*x9 + bx*y9 x11 ~ ax*x10 + bx*y10 y2 ~ by*x1 + ay*y1 y3 ~ by*x2 + ay*y2 y4 ~ by*x3 + ay*y3 y5 ~ by*x4 + ay*y4 y6 ~ by*x5 + ay*y5 y7 ~ by*x6 + ay*y6 y8 ~ by*x7 + ay*y7 y9 ~ by*x8 + ay*y8 y10 ~ by*x9 + ay*y9 y11 ~ by*x10 + ay*y10 dif1 := ax - ay dif2 := bx - by dif3 := ex - ey # Estimate the (residual) covariance between the within-person centered variables wx1 ~~ wy1 # Covariance wx2 ~~ wy2 wx3 ~~ wy3 wx4 ~~ wy4 wx5 ~~ wy5 wx6 ~~ wy6 wx7 ~~ wy7 wx8 ~~ wy8 wx9 ~~ wy9 wx10 ~~ wy10 wx11 ~~ wy11 # Estimate the variance and covariance of the random intercepts. RIx ~~ RIx RIy ~~ RIy RIx ~~ RIy # Estimate the (residual) variance of the within-person centered variables. wx1 ~~ wx1 # Variances wy1 ~~ wy1 wx2 ~~ wx2 # Residual variances wy2 ~~ wy2 wx3 ~~ wx3 wy3 ~~ wy3 wx4 ~~ wx4 wy4 ~~ wy4 wx5 ~~ wx5 wy5 ~~ wy5 wx6 ~~ wx6 wy6 ~~ wy6 wx7 ~~ wx7 wy7 ~~ wy7 wx8 ~~ wx8 wy8 ~~ wy8 wx9 ~~ wx9 wy9 ~~ wy9 wx10 ~~ wx10 wy10 ~~ wy10 wx11 ~~ wx11 wy11 ~~ wy11 &#39; #Estimate models a bit faster: estimate &lt;- function(x) lavaan(RICLPM, data=x, missing = &quot;fiml.x&quot;, meanstructure = T ) library(future.apply) plan(multisession) results_temp &lt;- future_lapply(datalist_ori, estimate) summary(results_temp[[4]]) results[[21]] &lt;- results_temp[[1]] results[[22]] &lt;- results_temp[[2]] results[[23]] &lt;- results_temp[[3]] results[[24]] &lt;- results_temp[[4]] names(results)[21:24] &lt;- c(&quot;fitm2h2y1&quot;, &quot;fitm2h2y2&quot;,&quot;fitm2h2y3&quot;,&quot;fitm2h2y4&quot;) save(results, file=&quot;results.RData&quot;) load(&quot;addfiles/results.Rdata&quot;) summary(results[[21]]) summary(results[[22]]) summary(results[[23]]) summary(results[[24]]) #&gt; lavaan 0.6-7 ended normally after 32 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 78 #&gt; Number of equality constraints 36 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1415 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 1997.479 #&gt; Degrees of freedom 277 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (ex) 0.107 0.002 62.193 0.000 #&gt; RIy ~ #&gt; oply (ey) 0.108 0.002 66.277 0.000 #&gt; x2 ~ #&gt; x1 (ax) 0.131 0.010 13.320 0.000 #&gt; y1 (bx) 0.004 0.011 0.423 0.672 #&gt; x3 ~ #&gt; x2 (ax) 0.131 0.010 13.320 0.000 #&gt; y2 (bx) 0.004 0.011 0.423 0.672 #&gt; x4 ~ #&gt; x3 (ax) 0.131 0.010 13.320 0.000 #&gt; y3 (bx) 0.004 0.011 0.423 0.672 #&gt; x5 ~ #&gt; x4 (ax) 0.131 0.010 13.320 0.000 #&gt; y4 (bx) 0.004 0.011 0.423 0.672 #&gt; x6 ~ #&gt; x5 (ax) 0.131 0.010 13.320 0.000 #&gt; y5 (bx) 0.004 0.011 0.423 0.672 #&gt; x7 ~ #&gt; x6 (ax) 0.131 0.010 13.320 0.000 #&gt; y6 (bx) 0.004 0.011 0.423 0.672 #&gt; x8 ~ #&gt; x7 (ax) 0.131 0.010 13.320 0.000 #&gt; y7 (bx) 0.004 0.011 0.423 0.672 #&gt; x9 ~ #&gt; x8 (ax) 0.131 0.010 13.320 0.000 #&gt; y8 (bx) 0.004 0.011 0.423 0.672 #&gt; x10 ~ #&gt; x9 (ax) 0.131 0.010 13.320 0.000 #&gt; y9 (bx) 0.004 0.011 0.423 0.672 #&gt; x11 ~ #&gt; x10 (ax) 0.131 0.010 13.320 0.000 #&gt; y10 (bx) 0.004 0.011 0.423 0.672 #&gt; y2 ~ #&gt; x1 (by) 0.029 0.009 3.263 0.001 #&gt; y1 (ay) 0.100 0.010 9.719 0.000 #&gt; y3 ~ #&gt; x2 (by) 0.029 0.009 3.263 0.001 #&gt; y2 (ay) 0.100 0.010 9.719 0.000 #&gt; y4 ~ #&gt; x3 (by) 0.029 0.009 3.263 0.001 #&gt; y3 (ay) 0.100 0.010 9.719 0.000 #&gt; y5 ~ #&gt; x4 (by) 0.029 0.009 3.263 0.001 #&gt; y4 (ay) 0.100 0.010 9.719 0.000 #&gt; y6 ~ #&gt; x5 (by) 0.029 0.009 3.263 0.001 #&gt; y5 (ay) 0.100 0.010 9.719 0.000 #&gt; y7 ~ #&gt; x6 (by) 0.029 0.009 3.263 0.001 #&gt; y6 (ay) 0.100 0.010 9.719 0.000 #&gt; y8 ~ #&gt; x7 (by) 0.029 0.009 3.263 0.001 #&gt; y7 (ay) 0.100 0.010 9.719 0.000 #&gt; y9 ~ #&gt; x8 (by) 0.029 0.009 3.263 0.001 #&gt; y8 (ay) 0.100 0.010 9.719 0.000 #&gt; y10 ~ #&gt; x9 (by) 0.029 0.009 3.263 0.001 #&gt; y9 (ay) 0.100 0.010 9.719 0.000 #&gt; y11 ~ #&gt; x10 (by) 0.029 0.009 3.263 0.001 #&gt; y10 (ay) 0.100 0.010 9.719 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.208 0.026 8.085 0.000 #&gt; wx2 ~~ #&gt; wy2 0.109 0.020 5.432 0.000 #&gt; wx3 ~~ #&gt; wy3 0.136 0.019 7.010 0.000 #&gt; wx4 ~~ #&gt; wy4 0.092 0.018 5.055 0.000 #&gt; wx5 ~~ #&gt; wy5 0.087 0.021 4.158 0.000 #&gt; wx6 ~~ #&gt; wy6 0.057 0.016 3.567 0.000 #&gt; wx7 ~~ #&gt; wy7 0.094 0.016 5.990 0.000 #&gt; wx8 ~~ #&gt; wy8 0.074 0.018 4.163 0.000 #&gt; wx9 ~~ #&gt; wy9 0.096 0.019 5.030 0.000 #&gt; wx10 ~~ #&gt; wy10 0.032 0.020 1.629 0.103 #&gt; wx11 ~~ #&gt; wy11 0.101 0.021 4.810 0.000 #&gt; .RIx ~~ #&gt; .RIy 0.285 0.016 18.369 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; wx2 0.000 #&gt; wx3 0.000 #&gt; wx4 0.000 #&gt; wx5 0.000 #&gt; wx6 0.000 #&gt; wx7 0.000 #&gt; wx8 0.000 #&gt; wx9 0.000 #&gt; wx10 0.000 #&gt; wx11 0.000 #&gt; wy1 0.000 #&gt; wy2 0.000 #&gt; wy3 0.000 #&gt; wy4 0.000 #&gt; wy5 0.000 #&gt; wy6 0.000 #&gt; wy7 0.000 #&gt; wy8 0.000 #&gt; wy9 0.000 #&gt; wy10 0.000 #&gt; wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 0.610 0.024 25.889 0.000 #&gt; .RIy 0.411 0.017 23.879 0.000 #&gt; wx1 0.831 0.036 23.057 0.000 #&gt; wy1 0.706 0.031 22.464 0.000 #&gt; wx2 0.702 0.029 23.981 0.000 #&gt; wy2 0.567 0.024 23.148 0.000 #&gt; wx3 0.623 0.026 23.779 0.000 #&gt; wy3 0.542 0.024 22.994 0.000 #&gt; wx4 0.577 0.026 22.451 0.000 #&gt; wy4 0.463 0.021 21.622 0.000 #&gt; wx5 0.732 0.030 24.014 0.000 #&gt; wy5 0.546 0.024 23.234 0.000 #&gt; wx6 0.494 0.022 22.803 0.000 #&gt; wy6 0.410 0.019 21.986 0.000 #&gt; wx7 0.476 0.021 22.625 0.000 #&gt; wy7 0.438 0.020 22.399 0.000 #&gt; wx8 0.529 0.023 22.915 0.000 #&gt; wy8 0.490 0.022 22.687 0.000 #&gt; wx9 0.600 0.026 22.936 0.000 #&gt; wy9 0.493 0.022 21.983 0.000 #&gt; wx10 0.545 0.025 21.594 0.000 #&gt; wy10 0.490 0.023 21.146 0.000 #&gt; wx11 0.604 0.028 21.355 0.000 #&gt; wy11 0.523 0.026 20.465 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 0.031 0.014 2.157 0.031 #&gt; dif2 -0.025 0.013 -1.817 0.069 #&gt; dif3 -0.000 0.002 -0.137 0.891 #&gt; #&gt; lavaan 0.6-7 ended normally after 41 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 78 #&gt; Number of equality constraints 36 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1230 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 802.295 #&gt; Degrees of freedom 277 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (ex) 0.092 0.001 67.348 0.000 #&gt; RIy ~ #&gt; oply (ey) 0.102 0.001 74.487 0.000 #&gt; x2 ~ #&gt; x1 (ax) 0.064 0.009 7.024 0.000 #&gt; y1 (bx) 0.027 0.009 2.946 0.003 #&gt; x3 ~ #&gt; x2 (ax) 0.064 0.009 7.024 0.000 #&gt; y2 (bx) 0.027 0.009 2.946 0.003 #&gt; x4 ~ #&gt; x3 (ax) 0.064 0.009 7.024 0.000 #&gt; y3 (bx) 0.027 0.009 2.946 0.003 #&gt; x5 ~ #&gt; x4 (ax) 0.064 0.009 7.024 0.000 #&gt; y4 (bx) 0.027 0.009 2.946 0.003 #&gt; x6 ~ #&gt; x5 (ax) 0.064 0.009 7.024 0.000 #&gt; y5 (bx) 0.027 0.009 2.946 0.003 #&gt; x7 ~ #&gt; x6 (ax) 0.064 0.009 7.024 0.000 #&gt; y6 (bx) 0.027 0.009 2.946 0.003 #&gt; x8 ~ #&gt; x7 (ax) 0.064 0.009 7.024 0.000 #&gt; y7 (bx) 0.027 0.009 2.946 0.003 #&gt; x9 ~ #&gt; x8 (ax) 0.064 0.009 7.024 0.000 #&gt; y8 (bx) 0.027 0.009 2.946 0.003 #&gt; x10 ~ #&gt; x9 (ax) 0.064 0.009 7.024 0.000 #&gt; y9 (bx) 0.027 0.009 2.946 0.003 #&gt; x11 ~ #&gt; x10 (ax) 0.064 0.009 7.024 0.000 #&gt; y10 (bx) 0.027 0.009 2.946 0.003 #&gt; y2 ~ #&gt; x1 (by) 0.010 0.009 1.125 0.261 #&gt; y1 (ay) 0.065 0.009 7.188 0.000 #&gt; y3 ~ #&gt; x2 (by) 0.010 0.009 1.125 0.261 #&gt; y2 (ay) 0.065 0.009 7.188 0.000 #&gt; y4 ~ #&gt; x3 (by) 0.010 0.009 1.125 0.261 #&gt; y3 (ay) 0.065 0.009 7.188 0.000 #&gt; y5 ~ #&gt; x4 (by) 0.010 0.009 1.125 0.261 #&gt; y4 (ay) 0.065 0.009 7.188 0.000 #&gt; y6 ~ #&gt; x5 (by) 0.010 0.009 1.125 0.261 #&gt; y5 (ay) 0.065 0.009 7.188 0.000 #&gt; y7 ~ #&gt; x6 (by) 0.010 0.009 1.125 0.261 #&gt; y6 (ay) 0.065 0.009 7.188 0.000 #&gt; y8 ~ #&gt; x7 (by) 0.010 0.009 1.125 0.261 #&gt; y7 (ay) 0.065 0.009 7.188 0.000 #&gt; y9 ~ #&gt; x8 (by) 0.010 0.009 1.125 0.261 #&gt; y8 (ay) 0.065 0.009 7.188 0.000 #&gt; y10 ~ #&gt; x9 (by) 0.010 0.009 1.125 0.261 #&gt; y9 (ay) 0.065 0.009 7.188 0.000 #&gt; y11 ~ #&gt; x10 (by) 0.010 0.009 1.125 0.261 #&gt; y10 (ay) 0.065 0.009 7.188 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.063 0.013 4.778 0.000 #&gt; wx2 ~~ #&gt; wy2 0.045 0.013 3.552 0.000 #&gt; wx3 ~~ #&gt; wy3 0.027 0.011 2.439 0.015 #&gt; wx4 ~~ #&gt; wy4 0.043 0.011 3.995 0.000 #&gt; wx5 ~~ #&gt; wy5 0.043 0.011 3.939 0.000 #&gt; wx6 ~~ #&gt; wy6 0.023 0.011 2.175 0.030 #&gt; wx7 ~~ #&gt; wy7 0.032 0.011 2.881 0.004 #&gt; wx8 ~~ #&gt; wy8 0.029 0.011 2.593 0.010 #&gt; wx9 ~~ #&gt; wy9 0.012 0.013 0.971 0.331 #&gt; wx10 ~~ #&gt; wy10 0.043 0.013 3.403 0.001 #&gt; wx11 ~~ #&gt; wy11 0.063 0.013 4.896 0.000 #&gt; .RIx ~~ #&gt; .RIy 0.266 0.013 21.096 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; wx2 0.000 #&gt; wx3 0.000 #&gt; wx4 0.000 #&gt; wx5 0.000 #&gt; wx6 0.000 #&gt; wx7 0.000 #&gt; wx8 0.000 #&gt; wx9 0.000 #&gt; wx10 0.000 #&gt; wx11 0.000 #&gt; wy1 0.000 #&gt; wy2 0.000 #&gt; wy3 0.000 #&gt; wy4 0.000 #&gt; wy5 0.000 #&gt; wy6 0.000 #&gt; wy7 0.000 #&gt; wy8 0.000 #&gt; wy9 0.000 #&gt; wy10 0.000 #&gt; wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 0.467 0.017 27.763 0.000 #&gt; .RIy 0.442 0.016 28.012 0.000 #&gt; wx1 0.462 0.019 24.034 0.000 #&gt; wy1 0.389 0.017 23.503 0.000 #&gt; wx2 0.402 0.017 23.994 0.000 #&gt; wy2 0.424 0.017 24.485 0.000 #&gt; wx3 0.346 0.015 23.757 0.000 #&gt; wy3 0.313 0.013 23.292 0.000 #&gt; wx4 0.323 0.014 22.711 0.000 #&gt; wy4 0.322 0.014 22.565 0.000 #&gt; wx5 0.326 0.014 23.605 0.000 #&gt; wy5 0.332 0.014 23.560 0.000 #&gt; wx6 0.348 0.015 23.638 0.000 #&gt; wy6 0.304 0.013 23.253 0.000 #&gt; wx7 0.349 0.015 23.491 0.000 #&gt; wy7 0.328 0.014 23.564 0.000 #&gt; wx8 0.322 0.014 22.979 0.000 #&gt; wy8 0.327 0.014 23.170 0.000 #&gt; wx9 0.370 0.016 23.022 0.000 #&gt; wy9 0.373 0.016 22.741 0.000 #&gt; wx10 0.369 0.017 22.106 0.000 #&gt; wy10 0.338 0.016 21.599 0.000 #&gt; wx11 0.365 0.017 21.431 0.000 #&gt; wy11 0.328 0.016 20.622 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 -0.001 0.013 -0.050 0.960 #&gt; dif2 0.017 0.012 1.376 0.169 #&gt; dif3 -0.010 0.002 -6.291 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 65 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 78 #&gt; Number of equality constraints 36 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1290 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 5819.488 #&gt; Degrees of freedom 277 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (ex) 0.321 0.002 150.244 0.000 #&gt; RIy ~ #&gt; oply (ey) 0.334 0.002 148.908 0.000 #&gt; x2 ~ #&gt; x1 (ax) -0.029 0.008 -3.764 0.000 #&gt; y1 (bx) 0.062 0.008 7.961 0.000 #&gt; x3 ~ #&gt; x2 (ax) -0.029 0.008 -3.764 0.000 #&gt; y2 (bx) 0.062 0.008 7.961 0.000 #&gt; x4 ~ #&gt; x3 (ax) -0.029 0.008 -3.764 0.000 #&gt; y3 (bx) 0.062 0.008 7.961 0.000 #&gt; x5 ~ #&gt; x4 (ax) -0.029 0.008 -3.764 0.000 #&gt; y4 (bx) 0.062 0.008 7.961 0.000 #&gt; x6 ~ #&gt; x5 (ax) -0.029 0.008 -3.764 0.000 #&gt; y5 (bx) 0.062 0.008 7.961 0.000 #&gt; x7 ~ #&gt; x6 (ax) -0.029 0.008 -3.764 0.000 #&gt; y6 (bx) 0.062 0.008 7.961 0.000 #&gt; x8 ~ #&gt; x7 (ax) -0.029 0.008 -3.764 0.000 #&gt; y7 (bx) 0.062 0.008 7.961 0.000 #&gt; x9 ~ #&gt; x8 (ax) -0.029 0.008 -3.764 0.000 #&gt; y8 (bx) 0.062 0.008 7.961 0.000 #&gt; x10 ~ #&gt; x9 (ax) -0.029 0.008 -3.764 0.000 #&gt; y9 (bx) 0.062 0.008 7.961 0.000 #&gt; x11 ~ #&gt; x10 (ax) -0.029 0.008 -3.764 0.000 #&gt; y10 (bx) 0.062 0.008 7.961 0.000 #&gt; y2 ~ #&gt; x1 (by) 0.058 0.008 7.698 0.000 #&gt; y1 (ay) -0.023 0.008 -3.037 0.002 #&gt; y3 ~ #&gt; x2 (by) 0.058 0.008 7.698 0.000 #&gt; y2 (ay) -0.023 0.008 -3.037 0.002 #&gt; y4 ~ #&gt; x3 (by) 0.058 0.008 7.698 0.000 #&gt; y3 (ay) -0.023 0.008 -3.037 0.002 #&gt; y5 ~ #&gt; x4 (by) 0.058 0.008 7.698 0.000 #&gt; y4 (ay) -0.023 0.008 -3.037 0.002 #&gt; y6 ~ #&gt; x5 (by) 0.058 0.008 7.698 0.000 #&gt; y5 (ay) -0.023 0.008 -3.037 0.002 #&gt; y7 ~ #&gt; x6 (by) 0.058 0.008 7.698 0.000 #&gt; y6 (ay) -0.023 0.008 -3.037 0.002 #&gt; y8 ~ #&gt; x7 (by) 0.058 0.008 7.698 0.000 #&gt; y7 (ay) -0.023 0.008 -3.037 0.002 #&gt; y9 ~ #&gt; x8 (by) 0.058 0.008 7.698 0.000 #&gt; y8 (ay) -0.023 0.008 -3.037 0.002 #&gt; y10 ~ #&gt; x9 (by) 0.058 0.008 7.698 0.000 #&gt; y9 (ay) -0.023 0.008 -3.037 0.002 #&gt; y11 ~ #&gt; x10 (by) 0.058 0.008 7.698 0.000 #&gt; y10 (ay) -0.023 0.008 -3.037 0.002 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.076 0.011 7.020 0.000 #&gt; wx2 ~~ #&gt; wy2 0.040 0.009 4.729 0.000 #&gt; wx3 ~~ #&gt; wy3 0.071 0.009 7.893 0.000 #&gt; wx4 ~~ #&gt; wy4 0.031 0.008 3.893 0.000 #&gt; wx5 ~~ #&gt; wy5 0.038 0.007 5.179 0.000 #&gt; wx6 ~~ #&gt; wy6 0.036 0.007 5.318 0.000 #&gt; wx7 ~~ #&gt; wy7 0.033 0.007 4.761 0.000 #&gt; wx8 ~~ #&gt; wy8 0.024 0.007 3.179 0.001 #&gt; wx9 ~~ #&gt; wy9 0.033 0.008 4.099 0.000 #&gt; wx10 ~~ #&gt; wy10 0.061 0.010 6.083 0.000 #&gt; wx11 ~~ #&gt; wy11 0.067 0.010 7.022 0.000 #&gt; .RIx ~~ #&gt; .RIy 0.998 0.037 26.915 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; wx2 0.000 #&gt; wx3 0.000 #&gt; wx4 0.000 #&gt; wx5 0.000 #&gt; wx6 0.000 #&gt; wx7 0.000 #&gt; wx8 0.000 #&gt; wx9 0.000 #&gt; wx10 0.000 #&gt; wx11 0.000 #&gt; wy1 0.000 #&gt; wy2 0.000 #&gt; wy3 0.000 #&gt; wy4 0.000 #&gt; wy5 0.000 #&gt; wy6 0.000 #&gt; wy7 0.000 #&gt; wy8 0.000 #&gt; wy9 0.000 #&gt; wy10 0.000 #&gt; wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 1.565 0.043 36.053 0.000 #&gt; .RIy 1.627 0.045 36.277 0.000 #&gt; wx1 0.321 0.015 22.134 0.000 #&gt; wy1 0.327 0.014 22.765 0.000 #&gt; wx2 0.281 0.012 22.970 0.000 #&gt; wy2 0.237 0.011 22.474 0.000 #&gt; wx3 0.264 0.011 23.577 0.000 #&gt; wy3 0.302 0.013 23.913 0.000 #&gt; wx4 0.216 0.010 22.195 0.000 #&gt; wy4 0.238 0.011 22.435 0.000 #&gt; wx5 0.241 0.010 23.106 0.000 #&gt; wy5 0.194 0.009 22.701 0.000 #&gt; wx6 0.208 0.009 22.382 0.000 #&gt; wy6 0.177 0.008 21.961 0.000 #&gt; wx7 0.203 0.009 22.572 0.000 #&gt; wy7 0.198 0.009 22.483 0.000 #&gt; wx8 0.210 0.009 22.162 0.000 #&gt; wy8 0.219 0.010 22.772 0.000 #&gt; wx9 0.241 0.011 22.239 0.000 #&gt; wy9 0.209 0.009 22.067 0.000 #&gt; wx10 0.269 0.012 21.724 0.000 #&gt; wy10 0.260 0.012 21.617 0.000 #&gt; wx11 0.262 0.013 20.850 0.000 #&gt; wy11 0.243 0.012 20.395 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 -0.006 0.012 -0.528 0.597 #&gt; dif2 0.004 0.012 0.300 0.764 #&gt; dif3 -0.013 0.002 -6.125 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 45 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 78 #&gt; Number of equality constraints 36 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1309 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 6172.967 #&gt; Degrees of freedom 277 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (ex) 0.263 0.002 119.615 0.000 #&gt; RIy ~ #&gt; oply (ey) 0.286 0.002 129.685 0.000 #&gt; x2 ~ #&gt; x1 (ax) 0.016 0.008 2.021 0.043 #&gt; y1 (bx) 0.040 0.008 5.117 0.000 #&gt; x3 ~ #&gt; x2 (ax) 0.016 0.008 2.021 0.043 #&gt; y2 (bx) 0.040 0.008 5.117 0.000 #&gt; x4 ~ #&gt; x3 (ax) 0.016 0.008 2.021 0.043 #&gt; y3 (bx) 0.040 0.008 5.117 0.000 #&gt; x5 ~ #&gt; x4 (ax) 0.016 0.008 2.021 0.043 #&gt; y4 (bx) 0.040 0.008 5.117 0.000 #&gt; x6 ~ #&gt; x5 (ax) 0.016 0.008 2.021 0.043 #&gt; y5 (bx) 0.040 0.008 5.117 0.000 #&gt; x7 ~ #&gt; x6 (ax) 0.016 0.008 2.021 0.043 #&gt; y6 (bx) 0.040 0.008 5.117 0.000 #&gt; x8 ~ #&gt; x7 (ax) 0.016 0.008 2.021 0.043 #&gt; y7 (bx) 0.040 0.008 5.117 0.000 #&gt; x9 ~ #&gt; x8 (ax) 0.016 0.008 2.021 0.043 #&gt; y8 (bx) 0.040 0.008 5.117 0.000 #&gt; x10 ~ #&gt; x9 (ax) 0.016 0.008 2.021 0.043 #&gt; y9 (bx) 0.040 0.008 5.117 0.000 #&gt; x11 ~ #&gt; x10 (ax) 0.016 0.008 2.021 0.043 #&gt; y10 (bx) 0.040 0.008 5.117 0.000 #&gt; y2 ~ #&gt; x1 (by) 0.049 0.008 6.169 0.000 #&gt; y1 (ay) -0.003 0.008 -0.404 0.686 #&gt; y3 ~ #&gt; x2 (by) 0.049 0.008 6.169 0.000 #&gt; y2 (ay) -0.003 0.008 -0.404 0.686 #&gt; y4 ~ #&gt; x3 (by) 0.049 0.008 6.169 0.000 #&gt; y3 (ay) -0.003 0.008 -0.404 0.686 #&gt; y5 ~ #&gt; x4 (by) 0.049 0.008 6.169 0.000 #&gt; y4 (ay) -0.003 0.008 -0.404 0.686 #&gt; y6 ~ #&gt; x5 (by) 0.049 0.008 6.169 0.000 #&gt; y5 (ay) -0.003 0.008 -0.404 0.686 #&gt; y7 ~ #&gt; x6 (by) 0.049 0.008 6.169 0.000 #&gt; y6 (ay) -0.003 0.008 -0.404 0.686 #&gt; y8 ~ #&gt; x7 (by) 0.049 0.008 6.169 0.000 #&gt; y7 (ay) -0.003 0.008 -0.404 0.686 #&gt; y9 ~ #&gt; x8 (by) 0.049 0.008 6.169 0.000 #&gt; y8 (ay) -0.003 0.008 -0.404 0.686 #&gt; y10 ~ #&gt; x9 (by) 0.049 0.008 6.169 0.000 #&gt; y9 (ay) -0.003 0.008 -0.404 0.686 #&gt; y11 ~ #&gt; x10 (by) 0.049 0.008 6.169 0.000 #&gt; y10 (ay) -0.003 0.008 -0.404 0.686 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.133 0.017 7.847 0.000 #&gt; wx2 ~~ #&gt; wy2 0.041 0.013 3.141 0.002 #&gt; wx3 ~~ #&gt; wy3 0.064 0.013 5.012 0.000 #&gt; wx4 ~~ #&gt; wy4 0.035 0.012 2.818 0.005 #&gt; wx5 ~~ #&gt; wy5 0.018 0.012 1.514 0.130 #&gt; wx6 ~~ #&gt; wy6 0.058 0.012 4.811 0.000 #&gt; wx7 ~~ #&gt; wy7 0.052 0.012 4.514 0.000 #&gt; wx8 ~~ #&gt; wy8 0.044 0.013 3.515 0.000 #&gt; wx9 ~~ #&gt; wy9 0.035 0.013 2.638 0.008 #&gt; wx10 ~~ #&gt; wy10 0.048 0.014 3.412 0.001 #&gt; wx11 ~~ #&gt; wy11 0.053 0.016 3.301 0.001 #&gt; .RIx ~~ #&gt; .RIy 0.910 0.034 26.466 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; wx2 0.000 #&gt; wx3 0.000 #&gt; wx4 0.000 #&gt; wx5 0.000 #&gt; wx6 0.000 #&gt; wx7 0.000 #&gt; wx8 0.000 #&gt; wx9 0.000 #&gt; wx10 0.000 #&gt; wx11 0.000 #&gt; wy1 0.000 #&gt; wy2 0.000 #&gt; wy3 0.000 #&gt; wy4 0.000 #&gt; wy5 0.000 #&gt; wy6 0.000 #&gt; wy7 0.000 #&gt; wy8 0.000 #&gt; wy9 0.000 #&gt; wy10 0.000 #&gt; wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 1.475 0.043 34.155 0.000 #&gt; .RIy 1.355 0.040 34.092 0.000 #&gt; wx1 0.515 0.023 22.469 0.000 #&gt; wy1 0.499 0.022 22.710 0.000 #&gt; wx2 0.398 0.017 22.953 0.000 #&gt; wy2 0.394 0.017 22.918 0.000 #&gt; wx3 0.392 0.017 23.514 0.000 #&gt; wy3 0.408 0.017 23.379 0.000 #&gt; wx4 0.369 0.017 22.294 0.000 #&gt; wy4 0.320 0.015 21.716 0.000 #&gt; wx5 0.342 0.015 22.862 0.000 #&gt; wy5 0.349 0.015 22.930 0.000 #&gt; wx6 0.366 0.016 23.094 0.000 #&gt; wy6 0.351 0.015 22.843 0.000 #&gt; wx7 0.364 0.016 22.956 0.000 #&gt; wy7 0.305 0.014 22.303 0.000 #&gt; wx8 0.349 0.015 22.667 0.000 #&gt; wy8 0.383 0.017 22.891 0.000 #&gt; wx9 0.380 0.017 22.382 0.000 #&gt; wy9 0.383 0.017 22.293 0.000 #&gt; wx10 0.371 0.017 21.401 0.000 #&gt; wy10 0.388 0.018 21.242 0.000 #&gt; wx11 0.462 0.021 21.518 0.000 #&gt; wy11 0.383 0.019 20.177 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 0.019 0.012 1.649 0.099 #&gt; dif2 -0.009 0.012 -0.781 0.435 #&gt; dif3 -0.024 0.002 -10.618 0.000 3.9.3 SC-RI-CLPM SCCLPM &lt;- &#39; # Create between components (random intercepts) RIx =~ 1*x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 RIy =~ 1*y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9 + y10 + y11 RIx ~ ex*oplx RIy ~ ey*oply # Create within-person centered variables wx1 =~ 1*x1 wx2 =~ 1*x2 wx3 =~ 1*x3 wx4 =~ 1*x4 wx5 =~ 1*x5 wx6 =~ 1*x6 wx7 =~ 1*x7 wx8 =~ 1*x8 wx9 =~ 1*x9 wx10 =~ 1*x10 wx11 =~ 1*x11 wy1 =~ 1*y1 wy2 =~ 1*y2 wy3 =~ 1*y3 wy4 =~ 1*y4 wy5 =~ 1*y5 wy6 =~ 1*y6 wy7 =~ 1*y7 wy8 =~ 1*y8 wy9 =~ 1*y9 wy10 =~ 1*y10 wy11 =~ 1*y11 # Estimate the lagged effects between the within-person centered variables. x2 ~ ax*x1 + bx*y1 x3 ~ ax*x2 + bx*y2 x4 ~ ax*x3 + bx*y3 x5 ~ ax*x4 + bx*y4 x6 ~ ax*x5 + bx*y5 x7 ~ ax*x6 + bx*y6 x8 ~ ax*x7 + bx*y7 x9 ~ ax*x8 + bx*y8 x10 ~ ax*x9 + bx*y9 x11 ~ ax*x10 + bx*y10 y2 ~ by*x1 + ay*y1 y3 ~ by*x2 + ay*y2 y4 ~ by*x3 + ay*y3 y5 ~ by*x4 + ay*y4 y6 ~ by*x5 + ay*y5 y7 ~ by*x6 + ay*y6 y8 ~ by*x7 + ay*y7 y9 ~ by*x8 + ay*y8 y10 ~ by*x9 + ay*y9 y11 ~ by*x10 + ay*y10 dif1 := ax - ay dif2 := bx - by dif3 := ex - ey # Estimate the (residual) covariance between the within-person centered variables wx1 ~~ wy1 # Covariance wx2 ~~ wy2 wx3 ~~ wy3 wx4 ~~ wy4 wx5 ~~ wy5 wx6 ~~ wy6 wx7 ~~ wy7 wx8 ~~ wy8 wx9 ~~ wy9 wx10 ~~ wy10 wx11 ~~ wy11 # Estimate the variance and covariance of the random intercepts. RIx ~~ RIx RIy ~~ RIy RIx ~~ RIy # Estimate the (residual) variance of the within-person centered variables. wx1 ~~ wx1 # Variances wy1 ~~ wy1 wx2 ~~ wx2 # Residual variances wy2 ~~ wy2 wx3 ~~ wx3 wy3 ~~ wy3 wx4 ~~ wx4 wy4 ~~ wy4 wx5 ~~ wx5 wy5 ~~ wy5 wx6 ~~ wx6 wy6 ~~ wy6 wx7 ~~ wx7 wy7 ~~ wy7 wx8 ~~ wx8 wy8 ~~ wy8 wx9 ~~ wx9 wy9 ~~ wy9 wx10 ~~ wx10 wy10 ~~ wy10 wx11 ~~ wx11 wy11 ~~ wy11 &#39; #Estimate models a bit faster: estimate &lt;- function(x) lavaan(SCCLPM, data=x, missing = &quot;fiml.x&quot;, meanstructure = T ) library(future.apply) plan(multisession) results_temp &lt;- future_lapply(datalist_ori, estimate) summary(results_temp[[4]]) results[[25]] &lt;- results_temp[[1]] results[[26]] &lt;- results_temp[[2]] results[[27]] &lt;- results_temp[[3]] results[[28]] &lt;- results_temp[[4]] names(results)[25:28] &lt;- c(&quot;fitm3h2y1&quot;, &quot;fitm3h2y2&quot;,&quot;fitm3h2y3&quot;,&quot;fitm3h2y4&quot;) save(results, file=&quot;results.RData&quot;) load(&quot;addfiles/results.Rdata&quot;) summary(results[[25]]) summary(results[[26]]) summary(results[[27]]) summary(results[[28]]) #&gt; lavaan 0.6-7 ended normally after 51 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 98 #&gt; Number of equality constraints 36 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1415 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 1144.862 #&gt; Degrees of freedom 257 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 0.763 0.021 36.188 0.000 #&gt; x3 0.767 0.021 37.058 0.000 #&gt; x4 0.637 0.021 30.424 0.000 #&gt; x5 0.782 0.021 37.498 0.000 #&gt; x6 0.666 0.020 33.092 0.000 #&gt; x7 0.626 0.019 33.115 0.000 #&gt; x8 0.685 0.019 35.811 0.000 #&gt; x9 0.626 0.020 32.096 0.000 #&gt; x10 0.709 0.020 35.892 0.000 #&gt; x11 0.741 0.021 35.665 0.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 0.775 0.022 35.802 0.000 #&gt; y3 0.776 0.021 36.197 0.000 #&gt; y4 0.625 0.022 28.846 0.000 #&gt; y5 0.672 0.021 32.760 0.000 #&gt; y6 0.652 0.020 32.553 0.000 #&gt; y7 0.617 0.019 31.933 0.000 #&gt; y8 0.661 0.019 34.008 0.000 #&gt; y9 0.657 0.020 32.846 0.000 #&gt; y10 0.735 0.020 36.116 0.000 #&gt; y11 0.762 0.022 35.406 0.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (ex) 0.126 0.002 61.856 0.000 #&gt; RIy ~ #&gt; oply (ey) 0.128 0.002 65.198 0.000 #&gt; x2 ~ #&gt; x1 (ax) 0.218 0.012 18.700 0.000 #&gt; y1 (bx) 0.064 0.011 5.987 0.000 #&gt; x3 ~ #&gt; x2 (ax) 0.218 0.012 18.700 0.000 #&gt; y2 (bx) 0.064 0.011 5.987 0.000 #&gt; x4 ~ #&gt; x3 (ax) 0.218 0.012 18.700 0.000 #&gt; y3 (bx) 0.064 0.011 5.987 0.000 #&gt; x5 ~ #&gt; x4 (ax) 0.218 0.012 18.700 0.000 #&gt; y4 (bx) 0.064 0.011 5.987 0.000 #&gt; x6 ~ #&gt; x5 (ax) 0.218 0.012 18.700 0.000 #&gt; y5 (bx) 0.064 0.011 5.987 0.000 #&gt; x7 ~ #&gt; x6 (ax) 0.218 0.012 18.700 0.000 #&gt; y6 (bx) 0.064 0.011 5.987 0.000 #&gt; x8 ~ #&gt; x7 (ax) 0.218 0.012 18.700 0.000 #&gt; y7 (bx) 0.064 0.011 5.987 0.000 #&gt; x9 ~ #&gt; x8 (ax) 0.218 0.012 18.700 0.000 #&gt; y8 (bx) 0.064 0.011 5.987 0.000 #&gt; x10 ~ #&gt; x9 (ax) 0.218 0.012 18.700 0.000 #&gt; y9 (bx) 0.064 0.011 5.987 0.000 #&gt; x11 ~ #&gt; x10 (ax) 0.218 0.012 18.700 0.000 #&gt; y10 (bx) 0.064 0.011 5.987 0.000 #&gt; y2 ~ #&gt; x1 (by) 0.078 0.009 8.823 0.000 #&gt; y1 (ay) 0.190 0.012 15.440 0.000 #&gt; y3 ~ #&gt; x2 (by) 0.078 0.009 8.823 0.000 #&gt; y2 (ay) 0.190 0.012 15.440 0.000 #&gt; y4 ~ #&gt; x3 (by) 0.078 0.009 8.823 0.000 #&gt; y3 (ay) 0.190 0.012 15.440 0.000 #&gt; y5 ~ #&gt; x4 (by) 0.078 0.009 8.823 0.000 #&gt; y4 (ay) 0.190 0.012 15.440 0.000 #&gt; y6 ~ #&gt; x5 (by) 0.078 0.009 8.823 0.000 #&gt; y5 (ay) 0.190 0.012 15.440 0.000 #&gt; y7 ~ #&gt; x6 (by) 0.078 0.009 8.823 0.000 #&gt; y6 (ay) 0.190 0.012 15.440 0.000 #&gt; y8 ~ #&gt; x7 (by) 0.078 0.009 8.823 0.000 #&gt; y7 (ay) 0.190 0.012 15.440 0.000 #&gt; y9 ~ #&gt; x8 (by) 0.078 0.009 8.823 0.000 #&gt; y8 (ay) 0.190 0.012 15.440 0.000 #&gt; y10 ~ #&gt; x9 (by) 0.078 0.009 8.823 0.000 #&gt; y9 (ay) 0.190 0.012 15.440 0.000 #&gt; y11 ~ #&gt; x10 (by) 0.078 0.009 8.823 0.000 #&gt; y10 (ay) 0.190 0.012 15.440 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.124 0.022 5.562 0.000 #&gt; wx2 ~~ #&gt; wy2 0.088 0.020 4.470 0.000 #&gt; wx3 ~~ #&gt; wy3 0.088 0.018 4.835 0.000 #&gt; wx4 ~~ #&gt; wy4 0.099 0.018 5.406 0.000 #&gt; wx5 ~~ #&gt; wy5 0.103 0.021 4.818 0.000 #&gt; wx6 ~~ #&gt; wy6 0.069 0.017 4.166 0.000 #&gt; wx7 ~~ #&gt; wy7 0.086 0.015 5.582 0.000 #&gt; wx8 ~~ #&gt; wy8 0.080 0.018 4.432 0.000 #&gt; wx9 ~~ #&gt; wy9 0.096 0.019 5.013 0.000 #&gt; wx10 ~~ #&gt; wy10 0.038 0.020 1.888 0.059 #&gt; wx11 ~~ #&gt; wy11 0.086 0.021 4.206 0.000 #&gt; .RIx ~~ #&gt; .RIy 0.327 0.020 16.012 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; wx2 0.000 #&gt; wx3 0.000 #&gt; wx4 0.000 #&gt; wx5 0.000 #&gt; wx6 0.000 #&gt; wx7 0.000 #&gt; wx8 0.000 #&gt; wx9 0.000 #&gt; wx10 0.000 #&gt; wx11 0.000 #&gt; wy1 0.000 #&gt; wy2 0.000 #&gt; wy3 0.000 #&gt; wy4 0.000 #&gt; wy5 0.000 #&gt; wy6 0.000 #&gt; wy7 0.000 #&gt; wy8 0.000 #&gt; wy9 0.000 #&gt; wy10 0.000 #&gt; wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 0.834 0.034 24.576 0.000 #&gt; .RIy 0.547 0.024 22.904 0.000 #&gt; wx1 0.689 0.032 21.686 0.000 #&gt; wy1 0.587 0.028 21.267 0.000 #&gt; wx2 0.684 0.029 23.634 0.000 #&gt; wy2 0.553 0.024 22.641 0.000 #&gt; wx3 0.577 0.025 23.050 0.000 #&gt; wy3 0.491 0.022 22.141 0.000 #&gt; wx4 0.613 0.027 23.124 0.000 #&gt; wy4 0.491 0.022 22.394 0.000 #&gt; wx5 0.714 0.031 23.172 0.000 #&gt; wy5 0.572 0.024 23.422 0.000 #&gt; wx6 0.525 0.023 23.217 0.000 #&gt; wy6 0.439 0.020 22.490 0.000 #&gt; wx7 0.493 0.021 23.425 0.000 #&gt; wy7 0.442 0.019 23.077 0.000 #&gt; wx8 0.555 0.024 23.101 0.000 #&gt; wy8 0.507 0.022 22.998 0.000 #&gt; wx9 0.610 0.026 23.509 0.000 #&gt; wy9 0.516 0.023 22.383 0.000 #&gt; wx10 0.567 0.026 21.556 0.000 #&gt; wy10 0.500 0.024 20.918 0.000 #&gt; wx11 0.599 0.028 21.091 0.000 #&gt; wy11 0.496 0.025 20.045 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 0.028 0.017 1.649 0.099 #&gt; dif2 -0.014 0.013 -1.063 0.288 #&gt; dif3 -0.002 0.002 -0.695 0.487 #&gt; #&gt; lavaan 0.6-7 ended normally after 50 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 98 #&gt; Number of equality constraints 36 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1230 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 689.156 #&gt; Degrees of freedom 257 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 0.883 0.021 41.305 0.000 #&gt; x3 0.889 0.021 41.388 0.000 #&gt; x4 0.890 0.022 40.779 0.000 #&gt; x5 0.900 0.022 41.363 0.000 #&gt; x6 0.883 0.022 39.901 0.000 #&gt; x7 0.902 0.022 40.899 0.000 #&gt; x8 0.858 0.022 39.387 0.000 #&gt; x9 0.839 0.022 38.446 0.000 #&gt; x10 0.906 0.022 40.350 0.000 #&gt; x11 0.873 0.023 38.683 0.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 0.875 0.021 42.424 0.000 #&gt; y3 0.902 0.020 44.815 0.000 #&gt; y4 0.897 0.021 42.970 0.000 #&gt; y5 0.902 0.021 43.112 0.000 #&gt; y6 0.894 0.021 43.056 0.000 #&gt; y7 0.895 0.021 43.037 0.000 #&gt; y8 0.858 0.021 41.292 0.000 #&gt; y9 0.852 0.021 40.471 0.000 #&gt; y10 0.886 0.021 42.419 0.000 #&gt; y11 0.889 0.021 41.479 0.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (ex) 0.096 0.002 61.519 0.000 #&gt; RIy ~ #&gt; oply (ey) 0.106 0.002 68.404 0.000 #&gt; x2 ~ #&gt; x1 (ax) 0.100 0.011 8.975 0.000 #&gt; y1 (bx) 0.053 0.010 5.351 0.000 #&gt; x3 ~ #&gt; x2 (ax) 0.100 0.011 8.975 0.000 #&gt; y2 (bx) 0.053 0.010 5.351 0.000 #&gt; x4 ~ #&gt; x3 (ax) 0.100 0.011 8.975 0.000 #&gt; y3 (bx) 0.053 0.010 5.351 0.000 #&gt; x5 ~ #&gt; x4 (ax) 0.100 0.011 8.975 0.000 #&gt; y4 (bx) 0.053 0.010 5.351 0.000 #&gt; x6 ~ #&gt; x5 (ax) 0.100 0.011 8.975 0.000 #&gt; y5 (bx) 0.053 0.010 5.351 0.000 #&gt; x7 ~ #&gt; x6 (ax) 0.100 0.011 8.975 0.000 #&gt; y6 (bx) 0.053 0.010 5.351 0.000 #&gt; x8 ~ #&gt; x7 (ax) 0.100 0.011 8.975 0.000 #&gt; y7 (bx) 0.053 0.010 5.351 0.000 #&gt; x9 ~ #&gt; x8 (ax) 0.100 0.011 8.975 0.000 #&gt; y8 (bx) 0.053 0.010 5.351 0.000 #&gt; x10 ~ #&gt; x9 (ax) 0.100 0.011 8.975 0.000 #&gt; y9 (bx) 0.053 0.010 5.351 0.000 #&gt; x11 ~ #&gt; x10 (ax) 0.100 0.011 8.975 0.000 #&gt; y10 (bx) 0.053 0.010 5.351 0.000 #&gt; y2 ~ #&gt; x1 (by) 0.036 0.009 3.775 0.000 #&gt; y1 (ay) 0.104 0.011 9.128 0.000 #&gt; y3 ~ #&gt; x2 (by) 0.036 0.009 3.775 0.000 #&gt; y2 (ay) 0.104 0.011 9.128 0.000 #&gt; y4 ~ #&gt; x3 (by) 0.036 0.009 3.775 0.000 #&gt; y3 (ay) 0.104 0.011 9.128 0.000 #&gt; y5 ~ #&gt; x4 (by) 0.036 0.009 3.775 0.000 #&gt; y4 (ay) 0.104 0.011 9.128 0.000 #&gt; y6 ~ #&gt; x5 (by) 0.036 0.009 3.775 0.000 #&gt; y5 (ay) 0.104 0.011 9.128 0.000 #&gt; y7 ~ #&gt; x6 (by) 0.036 0.009 3.775 0.000 #&gt; y6 (ay) 0.104 0.011 9.128 0.000 #&gt; y8 ~ #&gt; x7 (by) 0.036 0.009 3.775 0.000 #&gt; y7 (ay) 0.104 0.011 9.128 0.000 #&gt; y9 ~ #&gt; x8 (by) 0.036 0.009 3.775 0.000 #&gt; y8 (ay) 0.104 0.011 9.128 0.000 #&gt; y10 ~ #&gt; x9 (by) 0.036 0.009 3.775 0.000 #&gt; y9 (ay) 0.104 0.011 9.128 0.000 #&gt; y11 ~ #&gt; x10 (by) 0.036 0.009 3.775 0.000 #&gt; y10 (ay) 0.104 0.011 9.128 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.059 0.013 4.582 0.000 #&gt; wx2 ~~ #&gt; wy2 0.048 0.013 3.756 0.000 #&gt; wx3 ~~ #&gt; wy3 0.031 0.011 2.813 0.005 #&gt; wx4 ~~ #&gt; wy4 0.044 0.011 4.011 0.000 #&gt; wx5 ~~ #&gt; wy5 0.044 0.011 4.004 0.000 #&gt; wx6 ~~ #&gt; wy6 0.027 0.011 2.507 0.012 #&gt; wx7 ~~ #&gt; wy7 0.033 0.011 2.939 0.003 #&gt; wx8 ~~ #&gt; wy8 0.032 0.011 2.895 0.004 #&gt; wx9 ~~ #&gt; wy9 0.011 0.013 0.864 0.388 #&gt; wx10 ~~ #&gt; wy10 0.047 0.013 3.656 0.000 #&gt; wx11 ~~ #&gt; wy11 0.062 0.013 4.858 0.000 #&gt; .RIx ~~ #&gt; .RIy 0.276 0.014 20.076 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; wx2 0.000 #&gt; wx3 0.000 #&gt; wx4 0.000 #&gt; wx5 0.000 #&gt; wx6 0.000 #&gt; wx7 0.000 #&gt; wx8 0.000 #&gt; wx9 0.000 #&gt; wx10 0.000 #&gt; wx11 0.000 #&gt; wy1 0.000 #&gt; wy2 0.000 #&gt; wy3 0.000 #&gt; wy4 0.000 #&gt; wy5 0.000 #&gt; wy6 0.000 #&gt; wy7 0.000 #&gt; wy8 0.000 #&gt; wy9 0.000 #&gt; wy10 0.000 #&gt; wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 0.517 0.020 25.624 0.000 #&gt; .RIy 0.482 0.018 26.510 0.000 #&gt; wx1 0.449 0.019 23.603 0.000 #&gt; wy1 0.377 0.016 23.042 0.000 #&gt; wx2 0.407 0.017 23.965 0.000 #&gt; wy2 0.429 0.017 24.601 0.000 #&gt; wx3 0.354 0.015 23.575 0.000 #&gt; wy3 0.317 0.014 23.087 0.000 #&gt; wx4 0.325 0.014 22.599 0.000 #&gt; wy4 0.327 0.015 22.411 0.000 #&gt; wx5 0.327 0.014 23.315 0.000 #&gt; wy5 0.335 0.014 23.309 0.000 #&gt; wx6 0.355 0.015 23.545 0.000 #&gt; wy6 0.308 0.013 23.106 0.000 #&gt; wx7 0.349 0.015 23.275 0.000 #&gt; wy7 0.331 0.014 23.418 0.000 #&gt; wx8 0.329 0.014 23.031 0.000 #&gt; wy8 0.334 0.014 23.240 0.000 #&gt; wx9 0.373 0.016 23.223 0.000 #&gt; wy9 0.378 0.017 22.877 0.000 #&gt; wx10 0.370 0.017 21.705 0.000 #&gt; wy10 0.344 0.016 21.448 0.000 #&gt; wx11 0.366 0.017 21.458 0.000 #&gt; wy11 0.326 0.016 20.542 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 -0.004 0.016 -0.256 0.798 #&gt; dif2 0.017 0.013 1.310 0.190 #&gt; dif3 -0.010 0.002 -5.415 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 103 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 98 #&gt; Number of equality constraints 36 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1290 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 5022.772 #&gt; Degrees of freedom 257 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 0.686 0.015 45.498 0.000 #&gt; x3 0.683 0.015 45.363 0.000 #&gt; x4 0.692 0.015 45.982 0.000 #&gt; x5 0.691 0.015 45.416 0.000 #&gt; x6 0.695 0.015 45.675 0.000 #&gt; x7 0.700 0.015 45.845 0.000 #&gt; x8 0.701 0.015 45.549 0.000 #&gt; x9 0.692 0.015 44.722 0.000 #&gt; x10 0.691 0.015 44.768 0.000 #&gt; x11 0.702 0.015 45.625 0.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 0.718 0.014 49.717 0.000 #&gt; y3 0.712 0.015 48.836 0.000 #&gt; y4 0.724 0.015 49.767 0.000 #&gt; y5 0.726 0.015 49.612 0.000 #&gt; y6 0.726 0.015 49.526 0.000 #&gt; y7 0.729 0.015 49.555 0.000 #&gt; y8 0.729 0.015 49.069 0.000 #&gt; y9 0.722 0.015 48.614 0.000 #&gt; y10 0.720 0.015 48.332 0.000 #&gt; y11 0.730 0.015 49.132 0.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (ex) 0.328 0.002 150.866 0.000 #&gt; RIy ~ #&gt; oply (ey) 0.341 0.002 149.368 0.000 #&gt; x2 ~ #&gt; x1 (ax) 0.149 0.012 12.205 0.000 #&gt; y1 (bx) 0.170 0.009 19.343 0.000 #&gt; x3 ~ #&gt; x2 (ax) 0.149 0.012 12.205 0.000 #&gt; y2 (bx) 0.170 0.009 19.343 0.000 #&gt; x4 ~ #&gt; x3 (ax) 0.149 0.012 12.205 0.000 #&gt; y3 (bx) 0.170 0.009 19.343 0.000 #&gt; x5 ~ #&gt; x4 (ax) 0.149 0.012 12.205 0.000 #&gt; y4 (bx) 0.170 0.009 19.343 0.000 #&gt; x6 ~ #&gt; x5 (ax) 0.149 0.012 12.205 0.000 #&gt; y5 (bx) 0.170 0.009 19.343 0.000 #&gt; x7 ~ #&gt; x6 (ax) 0.149 0.012 12.205 0.000 #&gt; y6 (bx) 0.170 0.009 19.343 0.000 #&gt; x8 ~ #&gt; x7 (ax) 0.149 0.012 12.205 0.000 #&gt; y7 (bx) 0.170 0.009 19.343 0.000 #&gt; x9 ~ #&gt; x8 (ax) 0.149 0.012 12.205 0.000 #&gt; y8 (bx) 0.170 0.009 19.343 0.000 #&gt; x10 ~ #&gt; x9 (ax) 0.149 0.012 12.205 0.000 #&gt; y9 (bx) 0.170 0.009 19.343 0.000 #&gt; x11 ~ #&gt; x10 (ax) 0.149 0.012 12.205 0.000 #&gt; y10 (bx) 0.170 0.009 19.343 0.000 #&gt; y2 ~ #&gt; x1 (by) 0.156 0.009 17.816 0.000 #&gt; y1 (ay) 0.137 0.012 11.742 0.000 #&gt; y3 ~ #&gt; x2 (by) 0.156 0.009 17.816 0.000 #&gt; y2 (ay) 0.137 0.012 11.742 0.000 #&gt; y4 ~ #&gt; x3 (by) 0.156 0.009 17.816 0.000 #&gt; y3 (ay) 0.137 0.012 11.742 0.000 #&gt; y5 ~ #&gt; x4 (by) 0.156 0.009 17.816 0.000 #&gt; y4 (ay) 0.137 0.012 11.742 0.000 #&gt; y6 ~ #&gt; x5 (by) 0.156 0.009 17.816 0.000 #&gt; y5 (ay) 0.137 0.012 11.742 0.000 #&gt; y7 ~ #&gt; x6 (by) 0.156 0.009 17.816 0.000 #&gt; y6 (ay) 0.137 0.012 11.742 0.000 #&gt; y8 ~ #&gt; x7 (by) 0.156 0.009 17.816 0.000 #&gt; y7 (ay) 0.137 0.012 11.742 0.000 #&gt; y9 ~ #&gt; x8 (by) 0.156 0.009 17.816 0.000 #&gt; y8 (ay) 0.137 0.012 11.742 0.000 #&gt; y10 ~ #&gt; x9 (by) 0.156 0.009 17.816 0.000 #&gt; y9 (ay) 0.137 0.012 11.742 0.000 #&gt; y11 ~ #&gt; x10 (by) 0.156 0.009 17.816 0.000 #&gt; y10 (ay) 0.137 0.012 11.742 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.065 0.012 5.508 0.000 #&gt; wx2 ~~ #&gt; wy2 0.052 0.009 5.578 0.000 #&gt; wx3 ~~ #&gt; wy3 0.071 0.009 7.727 0.000 #&gt; wx4 ~~ #&gt; wy4 0.041 0.008 5.019 0.000 #&gt; wx5 ~~ #&gt; wy5 0.050 0.008 6.279 0.000 #&gt; wx6 ~~ #&gt; wy6 0.047 0.007 6.644 0.000 #&gt; wx7 ~~ #&gt; wy7 0.042 0.007 5.804 0.000 #&gt; wx8 ~~ #&gt; wy8 0.037 0.008 4.603 0.000 #&gt; wx9 ~~ #&gt; wy9 0.041 0.008 5.043 0.000 #&gt; wx10 ~~ #&gt; wy10 0.072 0.010 6.895 0.000 #&gt; wx11 ~~ #&gt; wy11 0.067 0.009 7.105 0.000 #&gt; .RIx ~~ #&gt; .RIy 0.934 0.038 24.664 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; wx2 0.000 #&gt; wx3 0.000 #&gt; wx4 0.000 #&gt; wx5 0.000 #&gt; wx6 0.000 #&gt; wx7 0.000 #&gt; wx8 0.000 #&gt; wx9 0.000 #&gt; wx10 0.000 #&gt; wx11 0.000 #&gt; wy1 0.000 #&gt; wy2 0.000 #&gt; wy3 0.000 #&gt; wy4 0.000 #&gt; wy5 0.000 #&gt; wy6 0.000 #&gt; wy7 0.000 #&gt; wy8 0.000 #&gt; wy9 0.000 #&gt; wy10 0.000 #&gt; wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 1.626 0.046 35.382 0.000 #&gt; .RIy 1.690 0.047 35.742 0.000 #&gt; wx1 0.325 0.016 20.142 0.000 #&gt; wy1 0.337 0.016 21.188 0.000 #&gt; wx2 0.307 0.013 22.959 0.000 #&gt; wy2 0.256 0.011 22.443 0.000 #&gt; wx3 0.268 0.011 23.451 0.000 #&gt; wy3 0.308 0.013 23.721 0.000 #&gt; wx4 0.224 0.010 22.193 0.000 #&gt; wy4 0.254 0.011 22.403 0.000 #&gt; wx5 0.256 0.011 22.825 0.000 #&gt; wy5 0.213 0.009 22.451 0.000 #&gt; wx6 0.227 0.010 22.418 0.000 #&gt; wy6 0.185 0.008 21.951 0.000 #&gt; wx7 0.215 0.010 22.461 0.000 #&gt; wy7 0.209 0.009 22.363 0.000 #&gt; wx8 0.225 0.010 21.896 0.000 #&gt; wy8 0.234 0.010 22.539 0.000 #&gt; wx9 0.256 0.011 22.348 0.000 #&gt; wy9 0.215 0.010 22.082 0.000 #&gt; wx10 0.289 0.013 21.592 0.000 #&gt; wy10 0.269 0.013 21.477 0.000 #&gt; wx11 0.256 0.012 20.810 0.000 #&gt; wy11 0.245 0.012 20.453 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 0.012 0.017 0.718 0.473 #&gt; dif2 0.014 0.013 1.094 0.274 #&gt; dif3 -0.013 0.002 -5.771 0.000 #&gt; #&gt; lavaan 0.6-7 ended normally after 69 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 98 #&gt; Number of equality constraints 36 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1309 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 5574.731 #&gt; Degrees of freedom 257 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 0.706 0.016 43.047 0.000 #&gt; x3 0.703 0.017 42.527 0.000 #&gt; x4 0.705 0.017 42.711 0.000 #&gt; x5 0.733 0.016 44.506 0.000 #&gt; x6 0.697 0.017 41.287 0.000 #&gt; x7 0.710 0.016 43.026 0.000 #&gt; x8 0.721 0.017 43.497 0.000 #&gt; x9 0.726 0.017 43.078 0.000 #&gt; x10 0.725 0.017 42.690 0.000 #&gt; x11 0.738 0.017 43.165 0.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 0.781 0.016 49.839 0.000 #&gt; y3 0.765 0.016 48.052 0.000 #&gt; y4 0.776 0.016 48.942 0.000 #&gt; y5 0.788 0.016 49.499 0.000 #&gt; y6 0.761 0.016 46.910 0.000 #&gt; y7 0.763 0.016 48.250 0.000 #&gt; y8 0.773 0.016 48.345 0.000 #&gt; y9 0.769 0.016 47.589 0.000 #&gt; y10 0.762 0.016 46.777 0.000 #&gt; y11 0.765 0.016 47.086 0.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (ex) 0.271 0.002 119.594 0.000 #&gt; RIy ~ #&gt; oply (ey) 0.296 0.002 130.188 0.000 #&gt; x2 ~ #&gt; x1 (ax) 0.161 0.012 13.435 0.000 #&gt; y1 (bx) 0.142 0.009 15.367 0.000 #&gt; x3 ~ #&gt; x2 (ax) 0.161 0.012 13.435 0.000 #&gt; y2 (bx) 0.142 0.009 15.367 0.000 #&gt; x4 ~ #&gt; x3 (ax) 0.161 0.012 13.435 0.000 #&gt; y3 (bx) 0.142 0.009 15.367 0.000 #&gt; x5 ~ #&gt; x4 (ax) 0.161 0.012 13.435 0.000 #&gt; y4 (bx) 0.142 0.009 15.367 0.000 #&gt; x6 ~ #&gt; x5 (ax) 0.161 0.012 13.435 0.000 #&gt; y5 (bx) 0.142 0.009 15.367 0.000 #&gt; x7 ~ #&gt; x6 (ax) 0.161 0.012 13.435 0.000 #&gt; y6 (bx) 0.142 0.009 15.367 0.000 #&gt; x8 ~ #&gt; x7 (ax) 0.161 0.012 13.435 0.000 #&gt; y7 (bx) 0.142 0.009 15.367 0.000 #&gt; x9 ~ #&gt; x8 (ax) 0.161 0.012 13.435 0.000 #&gt; y8 (bx) 0.142 0.009 15.367 0.000 #&gt; x10 ~ #&gt; x9 (ax) 0.161 0.012 13.435 0.000 #&gt; y9 (bx) 0.142 0.009 15.367 0.000 #&gt; x11 ~ #&gt; x10 (ax) 0.161 0.012 13.435 0.000 #&gt; y10 (bx) 0.142 0.009 15.367 0.000 #&gt; y2 ~ #&gt; x1 (by) 0.127 0.009 13.616 0.000 #&gt; y1 (ay) 0.120 0.012 10.183 0.000 #&gt; y3 ~ #&gt; x2 (by) 0.127 0.009 13.616 0.000 #&gt; y2 (ay) 0.120 0.012 10.183 0.000 #&gt; y4 ~ #&gt; x3 (by) 0.127 0.009 13.616 0.000 #&gt; y3 (ay) 0.120 0.012 10.183 0.000 #&gt; y5 ~ #&gt; x4 (by) 0.127 0.009 13.616 0.000 #&gt; y4 (ay) 0.120 0.012 10.183 0.000 #&gt; y6 ~ #&gt; x5 (by) 0.127 0.009 13.616 0.000 #&gt; y5 (ay) 0.120 0.012 10.183 0.000 #&gt; y7 ~ #&gt; x6 (by) 0.127 0.009 13.616 0.000 #&gt; y6 (ay) 0.120 0.012 10.183 0.000 #&gt; y8 ~ #&gt; x7 (by) 0.127 0.009 13.616 0.000 #&gt; y7 (ay) 0.120 0.012 10.183 0.000 #&gt; y9 ~ #&gt; x8 (by) 0.127 0.009 13.616 0.000 #&gt; y8 (ay) 0.120 0.012 10.183 0.000 #&gt; y10 ~ #&gt; x9 (by) 0.127 0.009 13.616 0.000 #&gt; y9 (ay) 0.120 0.012 10.183 0.000 #&gt; y11 ~ #&gt; x10 (by) 0.127 0.009 13.616 0.000 #&gt; y10 (ay) 0.120 0.012 10.183 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.131 0.018 7.457 0.000 #&gt; wx2 ~~ #&gt; wy2 0.070 0.014 5.062 0.000 #&gt; wx3 ~~ #&gt; wy3 0.070 0.013 5.276 0.000 #&gt; wx4 ~~ #&gt; wy4 0.060 0.013 4.499 0.000 #&gt; wx5 ~~ #&gt; wy5 0.017 0.012 1.424 0.154 #&gt; wx6 ~~ #&gt; wy6 0.087 0.013 6.756 0.000 #&gt; wx7 ~~ #&gt; wy7 0.059 0.012 5.030 0.000 #&gt; wx8 ~~ #&gt; wy8 0.057 0.013 4.372 0.000 #&gt; wx9 ~~ #&gt; wy9 0.050 0.014 3.650 0.000 #&gt; wx10 ~~ #&gt; wy10 0.067 0.015 4.543 0.000 #&gt; wx11 ~~ #&gt; wy11 0.046 0.016 2.927 0.003 #&gt; .RIx ~~ #&gt; .RIy 0.869 0.036 24.206 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; wx1 0.000 #&gt; wx2 0.000 #&gt; wx3 0.000 #&gt; wx4 0.000 #&gt; wx5 0.000 #&gt; wx6 0.000 #&gt; wx7 0.000 #&gt; wx8 0.000 #&gt; wx9 0.000 #&gt; wx10 0.000 #&gt; wx11 0.000 #&gt; wy1 0.000 #&gt; wy2 0.000 #&gt; wy3 0.000 #&gt; wy4 0.000 #&gt; wy5 0.000 #&gt; wy6 0.000 #&gt; wy7 0.000 #&gt; wy8 0.000 #&gt; wy9 0.000 #&gt; wy10 0.000 #&gt; wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 1.589 0.048 33.316 0.000 #&gt; .RIy 1.404 0.042 33.553 0.000 #&gt; wx1 0.504 0.024 21.037 0.000 #&gt; wy1 0.497 0.023 21.768 0.000 #&gt; wx2 0.434 0.019 23.110 0.000 #&gt; wy2 0.410 0.018 22.933 0.000 #&gt; wx3 0.405 0.017 23.521 0.000 #&gt; wy3 0.423 0.018 23.368 0.000 #&gt; wx4 0.397 0.018 22.445 0.000 #&gt; wy4 0.348 0.016 21.687 0.000 #&gt; wx5 0.341 0.015 22.330 0.000 #&gt; wy5 0.353 0.016 22.553 0.000 #&gt; wx6 0.397 0.017 23.271 0.000 #&gt; wy6 0.383 0.017 22.925 0.000 #&gt; wx7 0.374 0.016 23.056 0.000 #&gt; wy7 0.317 0.014 22.339 0.000 #&gt; wx8 0.374 0.017 22.579 0.000 #&gt; wy8 0.396 0.017 22.750 0.000 #&gt; wx9 0.397 0.018 22.364 0.000 #&gt; wy9 0.398 0.018 22.288 0.000 #&gt; wx10 0.392 0.019 21.191 0.000 #&gt; wy10 0.404 0.019 21.155 0.000 #&gt; wx11 0.439 0.021 21.345 0.000 #&gt; wy11 0.384 0.019 20.288 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 0.041 0.017 2.442 0.015 #&gt; dif2 0.015 0.014 1.103 0.270 #&gt; dif3 -0.025 0.002 -10.223 0.000 3.9.4 LT-RI-CLPM LTRICLPM &lt;- &#39; # Create between components (random intercepts) RIx =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 + 1*x5 + 1*x6 + 1*x7 + 1*x8 + 1*x9 + 1*x10 + 1*x11 RIy =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 + 1*y5 + 1*y6 + 1*y7 + 1*y8 + 1*y9 + 1*y10 + 1*y11 RIx ~ ex*oplx RIy ~ ey*oply #Random slopes RIsx =~ 1*x1 + 2*x2 + 3*x3 + 4*x4 + 5*x5 + 6*x6 + 7*x7 + 8*x8 + 9*x9 + 10*x10 + 11*x11 RIsy =~ 1*y1 + 2*y2 + 3*y3 + 4*y4 + 5*y5 + 6*y6 + 7*y7 + 8*y8 + 9*y9 + 10*y10 + 11*y11 RIsx ~ fx*oplx RIsy ~ fy*oply # Create within-person centered variables wx1 =~ 1*x1 wx2 =~ 1*x2 wx3 =~ 1*x3 wx4 =~ 1*x4 wx5 =~ 1*x5 wx6 =~ 1*x6 wx7 =~ 1*x7 wx8 =~ 1*x8 wx9 =~ 1*x9 wx10 =~ 1*x10 wx11 =~ 1*x11 wy1 =~ 1*y1 wy2 =~ 1*y2 wy3 =~ 1*y3 wy4 =~ 1*y4 wy5 =~ 1*y5 wy6 =~ 1*y6 wy7 =~ 1*y7 wy8 =~ 1*y8 wy9 =~ 1*y9 wy10 =~ 1*y10 wy11 =~ 1*y11 # Estimate the lagged effects between the within-person centered variables. x2 ~ ax*x1 + bx*y1 x3 ~ ax*x2 + bx*y2 x4 ~ ax*x3 + bx*y3 x5 ~ ax*x4 + bx*y4 x6 ~ ax*x5 + bx*y5 x7 ~ ax*x6 + bx*y6 x8 ~ ax*x7 + bx*y7 x9 ~ ax*x8 + bx*y8 x10 ~ ax*x9 + bx*y9 x11 ~ ax*x10 + bx*y10 y2 ~ by*x1 + ay*y1 y3 ~ by*x2 + ay*y2 y4 ~ by*x3 + ay*y3 y5 ~ by*x4 + ay*y4 y6 ~ by*x5 + ay*y5 y7 ~ by*x6 + ay*y6 y8 ~ by*x7 + ay*y7 y9 ~ by*x8 + ay*y8 y10 ~ by*x9 + ay*y9 y11 ~ by*x10 + ay*y10 dif1 := ax - ay dif2 := bx - by dif3 := ex - ey dif4 := fx - fy # Estimate the (residual) covariance between the within-person centered variables wx1 ~~ wy1 # Covariance wx2 ~~ wy2 wx3 ~~ wy3 wx4 ~~ wy4 wx5 ~~ wy5 wx6 ~~ wy6 wx7 ~~ wy7 wx8 ~~ wy8 wx9 ~~ wy9 wx10 ~~ wy10 wx11 ~~ wy11 # Estimate the variance and covariance of the random intercepts and random slopes. RIx ~~ RIx RIy ~~ RIy RIx ~~ RIy #covariance intercepts: interpretation SELECTION RIsx ~~ RIsx RIsy ~~ RIsy RIsx ~~ RIsy #covariance slopes: interpretation COMMON CONTEXT RIx ~~ RIsx #covariance intercept/slope: interpretation regression to the mean RIy ~~ RIsy RIx ~~ RIsy #cross-covariance: interpretation INFLUENCE? RIy ~~ RIsx # Estimate the (residual) variance of the within-person centered variables. wx1 ~~ wx1 # Variances wy1 ~~ wy1 wx2 ~~ wx2 # Residual variances wy2 ~~ wy2 wx3 ~~ wx3 wy3 ~~ wy3 wx4 ~~ wx4 wy4 ~~ wy4 wx5 ~~ wx5 wy5 ~~ wy5 wx6 ~~ wx6 wy6 ~~ wy6 wx7 ~~ wx7 wy7 ~~ wy7 wx8 ~~ wx8 wy8 ~~ wy8 wx9 ~~ wx9 wy9 ~~ wy9 wx10 ~~ wx10 wy10 ~~ wy10 wx11 ~~ wx11 wy11 ~~ wy11 &#39; #Estimate models a bit faster: estimate &lt;- function(x) lavaan(LTRICLPM, data=x, missing = &quot;fiml.x&quot;, meanstructure = T ) library(future.apply) plan(multisession) results_temp &lt;- future_lapply(datalist_ori, estimate) summary(results_temp[[4]]) results[[29]] &lt;- results_temp[[1]] results[[30]] &lt;- results_temp[[2]] results[[31]] &lt;- results_temp[[3]] results[[32]] &lt;- results_temp[[4]] names(results)[29:32] &lt;- c(&quot;fitm4h2y1&quot;, &quot;fitm4h2y2&quot;,&quot;fitm4h2y3&quot;,&quot;fitm4h2y4&quot;) save(results, file=&quot;results.RData&quot;) load(&quot;addfiles/results.Rdata&quot;) summary(results[[29]]) summary(results[[30]]) summary(results[[31]]) summary(results[[32]]) #&gt; lavaan 0.6-7 ended normally after 105 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 87 #&gt; Number of equality constraints 36 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1415 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 1478.192 #&gt; Degrees of freedom 268 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; RIsx =~ #&gt; x1 1.000 #&gt; x2 2.000 #&gt; x3 3.000 #&gt; x4 4.000 #&gt; x5 5.000 #&gt; x6 6.000 #&gt; x7 7.000 #&gt; x8 8.000 #&gt; x9 9.000 #&gt; x10 10.000 #&gt; x11 11.000 #&gt; RIsy =~ #&gt; y1 1.000 #&gt; y2 2.000 #&gt; y3 3.000 #&gt; y4 4.000 #&gt; y5 5.000 #&gt; y6 6.000 #&gt; y7 7.000 #&gt; y8 8.000 #&gt; y9 9.000 #&gt; y10 10.000 #&gt; y11 11.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (ex) 0.126 0.002 63.991 0.000 #&gt; RIy ~ #&gt; oply (ey) 0.123 0.002 65.556 0.000 #&gt; RIsx ~ #&gt; oplx (fx) -0.003 0.000 -11.534 0.000 #&gt; RIsy ~ #&gt; oply (fy) -0.002 0.000 -9.901 0.000 #&gt; x2 ~ #&gt; x1 (ax) 0.076 0.011 7.263 0.000 #&gt; y1 (bx) 0.024 0.011 2.168 0.030 #&gt; x3 ~ #&gt; x2 (ax) 0.076 0.011 7.263 0.000 #&gt; y2 (bx) 0.024 0.011 2.168 0.030 #&gt; x4 ~ #&gt; x3 (ax) 0.076 0.011 7.263 0.000 #&gt; y3 (bx) 0.024 0.011 2.168 0.030 #&gt; x5 ~ #&gt; x4 (ax) 0.076 0.011 7.263 0.000 #&gt; y4 (bx) 0.024 0.011 2.168 0.030 #&gt; x6 ~ #&gt; x5 (ax) 0.076 0.011 7.263 0.000 #&gt; y5 (bx) 0.024 0.011 2.168 0.030 #&gt; x7 ~ #&gt; x6 (ax) 0.076 0.011 7.263 0.000 #&gt; y6 (bx) 0.024 0.011 2.168 0.030 #&gt; x8 ~ #&gt; x7 (ax) 0.076 0.011 7.263 0.000 #&gt; y7 (bx) 0.024 0.011 2.168 0.030 #&gt; x9 ~ #&gt; x8 (ax) 0.076 0.011 7.263 0.000 #&gt; y8 (bx) 0.024 0.011 2.168 0.030 #&gt; x10 ~ #&gt; x9 (ax) 0.076 0.011 7.263 0.000 #&gt; y9 (bx) 0.024 0.011 2.168 0.030 #&gt; x11 ~ #&gt; x10 (ax) 0.076 0.011 7.263 0.000 #&gt; y10 (bx) 0.024 0.011 2.168 0.030 #&gt; y2 ~ #&gt; x1 (by) 0.027 0.009 2.926 0.003 #&gt; y1 (ay) 0.072 0.011 6.631 0.000 #&gt; y3 ~ #&gt; x2 (by) 0.027 0.009 2.926 0.003 #&gt; y2 (ay) 0.072 0.011 6.631 0.000 #&gt; y4 ~ #&gt; x3 (by) 0.027 0.009 2.926 0.003 #&gt; y3 (ay) 0.072 0.011 6.631 0.000 #&gt; y5 ~ #&gt; x4 (by) 0.027 0.009 2.926 0.003 #&gt; y4 (ay) 0.072 0.011 6.631 0.000 #&gt; y6 ~ #&gt; x5 (by) 0.027 0.009 2.926 0.003 #&gt; y5 (ay) 0.072 0.011 6.631 0.000 #&gt; y7 ~ #&gt; x6 (by) 0.027 0.009 2.926 0.003 #&gt; y6 (ay) 0.072 0.011 6.631 0.000 #&gt; y8 ~ #&gt; x7 (by) 0.027 0.009 2.926 0.003 #&gt; y7 (ay) 0.072 0.011 6.631 0.000 #&gt; y9 ~ #&gt; x8 (by) 0.027 0.009 2.926 0.003 #&gt; y8 (ay) 0.072 0.011 6.631 0.000 #&gt; y10 ~ #&gt; x9 (by) 0.027 0.009 2.926 0.003 #&gt; y9 (ay) 0.072 0.011 6.631 0.000 #&gt; y11 ~ #&gt; x10 (by) 0.027 0.009 2.926 0.003 #&gt; y10 (ay) 0.072 0.011 6.631 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.114 0.023 5.062 0.000 #&gt; wx2 ~~ #&gt; wy2 0.052 0.019 2.801 0.005 #&gt; wx3 ~~ #&gt; wy3 0.092 0.018 5.091 0.000 #&gt; wx4 ~~ #&gt; wy4 0.100 0.018 5.440 0.000 #&gt; wx5 ~~ #&gt; wy5 0.081 0.021 3.936 0.000 #&gt; wx6 ~~ #&gt; wy6 0.061 0.016 3.837 0.000 #&gt; wx7 ~~ #&gt; wy7 0.079 0.015 5.258 0.000 #&gt; wx8 ~~ #&gt; wy8 0.064 0.017 3.698 0.000 #&gt; wx9 ~~ #&gt; wy9 0.068 0.018 3.746 0.000 #&gt; wx10 ~~ #&gt; wy10 0.036 0.020 1.799 0.072 #&gt; wx11 ~~ #&gt; wy11 0.119 0.023 5.245 0.000 #&gt; .RIx ~~ #&gt; .RIy 0.282 0.025 11.367 0.000 #&gt; .RIsx ~~ #&gt; .RIsy 0.002 0.000 4.159 0.000 #&gt; .RIx ~~ #&gt; .RIsx -0.022 0.004 -5.929 0.000 #&gt; .RIy ~~ #&gt; .RIsy -0.013 0.003 -4.447 0.000 #&gt; .RIx ~~ #&gt; .RIsy -0.003 0.003 -1.121 0.262 #&gt; .RIy ~~ #&gt; .RIsx -0.003 0.003 -1.109 0.267 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; .RIsx 0.000 #&gt; .RIsy 0.000 #&gt; wx1 0.000 #&gt; wx2 0.000 #&gt; wx3 0.000 #&gt; wx4 0.000 #&gt; wx5 0.000 #&gt; wx6 0.000 #&gt; wx7 0.000 #&gt; wx8 0.000 #&gt; wx9 0.000 #&gt; wx10 0.000 #&gt; wx11 0.000 #&gt; wy1 0.000 #&gt; wy2 0.000 #&gt; wy3 0.000 #&gt; wy4 0.000 #&gt; wy5 0.000 #&gt; wy6 0.000 #&gt; wy7 0.000 #&gt; wy8 0.000 #&gt; wy9 0.000 #&gt; wy10 0.000 #&gt; wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 0.746 0.039 19.316 0.000 #&gt; .RIy 0.482 0.029 16.560 0.000 #&gt; .RIsx 0.005 0.001 9.142 0.000 #&gt; .RIsy 0.003 0.000 6.925 0.000 #&gt; wx1 0.634 0.031 20.236 0.000 #&gt; wy1 0.584 0.028 20.528 0.000 #&gt; wx2 0.591 0.027 21.858 0.000 #&gt; wy2 0.495 0.023 21.300 0.000 #&gt; wx3 0.546 0.024 22.466 0.000 #&gt; wy3 0.485 0.022 21.877 0.000 #&gt; wx4 0.572 0.026 22.085 0.000 #&gt; wy4 0.466 0.022 21.369 0.000 #&gt; wx5 0.697 0.029 23.839 0.000 #&gt; wy5 0.543 0.023 23.169 0.000 #&gt; wx6 0.492 0.022 22.859 0.000 #&gt; wy6 0.407 0.019 21.982 0.000 #&gt; wx7 0.448 0.020 22.275 0.000 #&gt; wy7 0.423 0.019 22.154 0.000 #&gt; wx8 0.498 0.022 22.311 0.000 #&gt; wy8 0.472 0.021 22.196 0.000 #&gt; wx9 0.531 0.025 21.539 0.000 #&gt; wy9 0.453 0.022 20.814 0.000 #&gt; wx10 0.490 0.025 19.383 0.000 #&gt; wy10 0.467 0.024 19.368 0.000 #&gt; wx11 0.570 0.030 18.710 0.000 #&gt; wy11 0.503 0.028 18.049 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 0.004 0.015 0.270 0.787 #&gt; dif2 -0.004 0.014 -0.267 0.789 #&gt; dif3 0.003 0.002 1.494 0.135 #&gt; dif4 -0.001 0.000 -1.904 0.057 #&gt; #&gt; lavaan 0.6-7 ended normally after 103 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 87 #&gt; Number of equality constraints 36 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1230 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 671.759 #&gt; Degrees of freedom 268 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; RIsx =~ #&gt; x1 1.000 #&gt; x2 2.000 #&gt; x3 3.000 #&gt; x4 4.000 #&gt; x5 5.000 #&gt; x6 6.000 #&gt; x7 7.000 #&gt; x8 8.000 #&gt; x9 9.000 #&gt; x10 10.000 #&gt; x11 11.000 #&gt; RIsy =~ #&gt; y1 1.000 #&gt; y2 2.000 #&gt; y3 3.000 #&gt; y4 4.000 #&gt; y5 5.000 #&gt; y6 6.000 #&gt; y7 7.000 #&gt; y8 8.000 #&gt; y9 9.000 #&gt; y10 10.000 #&gt; y11 11.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (ex) 0.094 0.002 60.054 0.000 #&gt; RIy ~ #&gt; oply (ey) 0.104 0.002 65.067 0.000 #&gt; RIsx ~ #&gt; oplx (fx) -0.000 0.000 -1.214 0.225 #&gt; RIsy ~ #&gt; oply (fy) -0.000 0.000 -0.749 0.454 #&gt; x2 ~ #&gt; x1 (ax) 0.045 0.010 4.475 0.000 #&gt; y1 (bx) 0.030 0.010 3.179 0.001 #&gt; x3 ~ #&gt; x2 (ax) 0.045 0.010 4.475 0.000 #&gt; y2 (bx) 0.030 0.010 3.179 0.001 #&gt; x4 ~ #&gt; x3 (ax) 0.045 0.010 4.475 0.000 #&gt; y3 (bx) 0.030 0.010 3.179 0.001 #&gt; x5 ~ #&gt; x4 (ax) 0.045 0.010 4.475 0.000 #&gt; y4 (bx) 0.030 0.010 3.179 0.001 #&gt; x6 ~ #&gt; x5 (ax) 0.045 0.010 4.475 0.000 #&gt; y5 (bx) 0.030 0.010 3.179 0.001 #&gt; x7 ~ #&gt; x6 (ax) 0.045 0.010 4.475 0.000 #&gt; y6 (bx) 0.030 0.010 3.179 0.001 #&gt; x8 ~ #&gt; x7 (ax) 0.045 0.010 4.475 0.000 #&gt; y7 (bx) 0.030 0.010 3.179 0.001 #&gt; x9 ~ #&gt; x8 (ax) 0.045 0.010 4.475 0.000 #&gt; y8 (bx) 0.030 0.010 3.179 0.001 #&gt; x10 ~ #&gt; x9 (ax) 0.045 0.010 4.475 0.000 #&gt; y9 (bx) 0.030 0.010 3.179 0.001 #&gt; x11 ~ #&gt; x10 (ax) 0.045 0.010 4.475 0.000 #&gt; y10 (bx) 0.030 0.010 3.179 0.001 #&gt; y2 ~ #&gt; x1 (by) 0.016 0.009 1.735 0.083 #&gt; y1 (ay) 0.045 0.010 4.525 0.000 #&gt; y3 ~ #&gt; x2 (by) 0.016 0.009 1.735 0.083 #&gt; y2 (ay) 0.045 0.010 4.525 0.000 #&gt; y4 ~ #&gt; x3 (by) 0.016 0.009 1.735 0.083 #&gt; y3 (ay) 0.045 0.010 4.525 0.000 #&gt; y5 ~ #&gt; x4 (by) 0.016 0.009 1.735 0.083 #&gt; y4 (ay) 0.045 0.010 4.525 0.000 #&gt; y6 ~ #&gt; x5 (by) 0.016 0.009 1.735 0.083 #&gt; y5 (ay) 0.045 0.010 4.525 0.000 #&gt; y7 ~ #&gt; x6 (by) 0.016 0.009 1.735 0.083 #&gt; y6 (ay) 0.045 0.010 4.525 0.000 #&gt; y8 ~ #&gt; x7 (by) 0.016 0.009 1.735 0.083 #&gt; y7 (ay) 0.045 0.010 4.525 0.000 #&gt; y9 ~ #&gt; x8 (by) 0.016 0.009 1.735 0.083 #&gt; y8 (ay) 0.045 0.010 4.525 0.000 #&gt; y10 ~ #&gt; x9 (by) 0.016 0.009 1.735 0.083 #&gt; y9 (ay) 0.045 0.010 4.525 0.000 #&gt; y11 ~ #&gt; x10 (by) 0.016 0.009 1.735 0.083 #&gt; y10 (ay) 0.045 0.010 4.525 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.039 0.013 3.029 0.002 #&gt; wx2 ~~ #&gt; wy2 0.041 0.013 3.218 0.001 #&gt; wx3 ~~ #&gt; wy3 0.020 0.011 1.816 0.069 #&gt; wx4 ~~ #&gt; wy4 0.038 0.011 3.536 0.000 #&gt; wx5 ~~ #&gt; wy5 0.040 0.011 3.770 0.000 #&gt; wx6 ~~ #&gt; wy6 0.024 0.011 2.267 0.023 #&gt; wx7 ~~ #&gt; wy7 0.032 0.011 2.846 0.004 #&gt; wx8 ~~ #&gt; wy8 0.026 0.011 2.409 0.016 #&gt; wx9 ~~ #&gt; wy9 0.010 0.013 0.829 0.407 #&gt; wx10 ~~ #&gt; wy10 0.041 0.013 3.203 0.001 #&gt; wx11 ~~ #&gt; wy11 0.054 0.013 4.179 0.000 #&gt; .RIx ~~ #&gt; .RIy 0.345 0.020 17.055 0.000 #&gt; .RIsx ~~ #&gt; .RIsy 0.001 0.000 3.214 0.001 #&gt; .RIx ~~ #&gt; .RIsx -0.013 0.002 -5.989 0.000 #&gt; .RIy ~~ #&gt; .RIsy -0.016 0.002 -7.090 0.000 #&gt; .RIx ~~ #&gt; .RIsy -0.010 0.002 -5.070 0.000 #&gt; .RIy ~~ #&gt; .RIsx -0.007 0.002 -3.652 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; .RIsx 0.000 #&gt; .RIsy 0.000 #&gt; wx1 0.000 #&gt; wx2 0.000 #&gt; wx3 0.000 #&gt; wx4 0.000 #&gt; wx5 0.000 #&gt; wx6 0.000 #&gt; wx7 0.000 #&gt; wx8 0.000 #&gt; wx9 0.000 #&gt; wx10 0.000 #&gt; wx11 0.000 #&gt; wy1 0.000 #&gt; wy2 0.000 #&gt; wy3 0.000 #&gt; wy4 0.000 #&gt; wy5 0.000 #&gt; wy6 0.000 #&gt; wy7 0.000 #&gt; wy8 0.000 #&gt; wy9 0.000 #&gt; wy10 0.000 #&gt; wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 0.579 0.027 21.592 0.000 #&gt; .RIy 0.577 0.026 21.949 0.000 #&gt; .RIsx 0.001 0.000 5.600 0.000 #&gt; .RIsy 0.002 0.000 6.184 0.000 #&gt; wx1 0.416 0.019 21.689 0.000 #&gt; wy1 0.339 0.017 20.520 0.000 #&gt; wx2 0.383 0.017 22.667 0.000 #&gt; wy2 0.404 0.017 23.284 0.000 #&gt; wx3 0.332 0.015 22.866 0.000 #&gt; wy3 0.298 0.013 22.324 0.000 #&gt; wx4 0.312 0.014 22.295 0.000 #&gt; wy4 0.313 0.014 22.208 0.000 #&gt; wx5 0.322 0.014 23.460 0.000 #&gt; wy5 0.328 0.014 23.418 0.000 #&gt; wx6 0.347 0.015 23.609 0.000 #&gt; wy6 0.301 0.013 23.213 0.000 #&gt; wx7 0.347 0.015 23.416 0.000 #&gt; wy7 0.324 0.014 23.455 0.000 #&gt; wx8 0.315 0.014 22.654 0.000 #&gt; wy8 0.320 0.014 22.812 0.000 #&gt; wx9 0.360 0.016 22.425 0.000 #&gt; wy9 0.361 0.016 22.117 0.000 #&gt; wx10 0.348 0.017 20.643 0.000 #&gt; wy10 0.318 0.016 20.315 0.000 #&gt; wx11 0.340 0.017 19.702 0.000 #&gt; wy11 0.300 0.016 18.672 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 0.000 0.014 0.026 0.980 #&gt; dif2 0.014 0.013 1.153 0.249 #&gt; dif3 -0.009 0.002 -5.209 0.000 #&gt; dif4 -0.000 0.000 -0.337 0.736 #&gt; #&gt; lavaan 0.6-7 ended normally after 123 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 87 #&gt; Number of equality constraints 36 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1290 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 5437.473 #&gt; Degrees of freedom 268 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; RIsx =~ #&gt; x1 1.000 #&gt; x2 2.000 #&gt; x3 3.000 #&gt; x4 4.000 #&gt; x5 5.000 #&gt; x6 6.000 #&gt; x7 7.000 #&gt; x8 8.000 #&gt; x9 9.000 #&gt; x10 10.000 #&gt; x11 11.000 #&gt; RIsy =~ #&gt; y1 1.000 #&gt; y2 2.000 #&gt; y3 3.000 #&gt; y4 4.000 #&gt; y5 5.000 #&gt; y6 6.000 #&gt; y7 7.000 #&gt; y8 8.000 #&gt; y9 9.000 #&gt; y10 10.000 #&gt; y11 11.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (ex) 0.322 0.002 144.287 0.000 #&gt; RIy ~ #&gt; oply (ey) 0.335 0.002 141.169 0.000 #&gt; RIsx ~ #&gt; oplx (fx) 0.000 0.000 2.606 0.009 #&gt; RIsy ~ #&gt; oply (fy) 0.000 0.000 2.659 0.008 #&gt; x2 ~ #&gt; x1 (ax) -0.060 0.008 -7.469 0.000 #&gt; y1 (bx) 0.080 0.008 10.062 0.000 #&gt; x3 ~ #&gt; x2 (ax) -0.060 0.008 -7.469 0.000 #&gt; y2 (bx) 0.080 0.008 10.062 0.000 #&gt; x4 ~ #&gt; x3 (ax) -0.060 0.008 -7.469 0.000 #&gt; y3 (bx) 0.080 0.008 10.062 0.000 #&gt; x5 ~ #&gt; x4 (ax) -0.060 0.008 -7.469 0.000 #&gt; y4 (bx) 0.080 0.008 10.062 0.000 #&gt; x6 ~ #&gt; x5 (ax) -0.060 0.008 -7.469 0.000 #&gt; y5 (bx) 0.080 0.008 10.062 0.000 #&gt; x7 ~ #&gt; x6 (ax) -0.060 0.008 -7.469 0.000 #&gt; y6 (bx) 0.080 0.008 10.062 0.000 #&gt; x8 ~ #&gt; x7 (ax) -0.060 0.008 -7.469 0.000 #&gt; y7 (bx) 0.080 0.008 10.062 0.000 #&gt; x9 ~ #&gt; x8 (ax) -0.060 0.008 -7.469 0.000 #&gt; y8 (bx) 0.080 0.008 10.062 0.000 #&gt; x10 ~ #&gt; x9 (ax) -0.060 0.008 -7.469 0.000 #&gt; y9 (bx) 0.080 0.008 10.062 0.000 #&gt; x11 ~ #&gt; x10 (ax) -0.060 0.008 -7.469 0.000 #&gt; y10 (bx) 0.080 0.008 10.062 0.000 #&gt; y2 ~ #&gt; x1 (by) 0.079 0.008 10.245 0.000 #&gt; y1 (ay) -0.055 0.008 -7.091 0.000 #&gt; y3 ~ #&gt; x2 (by) 0.079 0.008 10.245 0.000 #&gt; y2 (ay) -0.055 0.008 -7.091 0.000 #&gt; y4 ~ #&gt; x3 (by) 0.079 0.008 10.245 0.000 #&gt; y3 (ay) -0.055 0.008 -7.091 0.000 #&gt; y5 ~ #&gt; x4 (by) 0.079 0.008 10.245 0.000 #&gt; y4 (ay) -0.055 0.008 -7.091 0.000 #&gt; y6 ~ #&gt; x5 (by) 0.079 0.008 10.245 0.000 #&gt; y5 (ay) -0.055 0.008 -7.091 0.000 #&gt; y7 ~ #&gt; x6 (by) 0.079 0.008 10.245 0.000 #&gt; y6 (ay) -0.055 0.008 -7.091 0.000 #&gt; y8 ~ #&gt; x7 (by) 0.079 0.008 10.245 0.000 #&gt; y7 (ay) -0.055 0.008 -7.091 0.000 #&gt; y9 ~ #&gt; x8 (by) 0.079 0.008 10.245 0.000 #&gt; y8 (ay) -0.055 0.008 -7.091 0.000 #&gt; y10 ~ #&gt; x9 (by) 0.079 0.008 10.245 0.000 #&gt; y9 (ay) -0.055 0.008 -7.091 0.000 #&gt; y11 ~ #&gt; x10 (by) 0.079 0.008 10.245 0.000 #&gt; y10 (ay) -0.055 0.008 -7.091 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.065 0.010 6.202 0.000 #&gt; wx2 ~~ #&gt; wy2 0.034 0.008 4.100 0.000 #&gt; wx3 ~~ #&gt; wy3 0.065 0.009 7.512 0.000 #&gt; wx4 ~~ #&gt; wy4 0.030 0.008 3.877 0.000 #&gt; wx5 ~~ #&gt; wy5 0.038 0.007 5.206 0.000 #&gt; wx6 ~~ #&gt; wy6 0.037 0.007 5.555 0.000 #&gt; wx7 ~~ #&gt; wy7 0.032 0.007 4.668 0.000 #&gt; wx8 ~~ #&gt; wy8 0.024 0.007 3.368 0.001 #&gt; wx9 ~~ #&gt; wy9 0.033 0.008 4.281 0.000 #&gt; wx10 ~~ #&gt; wy10 0.063 0.010 6.512 0.000 #&gt; wx11 ~~ #&gt; wy11 0.055 0.009 5.930 0.000 #&gt; .RIx ~~ #&gt; .RIy 1.047 0.044 23.905 0.000 #&gt; .RIsx ~~ #&gt; .RIsy 0.000 0.000 1.325 0.185 #&gt; .RIx ~~ #&gt; .RIsx -0.012 0.003 -4.256 0.000 #&gt; .RIy ~~ #&gt; .RIsy -0.017 0.003 -5.846 0.000 #&gt; .RIx ~~ #&gt; .RIsy -0.006 0.003 -2.163 0.031 #&gt; .RIy ~~ #&gt; .RIsx -0.002 0.003 -0.755 0.450 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; .RIsx 0.000 #&gt; .RIsy 0.000 #&gt; wx1 0.000 #&gt; wx2 0.000 #&gt; wx3 0.000 #&gt; wx4 0.000 #&gt; wx5 0.000 #&gt; wx6 0.000 #&gt; wx7 0.000 #&gt; wx8 0.000 #&gt; wx9 0.000 #&gt; wx10 0.000 #&gt; wx11 0.000 #&gt; wy1 0.000 #&gt; wy2 0.000 #&gt; wy3 0.000 #&gt; wy4 0.000 #&gt; wy5 0.000 #&gt; wy6 0.000 #&gt; wy7 0.000 #&gt; wy8 0.000 #&gt; wy9 0.000 #&gt; wy10 0.000 #&gt; wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 1.665 0.052 31.990 0.000 #&gt; .RIy 1.780 0.055 32.356 0.000 #&gt; .RIsx 0.002 0.000 9.412 0.000 #&gt; .RIsy 0.002 0.000 10.107 0.000 #&gt; wx1 0.281 0.014 19.895 0.000 #&gt; wy1 0.283 0.014 20.425 0.000 #&gt; wx2 0.249 0.012 20.973 0.000 #&gt; wy2 0.205 0.010 20.001 0.000 #&gt; wx3 0.239 0.011 22.202 0.000 #&gt; wy3 0.282 0.012 22.850 0.000 #&gt; wx4 0.206 0.010 21.568 0.000 #&gt; wy4 0.229 0.010 21.933 0.000 #&gt; wx5 0.235 0.010 22.805 0.000 #&gt; wy5 0.186 0.008 22.334 0.000 #&gt; wx6 0.206 0.009 22.323 0.000 #&gt; wy6 0.176 0.008 21.927 0.000 #&gt; wx7 0.200 0.009 22.423 0.000 #&gt; wy7 0.194 0.009 22.241 0.000 #&gt; wx8 0.204 0.009 21.698 0.000 #&gt; wy8 0.208 0.009 22.250 0.000 #&gt; wx9 0.222 0.011 21.147 0.000 #&gt; wy9 0.190 0.009 20.769 0.000 #&gt; wx10 0.243 0.012 20.177 0.000 #&gt; wy10 0.235 0.012 19.995 0.000 #&gt; wx11 0.218 0.012 17.891 0.000 #&gt; wy11 0.197 0.012 17.115 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 -0.005 0.012 -0.381 0.703 #&gt; dif2 0.000 0.012 0.034 0.973 #&gt; dif3 -0.013 0.002 -5.475 0.000 #&gt; dif4 -0.000 0.000 -0.120 0.905 #&gt; #&gt; lavaan 0.6-7 ended normally after 96 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of free parameters 87 #&gt; Number of equality constraints 36 #&gt; #&gt; Number of observations 3283 #&gt; Number of missing patterns 1309 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 5808.751 #&gt; Degrees of freedom 268 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; x5 1.000 #&gt; x6 1.000 #&gt; x7 1.000 #&gt; x8 1.000 #&gt; x9 1.000 #&gt; x10 1.000 #&gt; x11 1.000 #&gt; RIy =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; y5 1.000 #&gt; y6 1.000 #&gt; y7 1.000 #&gt; y8 1.000 #&gt; y9 1.000 #&gt; y10 1.000 #&gt; y11 1.000 #&gt; RIsx =~ #&gt; x1 1.000 #&gt; x2 2.000 #&gt; x3 3.000 #&gt; x4 4.000 #&gt; x5 5.000 #&gt; x6 6.000 #&gt; x7 7.000 #&gt; x8 8.000 #&gt; x9 9.000 #&gt; x10 10.000 #&gt; x11 11.000 #&gt; RIsy =~ #&gt; y1 1.000 #&gt; y2 2.000 #&gt; y3 3.000 #&gt; y4 4.000 #&gt; y5 5.000 #&gt; y6 6.000 #&gt; y7 7.000 #&gt; y8 8.000 #&gt; y9 9.000 #&gt; y10 10.000 #&gt; y11 11.000 #&gt; wx1 =~ #&gt; x1 1.000 #&gt; wx2 =~ #&gt; x2 1.000 #&gt; wx3 =~ #&gt; x3 1.000 #&gt; wx4 =~ #&gt; x4 1.000 #&gt; wx5 =~ #&gt; x5 1.000 #&gt; wx6 =~ #&gt; x6 1.000 #&gt; wx7 =~ #&gt; x7 1.000 #&gt; wx8 =~ #&gt; x8 1.000 #&gt; wx9 =~ #&gt; x9 1.000 #&gt; wx10 =~ #&gt; x10 1.000 #&gt; wx11 =~ #&gt; x11 1.000 #&gt; wy1 =~ #&gt; y1 1.000 #&gt; wy2 =~ #&gt; y2 1.000 #&gt; wy3 =~ #&gt; y3 1.000 #&gt; wy4 =~ #&gt; y4 1.000 #&gt; wy5 =~ #&gt; y5 1.000 #&gt; wy6 =~ #&gt; y6 1.000 #&gt; wy7 =~ #&gt; y7 1.000 #&gt; wy8 =~ #&gt; y8 1.000 #&gt; wy9 =~ #&gt; y9 1.000 #&gt; wy10 =~ #&gt; y10 1.000 #&gt; wy11 =~ #&gt; y11 1.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; RIx ~ #&gt; oplx (ex) 0.263 0.002 110.425 0.000 #&gt; RIy ~ #&gt; oply (ey) 0.290 0.002 122.043 0.000 #&gt; RIsx ~ #&gt; oplx (fx) 0.001 0.000 4.283 0.000 #&gt; RIsy ~ #&gt; oply (fy) -0.001 0.000 -2.612 0.009 #&gt; x2 ~ #&gt; x1 (ax) -0.024 0.008 -2.870 0.004 #&gt; y1 (bx) 0.059 0.008 7.391 0.000 #&gt; x3 ~ #&gt; x2 (ax) -0.024 0.008 -2.870 0.004 #&gt; y2 (bx) 0.059 0.008 7.391 0.000 #&gt; x4 ~ #&gt; x3 (ax) -0.024 0.008 -2.870 0.004 #&gt; y3 (bx) 0.059 0.008 7.391 0.000 #&gt; x5 ~ #&gt; x4 (ax) -0.024 0.008 -2.870 0.004 #&gt; y4 (bx) 0.059 0.008 7.391 0.000 #&gt; x6 ~ #&gt; x5 (ax) -0.024 0.008 -2.870 0.004 #&gt; y5 (bx) 0.059 0.008 7.391 0.000 #&gt; x7 ~ #&gt; x6 (ax) -0.024 0.008 -2.870 0.004 #&gt; y6 (bx) 0.059 0.008 7.391 0.000 #&gt; x8 ~ #&gt; x7 (ax) -0.024 0.008 -2.870 0.004 #&gt; y7 (bx) 0.059 0.008 7.391 0.000 #&gt; x9 ~ #&gt; x8 (ax) -0.024 0.008 -2.870 0.004 #&gt; y8 (bx) 0.059 0.008 7.391 0.000 #&gt; x10 ~ #&gt; x9 (ax) -0.024 0.008 -2.870 0.004 #&gt; y9 (bx) 0.059 0.008 7.391 0.000 #&gt; x11 ~ #&gt; x10 (ax) -0.024 0.008 -2.870 0.004 #&gt; y10 (bx) 0.059 0.008 7.391 0.000 #&gt; y2 ~ #&gt; x1 (by) 0.081 0.008 9.788 0.000 #&gt; y1 (ay) -0.034 0.008 -4.213 0.000 #&gt; y3 ~ #&gt; x2 (by) 0.081 0.008 9.788 0.000 #&gt; y2 (ay) -0.034 0.008 -4.213 0.000 #&gt; y4 ~ #&gt; x3 (by) 0.081 0.008 9.788 0.000 #&gt; y3 (ay) -0.034 0.008 -4.213 0.000 #&gt; y5 ~ #&gt; x4 (by) 0.081 0.008 9.788 0.000 #&gt; y4 (ay) -0.034 0.008 -4.213 0.000 #&gt; y6 ~ #&gt; x5 (by) 0.081 0.008 9.788 0.000 #&gt; y5 (ay) -0.034 0.008 -4.213 0.000 #&gt; y7 ~ #&gt; x6 (by) 0.081 0.008 9.788 0.000 #&gt; y6 (ay) -0.034 0.008 -4.213 0.000 #&gt; y8 ~ #&gt; x7 (by) 0.081 0.008 9.788 0.000 #&gt; y7 (ay) -0.034 0.008 -4.213 0.000 #&gt; y9 ~ #&gt; x8 (by) 0.081 0.008 9.788 0.000 #&gt; y8 (ay) -0.034 0.008 -4.213 0.000 #&gt; y10 ~ #&gt; x9 (by) 0.081 0.008 9.788 0.000 #&gt; y9 (ay) -0.034 0.008 -4.213 0.000 #&gt; y11 ~ #&gt; x10 (by) 0.081 0.008 9.788 0.000 #&gt; y10 (ay) -0.034 0.008 -4.213 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; wx1 ~~ #&gt; wy1 0.131 0.016 8.063 0.000 #&gt; wx2 ~~ #&gt; wy2 0.052 0.013 4.095 0.000 #&gt; wx3 ~~ #&gt; wy3 0.061 0.013 4.836 0.000 #&gt; wx4 ~~ #&gt; wy4 0.035 0.012 2.899 0.004 #&gt; wx5 ~~ #&gt; wy5 0.019 0.012 1.592 0.111 #&gt; wx6 ~~ #&gt; wy6 0.060 0.012 5.030 0.000 #&gt; wx7 ~~ #&gt; wy7 0.051 0.011 4.469 0.000 #&gt; wx8 ~~ #&gt; wy8 0.046 0.012 3.816 0.000 #&gt; wx9 ~~ #&gt; wy9 0.041 0.013 3.183 0.001 #&gt; wx10 ~~ #&gt; wy10 0.052 0.014 3.843 0.000 #&gt; wx11 ~~ #&gt; wy11 0.054 0.016 3.406 0.001 #&gt; .RIx ~~ #&gt; .RIy 0.966 0.044 21.726 0.000 #&gt; .RIsx ~~ #&gt; .RIsy -0.000 0.000 -1.221 0.222 #&gt; .RIx ~~ #&gt; .RIsx -0.026 0.004 -7.036 0.000 #&gt; .RIy ~~ #&gt; .RIsy -0.026 0.004 -7.098 0.000 #&gt; .RIx ~~ #&gt; .RIsy -0.006 0.003 -1.819 0.069 #&gt; .RIy ~~ #&gt; .RIsx -0.002 0.003 -0.509 0.611 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; .RIx 0.000 #&gt; .RIy 0.000 #&gt; .RIsx 0.000 #&gt; .RIsy 0.000 #&gt; wx1 0.000 #&gt; wx2 0.000 #&gt; wx3 0.000 #&gt; wx4 0.000 #&gt; wx5 0.000 #&gt; wx6 0.000 #&gt; wx7 0.000 #&gt; wx8 0.000 #&gt; wx9 0.000 #&gt; wx10 0.000 #&gt; wx11 0.000 #&gt; wy1 0.000 #&gt; wy2 0.000 #&gt; wy3 0.000 #&gt; wy4 0.000 #&gt; wy5 0.000 #&gt; wy6 0.000 #&gt; wy7 0.000 #&gt; wy8 0.000 #&gt; wy9 0.000 #&gt; wy10 0.000 #&gt; wy11 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .RIx 1.724 0.058 29.671 0.000 #&gt; .RIy 1.534 0.053 28.805 0.000 #&gt; .RIsx 0.003 0.000 9.076 0.000 #&gt; .RIsy 0.003 0.000 9.228 0.000 #&gt; wx1 0.443 0.022 20.212 0.000 #&gt; wy1 0.422 0.021 20.054 0.000 #&gt; wx2 0.356 0.017 21.061 0.000 #&gt; wy2 0.355 0.017 21.063 0.000 #&gt; wx3 0.365 0.016 22.428 0.000 #&gt; wy3 0.386 0.017 22.367 0.000 #&gt; wx4 0.348 0.016 21.685 0.000 #&gt; wy4 0.311 0.015 21.201 0.000 #&gt; wx5 0.339 0.015 22.638 0.000 #&gt; wy5 0.345 0.015 22.758 0.000 #&gt; wx6 0.360 0.016 23.032 0.000 #&gt; wy6 0.348 0.015 22.762 0.000 #&gt; wx7 0.365 0.016 22.850 0.000 #&gt; wy7 0.301 0.014 22.120 0.000 #&gt; wx8 0.333 0.015 22.202 0.000 #&gt; wy8 0.366 0.016 22.401 0.000 #&gt; wx9 0.356 0.017 21.419 0.000 #&gt; wy9 0.357 0.017 21.258 0.000 #&gt; wx10 0.322 0.017 19.326 0.000 #&gt; wy10 0.345 0.018 19.361 0.000 #&gt; wx11 0.401 0.021 19.206 0.000 #&gt; wy11 0.337 0.019 17.681 0.000 #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .x5 0.000 #&gt; .x6 0.000 #&gt; .x7 0.000 #&gt; .x8 0.000 #&gt; .x9 0.000 #&gt; .x10 0.000 #&gt; .x11 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .y5 0.000 #&gt; .y6 0.000 #&gt; .y7 0.000 #&gt; .y8 0.000 #&gt; .y9 0.000 #&gt; .y10 0.000 #&gt; .y11 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; dif1 0.010 0.012 0.816 0.415 #&gt; dif2 -0.022 0.012 -1.787 0.074 #&gt; dif3 -0.027 0.002 -10.782 0.000 #&gt; dif4 0.001 0.000 5.018 0.000 3.9.5 Summary results Hypo2 load(&quot;addfiles/results.Rdata&quot;) library(knitr) #for kable/kables library(kableExtra) # retrieving data to show model 1 ax &lt;- parameterEstimates(results[[17]])[parameterEstimates(results[[17]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[17]])[parameterEstimates(results[[17]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[17]])[parameterEstimates(results[[17]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[17]])[parameterEstimates(results[[17]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m1h2y1 &lt;- rbind(ax, ay, bx, by) ax &lt;- parameterEstimates(results[[18]])[parameterEstimates(results[[18]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[18]])[parameterEstimates(results[[18]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[18]])[parameterEstimates(results[[18]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[18]])[parameterEstimates(results[[18]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m1h2y2 &lt;- rbind(ax, ay, bx, by) ax &lt;- parameterEstimates(results[[19]])[parameterEstimates(results[[19]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[19]])[parameterEstimates(results[[19]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[19]])[parameterEstimates(results[[19]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[19]])[parameterEstimates(results[[19]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m1h2y3 &lt;- rbind(ax, ay, bx, by) ax &lt;- parameterEstimates(results[[20]])[parameterEstimates(results[[20]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[20]])[parameterEstimates(results[[20]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[20]])[parameterEstimates(results[[20]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[20]])[parameterEstimates(results[[20]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m1h2y4 &lt;- rbind(ax, ay, bx, by) # model 2 ax &lt;- parameterEstimates(results[[21]])[parameterEstimates(results[[21]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[21]])[parameterEstimates(results[[21]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[21]])[parameterEstimates(results[[21]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[21]])[parameterEstimates(results[[21]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m2h2y1 &lt;- rbind(ax, ay, bx, by) ax &lt;- parameterEstimates(results[[22]])[parameterEstimates(results[[22]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[22]])[parameterEstimates(results[[22]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[22]])[parameterEstimates(results[[22]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[22]])[parameterEstimates(results[[22]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m2h2y2 &lt;- rbind(ax, ay, bx, by) ax &lt;- parameterEstimates(results[[23]])[parameterEstimates(results[[23]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[23]])[parameterEstimates(results[[23]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[23]])[parameterEstimates(results[[23]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[23]])[parameterEstimates(results[[23]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m2h2y3 &lt;- rbind(ax, ay, bx, by) ax &lt;- parameterEstimates(results[[24]])[parameterEstimates(results[[24]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[24]])[parameterEstimates(results[[24]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[24]])[parameterEstimates(results[[24]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[24]])[parameterEstimates(results[[24]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m2h2y4 &lt;- rbind(ax, ay, bx, by) # model 3 ax &lt;- parameterEstimates(results[[25]])[parameterEstimates(results[[25]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[25]])[parameterEstimates(results[[25]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[25]])[parameterEstimates(results[[25]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[25]])[parameterEstimates(results[[25]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m3h2y1 &lt;- rbind(ax, ay, bx, by) ax &lt;- parameterEstimates(results[[26]])[parameterEstimates(results[[26]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[26]])[parameterEstimates(results[[26]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[26]])[parameterEstimates(results[[26]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[26]])[parameterEstimates(results[[26]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m3h2y2 &lt;- rbind(ax, ay, bx, by) ax &lt;- parameterEstimates(results[[27]])[parameterEstimates(results[[27]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[27]])[parameterEstimates(results[[27]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[27]])[parameterEstimates(results[[27]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[27]])[parameterEstimates(results[[27]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m3h2y3 &lt;- rbind(ax, ay, bx, by) ax &lt;- parameterEstimates(results[[28]])[parameterEstimates(results[[28]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[28]])[parameterEstimates(results[[28]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[28]])[parameterEstimates(results[[28]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[28]])[parameterEstimates(results[[28]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m3h2y4 &lt;- rbind(ax, ay, bx, by) # model 4 ax &lt;- parameterEstimates(results[[29]])[parameterEstimates(results[[29]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[29]])[parameterEstimates(results[[29]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[29]])[parameterEstimates(results[[29]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[29]])[parameterEstimates(results[[29]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m4h2y1 &lt;- rbind(ax, ay, bx, by) ax &lt;- parameterEstimates(results[[30]])[parameterEstimates(results[[30]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[30]])[parameterEstimates(results[[30]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[30]])[parameterEstimates(results[[30]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[30]])[parameterEstimates(results[[30]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m4h2y2 &lt;- rbind(ax, ay, bx, by) ax &lt;- parameterEstimates(results[[31]])[parameterEstimates(results[[31]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[31]])[parameterEstimates(results[[31]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[31]])[parameterEstimates(results[[31]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[31]])[parameterEstimates(results[[31]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m4h2y3 &lt;- rbind(ax, ay, bx, by) ax &lt;- parameterEstimates(results[[32]])[parameterEstimates(results[[32]])$label == &quot;ax&quot;, ][1, c(5, 6, 8)] bx &lt;- parameterEstimates(results[[32]])[parameterEstimates(results[[32]])$label == &quot;bx&quot;, ][1, c(5, 6, 8)] ay &lt;- parameterEstimates(results[[32]])[parameterEstimates(results[[32]])$label == &quot;ay&quot;, ][1, c(5, 6, 8)] by &lt;- parameterEstimates(results[[32]])[parameterEstimates(results[[32]])$label == &quot;by&quot;, ][1, c(5, 6, 8)] m4h2y4 &lt;- rbind(ax, ay, bx, by) # combine put deps under each other m1deps &lt;- rbind(m1h2y1, m1h2y2, m1h2y3, m1h2y4) m2deps &lt;- rbind(m2h2y1, m2h2y2, m2h2y3, m2h2y4) m3deps &lt;- rbind(m3h2y1, m3h2y2, m3h2y3, m3h2y4) m4deps &lt;- rbind(m4h2y1, m4h2y2, m4h2y3, m4h2y4) # put methods next to each other h2 &lt;- cbind(m1deps, m2deps, m3deps, m4deps) row.names(h2) &lt;- NULL paths &lt;- rep(c(&quot;Men:stability&quot;, &quot;Women:stability&quot;, &quot;Men:partner-effect&quot;, &quot;Women:partner-effect&quot;), 2) h2 &lt;- cbind(paths, h2) hypo2 &lt;- kbl(h2, booktabs = TRUE, digits = 2, caption = &quot;Results Hypo2&quot;, align = &quot;lcccccccccccc&quot;) %&gt;% add_header_above(c(&quot; &quot;, CLPM = 3, `RI-CLPM` = 3, `SC-RI-CLPM` = 3, `LT-RI-CLPM` = 3)) %&gt;% pack_rows(index = c(`eu-integration` = 4, immigrants = 4, euthanasia = 4, income_diff = 4)) %&gt;% kable_classic(full_width = F, html_font = &quot;Cambria&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) %&gt;% column_spec(5:7, color = &quot;white&quot;, background = &quot;green&quot;) hypo2 Table 3.2: Results Hypo2 CLPM RI-CLPM SC-RI-CLPM LT-RI-CLPM paths est se pvalue est se pvalue est se pvalue est se pvalue eu-integration Men:stability 0.60 0.01 0 0.13 0.01 0.00 0.22 0.01 0 0.08 0.01 0.00 Women:stability 0.52 0.01 0 0.10 0.01 0.00 0.19 0.01 0 0.07 0.01 0.00 Men:partner-effect 0.16 0.01 0 0.00 0.01 0.67 0.06 0.01 0 0.02 0.01 0.03 Women:partner-effect 0.15 0.01 0 0.03 0.01 0.00 0.08 0.01 0 0.03 0.01 0.00 immigrants Men:stability 0.57 0.01 0 0.06 0.01 0.00 0.10 0.01 0 0.05 0.01 0.00 Women:stability 0.57 0.01 0 0.06 0.01 0.00 0.10 0.01 0 0.04 0.01 0.00 Men:partner-effect 0.18 0.01 0 0.03 0.01 0.00 0.05 0.01 0 0.03 0.01 0.00 Women:partner-effect 0.15 0.01 0 0.01 0.01 0.26 0.04 0.01 0 0.02 0.01 0.08 euthanasia Men:stability 0.66 0.01 0 -0.03 0.01 0.00 0.15 0.01 0 -0.06 0.01 0.00 Women:stability 0.70 0.01 0 -0.02 0.01 0.00 0.14 0.01 0 -0.06 0.01 0.00 Men:partner-effect 0.19 0.01 0 0.06 0.01 0.00 0.17 0.01 0 0.08 0.01 0.00 Women:partner-effect 0.17 0.01 0 0.06 0.01 0.00 0.16 0.01 0 0.08 0.01 0.00 income_diff Men:stability 0.61 0.01 0 0.02 0.01 0.04 0.16 0.01 0 -0.02 0.01 0.00 Women:stability 0.54 0.01 0 0.00 0.01 0.69 0.12 0.01 0 -0.03 0.01 0.00 Men:partner-effect 0.14 0.01 0 0.04 0.01 0.00 0.14 0.01 0 0.06 0.01 0.00 Women:partner-effect 0.15 0.01 0 0.05 0.01 0.00 0.13 0.01 0 0.08 0.01 0.00 3.9.6 Conclusion Hypo2 naturally this will depend on how strong we simulate this preference to be. "],["data-1.html", "Chapter 4 Data 4.1 Sampling 4.2 Ethical considerations 4.3 Measurement", " Chapter 4 Data 4.1 Sampling 4.2 Ethical considerations 4.3 Measurement "],["theory-1.html", "Chapter 5 Theory 5.1 Causes 5.2 Consequences", " Chapter 5 Theory 5.1 Causes 5.2 Consequences "],["methods-1.html", "Chapter 6 Methods 6.1 Before you start 6.2 Causes 6.3 Consequences", " Chapter 6 Methods 6.1 Before you start 6.2 Causes 6.2.1 Aggregation 6.2.2 Disaggregation 6.2.3 Micro-macro Model 6.2.3.1 Multi-level framework 6.2.3.2 SEM 6.3 Consequences 6.3.1 Macro-micro model 6.3.1.1 Multi-level framework 6.3.1.2 SEM 6.3.2 Micro-macro-RI-CLPM "],["data-2.html", "Chapter 7 Data 7.1 Sampling 7.2 Ethical considerations 7.3 Measurement", " Chapter 7 Data 7.1 Sampling 7.2 Ethical considerations 7.3 Measurement "],["theory-2.html", "Chapter 8 Theory 8.1 Causes 8.2 Consequences", " Chapter 8 Theory 8.1 Causes 8.2 Consequences "],["methods-2.html", "Chapter 9 Methods 9.1 Causes 9.2 Consequences", " Chapter 9 Methods 9.1 Causes 9.2 Consequences "],["data-3.html", "Chapter 10 Data 10.1 Sampling 10.2 Ethical considerations 10.3 Measurement", " Chapter 10 Data 10.1 Sampling 10.2 Ethical considerations 10.3 Measurement "],["webintro.html", "Chapter 11 Webscraping for Sociologists 11.1 Chapter overview 11.2 Promises and pitfalls 11.3 Best of both worlds? 11.4 Where does this lead us? 11.5 Ethics 11.6 Webscraping techniques 11.7 Hands-on webscraping", " Chapter 11 Webscraping for Sociologists Latest Version: 26-08-2021 Please email any comments to: bas.hofstra@ru.nl 11.1 Chapter overview [The] technological revolution in mobile, Web, and Internet communications has the potential to revolutionize our understanding of ourselves and how we interact. Merton was right: Social science has still not found its Kepler. But three hundred years after Alexander Pope argued that the proper study of mankind should lie not in the heavens but in ourselves, we have finally found our telescope. Let the revolution begin (Watts 2011: 266) Watts already-famous quote predicts a revolution in the social sciences. He and others (see also Lazer et al. 2009) essentially argue that social science will be revolutionized by the unprecedented use of of the social internet. Given that people overwhelmingly adopted internet technologies and given that many of the platforms that offer these technologies automatically archive all kinds of behavior (Spiro 2016) such as clicks, messages, social media relationships, and so forth, there may be a treasure trove of data on the internet that social scientists can use for their research on social processes. In this chapter, we discuss some of the promises and pitfalls of webscraping so-called digital trace data (Golder and Macy 2014) on the internet for social network analysis. We are then going to discuss some different techniques that are often used for webscraping. Note that the fast-pace nature of the internet inherently means that by the time you read this text, some of the things we discuss will be outdated. (Which can be argued to be one of the pitfalls of social science research with webscraping!) We are also getting our hands dirty with a hands-on example of digital trace data that we are going to collect ourselves. So by the end of this chapter, you will be familiar with some of the unique opportunities and difficulties of webscraped (social network) data, have a birds-eye perspective on the different techniques for scraping the web for your own research, have knowledge on the ethics surrounding webscraping, and have more in-depth experience on one specific package for webscraping bibliometric data in R. In short, you will have firsthand knowledge on the current state-of-the-art in sociological data collection. There are really good, exhaustive resources for webscraping and computational sociology. See, for instance, the book by Robert Ackland (Ackland 2013). Yet, to get up to speed for this chapter, you need to read the first chapter of Bas Hofstras dissertation (Hofstra 2017), Golder and Macys Annual Review of Sociology article (Golder and Macy 2014), and Lazer and colleagues Science article (Lazer et al. 2009). (TODO: referenties in blue box zetten) 11.1.1 Definitions Webscraping The process by which you collect data from the internet. This can entail different routes: manual data collection, automated data collection via code, and so forth. Digital footprints Automatically logged behavioral signals that actors  broadly construed: individuals, companies, organizations, groups, etc.  leave on the internet. This may imply many things, including the messages one leaves on Instagram posts, back-and-forth conversations on Whatsapp, companies job advertisements, university course texts, and so forth. All of these signals can capture some social process: networking on social media, signalling specific job requirements, or university course prerequisites. This also means that digital footprints can contain a lot of different and sometimes unstructured data types. Social network data is obvious: who is friends with whom on Facebook, who Tweets to whom, and so forth. Network data (not social) is also obvious. For instance, which website links to what other websites. (Sidenote: Googles page-rank algorithm made them succesful, and this page-rank algorithm is based on network centrality that essentially filters out influential websites quickly. In other words, Google became such an influential company because of network analyses.) It can also contain (unstructured) text data, which in itself signals a lot of interesting social processes that one may consider. Computational sociology Problem-driven, empirical sociology, but with the empirical part specifically containing some form of digital footprint data and/or some new methodological technique. Sociologists are usually (necessarily?) interested in digital footprints concerning some social process. Because digital footprints are often related to social network processes (e.g., befriending on Facebook, messaging on Twitter, etc.), a lot of computational sociology includes some form of social network analysis. Because this is often, though not always, the case, discussing webscraping in the context of this book on social network analyses makes perfect sense. Some claim Agent-Based Modelling to be part of computational sociology too, others not. Again others claim performing RSiena analyses is part of computational sociology, others not. Note that this definition-issue is somewhat of a useless moving target. Computational sociologys definition will be different next week depending on who you ask. In this book, we use a pragmatic definition. This means that you are a computational sociologists if you use digital footprint data and/or use relatively new methodological techniques in your research. Also note that there is a certain cause-effect sequence in the three definions above: using webscraping techniques to gather digital footprint data to study social problems makes you a computational sociologist. 11.2 Promises and pitfalls Like every data source in the social sciences and beyond, there are unique features as well as difficult challenges to webscraped data. In this subsection, we will discuss some of these advantages and challenges of webscraping and, by extension, digital footprint data. Like we discussed before, most of the research using webscraped digital footprint data concerns social networks and so we situate these promises and pitfalls in the context of social network analysis. Note, however, that some of the promises and pitfalls generalize to other types of digital footprint data too. 11.2.1 Promises (Social) networks One of the crucial advantages of scraping data from the internet is that it is relatively easy to collect sociologically interesting network data. This may sound like a surprising thing to note in a book on social network analyses. But imagine a world without the internet, and then imagine that you are a social scientist interested in weak ties. What toolset do you have available to collect data on and then study those weak ties? You would probably think about qualitative interviews or collecting survey data. For the purpose of studying weak ties, however, both of these methods of data collection suffer from some some weaknesses. For instance, it is incredibly hard for respondents to recall those social ties that are weakly related. So asking about weak ties will likely not yield very reliable and valid results. That is, respondents will mostly acquiesce to naming those ties that they met recently or which are relatively stronger. (There are some techniques to circumvent some of these issues, but those have their own drawbacks too (see Hofstra, Corten, and Tubergen 2021).) Most surveys are also restricted, in that respondents can only name five social ties. It is possible to collect sociometric data of entire contexts in surveys, for instance by presenting respondents with a class-roster or department-roster and asking them who their trustees, friends, etc. This book even devotes an entire section to such data. Yet, such a design is pretty expensive to set up and quite taxing for respondents. In contrast, an inherent feature of many places on the social internet, respondents curate themselves who their connections are over a long time-span (e.g., friendships on Facebook) or leave many traces of interactions (e.g., mentioning someone on Twitter). Sometimes networks online are even pushed towards network closure by recommendation systems on platforms like Facebook or Instagram. These data are relatively easy and cheap to collect with some creativity on the scientists part. This will often lead to large and complete networks are not restricted by relationship type (e.g., strong or weak), social context (e.g., family or school friends), respondent recall (acquiesce to strong ties), or social desirability bias (e.g., only nominating the popular kid in town). As an examplary paper who circumvents some of the regular biases of social network research mentioned above, see Hofstra et al. (2017) who analyze segregation among weak ties by means of Facebook data. The benefits mentioned here are also prime reasons as to why much research using digital traces incorporates some type of social network analysis. Dynamics A second advantage of webscraped data is that these data are often time-stamped. This means that the the researcher knows exactly when the digital trace  e.g., the social interaction on Twitter  occurred. So the researcher can potentially perform some sort of longitudinal analyses so as to come closer to causal estimates in inferential statistical models. In the context of webscraped social networks this is particularly useful so as to separate selection from influence in larger social networks. Gathering such longitudinal sociometric data for many social foci (e.g., school classes) is difficult (yet, definitely not impossible!), whereas collecting time-stamped social interactions on the internet may be somewhat easier. Note also that whereas network data collected in, for instance, school classes often contain the same time-stamp and that longitudinal sociometric data is often collected using the same timestamp Signals A third advantage of webscraped data is that it can potentially capture behavioral signals that are otherwise hard to come by. In controlled lab environments some xyz, its hard. In survey data its hard to xyz. Yet, online xyz, makes that we can xyz. Similar to online social network data, digital footprints can be unobtrusively collected, such that social desirability biases or xyz . One should, however, be aware that the way one behaves online may not necessarily be representative for offline behavior. Yet, to study sensitive topics such as political polarization, x, or y, digital trace data may offer an alternative route (one that is less prone to social desirability biases) to xxx. Size Finally, and we discuss why this is both a blessing and a curse, webscraping can lead to collected data that may contain a lot of observations. See this study of xyz, or this study by xyz of abc. More data is not always better data, yet the sheer size of data  under appropriate sampling!  may make it easier to observe some intervention xyz. See xyz. 11.2.2 Pitfalls Sampling Often non representative (convenience sampling) Size Data size may be a pitfall; hard to analyze, sampling necessary, and sampling from social networks is especially hard Thin Many rows, yet not much information about those rows Data structure Unstructured data, hard to work with, requires some skill/imagination 11.3 Best of both worlds? The most-impactful computational sociology papers leverage the strengths of digital trace data but simultaneously account for (or at least acknowledge) its weaknesses. Some examples here 11.4 Where does this lead us? 1- New tests of old sociological hypotheses made possible by the availability of digital footprint data; 2- Tests of newly derived sociological hypotheses made possible by the availability of digital footprint data; 3- Tests of new theories about the internet as social phenomenon by itself. (TO DO: Small worlds nieuwe test oude vraag: mooi voorbeeld om te integreren.) 11.5 Ethics In webscraping digital footprins, one has to always consider ethics. In an ideal situation, a researcher has informed consent to study research subjects. In practice, however, the nature of webscraping digital footprints makes it very difficult to obtain such consent. Ethic review boards 11.6 Webscraping techniques 11.6.1 Manual Army of research assistants looking up information, saving that 11.6.2 APIs Utilizing structures in place 11.6.3 Crawling Designing own crawlers 11.7 Hands-on webscraping Now that we learned about webscraping and some of its techniques, it is time to get our hands dirty ourselves. In what follows is a short tutorial on webscraping where we will be collecting data from webpages on the internet. We will use the specific case of sociology staff at Radboud University. What do they publish? Where? And with whom do they collaborate? We assume you followed the R tutorial in this book, or that you otherwise have at least some experience with coding in R. In the rest of this tutorial, we will switch between base R and Tidyverse (just a bit), whatever is most convenient. (Note that this will happen often if you become an applied computational sociologist.) 11.7.1 Staging your script Open a new R-script (via file &gt; new &gt; RScript (or simply hit Ctrl+Shift+N or Cmd+Shift+N if you work on Mac) Before you start scraping and analyzing, take all the precautionary steps noted in A So for this tutorial, your starting script will look something like this: ######################################### Title: Webscraping in R Author: Bas Hofstra Version: 29-07-2021 # start with clean workspace rm(list = ls()) library(tidyverse) # I assume you already installed this one! install.packages(&quot;httr&quot;) require(httr) install.packages(&quot;xml2&quot;) require(xml2) install.packages(&quot;rvest&quot;) require(rvest) install.packages(&quot;devtools&quot;) require(devtools) # Note we&#39;re doing something different here. We&#39;re installing a *latest* version directly from GitHub # This is because the released version of this packages contains some errors! devtools::install_github(&quot;jkeirstead/scholar&quot;) require(scholar) # define workdirectory, note the double backslashes setwd(&#39;/yourpathhere)&#39; 11.7.2 Getting anchor data What do we mean by anchor data? Our goal is to get to know (i) who the Radboud University Department of Sociology staff is, (ii) what they publish with respect to scientific work, and (iii) who they collaborate with. So that means at least three data sources we need to collect from somewhere. What would be a nice starting (read: anchor) point be? First, we have to know who is on the sociology staff. Lets check out the Radboud sociology website. There is lots of intruiging information, but not on who is who. There is, however, a specific link to the research staff. Here we do see a nice list on who is on the sociology staff. How do we get that data? It is actually quite simple, the package xml2 has a very nice function html_read() which simply derives the source html of a webpage: # Let&#39;s first get the staff page read_html is a function that simply extracts html webpages and puts # them in xml format soc_staff &lt;- read_html(&quot;https://www.ru.nl/sociology/research/staff/&quot;) head(soc_staff) That looks kinda weird. What type of object did we store it by putting the html into soc_staff? class(soc_staff) So it is is stored in something thats called an xml object. Not important for now what that is. But it is important to extract the relevant table that we saw on the sociology staff website. How do we do that? Go to the https://www.ru.nl/sociology/research/staff/ in Google Chrome and then press Inspect on the webpage (right click&gt;Inspect). Look at the screenshot below, you should be able to see something like this. In the html code we extracted from the Radboud website, we need to go to one of the nodes first. If you move your cursor over body in the html code on the right-hand side of your screen, the entire body of the page should become some shade of blue. This means that the elements encapsulated in the body node captures everything that turned blue. Next, we need to look at the specific elements on the page that we need to extract. Somewhat by informed trial and error, looking for the correct code, we can select the elements we want. In the screenshot below, you see that the td elements actually are the ones we need. So we need code that looks for the node body and the td elements in the xml object and then extract those elements in it. Note that you can click on the arrows once you are in the Inspect mode in the web browser to trial-and-error to get at the correct elements. Something like the code below should do just that: # so we need to find WHERE the table is located in the html &#39;inspect element&#39; in mozilla firefox or # &#39;view page source&#39; and you see that everything AFTER /td in the &#39;body&#39; of the page seems to be the # table we do need soc_staff &lt;- soc_staff %&gt;% rvest::html_nodes(&quot;body&quot;) %&gt;% xml2::xml_find_all(&quot;//td&quot;) %&gt;% rvest::html_text() Question: What happens in the code above? Why do we specify body and //td? Let us check out what happened to the soc_staff object now: head(soc_staff) # looks much better! So it looks much nicer but does not seem to be in the entirely correct order. We have odd rows and even rows: odd rows are names, even rows have the expertise of staff. We need to get a bit creative to put the data in a nicer format. The %% operator gives a remainder of integers (whole numbers). So 10/2=5 with no remainder, but 11/2=5 with a remainder of 1. odd &lt;- function(x) x%%2 != 0 even &lt;- function(x) x%%2 == 0 Question: Can you find out what the following function does? How long are the data? nstaf &lt;- length(soc_staff) # 94 nstaf Alright, can we get the odd rows out of there? soc_names &lt;- soc_staff[odd(1:nstaf)] # in the 1 until 94st number, get the odd elements soc_names And how about peoples expertise? soc_experts &lt;- soc_staff[even(1:nstaf)] # in the 1 until 94st number, get the even elements soc_experts Finally, can we merge those two vectors? soc_df &lt;- data.frame(cbind(soc_names, soc_experts)) # columnbind those and we have a DF for soc staff! soc_df That looks much better! Now we only need to remove the redundant rows that state expertise, staff, and so forth. # inspect again, and remove the rows we don&#39;t need (check for yourself to be certain!) delrows &lt;- which(soc_df$soc_names == &quot;Staff:&quot; | soc_df$soc_names == &quot;PhD:&quot; | soc_df$soc_names == &quot;External PhD:&quot; | soc_df$soc_names == &quot;Guest researchers:&quot;) soc_df &lt;- soc_df[-delrows, ] soc_df Now we have a nice relatively clean dataset with all sociology staff and their expterise. But there is yet some work to do before we can move on. We need to do some data cleaning. Ideally, we have staff their first and last names in clean columns. So the last name seems easy, everything before the comma. Do you understand the code below? gsub is a function that remove something and replaces it with something else. In the code below it replaces everything thats behind a comma with nothing in the column soc_names in the data frame soc_df. The first name is trickier, we need some more difficult expressions to extract first names from this string. Its not necessary for now to exactly know how the expressions below work, but if you want to get into it, heres a nice resource. The important part of the code below is that it extracts everything thats in between the brackets. # Last name seems to be everything before the comma soc_df$last_name &lt;- gsub(&quot;,.*$&quot;, &quot;&quot;, soc_df$soc_names) # first name is everything between brackets soc_df$first_name &lt;- str_extract_all(soc_df$soc_names, &quot;(?&lt;=\\\\().+?(?=\\\\))&quot;, simplify = TRUE) soc_df soc_df$first_name So we need yet to do some manual cleaning, one name seemed to be inconsistent with how the other names were listed on the webpage. As data get bigger, this becomes impossible to do manually and we simply have to accept this as noise. soc_df$last_name &lt;- gsub(&quot; J. \\\\(Jansje\\\\) van MSc&quot;, &quot;&quot;, soc_df$last_name) Not quite there yet. To be sure, well trim some white space in the variables we know created. This means we remove spaces before and after strings. # trimws looses all spacing before and after (if you specify &#39;both&#39;) a character string soc_df$last_name &lt;- trimws(soc_df$last_name, which = c(&quot;both&quot;), whitespace = &quot;[ \\t\\r\\n]&quot;) soc_df$first_name &lt;- trimws(soc_df$first_name, which = c(&quot;both&quot;), whitespace = &quot;[ \\t\\r\\n]&quot;) soc_df$soc_experts &lt;- trimws(soc_df$soc_experts, which = c(&quot;both&quot;), whitespace = &quot;[ \\t\\r\\n]&quot;) soc_df$soc_names &lt;- trimws(soc_df$soc_names, which = c(&quot;both&quot;), whitespace = &quot;[ \\t\\r\\n]&quot;) Finally, because were quite sure that all these staff belong to Radboud University, we simply create a variable that contains a character string. # set affiliation to radboud, comes in handy for querying google scholar soc_df$affiliation &lt;- &quot;radboud university&quot; How do the data look? soc_df Pretty good, so I think we can move on to the next section. 11.7.3 Google Scholar Profiles and Publications What we now have is a data frame of sociology staff members. So we succesfully gathered the anchor data set we can move on with. Next, we need to find out whether these staff have a Google Scholar profile. I imagine you have accessed Google Scholar many times during your studies for finding scientists or publications. The nice thing about Google Scholar is that it lists collaborators, publications, and citations on profiles. So what we first need to do is look for Google Scholar profiles among sociology staff. Luckily, we cleaned first and last names and have their affiliation. That makes looking them up much easier. So we need to do this for every person in our data frame. Before we query Google Scholar, we first need to learn a neat trick: for loops. Can you follow the code below? We can do all kinds of things automatically in a for loop. # The &#39;for loop&#39;: for every i in a vector (can be numbers, strings, etc.), say 1 to 10, you can do # &#39;something&#39; for (i in 1:10) { print(i) # So for every i from 1 to 10, we print i, see what happens! } # or do something more complicated p &lt;- rnorm(10, 0, 1) # draw 10 normally distributed numbers with mean 0 and SD 1 (so z-scores, essentially) plot(density(p)) # relatively, normal, right? u &lt;- 0 # make an element we can fill up in the loop below for (i in 1:10) { u[i] &lt;- p[i] * p[i] # get p-squared for every i-th element in vector p print(u[i]) # and print that squared element } Now that we know how to implement for loops in our workflow, we can utilize them to do slightly more complicated stuff. We want to know the identifying link on Google Scholar for each sociology staff member. We first set an empty identifier in our data frame so that we can fill up that data column later. soc_df$gs_id &lt;- &quot;&quot; # we set an empty identifier So lets move on with attempting to find Google Scholar profiles. The package scholar has a very nice function get_scholar_id. It needs a last name, first name, and affiliation. Luckily, we already found those on the Radboud University website! So we can fill in those. Lets try it for one staff member first. source(&quot;addfiles/function_fix.R&quot;) # Put the function_fix.R in your working directory, we need this first line. get_scholar_id_fix(last_name = &quot;tolsma&quot;, first_name = &quot;jochem&quot;, affiliation = &quot;radboud university&quot;) We now know that Jochems Scholar ID is Iu23-90AAAAJ. Thats very convenient, because now we can use the package scholar to extract a range of useful information from his Google Scholar profile. Lets try it out on his profile first. Notice the nice function get_profiles. We simply have to input his Google Scholar ID and it shows everything on the profile get_profile(&quot;Iu23-90AAAAJ&quot;) # Jochem&#39;s profile Next up, Jochems publications. Notice how not everything is in a nice data frame format yet, well get to that later. get_publications(&quot;Iu23-90AAAAJ&quot;) # Jochem&#39;s pubs When and how often was Jochem cited? Seems like an increasing trend line! get_citation_history(&quot;Iu23-90AAAAJ&quot;) # Jochem&#39;s citation history Get jochems collaborators, and the collaborators of those collaborators. So essentially a one-step-further-than-Jochem network. get_coauthors(&quot;Iu23-90AAAAJ&quot;, n_coauthors = 50, n_deep = 1) # Jochem&#39;s collaborators and their co-authors! Notice, however, that we could easily plot Jochems collaboration network already! (Though we leave the specifics for the sister-tutorial on viz.) plot_coauthors(get_coauthors(&quot;Iu23-90AAAAJ&quot;, n_coauthors = 50, n_deep = 1), size_labels = 2) # Doesn&#39;t look like much yet, but we&#39;ll make it prettier later. So lets gather these data, but now for all sociology staff simultaneously! For this, we use the for loop again. The for loop I make below is a bit more complicated, but follows the same logic as before. For each row (i) in soc_df, we attempt to query Google Scholar on the basis of the first name, last name, and affiliation listed in that row in the data frame. We use some handy subsetting, e.g., soc_df[i, 3] means we input last_name= with the last name (which is the third column) found in the i-th row in the data frame. The same goes for first name and affiliation. We fill up gs_id in the data frame with the Google Scholar IDs well hopefully find. The for (i in nrow(soc_df)) simply means we let i run for however many rows the data frame has. Finally, the tryCatch({}) function makes that we can continue the loop even though we may encounter errors for a given row. Here, that probably means that not every row (i.e., sociology staff member) can be found on Google Scholar. We print the error, but continue the for loop with the tryCatch({}) function. In the final rows of the code below. We simply drop those rows that we cannot identify on Google Scholar. # Look throught get_scholar_id_fix(last_name, first_name, affiliation) # if we can find google scholar profiles of sociology staff! for (i in 1:nrow(soc_df)) { tryCatch({ soc_df[i,c(&quot;gs_id&quot;)] &lt;- get_scholar_id_fix(last_name = soc_df[i, 3], # so search on last_name of staff (third column) first_name = soc_df[i,4], # search on first_name of staff (fourth column) affiliation = soc_df[i,5]) # search on affiliation of each staff (fifth column) }, error=function(e){cat(&quot;ERROR :&quot;,conditionMessage(e), &quot;\\n&quot;)}) # continue on error, but print the error } # remove those without pubs from the df # seems we&#39;re left with about 34 sociology staff members! soc_df &lt;- soc_df[!soc_df$gs_id == &quot;&quot;, ] soc_df It works! So what is left to do is simply to get the data we already extracted for Jochem, but for all sociology staff. For that, we need a bunch of for loops. Lets first gather the profiles and publications. We store those in a list() which is an object in which you can store multiple data frames, vectors, matrices, and so forth. This is particularly good for for loops because you can store information that is  at first sight  not necessarily compatible. For instance, matrices of different length. Note that bind a Google Scholar ID to the publications too. soc_list_profiles &lt;- list() # first we create an empty list that we then fill up with the for loop soc_list_publications &lt;- list() for (i in 1:nrow(soc_df)) { # note how you call different elements in a list &#39;[[]]&#39;, fill in the i-th element soc_list_profiles[[i]] &lt;- get_profile(soc_df[i, c(&quot;gs_id&quot;)]) # Note how we call row i (remember how to call rows in a DF/Matrix) and then the associated scholar id soc_list_publications[[i]] &lt;- get_publications(soc_df[i, c(&quot;gs_id&quot;)]) soc_list_publications[[i]][, c(&quot;gs_id&quot;)] &lt;- soc_df[i, c(&quot;gs_id&quot;)] # note that we again attach an id # so both functions here call the entire profile and pubs for an author, based on google scholar ids } # Notice how fast the data blow up! 34 scholars publish ~3000 papers soc_df_publications &lt;- bind_rows(soc_list_publications) soc_df_publications We need to do some relatively involved data handling to attach the Google Scholar profiles in soc_list_profiles to the soc_df. That is mostly because profile elements can contain more than one row. For instance, co-authors are stored in long format per profile that do not easily merge to a data frame where each staff member is a row. So we need to get only the profile elements that have a single element per profile element (e.g., total cites). Seems these are the first 8 elements. So we need to get those out of the lists and store those in a new list. We use a couple of functions to first unlist the 1 tot 8-th elements in that list, make it a data frame, and transpose the data such that each row contains 8 columns. We then use the function bind_rows() to simply make a data frame from the list elements. We then merge it to soc_df. So what we end up with is a sociology staff data frame with much more information than before: citations, indices, expertise listed on Google Scholar, and so forth. # get the profiles too, just to be sure soc_profiles_df &lt;- list() for (i in 1:length(soc_list_profiles)) { soc_profiles_df[[i]] &lt;- data.frame(t(unlist(soc_list_profiles[[i]][1:8]))) #some annyoing data handling } soc_profiles_df &lt;- bind_rows(soc_profiles_df) soc_df &lt;- left_join(soc_df, soc_profiles_df, by = c(gs_id = &quot;id&quot;)) # merge data with soc_df soc_df So we have papers and profile. Remember how we got Jochems citation history? We want that for each staff member too. Yet again, we use a for loop. We first store the citation history in a list. But notice the if statement! We only continue the for loop for that i-th element if some statement is TRUE. Here, we attempt to find out if the i-th element, the citation history of the staff member, has a length than is larger than 0. Some staff members are never cited (which happens all the time if papers are only just published), and so for these staff members that is no list element that contains information. We only attach a Google Scholar ID for those staff members that are cited at least once. We bind the rows again and end up with a data frame in long format: three columns with years, cites, and Google Scholar ID. Therefore, there is more than one row per staff member. # get citation history of a scholar soc_staff_cit &lt;- list() for (i in 1:nrow(soc_df)) { soc_staff_cit[[i]] &lt;- get_citation_history(soc_df[i, c(&quot;gs_id&quot;)]) if (nrow(soc_staff_cit[[i]]) &gt; 0) { soc_staff_cit[[i]][, c(&quot;gs_id&quot;)] &lt;- soc_df[i, c(&quot;gs_id&quot;)] # again attach the gs_id as third column } } soc_staff_cit &lt;- bind_rows(soc_staff_cit) colnames(soc_staff_cit)[3] &lt;- &quot;gs_id&quot; soc_staff_cit Next, we get the collaborators. For loop should be clear by now. We get collaborators for a given Google Scholar ID, 50 of them, with a distance of at most 1. We then bind_rows again, and remove those staff members that did not list any collaborator. # the first 10 at most! n_deep means the co-authors of my co-authors, which can blow up fairly # quickly, so keep that number low. soc_collabs &lt;- list() for (i in 1:nrow(soc_df)) { # one deep soc_collabs[[i]] &lt;- get_coauthors(soc_df[i, c(&quot;gs_id&quot;)], n_coauthors = 10, n_deep = 1) # note again the gs_id that I use soc_collabs[[i]][, c(&quot;gs_id&quot;)] &lt;- soc_df[i, c(&quot;gs_id&quot;)] } soc_df_collabs &lt;- data.frame(bind_rows(soc_collabs)) soc_df_collabs &lt;- soc_df_collabs[!is.na(soc_df_collabs$author), ] soc_df_collabs Finally, we want to get the article citation history! Notice how we got like ~3K articles? For all of those articles we need in each year how often they were cited. That means a lot of queries to Google Scholar. We need to prevent that we hit the so-called rate-limit. This means that our IP will be blocked for requesting access to a webpage because we did it too often too quickly. Luckily, we can randomize our calls by time in a for loop! Do you understand the code below? (Hint: the code annotation kinda gives it away.) # because we don&#39;t wanna &#39;Rate limit&#39; google scholar, they throw you out if you make to many # requests, we randomize request time do you understand the code below? for (i in 1:10) { time &lt;- runif(1, 0, 5) Sys.sleep(time) print(paste(i, &quot;: R slept for&quot;, round(time, 1), &quot;seconds&quot;)) } # for every number from 1 to 10 we draw one number from 0 to 5 from a uniform distribution we put the # wrapper sys.sleep around it that we put R to sleep for the drawn number So we time-randomize our calls to Google. In this final for loop, we again put the citation history in a list and only put a Google Scholar ID next to it if there is any citation ever on that paper. Notice how we now call columns and rows from soc_df_publications. This is because those contain both the publications of staff members and the publication ids which we need to gather the citation history of papers. Finally, we bind_rows() again to have data frame in long format with year, citation, publication id, and Google Scholar ID. Notice how this will take way too long for this tutorial to finish. For instance, lets say the mean waiting time is 2 seconds per query. That means at 2*3000 papers=6000 seconds, which is longer than 90 minutes. So we already gathered the data for you to continue with. # get citation history of a scholar-paper soc_art_cit &lt;- list() for (i in 1:nrow(soc_df_publications)) { Sys.sleep(runif(1, 0, 4)) tryCatch({ soc_art_cit[[i]] &lt;- get_article_cite_history(soc_df_publications[i, c(&quot;gs_id&quot;)], soc_df_publications[i, c(&quot;pubid&quot;)]) }, error = function(e) { cat(&quot;ERROR :&quot;, conditionMessage(e), &quot;\\n&quot;) }) # continue on error, but print the error tryCatch({ if (nrow(soc_art_cit[[i]]) &gt; 0) { soc_art_cit[[i]][, c(&quot;gs_id&quot;)] &lt;- soc_df_publications[i, c(&quot;gs_id&quot;)] } }, error = function(e) { cat(&quot;ERROR :&quot;, conditionMessage(e), &quot;\\n&quot;) }) # continue on error, but print the error } soc_art_cit &lt;- bind_rows(soc_art_cit) Lets save the data we need in for the next tutorial. # save the DFs thus far save(soc_df_publications, &quot;addfiles/soc_df_publications.rda&quot;)) save(soc_df, &quot;addfiles/soc_df.rda&quot;)) save(soc_df_collabs, &quot;addfiles/soc_df_collabs.rda&quot;)) #save(soc_art_cit, &quot;addfiles/soc_art_cit.rda&quot;)) Notice how we did this one for you. save(soc_staff_cit, &quot;addfiles/soc_staff_cit.rda&quot;)) Nicely done, this was the webscraping tutorial for bibliometric data. We gathered useful information about sociology staff: - 1.1 who actually is the staff on the RU website? - 1.2 staff google scholar profiles (we merged 1.1 and 1.2) - 2 publications and total cites per publication - 3 collaborators plus their collaborators (friends-of-friends) - 4 publication citation history (cites per year) - 5 citation history of scholars themselves (cites per year) Next, we can move on to some cool network visualization. "],["tutorial.html", "A Introduction to R for SNA A.1 Preliminary notes A.2 Getting up and running A.3 Working with RScript A.4 Installing additional packages A.5 I dont understand the code!! A.6 Reading in data files A.7 Define missings A.8 Recoding variables A.9 Means and counting specific values A.10 Merging data files A.11 Aggregate data A.12 Missing values", " A Introduction to R for SNA ## Loading required package: xfun ## ## Attaching package: &#39;xfun&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## attr, isFALSE ## Loading required package: foreign ## Loading required package: tidyverse ## -- Attaching packages ----------------------------------------------------------- tidyverse 1.3.1 -- ## v ggplot2 3.3.3 v purrr 0.3.4 ## v tibble 3.1.0 v dplyr 1.0.5 ## v tidyr 1.1.3 v stringr 1.4.0 ## v readr 1.4.0 v forcats 0.5.1 ## -- Conflicts -------------------------------------------------------------- tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() ## Loading required package: mice ## ## Attaching package: &#39;mice&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## filter ## The following objects are masked from &#39;package:base&#39;: ## ## cbind, rbind ## Loading required package: labelled Latest Version: 26-08-2021 Please email any comments to: j.tolsma@ru.nl A.1 Preliminary notes This very short R tutorial is for students who already have some experience with R who want to make the switch from stata/spss to R. - In this tutorial I assume you will work with RScripts (.R files) not with Rmarkdown (.Rmd files) - I will show you how to do things in base R and in a Tidyverse way. A.2 Getting up and running install the latest version of R: R install the latest version of RStudio: RStudio open RStudio and follow a brief tour/tutorial brief tour of Gulzar Do you Want more information, or are you looking for a different (tidyverse) tutorial? R-bloggers RStudio cheatsheets R for Data Science Statistical Inference via Data Science: A Modern Dive into R and the tidyverse Are you a Research Master Social and Cultural Science student? Or, a social science student/scientists with some statistical background in descriptive and explanatory statistics (e.g. regression analysis) who wants to make a switch from SPSS to R? Please read on. Open RStudio. Your screen will look something like this: Figure A.1: Screenshot Rstudio During the workgroup I will show you around the major subwindows and taps in RStudio. A.3 Working with RScript Open a new R-script (via file &gt; new &gt; RScript (see Figure A.1 Arrow 1), or simply hit Ctrl+Shift+N) Start your script with your name and date. Start with a clean workspace. Start with the latest versions of R, RStudio and your packages. Load the additional packages you will need later. Define your workdirectory. Thus your RScript will look something like this: ########################### # Title: Introducation to R for SNA # Author: J Tolsma # version: 30-10-2019 ########################### #start with clean workspace rm(list=ls()) #install.packages I will need later here install.packages(&quot;installr&quot;) #you first install packages require(installr) #then you will need to load them. This package is used to simply update R install.packages(&quot;foreign&quot;) require(foreign) #used to read in spss data files require(tidyverse) #update if necessarry updateR() #define workdirectory, note the double backslashes setwd(&#39;C:\\\\SNA-4-Social-Scientists\\\\&#39;) #change to your own workdirectory Do you see I start some lines with a # these lines are comments and not code/commands. This is similar as the * sign in SPSS. To run some code, you place your cursor in the line and hit Ctrl+Enter. You may also select the code you want to run, or copy and paste it directly in the console window (A.1 Arrow 2). To see which commands you have executed, you may want to have a look at the history tab (A.1 Arrow 3). Hint 1: In the upper right corner of the code blocks you see a copy-and-paste sign. You may use this to copy and paste the code of this tutorial in your own script. Hint 2: You really want to learn R? Never ever copy and paste code. Type the code yourself. A.4 Installing additional packages You will probably always need to load and/or install additional packages. You may want to use RStudios functionality (A.1 Arrow 4). I normally prefer to put everything in my script. See for example in the code block above, line 9 to 12. A.5 I dont understand the code!! When you see functionname()2 it means we use a build-in function of R If you want to see how lines/commands/functions work, try to decipher them from the inside out. Thus if you want to dechiper rm(list=ls()): ls() list=ls() list Lets give it a go: tesvariable &lt;- 4 ls() ## [1] &quot;tesvariable&quot; list=ls() list ## [1] &quot;tesvariable&quot; ls() ## [1] &quot;list&quot; &quot;tesvariable&quot; rm(list) ls() ## [1] &quot;tesvariable&quot; #? :-) rm(list=ls()) ls() ## character(0) If you want to know more about specific functions, try to use the help function. For example try the following: ?ls ?rm Any idea what &lt;- does? At first it will be difficult to read the R Documentation pages. Dont worry, you will get the hang of it. How am I to remember all that code/syntax??!! By using them. You dont need to, you just need to remember in which script you used them before. By using the existing cheat sheets: By making your own cheat sheets. You being the ideal student, you started your own cheat sheet. What should be on it by know? Functions: install.packages() # to install additional packages. Only do this once or to update package. require() # activate installed package setwd() # set your working directory ls() # list the objects in your environment rm() # to remove objects packages: installr # a package to easily update R (needs to be run in Rgui directly instead of RStudio ) foreign # to read in spss data files tidyverse # a bunch of packages which allows for a completely different way of programming/scripting in R. operators / symbols: ? # if placed in front of a function opens up the help pages. &lt;- # used to assign values/objects to a different object. = # used to assign values/objects to arguments within a function. A.6 Reading in data files We are going to work with two datasets: Culturele Veranderingen. For more information on these datasets, see here. Please download the files to your working directory. Cultural_Changes_2008.sav Cultural_Changes_2010.sav There are different packages to read in data. Generally, I would recommend to use the haven package. In the past I used to foreign package. The advantage of using haven::read_spss is that more information is stored in the dataset and in the variables (variable/value labels!!). A disadvantage is that not all other functions/packages of R are capable of dealing with the dataobject that haven produces. below I will use package_name::function_name notation, to make explicit from which package the function belongs. #ignore the warnings #?read.spss #note that I have saved the data files in a folder called &#39;addfiles&#39;. cv08 &lt;- foreign::read.spss(&quot;addfiles\\\\Cultural_Changes_2008.sav&quot;, use.value.labels=T, to.data.frame=T) cv10 &lt;- foreign::read.spss(&quot;addfiles\\\\Cultural_Changes_2010.sav&quot;, use.value.labels=T, to.data.frame=T) #normally I think setting use.value.labels=F is more convenient. Thus lets load the data again but now without labels cv08_nolab &lt;- foreign::read.spss(&quot;addfiles\\\\Cultural_Changes_2008.sav&quot;, use.value.labels=F, to.data.frame=T) cv10_nolab &lt;- foreign::read.spss(&quot;addfiles\\\\Cultural_Changes_2010.sav&quot;, use.value.labels=F, to.data.frame=T) #finally, import the data using haven cv08_haven &lt;- haven::read_spss(&quot;addfiles\\\\Cultural_Changes_2008.sav&quot;) cv10_haven &lt;- haven::read_spss(&quot;addfiles\\\\Cultural_Changes_2010.sav&quot;) So you see I read in the data by using the function read.spss() of the package foreign. Within this function I set some arguments/parameters (e.g. use.value.labels). Now we can inspect our datasets and look for some differences: Find the Environment tab in the upper right window (A.1 Arrow 5). Find the little arrow and decollapse. What do we see? Double click on the three versions of the cv08 datasets. What happens? Go to the new windows and have a look at the data. What are the differences? Close this window when finished. Lets use some build-in functions to get more information of our dataset. str(cv08) ## &#39;data.frame&#39;: 1963 obs. of 278 variables: ## $ we_id : Factor w/ 1963 levels &quot;36775330&quot;,&quot;36775340&quot;,..: 1 2 3 4 5 6 7 8 9 10 ... ## $ veilignr: num 8.11e+08 8.11e+08 8.11e+08 8.11e+08 8.11e+08 ... ## $ lft1 : Factor w/ 78 levels &quot;0&quot;,&quot;15&quot;,&quot;16&quot;,..: 38 26 3 17 44 36 49 21 46 28 ... ## $ geslacht: Factor w/ 3 levels &quot;Onbekend&quot;,&quot;Man&quot;,..: 2 3 3 2 2 3 2 3 2 2 ... ## $ allochtn: Factor w/ 4 levels &quot;geen allochtoon&quot;,..: 1 1 2 1 1 2 1 2 1 1 ... ## $ lft01 : Factor w/ 82 levels &quot;&lt; één jaar&quot;,&quot;één jaar&quot;,..: 40 28 4 19 46 38 51 23 48 30 ... ## $ lftop : Factor w/ 81 levels &quot;&lt; één jaar&quot;,&quot;één jaar&quot;,..: 40 28 4 18 46 38 51 23 48 30 ... ## $ gewicht : num 8423 6244 13434 8997 8423 ... ## $ var006n : Factor w/ 11 levels &quot;onbekend&quot;,&quot;OP &lt; 12 jr of volgt actueel bas.ondw.&quot;,..: 8 10 5 10 8 4 4 7 7 3 ... ## $ v040 : Factor w/ 6 levels &quot;Geen opgave&quot;,..: 6 5 6 5 6 6 5 5 5 5 ... ## $ var723 : Factor w/ 62 levels &quot;Weigert&quot;,&quot;Weet niet&quot;,..: 3 43 3 17 3 3 39 30 28 17 ... ## $ var723a : Factor w/ 8 levels &quot;Geen opgave&quot;,..: 2 2 2 2 2 2 2 2 2 2 ... ## $ v202n : Factor w/ 10 levels &quot;-3&quot;,&quot;werkt &gt;12 uur&quot;,..: 6 2 9 2 5 4 2 2 2 2 ... ## $ var1061a: Factor w/ 6 levels &quot;Geen opgave&quot;,..: 5 6 6 6 6 6 6 6 6 6 ... ## $ var1061b: Factor w/ 31 levels &quot;Weigert&quot;,&quot;Weet niet&quot;,..: 17 3 3 3 3 3 3 3 3 3 ... ## $ var1062a: Factor w/ 6 levels &quot;Geen opgave&quot;,..: 6 6 6 6 6 6 6 6 5 6 ... ## $ var1062b: Factor w/ 31 levels &quot;Weigert&quot;,&quot;Weet niet&quot;,..: 3 3 3 3 3 3 3 3 21 3 ... ## $ int137n : Factor w/ 8 levels &quot;Geen opgave&quot;,..: 2 7 2 5 2 5 6 7 7 6 ... ## $ int138n : Factor w/ 8 levels &quot;Geen opgave&quot;,..: 7 7 7 7 6 7 7 6 7 7 ... ## $ int139n : Factor w/ 8 levels &quot;Geen opgave&quot;,..: 2 7 2 2 2 7 5 5 7 2 ... ## $ int140n : Factor w/ 8 levels &quot;Geen opgave&quot;,..: 2 7 7 7 5 7 5 5 7 7 ... ## $ int141n : Factor w/ 8 levels &quot;Geen opgave&quot;,..: 5 7 5 7 5 7 5 5 7 5 ... ## $ v401 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 6 6 6 6 7 6 7 6 6 6 ... ## $ var1343 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 7 7 7 7 6 7 7 7 7 7 ... ## $ var648 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 7 5 7 8 7 7 7 8 7 7 ... ## $ var149 : Factor w/ 8 levels &quot;Geen opgave&quot;,..: 6 5 3 7 6 6 6 6 5 6 ... ## $ var058 : Factor w/ 6 levels &quot;Geen opgave&quot;,..: 5 5 5 5 5 6 6 5 5 5 ... ## $ var059 : Factor w/ 6 levels &quot;Geen opgave&quot;,..: 5 5 5 6 5 5 5 5 5 6 ... ## $ var064 : Factor w/ 6 levels &quot;Geen opgave&quot;,..: 5 5 6 5 6 6 6 5 6 6 ... ## $ var365 : Factor w/ 6 levels &quot;Geen opgave&quot;,..: 5 5 6 5 5 5 5 6 6 6 ... ## $ var065 : Factor w/ 6 levels &quot;Geen opgave&quot;,..: 6 5 5 6 3 5 6 6 5 5 ... ## $ var092 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 6 3 6 8 8 8 8 7 8 7 ... ## $ var096 : Factor w/ 10 levels &quot;Geen opgave&quot;,..: 7 7 6 7 7 5 6 6 5 5 ... ## $ int054 : Factor w/ 8 levels &quot;Geen opgave&quot;,..: 8 3 7 7 5 5 6 7 6 5 ... ## $ int055 : Factor w/ 8 levels &quot;Geen opgave&quot;,..: 7 7 7 6 3 5 6 7 7 6 ... ## $ int056 : Factor w/ 8 levels &quot;Geen opgave&quot;,..: 6 6 7 7 6 5 5 7 6 7 ... ## $ int057 : Factor w/ 8 levels &quot;Geen opgave&quot;,..: 6 7 6 6 5 6 7 7 6 5 ... ## $ int058 : Factor w/ 8 levels &quot;Geen opgave&quot;,..: 7 7 6 6 3 5 6 7 8 6 ... ## $ int059 : Factor w/ 8 levels &quot;Geen opgave&quot;,..: 6 7 3 7 7 5 5 6 8 6 ... ## $ int059a : Factor w/ 8 levels &quot;Geen opgave&quot;,..: 7 6 6 6 7 5 6 6 7 6 ... ## $ var571 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 6 7 7 6 6 6 6 7 6 7 ... ## $ var572 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 2 5 7 2 2 2 2 7 2 5 ... ## $ var573 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 5 6 7 6 5 5 5 5 6 6 ... ## $ var574 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 7 2 7 2 6 7 7 6 2 2 ... ## $ var576 : Factor w/ 10 levels &quot;Geen opgave&quot;,..: 9 6 7 8 9 6 9 8 8 9 ... ## $ var153 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 7 5 5 5 5 5 5 5 5 5 ... ## $ var154 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 7 6 6 6 7 6 7 6 7 7 ... ## $ var155 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 6 6 6 7 7 7 7 3 6 6 ... ## $ var156 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 7 6 6 6 6 3 7 6 6 6 ... ## $ var157 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 6 3 6 6 6 7 7 3 6 3 ... ## $ var157a : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 7 3 6 6 7 7 7 6 6 6 ... ## $ var154a : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 3 3 6 6 6 6 6 6 6 6 ... ## $ var164 : Factor w/ 8 levels &quot;Geen opgave&quot;,..: 6 6 6 5 5 5 5 6 5 5 ... ## $ var165 : Factor w/ 10 levels &quot;Geen opgave&quot;,..: 7 7 7 8 9 9 8 8 9 8 ... ## $ var166 : Factor w/ 10 levels &quot;Geen opgave&quot;,..: 7 7 8 7 9 9 8 7 8 8 ... ## $ var179 : Factor w/ 6 levels &quot;Geen opgave&quot;,..: 5 5 6 5 5 5 5 5 5 5 ... ## $ var180 : Factor w/ 6 levels &quot;Geen opgave&quot;,..: 5 5 5 6 5 6 6 5 5 5 ... ## $ var184 : Factor w/ 6 levels &quot;Geen opgave&quot;,..: 5 5 6 5 6 5 5 5 5 5 ... ## $ var185 : Factor w/ 6 levels &quot;Geen opgave&quot;,..: 6 5 5 5 6 5 5 5 5 5 ... ## $ var198a : Factor w/ 6 levels &quot;Geen opgave&quot;,..: 6 5 5 5 5 5 6 6 6 5 ... ## $ var198 : Factor w/ 11 levels &quot;Geen opgave&quot;,..: 2 7 9 7 5 5 2 2 2 7 ... ## $ var201a : Factor w/ 6 levels &quot;Geen opgave&quot;,..: 6 5 5 6 6 5 6 6 6 6 ... ## $ var201b : Factor w/ 10 levels &quot;Geen opgave&quot;,..: 2 6 8 2 2 5 2 2 2 2 ... ## $ var204 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 9 8 9 8 9 8 9 9 7 9 ... ## $ int257 : Factor w/ 11 levels &quot;Geen opgave&quot;,..: 11 7 7 8 10 6 7 9 7 11 ... ## $ var211 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 7 6 7 7 7 5 7 6 6 7 ... ## $ var223 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 5 6 5 7 5 5 5 7 5 5 ... ## $ var1320 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 5 6 6 6 6 6 6 7 5 5 ... ## $ var1321 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 5 8 6 6 8 6 8 8 6 6 ... ## $ var1322 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 7 7 6 6 7 5 5 6 5 5 ... ## $ var1323 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 7 7 6 7 7 6 7 7 7 7 ... ## $ var1324 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 7 7 6 7 7 7 7 7 7 7 ... ## $ var1325 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 7 7 7 7 7 6 7 7 7 6 ... ## $ var1326 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 7 7 7 7 7 7 7 7 7 7 ... ## $ var1327 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 7 7 6 7 7 6 7 7 6 7 ... ## $ var1328 : Factor w/ 7 levels &quot;Geen opgave&quot;,..: 7 7 7 7 7 7 7 7 7 7 ... ## $ var229 : Factor w/ 12 levels &quot;Geen opgave&quot;,..: 7 7 7 12 7 7 7 6 7 7 ... ## $ int218 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 6 6 7 7 6 8 7 7 8 7 ... ## $ int219 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 6 6 7 7 7 6 6 6 7 7 ... ## $ int221 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 9 6 9 7 7 6 7 7 6 7 ... ## $ int222 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 6 6 7 6 8 7 7 6 8 7 ... ## $ int223 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 7 7 5 6 7 6 7 6 5 8 ... ## $ int710 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 8 6 5 7 7 6 7 7 6 7 ... ## $ int711 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 8 6 7 6 7 9 7 6 5 8 ... ## $ int712 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 6 7 7 7 7 6 8 6 8 8 ... ## $ int713 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 7 7 3 7 6 8 8 6 8 7 ... ## $ int714 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 7 6 3 7 7 7 8 7 8 8 ... ## $ int715 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 7 6 9 6 6 7 9 7 7 8 ... ## $ int716 : Factor w/ 9 levels &quot;Geen opgave&quot;,..: 9 7 7 7 6 6 7 7 7 7 ... ## $ var433 : Factor w/ 10 levels &quot;Geen opgave&quot;,..: 6 6 7 7 7 5 9 6 7 6 ... ## $ var439 : Factor w/ 10 levels &quot;Geen opgave&quot;,..: 6 5 9 8 3 5 5 8 5 9 ... ## $ var1329 : Factor w/ 10 levels &quot;Geen opgave&quot;,..: 6 8 6 8 6 5 6 5 5 6 ... ## $ var1330 : Factor w/ 10 levels &quot;Geen opgave&quot;,..: 9 9 8 7 9 5 5 8 5 6 ... ## $ var445 : Factor w/ 10 levels &quot;Geen opgave&quot;,..: 8 9 6 6 8 8 9 6 7 6 ... ## $ var446 : Factor w/ 10 levels &quot;Geen opgave&quot;,..: 7 9 5 8 6 5 6 7 5 5 ... ## $ var447 : Factor w/ 10 levels &quot;Geen opgave&quot;,..: 7 9 5 8 6 5 8 7 5 5 ... ## $ var451 : Factor w/ 10 levels &quot;Geen opgave&quot;,..: 9 9 8 8 8 5 8 9 9 8 ... ## $ var452 : Factor w/ 10 levels &quot;Geen opgave&quot;,..: 6 7 6 6 6 5 8 7 5 5 ... ## $ var1316 : Factor w/ 10 levels &quot;Geen opgave&quot;,..: 9 9 8 8 9 5 6 6 5 9 ... ## [list output truncated] ## - attr(*, &quot;variable.labels&quot;)= Named chr [1:278] &quot;WE_ID&quot; &quot;veilignummer&quot; &quot;Leeftijd op 1-jan-2009&quot; &quot;Geslacht hhpersoon (GBA)&quot; ... ## ..- attr(*, &quot;names&quot;)= chr [1:278] &quot;we_id&quot; &quot;veilignr&quot; &quot;lft1&quot; &quot;geslacht&quot; ... ## - attr(*, &quot;codepage&quot;)= int 1252 str(cv08_nolab) ## &#39;data.frame&#39;: 1963 obs. of 278 variables: ## $ we_id : num 36775330 36775340 36775420 36775440 36775450 ... ## ..- attr(*, &quot;value.labels&quot;)= Named num(0) ## .. ..- attr(*, &quot;names&quot;)= chr(0) ## $ veilignr: num 8.11e+08 8.11e+08 8.11e+08 8.11e+08 8.11e+08 ... ## $ lft1 : num 51 39 16 30 57 49 62 34 59 41 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr &quot;99&quot; ## .. ..- attr(*, &quot;names&quot;)= chr &quot;Onbekend&quot; ## $ geslacht: chr &quot;M&quot; &quot;V&quot; &quot;V&quot; &quot;M&quot; ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:3] &quot;V &quot; &quot;M &quot; &quot;9 &quot; ## .. ..- attr(*, &quot;names&quot;)= chr [1:3] &quot;Vrouw&quot; &quot;Man&quot; &quot;Onbekend&quot; ## $ allochtn: num 0 0 1 0 0 1 0 1 0 0 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:4] &quot;9&quot; &quot;2&quot; &quot;1&quot; &quot;0&quot; ## .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;Onbekend&quot; &quot;onbekend&quot; &quot;allochtoon&quot; &quot;geen allochtoon&quot; ## $ lft01 : num 50 38 15 29 56 48 61 33 58 40 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:5] &quot;125&quot; &quot;99&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:5] &quot;125 jaar&quot; &quot;Onbekend&quot; &quot;twee jaar&quot; &quot;één jaar&quot; ... ## $ lftop : num 51 39 16 29 57 49 62 34 59 41 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:5] &quot;125&quot; &quot;99&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:5] &quot;125 jaar&quot; &quot;Onbekend&quot; &quot;twee jaar&quot; &quot;één jaar&quot; ... ## $ gewicht : num 8423 6244 13434 8997 8423 ... ## $ var006n : num 6 8 3 8 6 2 2 5 5 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:11] &quot;9999999999&quot; &quot;8&quot; &quot;7&quot; &quot;6&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:11] &quot;Onbekend&quot; &quot;wo&quot; &quot;wo&quot; &quot;hbo&quot; ... ## $ v040 : num 2 1 2 1 2 2 1 1 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:6] &quot;2&quot; &quot;1&quot; &quot;-2&quot; &quot;-3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Nee&quot; &quot;Ja&quot; &quot;Weigert&quot; &quot;Weet niet&quot; ... ## $ var723 : num -5 45 -5 20 -5 -5 40 32 30 20 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:4] &quot;-2&quot; &quot;-3&quot; &quot;-5&quot; &quot;-6&quot; ## .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;Weigert&quot; &quot;Weet niet&quot; &quot;N.v.t.&quot; &quot;Geen opgave&quot; ## $ var723a : num -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:8] &quot;4&quot; &quot;3&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;of om 30 uur of meer per week ?&quot; &quot;minder dan 30 uur,&quot; &quot;minder dan 12 uur,&quot; &quot;4 uur of minder per week,&quot; ... ## $ v202n : num 4 1 7 1 3 2 1 1 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;10&quot; &quot;8&quot; &quot;7&quot; &quot;6&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;vrijwilliger&quot; &quot;anders&quot; &quot;scholier, student&quot; &quot;werkt &lt;12 uur&quot; ... ## $ var1061a: num 1 2 2 2 2 2 2 2 2 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:6] &quot;2&quot; &quot;1&quot; &quot;-2&quot; &quot;-3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Nee&quot; &quot;Ja&quot; &quot;Weigert&quot; &quot;Weet niet&quot; ... ## $ var1061b: num 23 -5 -5 -5 -5 -5 -5 -5 -5 -5 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:4] &quot;-2&quot; &quot;-3&quot; &quot;-5&quot; &quot;-6&quot; ## .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;Weigert&quot; &quot;Weet niet&quot; &quot;N.v.t.&quot; &quot;Geen opgave&quot; ## $ var1062a: num 2 2 2 2 2 2 2 2 1 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:6] &quot;2&quot; &quot;1&quot; &quot;-2&quot; &quot;-3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Nee&quot; &quot;Ja&quot; &quot;Weigert&quot; &quot;Weet niet&quot; ... ## $ var1062b: num -5 -5 -5 -5 -5 -5 -5 -5 3 -5 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:4] &quot;-2&quot; &quot;-3&quot; &quot;-5&quot; &quot;-6&quot; ## .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;Weigert&quot; &quot;Weet niet&quot; &quot;N.v.t.&quot; &quot;Geen opgave&quot; ## $ int137n : num -5 3 -5 1 -5 1 2 3 3 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:8] &quot;4&quot; &quot;3&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Niet van toepassing (niet noemen)&quot; &quot;of net zoveel tijd als nu?&quot; &quot;minder tijd,&quot; &quot;meer tijd,&quot; ... ## $ int138n : num 3 3 3 3 2 3 3 2 3 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:8] &quot;4&quot; &quot;3&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Niet van toepassing (niet noemen)&quot; &quot;Net zoveel tijd als nu&quot; &quot;Minder tijd&quot; &quot;Meer tijd&quot; ... ## $ int139n : num -5 3 -5 -5 -5 3 1 1 3 -5 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:8] &quot;4&quot; &quot;3&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Niet van toepassing (niet noemen)&quot; &quot;Net zoveel tijd als nu&quot; &quot;Minder tijd&quot; &quot;Meer tijd&quot; ... ## $ int140n : num -5 3 3 3 1 3 1 1 3 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:8] &quot;4&quot; &quot;3&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Niet van toepassing (niet noemen)&quot; &quot;of net zoveel tijd als nu?&quot; &quot;minder tijd,&quot; &quot;meer tijd,&quot; ... ## $ int141n : num 1 3 1 3 1 3 1 1 3 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:8] &quot;4&quot; &quot;3&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Niet van toepassing (niet noemen)&quot; &quot;Net zoveel tijd als nu&quot; &quot;Minder tijd&quot; &quot;Meer tijd&quot; ... ## $ v401 : num 2 2 2 2 3 2 3 2 2 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;of zeer slecht?&quot; &quot;slecht,&quot; &quot;gaat wel,&quot; &quot;goed,&quot; ... ## $ var1343 : num 3 3 3 3 2 3 3 3 3 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Nee&quot; &quot;Soms&quot; &quot;Ja&quot; &quot;Weigert&quot; ... ## $ var648 : num 3 1 3 4 3 3 3 4 3 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;of niet zo tevreden?&quot; &quot;tamelijk tevreden,&quot; &quot;tevreden,&quot; &quot;zeer tevreden,&quot; ... ## $ var149 : num 2 1 -3 3 2 2 2 2 1 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:8] &quot;4&quot; &quot;3&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen mening&quot; &quot;Niet tevreden&quot; &quot;Tamelijk tevreden&quot; &quot;Tevreden&quot; ... ## $ var058 : num 1 1 1 1 1 2 2 1 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:6] &quot;2&quot; &quot;1&quot; &quot;-2&quot; &quot;-3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Nee&quot; &quot;Ja&quot; &quot;Weigert&quot; &quot;Weet niet&quot; ... ## $ var059 : num 1 1 1 2 1 1 1 1 1 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:6] &quot;2&quot; &quot;1&quot; &quot;-2&quot; &quot;-3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Nee&quot; &quot;Ja&quot; &quot;Weigert&quot; &quot;Weet niet&quot; ... ## $ var064 : num 1 1 2 1 2 2 2 1 2 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:6] &quot;2&quot; &quot;1&quot; &quot;-2&quot; &quot;-3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Onvoldoende&quot; &quot;Voldoende&quot; &quot;Weigert&quot; &quot;Weet niet&quot; ... ## $ var365 : num 1 1 2 1 1 1 1 2 2 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:6] &quot;2&quot; &quot;1&quot; &quot;-2&quot; &quot;-3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Nee&quot; &quot;Ja&quot; &quot;Weigert&quot; &quot;Weet niet&quot; ... ## $ var065 : num 2 1 1 2 -3 1 2 2 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:6] &quot;2&quot; &quot;1&quot; &quot;-2&quot; &quot;-3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Welvaart houdt aan&quot; &quot;Voorziet crisis&quot; &quot;Weigert&quot; &quot;Weet niet&quot; ... ## $ var092 : num 2 -3 2 4 4 4 4 3 4 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen mening&quot; &quot;of gaat achteruit?&quot; &quot;blijft ongeveer gelijk,&quot; &quot;gedeeltelijk vooruit gedeeltelijk achteruit,&quot; ... ## $ var096 : num 3 3 2 3 3 1 2 2 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:10] &quot;6&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen mening&quot; &quot;Veel minder&quot; &quot;Een beetje minder&quot; &quot;Laten zoals nu&quot; ... ## $ int054 : num 4 -3 3 3 1 1 2 3 2 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:8] &quot;4&quot; &quot;3&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Helemaal geen tegenstelling&quot; &quot;Niet zo groot&quot; &quot;Groot&quot; &quot;Zeer groot&quot; ... ## $ int055 : num 3 3 3 2 -3 1 2 3 3 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:8] &quot;4&quot; &quot;3&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Helemaal geen tegenstelling&quot; &quot;Niet zo groot&quot; &quot;Groot&quot; &quot;Zeer groot&quot; ... ## $ int056 : num 2 2 3 3 2 1 1 3 2 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:8] &quot;4&quot; &quot;3&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Helemaal geen tegenstelling&quot; &quot;Niet zo groot&quot; &quot;Groot&quot; &quot;Zeer groot&quot; ... ## $ int057 : num 2 3 2 2 1 2 3 3 2 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:8] &quot;4&quot; &quot;3&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Helemaal geen tegenstelling&quot; &quot;Niet zo groot&quot; &quot;Groot&quot; &quot;Zeer groot&quot; ... ## $ int058 : num 3 3 2 2 -3 1 2 3 4 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:8] &quot;4&quot; &quot;3&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Helemaal geen tegenstelling&quot; &quot;Niet zo groot&quot; &quot;Groot&quot; &quot;Zeer groot&quot; ... ## $ int059 : num 2 3 -3 3 3 1 1 2 4 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:8] &quot;4&quot; &quot;3&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Helemaal geen tegenstelling&quot; &quot;Niet zo groot&quot; &quot;Groot&quot; &quot;Zeer groot&quot; ... ## $ int059a : num 3 2 2 2 3 1 2 2 3 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:8] &quot;4&quot; &quot;3&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Helemaal geen tegenstelling&quot; &quot;Niet zo groot&quot; &quot;Groot&quot; &quot;Zeer groot&quot; ... ## $ var571 : num 2 3 3 2 2 2 2 3 2 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Dalen&quot; &quot;Gelijk blijven&quot; &quot;Stijgen&quot; &quot;Weigert&quot; ... ## $ var572 : num -5 1 3 -5 -5 -5 -5 3 -5 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Een klein beetje&quot; &quot;Enigszins&quot; &quot;Sterk&quot; &quot;Weigert&quot; ... ## $ var573 : num 1 2 3 2 1 1 1 1 2 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Dalen&quot; &quot;Gelijk blijven&quot; &quot;Stijgen&quot; &quot;Weigert&quot; ... ## $ var574 : num 3 -5 3 -5 2 3 3 2 -5 -5 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Een klein beetje&quot; &quot;Enigszins&quot; &quot;Sterk&quot; &quot;Weigert&quot; ... ## $ var576 : num 5 2 3 4 5 2 5 4 4 5 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:10] &quot;6&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen mening&quot; &quot;of sterk mee oneens?&quot; &quot;mee oneens,&quot; &quot;noch mee eens, noch mee oneens,&quot; ... ## $ var153 : num 3 1 1 1 1 1 1 1 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen oordeel&quot; &quot;Ontevreden&quot; &quot;Tevreden&quot; &quot;Weigert&quot; ... ## $ var154 : num 3 2 2 2 3 2 3 2 3 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Onvoldoende&quot; &quot;Voldoende&quot; &quot;Te goed (niet noemen)&quot; &quot;Weigert&quot; ... ## $ var155 : num 2 2 2 3 3 3 3 -3 2 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Onvoldoende&quot; &quot;Voldoende&quot; &quot;Te goed (niet noemen)&quot; &quot;Weigert&quot; ... ## $ var156 : num 3 2 2 2 2 -3 3 2 2 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Onvoldoende&quot; &quot;Voldoende&quot; &quot;Te goed (niet noemen)&quot; &quot;Weigert&quot; ... ## $ var157 : num 2 -3 2 2 2 3 3 -3 2 -3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Onvoldoende&quot; &quot;Voldoende&quot; &quot;Te goed (niet noemen)&quot; &quot;Weigert&quot; ... ## $ var157a : num 3 -3 2 2 3 3 3 2 2 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Onvoldoende&quot; &quot;Voldoende&quot; &quot;Te goed (niet noemen)&quot; &quot;Weigert&quot; ... ## $ var154a : num -3 -3 2 2 2 2 2 2 2 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Onvoldoende&quot; &quot;Voldoende&quot; &quot;Te goed (niet noemen)&quot; &quot;Weigert&quot; ... ## $ var164 : num 2 2 2 1 1 1 1 2 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:8] &quot;4&quot; &quot;3&quot; &quot;2&quot; &quot;1&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen mening (niet noemen)&quot; &quot;Te klein&quot; &quot;Ongeveer juist&quot; &quot;Te groot&quot; ... ## $ var165 : num 3 3 3 4 5 5 4 4 5 4 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:10] &quot;6&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen oordeel (niet noemen)&quot; &quot;Veel kleiner&quot; &quot;Een beetje kleiner&quot; &quot;Blijven zoals nu&quot; ... ## $ var166 : num 3 3 4 3 5 5 4 3 4 4 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:10] &quot;6&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen oordeel (niet noemen)&quot; &quot;Veel kleiner&quot; &quot;Een beetje kleiner&quot; &quot;Blijven zoals nu&quot; ... ## $ var179 : num 1 1 2 1 1 1 1 1 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:6] &quot;2&quot; &quot;1&quot; &quot;-2&quot; &quot;-3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Nee&quot; &quot;Ja&quot; &quot;Weigert&quot; &quot;Weet niet&quot; ... ## $ var180 : num 1 1 1 2 1 2 2 1 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:6] &quot;2&quot; &quot;1&quot; &quot;-2&quot; &quot;-3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Nee&quot; &quot;Ja&quot; &quot;Weigert&quot; &quot;Weet niet&quot; ... ## $ var184 : num 1 1 2 1 2 1 1 1 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:6] &quot;2&quot; &quot;1&quot; &quot;-2&quot; &quot;-3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Nee&quot; &quot;Ja&quot; &quot;Weigert&quot; &quot;Weet niet&quot; ... ## $ var185 : num 2 1 1 1 2 1 1 1 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:6] &quot;2&quot; &quot;1&quot; &quot;-2&quot; &quot;-3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Nee&quot; &quot;Ja&quot; &quot;Weigert&quot; &quot;Weet niet&quot; ... ## $ var198a : num 2 1 1 1 1 1 2 2 2 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:6] &quot;2&quot; &quot;1&quot; &quot;-2&quot; &quot;-3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Nee&quot; &quot;Ja&quot; &quot;Weigert&quot; &quot;Weet niet&quot; ... ## $ var198 : num -5 3 5 3 1 1 -5 -5 -5 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:11] &quot;7&quot; &quot;6&quot; &quot;5&quot; &quot;4&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:11] &quot;Ander geloof&quot; &quot;Boeddhistisch&quot; &quot;Islamitisch&quot; &quot;Hindoe&quot; ... ## $ var201a : num 2 1 1 2 2 1 2 2 2 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:6] &quot;2&quot; &quot;1&quot; &quot;-2&quot; &quot;-3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Nee&quot; &quot;Ja&quot; &quot;Weigert&quot; &quot;Weet niet&quot; ... ## $ var201b : num -5 2 4 -5 -5 1 -5 -5 -5 -5 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:10] &quot;6&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Ander kerkgenootschap of levensbeschouwelijke groepering&quot; &quot;Boeddhistisch&quot; &quot;Islamitisch&quot; &quot;Hindoe&quot; ... ## $ var204 : num 5 4 5 4 5 4 5 5 3 5 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;of nooit?&quot; &quot;minder dan eenmaal per maand,&quot; &quot;eens per maand,&quot; &quot;eens per 2 weken,&quot; ... ## $ int257 : num 7 3 3 4 6 2 3 5 3 7 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:11] &quot;7&quot; &quot;6&quot; &quot;5&quot; &quot;4&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:11] &quot;Buitengewoon ongelovig&quot; &quot;Erg ongelovig&quot; &quot;Enigszins ongelovig&quot; &quot;Noch gelovig, noch ongelovig&quot; ... ## $ var211 : num 3 2 3 3 3 1 3 2 2 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Nee&quot; &quot;Gedeeltelijk&quot; &quot;Ja&quot; &quot;Weigert&quot; ... ## $ var223 : num 1 2 1 3 1 1 1 3 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Hangt ervan af&quot; &quot;Moeten niet los van elkaar staan&quot; &quot;Moeten los van elkaar staan&quot; &quot;Weigert&quot; ... ## $ var1320 : num 1 2 2 2 2 2 2 3 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;of sterk mee oneens?&quot; &quot;enigszins mee oneens,&quot; &quot;niet mee eens, niet mee oneens,&quot; &quot;enigszins mee eens,&quot; ... ## $ var1321 : num 1 4 2 2 4 2 4 4 2 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;of sterk mee oneens?&quot; &quot;enigszins mee oneens,&quot; &quot;niet mee eens, niet mee oneens,&quot; &quot;enigszins mee eens,&quot; ... ## $ var1322 : num 3 3 2 2 3 1 1 2 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;of helemaal niet voor u?&quot; &quot;gedeeltelijk voor u,&quot; &quot;helemaal voor u,&quot; &quot;Weigert&quot; ... ## $ var1323 : num 3 3 2 3 3 2 3 3 3 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;of zelden of nooit?&quot; &quot;soms,&quot; &quot;vaak,&quot; &quot;Weigert&quot; ... ## $ var1324 : num 3 3 2 3 3 3 3 3 3 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Zelden of nooit?&quot; &quot;Soms,&quot; &quot;Vaak&quot; &quot;Weigert&quot; ... ## $ var1325 : num 3 3 3 3 3 2 3 3 3 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;of zelden of nooit?&quot; &quot;soms,&quot; &quot;vaak,&quot; &quot;Weigert&quot; ... ## $ var1326 : num 3 3 3 3 3 3 3 3 3 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Zelden of nooit?&quot; &quot;Soms,&quot; &quot;Vaak&quot; &quot;Weigert&quot; ... ## $ var1327 : num 3 3 2 3 3 2 3 3 2 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;of zelden of nooit?&quot; &quot;soms,&quot; &quot;vaak,&quot; &quot;Weigert&quot; ... ## $ var1328 : num 3 3 3 3 3 3 3 3 3 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:7] &quot;3&quot; &quot;2&quot; &quot;1&quot; &quot;-2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Zelden of nooit?&quot; &quot;Soms,&quot; &quot;Vaak&quot; &quot;Weigert&quot; ... ## $ var229 : num 3 3 3 8 3 3 3 2 3 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:12] &quot;8&quot; &quot;7&quot; &quot;6&quot; &quot;5&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:12] &quot;Veel vrienden en kennissen&quot; &quot;Prettig werk&quot; &quot;Een sterk geloof&quot; &quot;Een goed huwelijksleven&quot; ... ## $ int218 : num 2 2 3 3 2 4 3 3 4 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Helemaal geen vertrouwen&quot; &quot;Zeer weinig vertrouwen&quot; &quot;Enig vertrouwen&quot; &quot;Veel vertrouwen&quot; ... ## $ int219 : num 2 2 3 3 3 2 2 2 3 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Helemaal geen vertrouwen&quot; &quot;Zeer weinig vertrouwen&quot; &quot;Enig vertrouwen&quot; &quot;Veel vertrouwen&quot; ... ## $ int221 : num 5 2 5 3 3 2 3 3 2 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Helemaal geen vertrouwen&quot; &quot;Zeer weinig vertrouwen&quot; &quot;Enig vertrouwen&quot; &quot;Veel vertrouwen&quot; ... ## $ int222 : num 2 2 3 2 4 3 3 2 4 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Helemaal geen vertrouwen&quot; &quot;Zeer weinig vertrouwen&quot; &quot;Enig vertrouwen&quot; &quot;Veel vertrouwen&quot; ... ## $ int223 : num 3 3 1 2 3 2 3 2 1 4 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Helemaal geen vertrouwen&quot; &quot;Zeer weinig vertrouwen&quot; &quot;Enig vertrouwen&quot; &quot;Veel vertrouwen&quot; ... ## $ int710 : num 4 2 1 3 3 2 3 3 2 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Helemaal geen vertrouwen&quot; &quot;Zeer weinig vertrouwen&quot; &quot;Enig vertrouwen&quot; &quot;Veel vertrouwen&quot; ... ## $ int711 : num 4 2 3 2 3 5 3 2 1 4 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Helemaal geen vertrouwen&quot; &quot;Zeer weinig vertrouwen&quot; &quot;Enig vertrouwen&quot; &quot;Veel vertrouwen&quot; ... ## $ int712 : num 2 3 3 3 3 2 4 2 4 4 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Helemaal geen vertrouwen&quot; &quot;Zeer weinig vertrouwen&quot; &quot;Enig vertrouwen&quot; &quot;Veel vertrouwen&quot; ... ## $ int713 : num 3 3 -3 3 2 4 4 2 4 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Helemaal geen vertrouwen&quot; &quot;Zeer weinig vertrouwen&quot; &quot;Enig vertrouwen&quot; &quot;Veel vertrouwen&quot; ... ## $ int714 : num 3 2 -3 3 3 3 4 3 4 4 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Helemaal geen vertrouwen&quot; &quot;Zeer weinig vertrouwen&quot; &quot;Enig vertrouwen&quot; &quot;Veel vertrouwen&quot; ... ## $ int715 : num 3 2 5 2 2 3 5 3 3 4 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Helemaal geen vertrouwen&quot; &quot;Zeer weinig vertrouwen&quot; &quot;Enig vertrouwen&quot; &quot;Veel vertrouwen&quot; ... ## $ int716 : num 5 3 3 3 2 2 3 3 3 3 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:9] &quot;5&quot; &quot;4&quot; &quot;3&quot; &quot;2&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Helemaal geen vertrouwen&quot; &quot;Zeer weinig vertrouwen&quot; &quot;Enig vertrouwen&quot; &quot;Veel vertrouwen&quot; ... ## $ var433 : num 2 2 3 3 3 1 5 2 3 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:10] &quot;6&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen mening&quot; &quot;Helemaal niet mee eens&quot; &quot;Eigenlijk niet mee eens&quot; &quot;Noch mee eens, noch mee oneens&quot; ... ## $ var439 : num 2 1 5 4 -3 1 1 4 1 5 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:10] &quot;6&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen mening&quot; &quot;Helemaal niet mee eens&quot; &quot;Eigenlijk niet mee eens&quot; &quot;Noch mee eens, noch mee oneens&quot; ... ## $ var1329 : num 2 4 2 4 2 1 2 1 1 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:10] &quot;6&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen mening&quot; &quot;Helemaal niet mee eens&quot; &quot;Eigenlijk niet mee eens&quot; &quot;Noch mee eens, noch mee oneens&quot; ... ## $ var1330 : num 5 5 4 3 5 1 1 4 1 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:10] &quot;6&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen mening&quot; &quot;Helemaal niet mee eens&quot; &quot;Eigenlijk niet mee eens&quot; &quot;Noch mee eens, noch mee oneens&quot; ... ## $ var445 : num 4 5 2 2 4 4 5 2 3 2 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:10] &quot;6&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen mening&quot; &quot;Helemaal niet mee eens&quot; &quot;Eigenlijk niet mee eens&quot; &quot;Noch mee eens, noch mee oneens&quot; ... ## $ var446 : num 3 5 1 4 2 1 2 3 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:10] &quot;6&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen mening&quot; &quot;Helemaal niet mee eens&quot; &quot;Eigenlijk niet mee eens&quot; &quot;Noch mee eens, noch mee oneens&quot; ... ## $ var447 : num 3 5 1 4 2 1 4 3 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:10] &quot;6&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen mening&quot; &quot;Helemaal niet mee eens&quot; &quot;Eigenlijk niet mee eens&quot; &quot;Noch mee eens, noch mee oneens&quot; ... ## $ var451 : num 5 5 4 4 4 1 4 5 5 4 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:10] &quot;6&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen mening&quot; &quot;Helemaal niet mee eens&quot; &quot;Eigenlijk niet mee eens&quot; &quot;Noch mee eens, noch mee oneens&quot; ... ## $ var452 : num 2 3 2 2 2 1 4 3 1 1 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:10] &quot;6&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen mening&quot; &quot;Helemaal niet mee eens&quot; &quot;Eigenlijk niet mee eens&quot; &quot;Noch mee eens, noch mee oneens&quot; ... ## $ var1316 : num 5 5 4 4 5 1 2 2 1 5 ... ## ..- attr(*, &quot;value.labels&quot;)= Named chr [1:10] &quot;6&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen mening&quot; &quot;Helemaal niet mee eens&quot; &quot;Eigenlijk niet mee eens&quot; &quot;Noch mee eens, noch mee oneens&quot; ... ## [list output truncated] ## - attr(*, &quot;variable.labels&quot;)= Named chr [1:278] &quot;WE_ID&quot; &quot;veilignummer&quot; &quot;Leeftijd op 1-jan-2009&quot; &quot;Geslacht hhpersoon (GBA)&quot; ... ## ..- attr(*, &quot;names&quot;)= chr [1:278] &quot;we_id&quot; &quot;veilignr&quot; &quot;lft1&quot; &quot;geslacht&quot; ... ## - attr(*, &quot;codepage&quot;)= int 1252 str(cv08_haven) ## tibble[,278] [1,963 x 278] (S3: tbl_df/tbl/data.frame) ## $ we_id : dbl+lbl [1:1963] 36775330, 36775340, 36775420, 36775440, 36775450, 36775460, 36775480, 367... ## ..@ label : chr &quot;WE_ID&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:2] 1e+10 1e+10 ## .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;Refusal&quot; &quot;Don&#39;t Know&quot; ## $ veilignr: num [1:1963] 8.11e+08 8.11e+08 8.11e+08 8.11e+08 8.11e+08 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;veilignummer&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F10.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 12 ## $ lft1 : dbl+lbl [1:1963] 51, 39, 16, 30, 57, 49, 62, 34, 59, 41, 25, 43, 74, 17, 23, 32, 51, 66, 6... ## ..@ label : chr &quot;Leeftijd op 1-jan-2009&quot; ## ..@ format.spss : chr &quot;F8.0&quot; ## ..@ display_width: int 10 ## ..@ labels : Named num 99 ## .. ..- attr(*, &quot;names&quot;)= chr &quot;Onbekend&quot; ## $ geslacht: chr+lbl [1:1963] M, V, V, M, M, V, M, V, M, M, M, V, V, M, M, V, M, M, V, M, V, M, V, M, V... ## ..@ label : chr &quot;Geslacht hhpersoon (GBA)&quot; ## ..@ format.spss : chr &quot;A1&quot; ## ..@ display_width: int 10 ## ..@ labels : Named chr [1:3] &quot;9&quot; &quot;M&quot; &quot;V&quot; ## .. ..- attr(*, &quot;names&quot;)= chr [1:3] &quot;Onbekend&quot; &quot;Man&quot; &quot;Vrouw&quot; ## $ allochtn: dbl+lbl [1:1963] 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0... ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:4] 0 1 2 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;geen allochtoon&quot; &quot;allochtoon&quot; &quot;onbekend&quot; &quot;Onbekend&quot; ## $ lft01 : dbl+lbl [1:1963] 50, 38, 15, 29, 56, 48, 61, 33, 58, 40, 24, 42, 73, 16, 22, 31, 50, 65, 6... ## ..@ label : chr &quot;Leeftijd OP op 1 jan. v.h. onderzoekjaar&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:5] 0 1 2 99 125 ## .. ..- attr(*, &quot;names&quot;)= chr [1:5] &quot;&lt; één jaar&quot; &quot;één jaar&quot; &quot;twee jaar&quot; &quot;Onbekend&quot; ... ## $ lftop : dbl+lbl [1:1963] 51, 39, 16, 29, 57, 49, 62, 34, 59, 41, 25, 43, 74, 17, 22, 32, 51, 66, 6... ## ..@ label : chr &quot;Leeftijd OP op datum interview&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:5] 0 1 2 99 125 ## .. ..- attr(*, &quot;names&quot;)= chr [1:5] &quot;&lt; één jaar&quot; &quot;één jaar&quot; &quot;twee jaar&quot; &quot;Onbekend&quot; ... ## $ gewicht : num [1:1963] 8423 6244 13434 8997 8423 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Persoonsgewicht eindres30&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F8.2&quot; ## ..- attr(*, &quot;display_width&quot;)= int 10 ## $ var006n : dbl+lbl [1:1963] 6, 8, 3, 8, 6, 2, 2, 5, 5, 1, 1, 3, 2, 1, 1, 5, 6, 3, 1, 5, 6, 2, 5, 6, 1... ## ..@ label : chr &quot;Voltooid opleidingsniveau (uitgebreid) OP, 12-14 jarigen niet standaard op bas.ondw.&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:11] -3 -1 1 2 3 4 5 6 7 8 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:11] &quot;onbekend&quot; &quot;OP &lt; 12 jr of volgt actueel bas.ondw.&quot; &quot;basisonderwijs&quot; &quot;vmbo&quot; ... ## $ v040 : dbl+lbl [1:1963] 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2... ## ..@ label : chr &quot;Betaald werk?&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:6] -6 -5 -3 -2 1 2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var723 : dbl+lbl [1:1963] -5, 45, -5, 20, -5, -5, 40, 32, 30, 20, 38, 30, -5, -5, 18, 20, 40, -5, -... ## ..@ label : chr &quot;Uren werk per week&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:4] -6 -5 -3 -2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ## $ var723a : dbl+lbl [1:1963] -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, -... ## ..@ label : chr &quot;Categorie: uren werk per week&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ v202n : dbl+lbl [1:1963] 4, 1, 7, 1, 3, 2, 1, 1, 1, 1, 1, 1, 5, 7, 1, 1, 1, 5, 2, 1, 2, 1, 5, 1, 5... ## ..@ label : chr &quot;positie werkkring (nieuw)&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] 1 2 3 4 5 6 7 8 10 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;werkt &gt;12 uur&quot; &quot;eigen huishouden&quot; &quot;werkloos&quot; &quot;arbeidsongeschikt&quot; ... ## $ var1061a: dbl+lbl [1:1963] 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2... ## ..@ label : chr &quot;(16) Verricht u vrijwilligerwerk&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:6] -6 -5 -3 -2 1 2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var1061b: dbl+lbl [1:1963] 23, -5, -5, -5, -5, -5, -5, -5, -5, -5, -5, 3, 5, -5, -5, 1, -5, -5, -... ## ..@ label : chr &quot;(16) Hoeveel uur per week vrijwilligerwerk?&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:4] -6 -5 -3 -2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ## $ var1062a: dbl+lbl [1:1963] 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2... ## ..@ label : chr &quot;(17) Kosteloos hulp aan zieke of gehandicapte familieleden, kennissen of buren?&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:6] -6 -5 -3 -2 1 2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var1062b: dbl+lbl [1:1963] -5, -5, -5, -5, -5, -5, -5, -5, 3, -5, -5, 2, 5, -5, -5, 1, -5, -5, -... ## ..@ label : chr &quot;(17) Hoeveel uur per week kosteloos hulp?&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:4] -6 -5 -3 -2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ## $ int137n : dbl+lbl [1:1963] -5, 3, -5, 1, -5, 1, 2, 3, 3, 2, 1, 3, -5, -5, 1, 2, 2, 1, -... ## ..@ label : chr &quot;S003 Gewenste tijd betaald werk&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int138n : dbl+lbl [1:1963] 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 2, 3, -5, 3, 2, 1, 3, ... ## ..@ label : chr &quot;S003 Gewenste tijd huishoudelijk werk&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int139n : dbl+lbl [1:1963] -5, 3, -5, -5, -5, 3, 1, 1, 3, -5, 3, 1, 3, -5, -5, 1, 1, 1, ... ## ..@ label : chr &quot;S003 Gewenste tijd gezin&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int140n : dbl+lbl [1:1963] -5, 3, 3, 3, 1, 3, 1, 1, 3, 3, 3, 1, 3, -5, 1, 1, 3, 3, ... ## ..@ label : chr &quot;S003 Gewenste tijd vrienden&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int141n : dbl+lbl [1:1963] 1, 3, 1, 3, 1, 3, 1, 1, 3, 1, 3, 3, 3, 3, 3, 1, 1, -5, ... ## ..@ label : chr &quot;S003 Gewenste tijd vrijetijds-activiteit&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ v401 : dbl+lbl [1:1963] 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 1, 2, 3, 1, 2, 1... ## ..@ label : chr &quot;Niveau gezondheid&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var1343 : dbl+lbl [1:1963] 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3... ## ..@ label : chr &quot;(199) Ik voel me van andere mensen gesoleerd.&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var648 : dbl+lbl [1:1963] 3, 1, 3, 4, 3, 3, 3, 4, 3, 3, 1, 2, 3, 3, 3, 2, 3, 5, 3, 3, 3, 3, 2, 1, 3... ## ..@ label : chr &quot;Tevredenheid leven&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var149 : dbl+lbl [1:1963] 2, 1, -3, 3, 2, 2, 2, 2, 1, 2, 1, 2, 2, -3, 2, 1, 2, 3, ... ## ..@ label : chr &quot;Tevredenheid inkomen&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var058 : dbl+lbl [1:1963] 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, ... ## ..@ label : chr &quot;Welvarendheid Nederland&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:6] -6 -5 -3 -2 1 2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var059 : dbl+lbl [1:1963] 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1... ## ..@ label : chr &quot;Welvarendheid in eigen huishouden&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:6] -6 -5 -3 -2 1 2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var064 : dbl+lbl [1:1963] 1, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, ... ## ..@ label : chr &quot;Inzet regering vergroten uw welvaart&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:6] -6 -5 -3 -2 1 2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var365 : dbl+lbl [1:1963] 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, ... ## ..@ label : chr &quot;financieel een onbekommerde oude dag&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:6] -6 -5 -3 -2 1 2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var065 : dbl+lbl [1:1963] 2, 1, 1, 2, -3, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, ... ## ..@ label : chr &quot;Verwachting crisis met veel werklozen&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:6] -6 -5 -3 -2 1 2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var092 : dbl+lbl [1:1963] 2, -3, 2, 4, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, ... ## ..@ label : chr &quot;Ontwikkeling opvattingen gedrag en zeden&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var096 : dbl+lbl [1:1963] 3, 3, 2, 3, 3, 1, 2, 2, 1, 1, 2, 4, 3, 1, 2, 3, 2, 2, 1, 1, 2, 1, 3, 2, 1... ## ..@ label : chr &quot;Niveau geld voor openbare voorzieningen&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int054 : dbl+lbl [1:1963] 4, -3, 3, 3, 1, 1, 2, 3, 2, 1, 1, 1, 2, 2, 2, 2, 3, 1, ... ## ..@ label : chr &quot;Niveau tegenstelling arm en rijk&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int055 : dbl+lbl [1:1963] 3, 3, 3, 2, -3, 1, 2, 3, 3, 2, 2, 3, 3, 3, 3, 2, 3, 2, ... ## ..@ label : chr &quot;Tegenstelling arbeidersklasse en middenklasse&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int056 : dbl+lbl [1:1963] 2, 2, 3, 3, 2, 1, 1, 3, 2, 3, 2, 3, 2, 2, 2, 2, 2, 1, ... ## ..@ label : chr &quot;Tegenstelling werklozen en werkenden&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int057 : dbl+lbl [1:1963] 2, 3, 2, 2, 1, 2, 3, 3, 2, 1, 1, 1, 2, 2, 2, 3, 2, 1, ... ## ..@ label : chr &quot;Tegenstelling werkgevers en werknemers&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int058 : dbl+lbl [1:1963] 3, 3, 2, 2, -3, 1, 2, 3, 4, 2, -3, 1, 2, 3, 2, -3, 3, -3, -... ## ..@ label : chr &quot;Tegenstelling platteland en stadsmensen&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int059 : dbl+lbl [1:1963] 2, 3, -3, 3, 3, 1, 1, 2, 4, 2, 1, 1, 2, 2, 2, 2, 2, 2, ... ## ..@ label : chr &quot;Tegenstelling jongeren en ouderen&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int059a : dbl+lbl [1:1963] 3, 2, 2, 2, 3, 1, 2, 2, 3, 2, -3, 1, 2, 2, 2, 2, 2, -3, ... ## ..@ label : chr &quot;Tegenstelling allochtonen en autochtonen&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var571 : dbl+lbl [1:1963] 2, 3, 3, 2, 2, 2, 2, 3, 2, 3, 3, 2, 3, 3, 3, 3, 1, 3, ... ## ..@ label : chr &quot;Verwachting toekomst sociale uitkeringen&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var572 : dbl+lbl [1:1963] -5, 1, 3, -5, -5, -5, -5, 3, -5, 1, 2, -5, 1, 2, 3, 1, 2, 2, -... ## ..@ label : chr &quot;Verwachting niveau sociale uitkeringen&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var573 : dbl+lbl [1:1963] 1, 2, 3, 2, 1, 1, 1, 1, 2, 2, 2, 1, 3, 3, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1... ## ..@ label : chr &quot;Niveau uitkeringen in huidige economie 1&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var574 : dbl+lbl [1:1963] 3, -5, 3, -5, 2, 3, 3, 2, -5, -5, -5, 1, 3, 2, -5, -5, -5, 3, ... ## ..@ label : chr &quot;Niveau uitkeringen in huidige economie 2&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var576 : dbl+lbl [1:1963] 5, 2, 3, 4, 5, 2, 5, 4, 4, 5, 4, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 2, 2, 2, 4... ## ..@ label : chr &quot;Mening toekomst minder sociale zekerheid&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var153 : dbl+lbl [1:1963] 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 3, 1, 1, 1, 2... ## ..@ label : chr &quot;Tevredenheid sociale voorzieningen&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var154 : dbl+lbl [1:1963] 3, 2, 2, 2, 3, 2, 3, 2, 3, 3, -3, 3, 2, 2, -3, 2, 3, 3, ... ## ..@ label : chr &quot;Niveau Algemene Ouderdomswet (AOW)&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var155 : dbl+lbl [1:1963] 2, 2, 2, 3, 3, 3, 3, -3, 2, 2, -3, 3, 3, 3, 2, 3, 2, 3, -... ## ..@ label : chr &quot;Oordeel Wet Werk en Bijstand&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var156 : dbl+lbl [1:1963] 3, 2, 2, 2, 2, -3, 3, 2, 2, 2, -3, 1, 3, 2, -3, 2, 2, 3, ... ## ..@ label : chr &quot;Oordeel Werkloosheidswet (WW).&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var157 : dbl+lbl [1:1963] 2, -3, 2, 2, 2, 3, 3, -3, 2, -3, -3, 3, 3, 3, -3, -3, 3, 3, ... ## ..@ label : chr &quot;Oordeel Algemene Nabestaandenwet (ANW).&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var157a : dbl+lbl [1:1963] 3, -3, 2, 2, 3, 3, 3, 2, 2, 2, 3, 1, 3, 3, -3, 3, 2, 3, ... ## ..@ label : chr &quot;Oordeel Arbeidsongeschiktheidswet.&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var154a : dbl+lbl [1:1963] -3, -3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, -3, 2, 2, -3, -... ## ..@ label : chr &quot;Oordeel Ziektewet.&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var164 : dbl+lbl [1:1963] 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1... ## ..@ label : chr &quot;Mate verschil tussen inkomens in NL&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var165 : dbl+lbl [1:1963] 3, 3, 3, 4, 5, 5, 4, 4, 5, 4, 4, 5, 5, 1, 4, 2, 4, 5, 1, 4, 5, 4, 4, 3, 5... ## ..@ label : chr &quot;Wens vergroten verschil inkomens&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var166 : dbl+lbl [1:1963] 3, 3, 4, 3, 5, 5, 4, 3, 4, 4, 3, 4, 5, 3, 3, 3, 4, 3, ... ## ..@ label : chr &quot;Wens vergroten verschil bezit&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var179 : dbl+lbl [1:1963] 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1... ## ..@ label : chr &quot;M050 Vrij:om te demonstreren&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:6] -6 -5 -3 -2 1 2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var180 : dbl+lbl [1:1963] 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2... ## ..@ label : chr &quot;M051 Vrij:openlijk kritiek koningshuis&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:6] -6 -5 -3 -2 1 2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var184 : dbl+lbl [1:1963] 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1... ## ..@ label : chr &quot;M054 Vrij:openb schrijven wat men wil&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:6] -6 -5 -3 -2 1 2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var185 : dbl+lbl [1:1963] 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1... ## ..@ label : chr &quot;M054 Vrij:openb zeggen wat men wil&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:6] -6 -5 -3 -2 1 2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var198a : dbl+lbl [1:1963] 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1... ## ..@ label : chr &quot;Opgevoed met bepaald geloof&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:6] -6 -5 -3 -2 1 2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var198 : dbl+lbl [1:1963] -5, 3, 5, 3, 1, 1, -5, -5, -5, 3, 1, -5, 3, 2, -5, 2, 1, 2, ... ## ..@ label : chr &quot;Geloof opgevoed&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:11] -6 -5 -3 -2 1 2 3 4 5 6 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:11] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var201a : dbl+lbl [1:1963] 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2... ## ..@ label : chr &quot;Rekent zich tot kerkgenootschap&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:6] -6 -5 -3 -2 1 2 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var201b : dbl+lbl [1:1963] -5, 2, 4, -5, -5, 1, -5, -5, -5, -5, 1, -5, 2, 2, -5, 6, -5, -5, -... ## ..@ label : chr &quot;Welk kerkgenootschap is dat?&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var204 : dbl+lbl [1:1963] 5, 4, 5, 4, 5, 4, 5, 5, 3, 5, 4, 5, 1, 1, 5, 1, 5, 5, 5, 5, 1, 5, 5, 5, 5... ## ..@ label : chr &quot;Aantal bezoeken kerk afgelopen half jaar&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int257 : dbl+lbl [1:1963] 7, 3, 3, 4, 6, 2, 3, 5, 3, 7, 4, 7, 2, 2, 3, 2, 3, 2, 4, 7, 2, 4, 6, 7, 4... ## ..@ label : chr &quot;Mate gelovigheid&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:11] -6 -5 -3 -2 1 2 3 4 5 6 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:11] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var211 : dbl+lbl [1:1963] 3, 2, 3, 3, 3, 1, 3, 2, 2, 3, -3, 3, 1, 1, 3, 1, 1, 3, ... ## ..@ label : chr &quot;M069 Ziet bijbel als het woord van God&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var223 : dbl+lbl [1:1963] 1, 2, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1... ## ..@ label : chr &quot;M068 Politiek los van godsdienst&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var1320 : dbl+lbl [1:1963] 1, 2, 2, 2, 2, 2, 2, 3, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, ... ## ..@ label : chr &quot;(54) Zin van leven innerlijke ervaring en ontwikkeling eigen vermogens.&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var1321 : dbl+lbl [1:1963] 1, 4, 2, 2, 4, 2, 4, 4, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 4, 2, 5, 2, 2, 4, 1... ## ..@ label : chr &quot;(55) Bij beslissingen afgaan op intutie en gevoel.&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var1322 : dbl+lbl [1:1963] 3, 3, 2, 2, 3, 1, 1, 2, 1, 1, 2, 3, 2, 2, 3, 2, 3, 1, ... ## ..@ label : chr &quot;(56) Religie zoek ik zelf bijeen&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var1323 : dbl+lbl [1:1963] 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3... ## ..@ label : chr &quot;(57) Praten of mailen over spiritualiteit&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var1324 : dbl+lbl [1:1963] 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3... ## ..@ label : chr &quot;(58) Meedoen gespreksgroep over spiritueel onderwerp?&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var1325 : dbl+lbl [1:1963] 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3... ## ..@ label : chr &quot;(59) Op internet kijken naar informatie over spiritualiteit&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var1326 : dbl+lbl [1:1963] 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3... ## ..@ label : chr &quot;(60) Bezoek beurs etc over spirituele onderwerpen?&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var1327 : dbl+lbl [1:1963] 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3... ## ..@ label : chr &quot;(61) Tijdschriften of boeken lezen over spirituele onderwerpen&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var1328 : dbl+lbl [1:1963] 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3... ## ..@ label : chr &quot;(62) Deelnemen aan cursus, gericht op spiritualiteit?&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:7] -6 -5 -3 -2 1 2 3 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var229 : dbl+lbl [1:1963] 3, 3, 3, 8, 3, 3, 3, 2, 3, 3, 3, 5, 3, 2, 7, 6, 2, 3, 3, 3, 6, 3, 3, 2, 8... ## ..@ label : chr &quot;M064 Allerbelangrijkste in het leven&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:12] -6 -5 -3 -2 1 2 3 4 5 6 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:12] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int218 : dbl+lbl [1:1963] 2, 2, 3, 3, 2, 4, 3, 3, 4, 3, 3, 2, 2, 3, 4, 2, 4, 4, 5, 4, 3, 3, 3, 4, 2... ## ..@ label : chr &quot;Mate vertrouwen in regering&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int219 : dbl+lbl [1:1963] 2, 2, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 2, 3, 3, 2, 3, 4, -... ## ..@ label : chr &quot;Mate vertrouwen in bedrijfsleven&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int221 : dbl+lbl [1:1963] 5, 2, 5, 3, 3, 2, 3, 3, 2, 3, 3, 5, 2, 2, 4, 3, 3, -3, -... ## ..@ label : chr &quot;Mate vertrouwen kerken/reli organisaties&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int222 : dbl+lbl [1:1963] 2, 2, 3, 2, 4, 3, 3, 2, 4, 3, 2, 4, 2, 2, 4, 3, 2, 4, ... ## ..@ label : chr &quot;Mate vertrouwen in rechtspraak&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int223 : dbl+lbl [1:1963] 3, 3, 1, 2, 3, 2, 3, 2, 1, 4, 2, 1, 2, 2, 3, 3, 3, 3, -... ## ..@ label : chr &quot;Mate vertrouwen in onderwijs&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int710 : dbl+lbl [1:1963] 4, 2, 1, 3, 3, 2, 3, 3, 2, 3, 2, 1, 2, 2, 3, 3, 2, 3, 5, 2, 3, 2, 3, 2, 2... ## ..@ label : chr &quot;Mate vertrouwen in gezondheidszorg&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int711 : dbl+lbl [1:1963] 4, 2, 3, 2, 3, 5, 3, 2, 1, 4, 3, 5, 2, 2, 3, 4, 3, 4, ... ## ..@ label : chr &quot;Mate vertrouwen in kranten&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int712 : dbl+lbl [1:1963] 2, 3, 3, 3, 3, 2, 4, 2, 4, 4, 3, 2, 2, 2, 3, 3, 3, 4, 5, 3, 3, 2, 3, 2, 2... ## ..@ label : chr &quot;Mate vertrouwen in politie&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int713 : dbl+lbl [1:1963] 3, 3, -3, 3, 2, 4, 4, 2, 4, 3, 3, 3, 2, 2, 4, 3, 3, 4, ... ## ..@ label : chr &quot;Mate vertrouwen in Tweede Kamer&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int714 : dbl+lbl [1:1963] 3, 2, -3, 3, 3, 3, 4, 3, 4, 4, 3, 5, 2, 2, 3, 2, 3, 5, ... ## ..@ label : chr &quot;Mate vertrouwen in ambtenaren&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int715 : dbl+lbl [1:1963] 3, 2, 5, 2, 2, 3, 5, 3, 3, 4, -3, 2, 2, 2, 3, 3, 2, -3, ... ## ..@ label : chr &quot;Mate vertrouwen in Europese Unie&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ int716 : dbl+lbl [1:1963] 5, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 3, 2, 4, 3, 3, ... ## ..@ label : chr &quot;Mate vertrouwen in vakbonden&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:9] -6 -5 -3 -2 1 2 3 4 5 ## .. ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var433 : dbl+lbl [1:1963] 2, 2, 3, 3, 3, 1, 5, 2, 3, 2, 3, 5, 2, 4, 2, 2, 3, 5, 5, 5, 4, 3, 3, 5, 1... ## ..@ label : chr &quot;Misdadiger niet straffen maar veranderen&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var439 : dbl+lbl [1:1963] 2, 1, 5, 4, -3, 1, 1, 4, 1, 5, 3, 1, 2, 4, 3, 4, 2, 1, ... ## ..@ label : chr &quot;Minder regels, meer sterke leiders&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var1329 : dbl+lbl [1:1963] 2, 4, 2, 4, 2, 1, 2, 1, 1, 2, 3, 1, 2, 4, 2, 2, 1, 1, 1, 3, 2, 2, 1, 5, 2... ## ..@ label : chr &quot;De vrijheid van meningsuiting mag niet zover gaan dat mensen worden gekwetst in hun religieuze gevoelens.&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var1330 : dbl+lbl [1:1963] 5, 5, 4, 3, 5, 1, 1, 4, 1, 2, 3, 5, 2, 4, 3, 3, 2, -3, ... ## ..@ label : chr &quot;(79) Schaam me een Nederlander te zijn.&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var445 : dbl+lbl [1:1963] 4, 5, 2, 2, 4, 4, 5, 2, 3, 2, 5, 5, 3, 4, 2, 2, 3, 2, 5, 5, 4, 3, 4, 5, 5... ## ..@ label : chr &quot;Seks misdaad niet straffen maar genezen&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var446 : dbl+lbl [1:1963] 3, 5, 1, 4, 2, 1, 2, 3, 1, 1, 2, 1, 3, 4, 2, 5, 4, 1, 1, 3, 4, 2, 1, 5, 3... ## ..@ label : chr &quot;Onzekerheid wat goed/verkeerd&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var447 : dbl+lbl [1:1963] 3, 5, 1, 4, 2, 1, 4, 3, 1, 1, 3, 1, 2, 4, 4, 5, 4, 1, 1, 3, 4, 2, 2, 5, 2... ## ..@ label : chr &quot;Steeds anders onduidelijk goed/slecht&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var451 : dbl+lbl [1:1963] 5, 5, 4, 4, 4, 1, 4, 5, 5, 4, 3, 5, 2, 4, 4, 3, 5, 2, ... ## ..@ label : chr &quot;Geweld om ideaal te verwezenlijken&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var452 : dbl+lbl [1:1963] 2, 3, 2, 2, 2, 1, 4, 3, 1, 1, 5, 3, 2, 2, 2, 2, 5, 1, 4, 3, 2, 3, 2, 5, 2... ## ..@ label : chr &quot;Betekenis leven dmv ideaal of taak&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## $ var1316 : dbl+lbl [1:1963] 5, 5, 4, 4, 5, 1, 2, 2, 1, 5, 2, 4, 3, 2, 3, 4, 5, -3, ... ## ..@ label : chr &quot;Geld overheid om sportevenementen binnen te halen&quot; ## ..@ format.spss : chr &quot;F10.0&quot; ## ..@ display_width: int 12 ## ..@ labels : Named num [1:10] -6 -5 -3 -2 1 2 3 4 5 6 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... ## [list output truncated] The function str() asks for the structure of an object in your environment. You will see that the original data is stored differently in the three datasets. The different objects (cv08, cv08_nolab and cv08_haven) have a different structure. cv08 and cv08_nolab are data.frame objects, the haven::read_spss function produces a tibble. Let us have quick look at the structure of some variables. To access a variable in a dataset use datasetname$variablename . Add to your cheat sheet under operators/symbols: $ str(cv08$lftop) #a factor ## Factor w/ 81 levels &quot;&lt; één jaar&quot;,&quot;één jaar&quot;,..: 40 28 4 18 46 38 51 23 48 30 ... str(cv08_nolab$lftop) # a numeric variable ## num [1:1963] 51 39 16 29 57 49 62 34 59 41 ... ## - attr(*, &quot;value.labels&quot;)= Named chr [1:5] &quot;125&quot; &quot;99&quot; &quot;2&quot; &quot;1&quot; ... ## ..- attr(*, &quot;names&quot;)= chr [1:5] &quot;125 jaar&quot; &quot;Onbekend&quot; &quot;twee jaar&quot; &quot;één jaar&quot; ... str(cv08_haven$lftop) # a &#39;dbl+lbl&#39; this stands for doubles, or real numbers, which are labeled ## dbl+lbl [1:1963] 51, 39, 16, 29, 57, 49, 62, 34, 59, 41, 25, 43, 74, 17, 22, 32, 51, 66, 64, 2... ## @ label : chr &quot;Leeftijd OP op datum interview&quot; ## @ format.spss : chr &quot;F10.0&quot; ## @ display_width: int 12 ## @ labels : Named num [1:5] 0 1 2 99 125 ## ..- attr(*, &quot;names&quot;)= chr [1:5] &quot;&lt; één jaar&quot; &quot;één jaar&quot; &quot;twee jaar&quot; &quot;Onbekend&quot; ... #next to the data itself, attributes are stored attributes(cv08$lftop) ## $levels ## [1] &quot;&lt; één jaar&quot; &quot;één jaar&quot; &quot;125 jaar&quot; &quot;16&quot; &quot;17&quot; &quot;18&quot; &quot;19&quot; ## [8] &quot;twee jaar&quot; &quot;20&quot; &quot;21&quot; &quot;22&quot; &quot;23&quot; &quot;24&quot; &quot;25&quot; ## [15] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; &quot;30&quot; &quot;31&quot; &quot;32&quot; ## [22] &quot;33&quot; &quot;34&quot; &quot;35&quot; &quot;36&quot; &quot;37&quot; &quot;38&quot; &quot;39&quot; ## [29] &quot;40&quot; &quot;41&quot; &quot;42&quot; &quot;43&quot; &quot;44&quot; &quot;45&quot; &quot;46&quot; ## [36] &quot;47&quot; &quot;48&quot; &quot;49&quot; &quot;50&quot; &quot;51&quot; &quot;52&quot; &quot;53&quot; ## [43] &quot;54&quot; &quot;55&quot; &quot;56&quot; &quot;57&quot; &quot;58&quot; &quot;59&quot; &quot;60&quot; ## [50] &quot;61&quot; &quot;62&quot; &quot;63&quot; &quot;64&quot; &quot;65&quot; &quot;66&quot; &quot;67&quot; ## [57] &quot;68&quot; &quot;69&quot; &quot;70&quot; &quot;71&quot; &quot;72&quot; &quot;73&quot; &quot;74&quot; ## [64] &quot;75&quot; &quot;76&quot; &quot;77&quot; &quot;78&quot; &quot;79&quot; &quot;80&quot; &quot;81&quot; ## [71] &quot;82&quot; &quot;83&quot; &quot;84&quot; &quot;85&quot; &quot;86&quot; &quot;87&quot; &quot;88&quot; ## [78] &quot;89&quot; &quot;90&quot; &quot;91&quot; &quot;Onbekend&quot; ## ## $class ## [1] &quot;factor&quot; attributes(cv08_nolab$lftop) ## $value.labels ## 125 jaar Onbekend twee jaar één jaar &lt; één jaar ## &quot;125&quot; &quot;99&quot; &quot;2&quot; &quot;1&quot; &quot;0&quot; attributes(cv08_haven$lftop) ## $label ## [1] &quot;Leeftijd OP op datum interview&quot; ## ## $format.spss ## [1] &quot;F10.0&quot; ## ## $display_width ## [1] 12 ## ## $class ## [1] &quot;haven_labelled&quot; &quot;vctrs_vctr&quot; &quot;double&quot; ## ## $labels ## &lt; één jaar één jaar twee jaar Onbekend 125 jaar ## 0 1 2 99 125 #to access specific attributes attr(cv08_haven$lftop, &quot;labels&quot;) ## &lt; één jaar één jaar twee jaar Onbekend 125 jaar ## 0 1 2 99 125 summary(cv08$lftop) ## &lt; één jaar één jaar 125 jaar 16 17 18 19 twee jaar 20 ## 0 0 0 40 37 39 30 0 30 ## 21 22 23 24 25 26 27 28 29 ## 25 25 38 26 22 18 23 29 30 ## 30 31 32 33 34 35 36 37 38 ## 22 28 23 23 24 38 35 37 34 ## 39 40 41 42 43 44 45 46 47 ## 48 45 34 36 39 43 38 41 32 ## 48 49 50 51 52 53 54 55 56 ## 41 45 29 29 43 32 25 27 27 ## 57 58 59 60 61 62 63 64 65 ## 30 44 34 33 36 40 29 27 30 ## 66 67 68 69 70 71 72 73 74 ## 19 24 24 24 23 21 13 15 26 ## 75 76 77 78 79 80 81 82 83 ## 10 14 17 13 13 10 7 10 10 ## 84 85 86 87 88 89 90 91 Onbekend ## 7 6 3 8 2 3 1 3 4 summary(cv08_nolab$lftop) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 16.00 33.00 46.00 46.78 61.00 99.00 summary(cv08_haven$lftop) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 16.00 33.00 46.00 46.78 61.00 99.00 table(cv08_haven$lftop, useNA = &quot;always&quot;) ## ## 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 ## 40 37 39 30 30 25 25 38 26 22 18 23 29 30 22 28 23 23 24 38 ## 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 ## 35 37 34 48 45 34 36 39 43 38 41 32 41 45 29 29 43 32 25 27 ## 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 ## 27 30 44 34 33 36 40 29 27 30 19 24 24 24 23 21 13 15 26 10 ## 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 99 &lt;NA&gt; ## 14 17 13 13 10 7 10 10 7 6 3 8 2 3 1 3 4 0 names(cv08_haven) ## [1] &quot;we_id&quot; &quot;veilignr&quot; &quot;lft1&quot; &quot;geslacht&quot; &quot;allochtn&quot; &quot;lft01&quot; &quot;lftop&quot; &quot;gewicht&quot; ## [9] &quot;var006n&quot; &quot;v040&quot; &quot;var723&quot; &quot;var723a&quot; &quot;v202n&quot; &quot;var1061a&quot; &quot;var1061b&quot; &quot;var1062a&quot; ## [17] &quot;var1062b&quot; &quot;int137n&quot; &quot;int138n&quot; &quot;int139n&quot; &quot;int140n&quot; &quot;int141n&quot; &quot;v401&quot; &quot;var1343&quot; ## [25] &quot;var648&quot; &quot;var149&quot; &quot;var058&quot; &quot;var059&quot; &quot;var064&quot; &quot;var365&quot; &quot;var065&quot; &quot;var092&quot; ## [33] &quot;var096&quot; &quot;int054&quot; &quot;int055&quot; &quot;int056&quot; &quot;int057&quot; &quot;int058&quot; &quot;int059&quot; &quot;int059a&quot; ## [41] &quot;var571&quot; &quot;var572&quot; &quot;var573&quot; &quot;var574&quot; &quot;var576&quot; &quot;var153&quot; &quot;var154&quot; &quot;var155&quot; ## [49] &quot;var156&quot; &quot;var157&quot; &quot;var157a&quot; &quot;var154a&quot; &quot;var164&quot; &quot;var165&quot; &quot;var166&quot; &quot;var179&quot; ## [57] &quot;var180&quot; &quot;var184&quot; &quot;var185&quot; &quot;var198a&quot; &quot;var198&quot; &quot;var201a&quot; &quot;var201b&quot; &quot;var204&quot; ## [65] &quot;int257&quot; &quot;var211&quot; &quot;var223&quot; &quot;var1320&quot; &quot;var1321&quot; &quot;var1322&quot; &quot;var1323&quot; &quot;var1324&quot; ## [73] &quot;var1325&quot; &quot;var1326&quot; &quot;var1327&quot; &quot;var1328&quot; &quot;var229&quot; &quot;int218&quot; &quot;int219&quot; &quot;int221&quot; ## [81] &quot;int222&quot; &quot;int223&quot; &quot;int710&quot; &quot;int711&quot; &quot;int712&quot; &quot;int713&quot; &quot;int714&quot; &quot;int715&quot; ## [89] &quot;int716&quot; &quot;var433&quot; &quot;var439&quot; &quot;var1329&quot; &quot;var1330&quot; &quot;var445&quot; &quot;var446&quot; &quot;var447&quot; ## [97] &quot;var451&quot; &quot;var452&quot; &quot;var1316&quot; &quot;var1317&quot; &quot;var1331&quot; &quot;vw065&quot; &quot;var491&quot; &quot;var040&quot; ## [105] &quot;var1304&quot; &quot;var274&quot; &quot;var275&quot; &quot;var1196&quot; &quot;var1197&quot; &quot;var461&quot; &quot;var273&quot; &quot;var1262&quot; ## [113] &quot;var239&quot; &quot;var318&quot; &quot;var319&quot; &quot;var320&quot; &quot;var1209&quot; &quot;var1210&quot; &quot;var599&quot; &quot;var600&quot; ## [121] &quot;var408&quot; &quot;var409&quot; &quot;var10401&quot; &quot;var10402&quot; &quot;var10403&quot; &quot;var10404&quot; &quot;var10405&quot; &quot;var10406&quot; ## [129] &quot;var10407&quot; &quot;var10408&quot; &quot;var10409&quot; &quot;var10410&quot; &quot;var10411&quot; &quot;var10412&quot; &quot;var10413&quot; &quot;var10414&quot; ## [137] &quot;var10415&quot; &quot;var10416&quot; &quot;var1046a&quot; &quot;var1046b&quot; &quot;var1046c&quot; &quot;var1046d&quot; &quot;var1046e&quot; &quot;var1046f&quot; ## [145] &quot;var1046g&quot; &quot;var1046h&quot; &quot;var1046i&quot; &quot;var1046j&quot; &quot;var1046k&quot; &quot;var1046l&quot; &quot;var1046m&quot; &quot;var1046n&quot; ## [153] &quot;var1046o&quot; &quot;var1046p&quot; &quot;var687&quot; &quot;var688&quot; &quot;var689&quot; &quot;var953&quot; &quot;var1265&quot; &quot;var351&quot; ## [161] &quot;var402&quot; &quot;var595&quot; &quot;var972b&quot; &quot;var972d&quot; &quot;var972e&quot; &quot;var972f&quot; &quot;var972h&quot; &quot;var972i&quot; ## [169] &quot;var972k&quot; &quot;var1039b&quot; &quot;var1039c&quot; &quot;var1039d&quot; &quot;var1039e&quot; &quot;var1039f&quot; &quot;var1039g&quot; &quot;var1039h&quot; ## [177] &quot;var1039i&quot; &quot;var1039j&quot; &quot;var1039l&quot; &quot;var1039m&quot; &quot;var1145a&quot; &quot;var1145b&quot; &quot;var1145c&quot; &quot;var1145d&quot; ## [185] &quot;var1145e&quot; &quot;var1145f&quot; &quot;var1145g&quot; &quot;var1145h&quot; &quot;var1145i&quot; &quot;var1145j&quot; &quot;var1145k&quot; &quot;var1145l&quot; ## [193] &quot;var1145m&quot; &quot;var1145n&quot; &quot;var1145o&quot; &quot;var1145p&quot; &quot;var1146&quot; &quot;var1163&quot; &quot;var1335&quot; &quot;var1336&quot; ## [201] &quot;var1337&quot; &quot;var347&quot; &quot;var544&quot; &quot;var757bm&quot; &quot;var1318&quot; &quot;var1332&quot; &quot;var1333&quot; &quot;var1334&quot; ## [209] &quot;var763&quot; &quot;var766&quot; &quot;var767&quot; &quot;var1319&quot; &quot;var844&quot; &quot;var846&quot; &quot;var847&quot; &quot;var594&quot; ## [217] &quot;var1017&quot; &quot;var357&quot; &quot;var1307&quot; &quot;var1338&quot; &quot;var1339&quot; &quot;var1340&quot; &quot;var1341&quot; &quot;var1342&quot; ## [225] &quot;var516&quot; &quot;var683b&quot; &quot;var728b&quot; &quot;var729b&quot; &quot;var546&quot; &quot;var758&quot; &quot;var759&quot; &quot;var1031&quot; ## [233] &quot;var1103&quot; &quot;var1104&quot; &quot;var1106&quot; &quot;var1315a&quot; &quot;var1310&quot; &quot;var1311&quot; &quot;var1312&quot; &quot;var1313&quot; ## [241] &quot;var1314&quot; &quot;var900k&quot; &quot;var900l&quot; &quot;var548&quot; &quot;var5504&quot; &quot;var462b&quot; &quot;soorthhn&quot; &quot;plaatsin&quot; ## [249] &quot;lft2&quot; &quot;lft3&quot; &quot;lft4&quot; &quot;lft5&quot; &quot;lft6&quot; &quot;lft7&quot; &quot;lft8&quot; &quot;lft9&quot; ## [257] &quot;lft10&quot; &quot;geslac_1&quot; &quot;geslac_2&quot; &quot;geslac_3&quot; &quot;geslac_4&quot; &quot;geslac_5&quot; &quot;geslac_6&quot; &quot;geslac_7&quot; ## [265] &quot;geslac_8&quot; &quot;geslac_9&quot; &quot;lftcatjo&quot; &quot;soortbew&quot; &quot;soi98dop&quot; &quot;isco_op&quot; &quot;gemgrjj&quot; &quot;landd&quot; ## [273] &quot;stede&quot; &quot;generat&quot; &quot;typehh&quot; &quot;plaatshh&quot; &quot;plhh17&quot; &quot;wperiode&quot; summary(cv08_haven) ## we_id veilignr lft1 geslacht allochtn ## Min. :36775330 Min. :811000004 Min. : 0.00 Length:1963 Min. :0.0000 ## 1st Qu.:37604540 1st Qu.:812003955 1st Qu.:33.00 Class :character 1st Qu.:0.0000 ## Median :38724230 Median :902002867 Median :46.00 Mode :character Median :0.0000 ## Mean :38830177 Mean :875088135 Mean :46.56 Mean :0.1793 ## 3rd Qu.:40598965 3rd Qu.:904000134 3rd Qu.:60.00 3rd Qu.:0.0000 ## Max. :41199300 Max. :905010166 Max. :99.00 Max. :9.0000 ## ## lft01 lftop gewicht var006n v040 var723 ## Min. :15.00 Min. :16.00 Min. : 955.1 Min. :-3.000 Min. :1.000 Min. :-5.00 ## 1st Qu.:32.00 1st Qu.:33.00 1st Qu.: 5137.2 1st Qu.: 2.000 1st Qu.:1.000 1st Qu.:-5.00 ## Median :46.00 Median :46.00 Median : 6473.4 Median : 5.000 Median :1.000 Median :20.00 ## Mean :46.37 Mean :46.78 Mean : 6676.3 Mean : 3.999 Mean :1.352 Mean :18.69 ## 3rd Qu.:60.00 3rd Qu.:61.00 3rd Qu.: 7981.1 3rd Qu.: 6.000 3rd Qu.:2.000 3rd Qu.:38.00 ## Max. :99.00 Max. :99.00 Max. :20501.2 Max. : 8.000 Max. :2.000 Max. :90.00 ## ## var723a v202n var1061a var1061b var1062a ## Min. :-5.000 Min. :-3.000 Min. :1.000 Min. : -5.000 Min. :1.000 ## 1st Qu.:-5.000 1st Qu.: 1.000 1st Qu.:1.000 1st Qu.: -5.000 1st Qu.:2.000 ## Median :-5.000 Median : 1.000 Median :2.000 Median : -5.000 Median :2.000 ## Mean :-4.978 Mean : 2.695 Mean :1.721 Mean : -2.074 Mean :1.773 ## 3rd Qu.:-5.000 3rd Qu.: 5.000 3rd Qu.:2.000 3rd Qu.: 1.000 3rd Qu.:2.000 ## Max. : 4.000 Max. :10.000 Max. :2.000 Max. :168.000 Max. :2.000 ## ## var1062b int137n int138n int139n int140n ## Min. : -5.000 Min. :-5.0000 Min. :-5.000 Min. :-5.0000 Min. :-5.000 ## 1st Qu.: -5.000 1st Qu.: 1.0000 1st Qu.: 2.000 1st Qu.: 1.0000 1st Qu.: 1.000 ## Median : -5.000 Median : 2.0000 Median : 3.000 Median : 1.0000 Median : 2.000 ## Mean : -2.531 Mean : 0.5797 Mean : 2.232 Mean : 0.9103 Mean : 1.911 ## 3rd Qu.: -5.000 3rd Qu.: 3.0000 3rd Qu.: 3.000 3rd Qu.: 3.0000 3rd Qu.: 3.000 ## Max. :168.000 Max. : 3.0000 Max. : 3.000 Max. : 3.0000 Max. : 3.000 ## ## int141n v401 var1343 var648 var149 var058 ## Min. :-5.000 Min. :1.000 Min. :-3.00 Min. :1.00 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 1.000 1st Qu.:1.000 1st Qu.: 3.00 1st Qu.:2.00 1st Qu.: 1.000 1st Qu.: 1.000 ## Median : 1.000 Median :2.000 Median : 3.00 Median :3.00 Median : 1.000 Median : 1.000 ## Mean : 1.887 Mean :1.993 Mean : 2.86 Mean :2.58 Mean : 1.442 Mean : 1.149 ## 3rd Qu.: 3.000 3rd Qu.:2.000 3rd Qu.: 3.00 3rd Qu.:3.00 3rd Qu.: 2.000 3rd Qu.: 1.000 ## Max. : 3.000 Max. :5.000 Max. : 3.00 Max. :5.00 Max. : 3.000 Max. : 2.000 ## ## var059 var064 var365 var065 var092 ## Min. :-3.000 Min. :-3.000 Min. :-3.0000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.: 1.0000 1st Qu.: 1.000 1st Qu.: 3.000 ## Median : 1.000 Median : 1.000 Median : 1.0000 Median : 1.000 Median : 4.000 ## Mean : 1.083 Mean : 1.149 Mean : 0.9409 Mean : 1.148 Mean : 3.295 ## 3rd Qu.: 1.000 3rd Qu.: 2.000 3rd Qu.: 2.0000 3rd Qu.: 2.000 3rd Qu.: 4.000 ## Max. : 2.000 Max. : 2.000 Max. : 2.0000 Max. : 2.000 Max. : 4.000 ## ## var096 int054 int055 int056 int057 ## Min. :-3.000 Min. :-3.000 Min. :-3.00 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 1.000 1st Qu.: 2.000 1st Qu.: 2.00 1st Qu.: 2.000 1st Qu.: 2.000 ## Median : 2.000 Median : 2.000 Median : 3.00 Median : 2.000 Median : 2.000 ## Mean : 2.008 Mean : 1.948 Mean : 2.43 Mean : 1.888 Mean : 1.954 ## 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 3.00 3rd Qu.: 3.000 3rd Qu.: 3.000 ## Max. : 5.000 Max. : 4.000 Max. : 4.00 Max. : 4.000 Max. : 4.000 ## ## int058 int059 int059a var571 var572 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-5.000 ## 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.:-5.000 ## Median : 2.000 Median : 2.000 Median : 2.000 Median : 2.000 Median : 1.000 ## Mean : 2.065 Mean : 2.141 Mean : 1.851 Mean : 2.326 Mean :-0.864 ## 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 2.000 ## Max. : 4.000 Max. : 4.000 Max. : 4.000 Max. : 3.000 Max. : 3.000 ## ## var573 var574 var576 var153 var154 ## Min. :-3.000 Min. :-5.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 1.000 1st Qu.:-5.000 1st Qu.: 2.000 1st Qu.: 1.000 1st Qu.: 2.000 ## Median : 2.000 Median :-5.000 Median : 3.000 Median : 1.000 Median : 2.000 ## Mean : 1.615 Mean :-2.002 Mean : 2.985 Mean : 1.319 Mean : 1.889 ## 3rd Qu.: 2.000 3rd Qu.: 2.000 3rd Qu.: 4.000 3rd Qu.: 2.000 3rd Qu.: 3.000 ## Max. : 3.000 Max. : 3.000 Max. : 5.000 Max. : 3.000 Max. : 3.000 ## ## var155 var156 var157 var157a var154a ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.00 ## 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.:-3.000 1st Qu.: 2.000 1st Qu.: 2.00 ## Median : 2.000 Median : 2.000 Median : 2.000 Median : 2.000 Median : 2.00 ## Mean : 1.339 Mean : 1.415 Mean : 0.566 Mean : 1.506 Mean : 1.56 ## 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 2.00 ## Max. : 3.000 Max. : 3.000 Max. : 3.000 Max. : 3.000 Max. : 3.00 ## ## var164 var165 var166 var179 var180 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 1.000 1st Qu.: 3.000 1st Qu.: 3.000 1st Qu.: 1.000 1st Qu.: 1.000 ## Median : 1.000 Median : 4.000 Median : 3.000 Median : 1.000 Median : 1.000 ## Mean : 1.271 Mean : 3.752 Mean : 3.148 Mean : 1.061 Mean : 1.207 ## 3rd Qu.: 2.000 3rd Qu.: 5.000 3rd Qu.: 4.000 3rd Qu.: 1.000 3rd Qu.: 1.000 ## Max. : 3.000 Max. : 5.000 Max. : 5.000 Max. : 2.000 Max. : 2.000 ## ## var184 var185 var198a var198 var201a ## Min. :-3.000 Min. :-3.000 Min. :1.000 Min. :-5.0000 Min. :-3.000 ## 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.:1.000 1st Qu.:-5.0000 1st Qu.: 1.000 ## Median : 1.000 Median : 1.000 Median :1.000 Median : 1.0000 Median : 2.000 ## Mean : 1.233 Mean : 1.232 Mean :1.314 Mean :-0.2165 Mean : 1.661 ## 3rd Qu.: 2.000 3rd Qu.: 2.000 3rd Qu.:2.000 3rd Qu.: 2.0000 3rd Qu.: 2.000 ## Max. : 2.000 Max. : 2.000 Max. :2.000 Max. : 7.0000 Max. : 2.000 ## ## var201b var204 int257 var211 var223 ## Min. :-5.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.:-5.000 1st Qu.: 4.000 1st Qu.: 3.000 1st Qu.: 1.000 1st Qu.: 1.000 ## Median :-5.000 Median : 5.000 Median : 3.000 Median : 3.000 Median : 1.000 ## Mean :-2.512 Mean : 4.118 Mean : 3.881 Mean : 2.235 Mean : 1.258 ## 3rd Qu.: 1.000 3rd Qu.: 5.000 3rd Qu.: 5.000 3rd Qu.: 3.000 3rd Qu.: 1.000 ## Max. : 6.000 Max. : 5.000 Max. : 7.000 Max. : 3.000 Max. : 3.000 ## ## var1320 var1321 var1322 var1323 var1324 var1325 ## Min. :-3.000 Min. :-3.00 Min. :-3.00 Min. :-3.000 Min. :-3.000 Min. :-3.00 ## 1st Qu.: 1.000 1st Qu.: 2.00 1st Qu.: 2.00 1st Qu.: 3.000 1st Qu.: 3.000 1st Qu.: 3.00 ## Median : 2.000 Median : 2.00 Median : 2.00 Median : 3.000 Median : 3.000 Median : 3.00 ## Mean : 1.658 Mean : 2.61 Mean : 2.13 Mean : 2.669 Mean : 2.821 Mean : 2.79 ## 3rd Qu.: 2.000 3rd Qu.: 4.00 3rd Qu.: 3.00 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 3.00 ## Max. : 5.000 Max. : 5.00 Max. : 3.00 Max. : 3.000 Max. : 3.000 Max. : 3.00 ## ## var1326 var1327 var1328 var229 int218 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 3.000 1st Qu.: 3.000 1st Qu.: 3.000 1st Qu.: 3.000 1st Qu.: 3.000 ## Median : 3.000 Median : 3.000 Median : 3.000 Median : 3.000 Median : 3.000 ## Mean : 2.924 Mean : 2.683 Mean : 2.909 Mean : 3.319 Mean : 2.967 ## 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 3.000 ## Max. : 3.000 Max. : 3.000 Max. : 3.000 Max. : 8.000 Max. : 5.000 ## ## int219 int221 int222 int223 int710 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 2.000 1st Qu.: 3.000 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.: 2.000 ## Median : 3.000 Median : 3.000 Median : 3.000 Median : 3.000 Median : 3.000 ## Mean : 2.574 Mean : 3.034 Mean : 2.685 Mean : 2.501 Mean : 2.608 ## 3rd Qu.: 3.000 3rd Qu.: 4.000 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 3.000 ## Max. : 5.000 Max. : 5.000 Max. : 5.000 Max. : 5.000 Max. : 5.000 ## ## int711 int712 int713 int714 int715 ## Min. :-3.000 Min. :-3.00 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 3.000 1st Qu.: 2.00 1st Qu.: 3.000 1st Qu.: 3.000 1st Qu.: 2.000 ## Median : 3.000 Median : 3.00 Median : 3.000 Median : 3.000 Median : 3.000 ## Mean : 2.827 Mean : 2.76 Mean : 2.737 Mean : 2.829 Mean : 2.575 ## 3rd Qu.: 4.000 3rd Qu.: 3.00 3rd Qu.: 3.000 3rd Qu.: 4.000 3rd Qu.: 4.000 ## Max. : 5.000 Max. : 5.00 Max. : 5.000 Max. : 5.000 Max. : 5.000 ## ## int716 var433 var439 var1329 var1330 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.: 2.000 ## Median : 3.000 Median : 4.000 Median : 2.000 Median : 2.000 Median : 3.000 ## Mean : 2.322 Mean : 3.331 Mean : 2.407 Mean : 2.114 Mean : 3.163 ## 3rd Qu.: 3.000 3rd Qu.: 5.000 3rd Qu.: 4.000 3rd Qu.: 3.000 3rd Qu.: 5.000 ## Max. : 5.000 Max. : 5.000 Max. : 5.000 Max. : 5.000 Max. : 5.000 ## ## var445 var446 var447 var451 var452 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 3.000 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.: 3.000 1st Qu.: 2.000 ## Median : 4.000 Median : 3.000 Median : 3.000 Median : 4.000 Median : 3.000 ## Mean : 3.746 Mean : 2.706 Mean : 3.003 Mean : 3.779 Mean : 2.788 ## 3rd Qu.: 5.000 3rd Qu.: 4.000 3rd Qu.: 4.000 3rd Qu.: 5.000 3rd Qu.: 4.000 ## Max. : 5.000 Max. : 5.000 Max. : 5.000 Max. : 5.000 Max. : 5.000 ## ## var1316 var1317 var1331 vw065 var491 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.: 2.000 ## Median : 3.000 Median : 3.000 Median : 2.000 Median : 1.000 Median : 2.000 ## Mean : 2.952 Mean : 2.862 Mean : 1.735 Mean : 1.185 Mean : 2.665 ## 3rd Qu.: 4.000 3rd Qu.: 4.000 3rd Qu.: 2.000 3rd Qu.: 2.000 3rd Qu.: 3.000 ## Max. : 5.000 Max. : 5.000 Max. : 4.000 Max. : 2.000 Max. : 5.000 ## ## var040 var1304 var274 var275 var1196 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-5.000 Min. :-3.000 ## 1st Qu.: 1.000 1st Qu.: 2.000 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.: 1.000 ## Median : 1.000 Median : 2.000 Median : 1.000 Median : 3.000 Median : 1.000 ## Mean : 1.803 Mean : 1.964 Mean : 1.322 Mean : 4.462 Mean : 1.489 ## 3rd Qu.: 2.000 3rd Qu.: 2.000 3rd Qu.: 1.000 3rd Qu.: 8.000 3rd Qu.: 2.000 ## Max. : 4.000 Max. : 4.000 Max. : 4.000 Max. :14.000 Max. : 3.000 ## ## var1197 var461 var273 var1262 var239 ## Min. :-3.0000 Min. :-3.00 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 1.0000 1st Qu.: 2.00 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.: 1.000 ## Median : 1.0000 Median : 3.00 Median : 2.000 Median : 3.000 Median : 2.000 ## Mean : 0.8197 Mean : 2.33 Mean : 2.065 Mean : 2.863 Mean : 1.614 ## 3rd Qu.: 1.0000 3rd Qu.: 4.00 3rd Qu.: 3.000 3rd Qu.: 4.000 3rd Qu.: 2.000 ## Max. : 2.0000 Max. : 5.00 Max. : 5.000 Max. : 5.000 Max. : 2.000 ## ## var318 var319 var320 var1209 var1210 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.: 1.000 ## Median : 1.000 Median : 2.000 Median : 1.000 Median : 2.000 Median : 2.000 ## Mean : 1.435 Mean : 1.485 Mean : 1.194 Mean : 1.952 Mean : 1.785 ## 3rd Qu.: 2.000 3rd Qu.: 2.000 3rd Qu.: 2.000 3rd Qu.: 3.000 3rd Qu.: 2.000 ## Max. : 2.000 Max. : 2.000 Max. : 2.000 Max. : 4.000 Max. : 4.000 ## ## var599 var600 var408 var409 var10401 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Length:1963 ## 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.: 1.000 Class :character ## Median : 2.000 Median : 2.000 Median : 2.000 Median : 1.000 Mode :character ## Mean : 1.908 Mean : 1.759 Mean : 2.231 Mean : 1.485 ## 3rd Qu.: 2.000 3rd Qu.: 2.000 3rd Qu.: 3.000 3rd Qu.: 2.000 ## Max. : 2.000 Max. : 2.000 Max. : 3.000 Max. : 3.000 ## ## var10402 var10403 var10404 var10405 var10406 ## Length:1963 Length:1963 Length:1963 Length:1963 Length:1963 ## Class :character Class :character Class :character Class :character Class :character ## Mode :character Mode :character Mode :character Mode :character Mode :character ## ## ## ## ## var10407 var10408 var10409 var10410 var10411 ## Length:1963 Length:1963 Length:1963 Length:1963 Length:1963 ## Class :character Class :character Class :character Class :character Class :character ## Mode :character Mode :character Mode :character Mode :character Mode :character ## ## ## ## ## var10412 var10413 var10414 var10415 var10416 ## Length:1963 Length:1963 Length:1963 Length:1963 Length:1963 ## Class :character Class :character Class :character Class :character Class :character ## Mode :character Mode :character Mode :character Mode :character Mode :character ## ## ## ## ## var1046a var1046b var1046c var1046d var1046e ## Min. :-4.000 Min. :-4.000 Min. :-4.000 Min. :-4.000 Min. :-4.000 ## 1st Qu.: 3.000 1st Qu.: 7.000 1st Qu.: 5.000 1st Qu.: 2.000 1st Qu.: 5.000 ## Median : 6.000 Median :10.000 Median : 9.000 Median : 5.000 Median : 9.000 ## Mean : 6.175 Mean : 9.328 Mean : 8.621 Mean : 5.761 Mean : 8.733 ## 3rd Qu.: 9.000 3rd Qu.:13.000 3rd Qu.:12.000 3rd Qu.: 9.000 3rd Qu.:13.000 ## Max. :16.000 Max. :16.000 Max. :16.000 Max. :16.000 Max. :16.000 ## ## var1046f var1046g var1046h var1046i var1046j ## Min. :-4.00 Min. :-4.000 Min. :-4.00 Min. :-4.000 Min. :-4.000 ## 1st Qu.:12.00 1st Qu.: 7.000 1st Qu.:10.00 1st Qu.: 2.000 1st Qu.: 3.000 ## Median :15.00 Median :10.000 Median :13.00 Median : 5.000 Median : 5.000 ## Mean :13.17 Mean : 9.357 Mean :11.66 Mean : 5.423 Mean : 5.732 ## 3rd Qu.:16.00 3rd Qu.:13.000 3rd Qu.:15.00 3rd Qu.: 8.000 3rd Qu.: 8.000 ## Max. :16.00 Max. :16.000 Max. :16.00 Max. :16.000 Max. :16.000 ## ## var1046k var1046l var1046m var1046n var1046o ## Min. :-4.000 Min. :-4.000 Min. :-4.000 Min. :-4.000 Min. :-4.000 ## 1st Qu.: 3.000 1st Qu.: 6.000 1st Qu.: 4.000 1st Qu.: 5.000 1st Qu.: 3.000 ## Median : 6.000 Median :10.000 Median : 6.000 Median : 8.000 Median : 5.000 ## Mean : 6.542 Mean : 9.194 Mean : 6.552 Mean : 8.047 Mean : 5.587 ## 3rd Qu.:10.000 3rd Qu.:13.000 3rd Qu.: 9.000 3rd Qu.:12.000 3rd Qu.: 8.000 ## Max. :16.000 Max. :16.000 Max. :16.000 Max. :16.000 Max. :16.000 ## ## var1046p var687 var688 var689 var953 ## Min. :-4.00 Min. :-3.000 Min. :-5.0000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 8.00 1st Qu.: 1.000 1st Qu.:-5.0000 1st Qu.: 1.000 1st Qu.: 3.000 ## Median :13.00 Median : 1.000 Median : 1.0000 Median : 1.000 Median : 3.000 ## Mean :11.25 Mean : 1.279 Mean :-0.1854 Mean : 1.175 Mean : 2.593 ## 3rd Qu.:15.00 3rd Qu.: 2.000 3rd Qu.: 2.0000 3rd Qu.: 1.000 3rd Qu.: 3.000 ## Max. :16.00 Max. : 3.000 Max. : 3.0000 Max. : 2.000 Max. : 3.000 ## ## var1265 var351 var402 var595 var972b ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-2.000 ## 1st Qu.: 1.000 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.: 2.000 ## Median : 2.000 Median : 4.000 Median : 3.000 Median : 2.000 Median : 3.000 ## Mean : 1.386 Mean : 3.356 Mean : 2.891 Mean : 2.221 Mean : 3.118 ## 3rd Qu.: 3.000 3rd Qu.: 5.000 3rd Qu.: 4.000 3rd Qu.: 3.000 3rd Qu.: 4.000 ## Max. : 3.000 Max. : 5.000 Max. : 5.000 Max. : 5.000 Max. : 5.000 ## ## var972d var972e var972f var972h var972i ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.: 3.000 1st Qu.: 2.000 ## Median : 2.000 Median : 2.000 Median : 3.000 Median : 3.000 Median : 2.000 ## Mean : 2.343 Mean : 2.087 Mean : 2.853 Mean : 3.324 Mean : 2.109 ## 3rd Qu.: 3.000 3rd Qu.: 2.000 3rd Qu.: 3.000 3rd Qu.: 4.000 3rd Qu.: 3.000 ## Max. : 5.000 Max. : 5.000 Max. : 5.000 Max. : 5.000 Max. : 5.000 ## ## var972k var1039b var1039c var1039d var1039e ## Min. :-3.000 Min. :-3.000 Min. :-3.00 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 2.000 1st Qu.: 3.000 1st Qu.: 3.00 1st Qu.: 3.000 1st Qu.: 3.000 ## Median : 2.000 Median : 4.000 Median : 3.00 Median : 3.000 Median : 3.000 ## Mean : 2.523 Mean : 3.474 Mean : 3.42 Mean : 2.771 Mean : 2.997 ## 3rd Qu.: 3.000 3rd Qu.: 4.000 3rd Qu.: 4.00 3rd Qu.: 3.000 3rd Qu.: 3.000 ## Max. : 5.000 Max. : 5.000 Max. : 5.00 Max. : 5.000 Max. : 5.000 ## ## var1039f var1039g var1039h var1039i var1039j ## Min. :-3.000 Min. :-3.000 Min. :-3.00 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 3.000 1st Qu.: 3.000 1st Qu.: 3.00 1st Qu.: 3.000 1st Qu.: 3.000 ## Median : 4.000 Median : 3.000 Median : 4.00 Median : 4.000 Median : 3.000 ## Mean : 3.828 Mean : 3.483 Mean : 3.24 Mean : 3.731 Mean : 3.266 ## 3rd Qu.: 4.000 3rd Qu.: 4.000 3rd Qu.: 4.00 3rd Qu.: 4.000 3rd Qu.: 4.000 ## Max. : 5.000 Max. : 5.000 Max. : 5.00 Max. : 5.000 Max. : 5.000 ## ## var1039l var1039m var1145a var1145b var1145c ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.00 Min. :-3.000 ## 1st Qu.: 3.000 1st Qu.: 3.000 1st Qu.: 5.000 1st Qu.: 5.00 1st Qu.: 6.000 ## Median : 3.000 Median : 3.000 Median : 6.000 Median : 6.00 Median : 6.000 ## Mean : 3.171 Mean : 3.127 Mean : 5.439 Mean : 5.22 Mean : 5.628 ## 3rd Qu.: 4.000 3rd Qu.: 4.000 3rd Qu.: 7.000 3rd Qu.: 7.00 3rd Qu.: 7.000 ## Max. : 5.000 Max. : 5.000 Max. :10.000 Max. :10.00 Max. :10.000 ## ## var1145d var1145e var1145f var1145g var1145h ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 5.000 1st Qu.: 5.000 1st Qu.: 5.000 1st Qu.: 5.000 1st Qu.: 5.000 ## Median : 6.000 Median : 6.000 Median : 6.000 Median : 6.000 Median : 6.000 ## Mean : 5.595 Mean : 5.592 Mean : 5.938 Mean : 5.836 Mean : 5.697 ## 3rd Qu.: 7.000 3rd Qu.: 7.000 3rd Qu.: 7.000 3rd Qu.: 7.000 3rd Qu.: 7.000 ## Max. :10.000 Max. : 9.000 Max. :10.000 Max. :10.000 Max. :10.000 ## ## var1145i var1145j var1145k var1145l var1145m ## Min. :-3.00 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 5.00 1st Qu.: 5.000 1st Qu.: 5.000 1st Qu.: 5.000 1st Qu.: 5.000 ## Median : 6.00 Median : 6.000 Median : 6.000 Median : 6.000 Median : 6.000 ## Mean : 5.77 Mean : 5.428 Mean : 5.004 Mean : 5.345 Mean : 5.311 ## 3rd Qu.: 7.00 3rd Qu.: 7.000 3rd Qu.: 7.000 3rd Qu.: 7.000 3rd Qu.: 7.000 ## Max. :10.00 Max. :10.000 Max. :10.000 Max. :10.000 Max. :10.000 ## ## var1145n var1145o var1145p var1146 var1163 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 5.000 1st Qu.: 5.000 1st Qu.: 5.000 1st Qu.: 2.000 1st Qu.: 2.000 ## Median : 6.000 Median : 6.000 Median : 6.000 Median : 2.000 Median : 2.000 ## Mean : 5.145 Mean : 5.347 Mean : 4.607 Mean : 2.174 Mean : 2.094 ## 3rd Qu.: 7.000 3rd Qu.: 7.000 3rd Qu.: 7.000 3rd Qu.: 2.000 3rd Qu.: 3.000 ## Max. :10.000 Max. :10.000 Max. :10.000 Max. : 4.000 Max. : 4.000 ## ## var1335 var1336 var1337 var347 var544 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 3.000 1st Qu.: 2.000 1st Qu.: 3.000 1st Qu.: 2.000 1st Qu.: 1.000 ## Median : 4.000 Median : 2.000 Median : 4.000 Median : 2.000 Median : 2.000 ## Mean : 3.482 Mean : 2.065 Mean : 3.598 Mean : 2.427 Mean : 1.584 ## 3rd Qu.: 4.000 3rd Qu.: 2.000 3rd Qu.: 4.000 3rd Qu.: 3.000 3rd Qu.: 2.000 ## Max. : 5.000 Max. : 5.000 Max. : 5.000 Max. : 5.000 Max. : 3.000 ## ## var757bm var1318 var1332 var1333 var1334 ## Min. :-3.000 Min. :-3.000 Min. :-3.00 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.: 1.00 1st Qu.: 3.000 1st Qu.: 2.000 ## Median : 1.000 Median : 1.000 Median : 1.00 Median : 3.000 Median : 3.000 ## Mean : 1.164 Mean : 1.857 Mean : 1.34 Mean : 3.221 Mean : 2.646 ## 3rd Qu.: 2.000 3rd Qu.: 3.000 3rd Qu.: 1.00 3rd Qu.: 4.000 3rd Qu.: 3.000 ## Max. : 2.000 Max. : 3.000 Max. : 4.00 Max. : 4.000 Max. : 4.000 ## ## var763 var766 var767 var1319 var844 ## Length:1963 Length:1963 Length:1963 Min. :-3.000 Min. :-3.000 ## Class :character Class :character Class :character 1st Qu.: 3.000 1st Qu.: 1.000 ## Mode :character Mode :character Mode :character Median : 4.000 Median : 2.000 ## Mean : 3.875 Mean : 1.914 ## 3rd Qu.: 5.000 3rd Qu.: 2.000 ## Max. : 6.000 Max. : 5.000 ## ## var846 var847 var594 var1017 var357 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.: 3.000 1st Qu.: 2.000 1st Qu.: 2.000 ## Median : 2.000 Median : 2.000 Median : 4.000 Median : 3.000 Median : 3.000 ## Mean : 2.141 Mean : 1.986 Mean : 3.312 Mean : 2.702 Mean : 2.841 ## 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 4.000 3rd Qu.: 4.000 3rd Qu.: 4.000 ## Max. : 5.000 Max. : 5.000 Max. : 5.000 Max. : 5.000 Max. : 5.000 ## ## var1307 var1338 var1339 var1340 var1341 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.: 2.000 1st Qu.: 2.000 ## Median : 1.000 Median : 1.000 Median : 1.000 Median : 2.000 Median : 2.000 ## Mean : 1.085 Mean : 1.226 Mean : 1.133 Mean : 2.112 Mean : 1.756 ## 3rd Qu.: 2.000 3rd Qu.: 3.000 3rd Qu.: 2.000 3rd Qu.: 3.000 3rd Qu.: 2.000 ## Max. : 3.000 Max. : 3.000 Max. : 3.000 Max. : 3.000 Max. : 3.000 ## ## var1342 var516 var683b var728b var729b ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.00 ## 1st Qu.: 1.000 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.: 3.000 1st Qu.: 3.00 ## Median : 1.000 Median : 2.000 Median : 3.000 Median : 3.000 Median : 3.00 ## Mean : 1.198 Mean : 1.853 Mean : 2.606 Mean : 2.587 Mean : 2.71 ## 3rd Qu.: 2.000 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 3.00 ## Max. : 3.000 Max. : 3.000 Max. : 3.000 Max. : 3.000 Max. : 3.00 ## ## var546 var758 var759 var1031 var1103 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.000 ## 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.: 1.000 ## Median : 1.000 Median : 1.000 Median : 1.000 Median : 2.000 Median : 2.000 ## Mean : 1.618 Mean : 1.355 Mean : 1.177 Mean : 1.625 Mean : 1.709 ## 3rd Qu.: 3.000 3rd Qu.: 1.000 3rd Qu.: 1.000 3rd Qu.: 2.000 3rd Qu.: 2.000 ## Max. : 4.000 Max. : 4.000 Max. : 4.000 Max. : 3.000 Max. : 4.000 ## ## var1104 var1106 var1315a var1310 var1311 ## Min. :-3.000 Min. :-3.000 Min. :-3.000 Min. :-3.00 Min. :-3.000 ## 1st Qu.: 2.000 1st Qu.: 2.000 1st Qu.: 1.000 1st Qu.: 2.00 1st Qu.: 2.000 ## Median : 3.000 Median : 3.000 Median : 3.000 Median : 3.00 Median : 3.000 ## Mean : 2.527 Mean : 2.517 Mean : 2.208 Mean : 2.38 Mean : 2.271 ## 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 3.000 3rd Qu.: 3.00 3rd Qu.: 3.000 ## Max. : 4.000 Max. : 4.000 Max. : 4.000 Max. : 4.00 Max. : 4.000 ## ## var1312 var1313 var1314 var900k var900l ## Min. :-3.000 Min. :-3.000 Min. :-3.00 Min. :-3.000 Min. :-5.000 ## 1st Qu.: 2.000 1st Qu.: 1.000 1st Qu.: 1.00 1st Qu.: 2.000 1st Qu.: 2.000 ## Median : 3.000 Median : 2.000 Median : 2.00 Median : 3.000 Median : 2.000 ## Mean : 2.285 Mean : 1.561 Mean : 1.42 Mean : 2.971 Mean : 2.209 ## 3rd Qu.: 3.000 3rd Qu.: 2.000 3rd Qu.: 3.00 3rd Qu.: 4.000 3rd Qu.: 3.000 ## Max. : 4.000 Max. : 4.000 Max. : 4.00 Max. : 5.000 Max. : 3.000 ## ## var548 var5504 var462b soorthhn plaatsin lft2 ## Min. :-5.000 Min. :-5.00 Min. :-10105 Min. :1.000 Min. : 1.00 Min. : 1.00 ## 1st Qu.: 1.000 1st Qu.:-5.00 1st Qu.: 29826 1st Qu.:3.000 1st Qu.: 2.00 1st Qu.:20.00 ## Median : 2.000 Median :-5.00 Median : 48446 Median :4.000 Median : 4.00 Median :43.00 ## Mean : 1.698 Mean :-2.97 Mean : 54056 Mean :3.604 Mean : 3.94 Mean :40.02 ## 3rd Qu.: 2.000 3rd Qu.: 1.00 3rd Qu.: 71490 3rd Qu.:5.000 3rd Qu.: 6.00 3rd Qu.:58.00 ## Max. : 2.000 Max. : 2.00 Max. :317482 Max. :8.000 Max. :10.00 Max. :96.00 ## NA&#39;s :14 NA&#39;s :6 NA&#39;s :6 NA&#39;s :392 ## lft3 lft4 lft5 lft6 lft7 lft8 ## Min. : 1.00 Min. : 1.00 Min. : 1.00 Min. : 1.00 Min. : 11 Min. :14.00 ## 1st Qu.:12.00 1st Qu.:11.00 1st Qu.:10.00 1st Qu.: 9.00 1st Qu.: 43 1st Qu.:14.75 ## Median :22.50 Median :20.00 Median :17.00 Median :16.00 Median :2007 Median :20.00 ## Mean :28.03 Mean :27.03 Mean :23.59 Mean :26.12 Mean :1346 Mean :26.25 ## 3rd Qu.:46.00 3rd Qu.:45.00 3rd Qu.:43.00 3rd Qu.:43.50 3rd Qu.:2007 3rd Qu.:31.50 ## Max. :90.00 Max. :82.00 Max. :77.00 Max. :99.00 Max. :2007 Max. :51.00 ## NA&#39;s :1075 NA&#39;s :1390 NA&#39;s :1787 NA&#39;s :1912 NA&#39;s :1951 NA&#39;s :1959 ## lft9 lft10 geslac_1 geslac_2 geslac_3 ## Min. :15.00 Min. :12 Length:1963 Length:1963 Length:1963 ## 1st Qu.:19.50 1st Qu.:12 Class :character Class :character Class :character ## Median :24.00 Median :12 Mode :character Mode :character Mode :character ## Mean :30.33 Mean :12 ## 3rd Qu.:38.00 3rd Qu.:12 ## Max. :52.00 Max. :12 ## NA&#39;s :1960 NA&#39;s :1962 ## geslac_4 geslac_5 geslac_6 geslac_7 geslac_8 ## Length:1963 Length:1963 Length:1963 Length:1963 Length:1963 ## Class :character Class :character Class :character Class :character Class :character ## Mode :character Mode :character Mode :character Mode :character Mode :character ## ## ## ## ## geslac_9 lftcatjo soortbew soi98dop isco_op ## Length:1963 Length:1963 Length:1963 Min. :200123 Length:1963 ## Class :character Class :character Class :character 1st Qu.:338110 Class :character ## Mode :character Mode :character Mode :character Median :430168 Mode :character ## Mean :444655 ## 3rd Qu.:520799 ## Max. :999900 ## NA&#39;s :379 ## gemgrjj landd stede generat typehh plaatshh ## Min. :1.00 Min. :1.000 Min. :1.000 Min. :1.000 Min. :1.000 Min. : 1.000 ## 1st Qu.:4.00 1st Qu.:2.000 1st Qu.:2.000 1st Qu.:4.000 1st Qu.:3.000 1st Qu.: 2.000 ## Median :4.00 Median :3.000 Median :3.000 Median :4.000 Median :4.000 Median : 4.000 ## Mean :4.84 Mean :2.805 Mean :2.933 Mean :3.656 Mean :3.602 Mean : 3.938 ## 3rd Qu.:6.00 3rd Qu.:3.000 3rd Qu.:4.000 3rd Qu.:4.000 3rd Qu.:5.000 3rd Qu.: 6.000 ## Max. :8.00 Max. :4.000 Max. :5.000 Max. :4.000 Max. :8.000 Max. :10.000 ## NA&#39;s :6 NA&#39;s :6 ## plhh17 wperiode ## Min. :1 Min. :200811 ## 1st Qu.:1 1st Qu.:200812 ## Median :1 Median :200902 ## Mean :1 Mean :200875 ## 3rd Qu.:1 3rd Qu.:200904 ## Max. :1 Max. :200905 ## head(cv08_haven) ## # A tibble: 6 x 278 ## we_id veilignr lft1 geslacht allochtn lft01 lftop gewicht var006n v040 var723 var723a ## &lt;dbl+l&gt; &lt;dbl&gt; &lt;dbl+&gt; &lt;chr+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; ## 1 3.68e7 811002474 51 M [Man] 0 [geen ~ 50 51 8423. 6 [hbo] 2 [Nee] -5 [N.v~ -5 [N.v~ ## 2 3.68e7 811002539 39 V [Vrouw] 0 [geen ~ 38 39 6244. 8 [wo] 1 [Ja] 45 -5 [N.v~ ## 3 3.68e7 811002551 16 V [Vrouw] 1 [alloc~ 15 16 13434. 3 [mav~ 2 [Nee] -5 [N.v~ -5 [N.v~ ## 4 3.68e7 811002563 30 M [Man] 0 [geen ~ 29 29 8997 8 [wo] 1 [Ja] 20 -5 [N.v~ ## 5 3.68e7 811002743 57 M [Man] 0 [geen ~ 56 57 8423. 6 [hbo] 2 [Nee] -5 [N.v~ -5 [N.v~ ## 6 3.68e7 811002607 49 V [Vrouw] 1 [alloc~ 48 49 9537. 2 [vmb~ 2 [Nee] -5 [N.v~ -5 [N.v~ ## # ... with 266 more variables: v202n &lt;dbl+lbl&gt;, var1061a &lt;dbl+lbl&gt;, var1061b &lt;dbl+lbl&gt;, ## # var1062a &lt;dbl+lbl&gt;, var1062b &lt;dbl+lbl&gt;, int137n &lt;dbl+lbl&gt;, int138n &lt;dbl+lbl&gt;, ## # int139n &lt;dbl+lbl&gt;, int140n &lt;dbl+lbl&gt;, int141n &lt;dbl+lbl&gt;, v401 &lt;dbl+lbl&gt;, var1343 &lt;dbl+lbl&gt;, ## # var648 &lt;dbl+lbl&gt;, var149 &lt;dbl+lbl&gt;, var058 &lt;dbl+lbl&gt;, var059 &lt;dbl+lbl&gt;, var064 &lt;dbl+lbl&gt;, ## # var365 &lt;dbl+lbl&gt;, var065 &lt;dbl+lbl&gt;, var092 &lt;dbl+lbl&gt;, var096 &lt;dbl+lbl&gt;, int054 &lt;dbl+lbl&gt;, ## # int055 &lt;dbl+lbl&gt;, int056 &lt;dbl+lbl&gt;, int057 &lt;dbl+lbl&gt;, int058 &lt;dbl+lbl&gt;, int059 &lt;dbl+lbl&gt;, ## # int059a &lt;dbl+lbl&gt;, var571 &lt;dbl+lbl&gt;, var572 &lt;dbl+lbl&gt;, var573 &lt;dbl+lbl&gt;, var574 &lt;dbl+lbl&gt;, ## # var576 &lt;dbl+lbl&gt;, var153 &lt;dbl+lbl&gt;, var154 &lt;dbl+lbl&gt;, var155 &lt;dbl+lbl&gt;, var156 &lt;dbl+lbl&gt;, ## # var157 &lt;dbl+lbl&gt;, var157a &lt;dbl+lbl&gt;, var154a &lt;dbl+lbl&gt;, var164 &lt;dbl+lbl&gt;, var165 &lt;dbl+lbl&gt;, ## # var166 &lt;dbl+lbl&gt;, var179 &lt;dbl+lbl&gt;, var180 &lt;dbl+lbl&gt;, var184 &lt;dbl+lbl&gt;, var185 &lt;dbl+lbl&gt;, ## # var198a &lt;dbl+lbl&gt;, var198 &lt;dbl+lbl&gt;, var201a &lt;dbl+lbl&gt;, var201b &lt;dbl+lbl&gt;, var204 &lt;dbl+lbl&gt;, ## # int257 &lt;dbl+lbl&gt;, var211 &lt;dbl+lbl&gt;, var223 &lt;dbl+lbl&gt;, var1320 &lt;dbl+lbl&gt;, var1321 &lt;dbl+lbl&gt;, ## # var1322 &lt;dbl+lbl&gt;, var1323 &lt;dbl+lbl&gt;, var1324 &lt;dbl+lbl&gt;, var1325 &lt;dbl+lbl&gt;, var1326 &lt;dbl+lbl&gt;, ## # var1327 &lt;dbl+lbl&gt;, var1328 &lt;dbl+lbl&gt;, var229 &lt;dbl+lbl&gt;, int218 &lt;dbl+lbl&gt;, int219 &lt;dbl+lbl&gt;, ## # int221 &lt;dbl+lbl&gt;, int222 &lt;dbl+lbl&gt;, int223 &lt;dbl+lbl&gt;, int710 &lt;dbl+lbl&gt;, int711 &lt;dbl+lbl&gt;, ## # int712 &lt;dbl+lbl&gt;, int713 &lt;dbl+lbl&gt;, int714 &lt;dbl+lbl&gt;, int715 &lt;dbl+lbl&gt;, int716 &lt;dbl+lbl&gt;, ## # var433 &lt;dbl+lbl&gt;, var439 &lt;dbl+lbl&gt;, var1329 &lt;dbl+lbl&gt;, var1330 &lt;dbl+lbl&gt;, var445 &lt;dbl+lbl&gt;, ## # var446 &lt;dbl+lbl&gt;, var447 &lt;dbl+lbl&gt;, var451 &lt;dbl+lbl&gt;, var452 &lt;dbl+lbl&gt;, var1316 &lt;dbl+lbl&gt;, ## # var1317 &lt;dbl+lbl&gt;, var1331 &lt;dbl+lbl&gt;, vw065 &lt;dbl+lbl&gt;, var491 &lt;dbl+lbl&gt;, var040 &lt;dbl+lbl&gt;, ## # var1304 &lt;dbl+lbl&gt;, var274 &lt;dbl+lbl&gt;, var275 &lt;dbl+lbl&gt;, var1196 &lt;dbl+lbl&gt;, var1197 &lt;dbl+lbl&gt;, ## # var461 &lt;dbl+lbl&gt;, var273 &lt;dbl+lbl&gt;, var1262 &lt;dbl+lbl&gt;, ... #fix(cv08_haven) #will produce an error fix(cv08) View(cv08_haven) Add to your cheat sheet under functions: str(), summary(), attributes(), attr(), table(), names(), head(), fix(), View() A.7 Define missings Okay, lets start playing around with our dataset. We are going to have a look at specific variables, define missings, recode some values, etc. I will focus on the dataset created by the haven package. A.7.1 R Base Lets use age as example. This variable is called lftop in CV. First have a look at this variable. str(cv08_haven$lftop) summary(cv08_haven$lftop) attr(cv08_haven$lftop, &quot;labels&quot;) table(cv08_haven$lftop, useNA=&quot;always&quot;) ## dbl+lbl [1:1963] 51, 39, 16, 29, 57, 49, 62, 34, 59, 41, 25, 43, 74, 17, 22, 32, 51, 66, 64, 2... ## @ label : chr &quot;Leeftijd OP op datum interview&quot; ## @ format.spss : chr &quot;F10.0&quot; ## @ display_width: int 12 ## @ labels : Named num [1:5] 0 1 2 99 125 ## ..- attr(*, &quot;names&quot;)= chr [1:5] &quot;&lt; één jaar&quot; &quot;één jaar&quot; &quot;twee jaar&quot; &quot;Onbekend&quot; ... ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 16.00 33.00 46.00 46.78 61.00 99.00 ## &lt; één jaar één jaar twee jaar Onbekend 125 jaar ## 0 1 2 99 125 ## ## 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 ## 40 37 39 30 30 25 25 38 26 22 18 23 29 30 22 28 23 23 24 38 ## 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 ## 35 37 34 48 45 34 36 39 43 38 41 32 41 45 29 29 43 32 25 27 ## 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 ## 27 30 44 34 33 36 40 29 27 30 19 24 24 24 23 21 13 15 26 10 ## 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 99 &lt;NA&gt; ## 14 17 13 13 10 7 10 10 7 6 3 8 2 3 1 3 4 0 We have category onbekend, which should be a missing. Lets copy the original variable in a new one, and attach it to the dataset. Thus not: lftop_new &lt;- cv08$lftop but: cv08$lftop_new &lt;- cv08$lftop You probably already noticed that to assign values to a new object we use &lt;- What we now want to do is to replace those values of our new variable cv08$lftop_new which have the values Onbekend. cv08$lftop_new[cv08$lftop_new==&quot;Onbekend&quot;] &lt;- NA Dont forget, if you want to understand the code work inside out. Update your cheat sheet! Note that == is a logical operator. What are the other logical operators in R? Note that [] is used to subset elements from an object (e.g. dataframe/vector/matrix) Note that NA is used in R to define missing values. It means Not Applicable. So did our recode work? table(cv08$lftop_new, useNA=&quot;always&quot;) ## ## &lt; één jaar één jaar 125 jaar 16 17 18 19 twee jaar 20 ## 0 0 0 40 37 39 30 0 30 ## 21 22 23 24 25 26 27 28 29 ## 25 25 38 26 22 18 23 29 30 ## 30 31 32 33 34 35 36 37 38 ## 22 28 23 23 24 38 35 37 34 ## 39 40 41 42 43 44 45 46 47 ## 48 45 34 36 39 43 38 41 32 ## 48 49 50 51 52 53 54 55 56 ## 41 45 29 29 43 32 25 27 27 ## 57 58 59 60 61 62 63 64 65 ## 30 44 34 33 36 40 29 27 30 ## 66 67 68 69 70 71 72 73 74 ## 19 24 24 24 23 21 13 15 26 ## 75 76 77 78 79 80 81 82 83 ## 10 14 17 13 13 10 7 10 10 ## 84 85 86 87 88 89 90 91 Onbekend ## 7 6 3 8 2 3 1 3 0 ## &lt;NA&gt; ## 4 levels(cv08$lftop_new) ## [1] &quot;&lt; één jaar&quot; &quot;één jaar&quot; &quot;125 jaar&quot; &quot;16&quot; &quot;17&quot; &quot;18&quot; &quot;19&quot; ## [8] &quot;twee jaar&quot; &quot;20&quot; &quot;21&quot; &quot;22&quot; &quot;23&quot; &quot;24&quot; &quot;25&quot; ## [15] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; &quot;30&quot; &quot;31&quot; &quot;32&quot; ## [22] &quot;33&quot; &quot;34&quot; &quot;35&quot; &quot;36&quot; &quot;37&quot; &quot;38&quot; &quot;39&quot; ## [29] &quot;40&quot; &quot;41&quot; &quot;42&quot; &quot;43&quot; &quot;44&quot; &quot;45&quot; &quot;46&quot; ## [36] &quot;47&quot; &quot;48&quot; &quot;49&quot; &quot;50&quot; &quot;51&quot; &quot;52&quot; &quot;53&quot; ## [43] &quot;54&quot; &quot;55&quot; &quot;56&quot; &quot;57&quot; &quot;58&quot; &quot;59&quot; &quot;60&quot; ## [50] &quot;61&quot; &quot;62&quot; &quot;63&quot; &quot;64&quot; &quot;65&quot; &quot;66&quot; &quot;67&quot; ## [57] &quot;68&quot; &quot;69&quot; &quot;70&quot; &quot;71&quot; &quot;72&quot; &quot;73&quot; &quot;74&quot; ## [64] &quot;75&quot; &quot;76&quot; &quot;77&quot; &quot;78&quot; &quot;79&quot; &quot;80&quot; &quot;81&quot; ## [71] &quot;82&quot; &quot;83&quot; &quot;84&quot; &quot;85&quot; &quot;86&quot; &quot;87&quot; &quot;88&quot; ## [78] &quot;89&quot; &quot;90&quot; &quot;91&quot; &quot;Onbekend&quot; But we want age as numeric variable not as a factor (categorical). str(cv08$lftop_new) ## Factor w/ 81 levels &quot;&lt; één jaar&quot;,&quot;één jaar&quot;,..: 40 28 4 18 46 38 51 23 48 30 ... cv08$agen &lt;- as.numeric(as.character(cv08$lftop_new)) #how clumsy. we first convert the factor to a string and then to a numeric variable. table(cv08$agen, useNA=&quot;always&quot;) ## ## 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 ## 40 37 39 30 30 25 25 38 26 22 18 23 29 30 22 28 23 23 24 38 ## 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 ## 35 37 34 48 45 34 36 39 43 38 41 32 41 45 29 29 43 32 25 27 ## 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 ## 27 30 44 34 33 36 40 29 27 30 19 24 24 24 23 21 13 15 26 10 ## 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 &lt;NA&gt; ## 14 17 13 13 10 7 10 10 7 6 3 8 2 3 1 3 4 str(cv08$agen) ## num [1:1963] 51 39 16 29 57 49 62 34 59 41 ... Hint: R is case sensitive. Just try to avoid capitals in your variable names. There are people who have set up a whole list of rules how to name and label stuff. Interesting? You can have a look here. I will use all_lower_case_underscore_seperated. Add to your cheat sheet as.character() and as.numeric(). A.7.2 Tidy Copy the variable We will mutate the original dataset by adding a variable. cv08_haven &lt;- mutate(cv08_haven, lftop_new=lftop) Replace missings Be aware that the value 99 is the onbekend category. cv08_haven$lftop_new &lt;- na_if(cv08_haven$lftop_new, 99) Normally you would combine these two steps into one cv08_haven &lt;- mutate(cv08_haven, lftop_new=na_if(lftop, 99)) check table(cv08_haven$lftop_new, useNA=&quot;always&quot;) ## ## 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 ## 40 37 39 30 30 25 25 38 26 22 18 23 29 30 22 28 23 23 24 38 ## 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 ## 35 37 34 48 45 34 36 39 43 38 41 32 41 45 29 29 43 32 25 27 ## 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 ## 27 30 44 34 33 36 40 29 27 30 19 24 24 24 23 21 13 15 26 10 ## 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 &lt;NA&gt; ## 14 17 13 13 10 7 10 10 7 6 3 8 2 3 1 3 4 An advantage of the tidy way is that it is more intuitive and requires less subsetting. A disadvantage is that you need to know more specific functions. Hint: In your cheat sheet, make a distinction between all the stuff that belongs to R Base and all specific functions, operators, etc. that are part of Tidyverse. How do you know it is part of Tidyverse? Well, if you dont load tidyverse, the code will not work. A.8 Recoding variables So, we defined a missing value for age. As a second example let us recode the variable education. This one is called var006n in CV08. Lets create a new variable educ3 with three levels: 1. primary 2. secondary 3. tertiary A.8.1 R Base levels(cv08$var006n) ## [1] &quot;onbekend&quot; &quot;OP &lt; 12 jr of volgt actueel bas.ondw.&quot; ## [3] &quot;basisonderwijs&quot; &quot;vmbo&quot; ## [5] &quot;mavo&quot; &quot;havo/vwo&quot; ## [7] &quot;mbo&quot; &quot;hbo&quot; ## [9] &quot;wo&quot; &quot;wo_duplicated_8&quot; ## [11] &quot;Onbekend&quot; table(cv08$var006n, useNA=&quot;always&quot;) ## ## onbekend OP &lt; 12 jr of volgt actueel bas.ondw. ## 5 0 ## basisonderwijs vmbo ## 380 287 ## mavo havo/vwo ## 137 106 ## mbo hbo ## 543 339 ## wo wo_duplicated_8 ## 0 166 ## Onbekend &lt;NA&gt; ## 0 0 #lets make it a numeric var first cv08$educn &lt;- as.numeric(cv08$var006n) #check table(cv08$educn, useNA=&quot;always&quot;) ## ## 1 3 4 5 6 7 8 10 &lt;NA&gt; ## 5 380 287 137 106 543 339 166 0 #start with an empty variable cv08$educ3 &lt;- NA #fill category by category cv08$educ3[cv08$educn==2 | cv08$educn==3] &lt;- 1 cv08$educ3[cv08$educn&gt;3 &amp; cv08$educn&lt;8] &lt;- 2 cv08$educ3[cv08$educn&gt;7 &amp; cv08$educn&lt;11] &lt;- 3 #check table(cv08$educ3, useNA=&quot;always&quot;) ## ## 1 2 3 &lt;NA&gt; ## 380 1073 505 5 prop.table(table(cv08$educ3, useNA=&quot;always&quot;)) ## ## 1 2 3 &lt;NA&gt; ## 0.193581253 0.546612328 0.257259297 0.002547122 #now educ3 is a numeric variable, we want it as factor cv08$educ3 &lt;- as.factor(cv08$educ3) table(cv08$educ3, useNA=&quot;always&quot;) ## ## 1 2 3 &lt;NA&gt; ## 380 1073 505 5 levels(cv08$educ3) &lt;- c(&quot;primary&quot;, &quot;secondary&quot;, &quot;tertiary&quot;) table(cv08$educ3, useNA=&quot;always&quot;) ## ## primary secondary tertiary &lt;NA&gt; ## 380 1073 505 5 Is this really the first time we encountered the function c()? Well, make sure it is somewhere at the top of your cheat sheet. A.8.2 Tidy And now the fun starts. Tidyverse includes a dplyr::recode function, but this function does not work on labeled variables imported via the haven package. Luckily, there is a package that extends the original function, labelled. #install.packages(&quot;labelled&quot;) require(labelled) #to be able to use the recode function on haven labelled variables ## Loading required package: labelled ## Warning: package &#39;labelled&#39; was built under R version 4.0.5 #inspect variable str(cv08_haven$var006n) ## dbl+lbl [1:1963] 6, 8, 3, 8, 6, 2, 2, 5, 5, 1, 1, 3, 2, 1, 1, 5, 6, 3, 1, 5, 6, 2, 5, 6, 1, 3,... ## @ label : chr &quot;Voltooid opleidingsniveau (uitgebreid) OP, 12-14 jarigen niet standaard op bas.ondw.&quot; ## @ format.spss : chr &quot;F10.0&quot; ## @ display_width: int 12 ## @ labels : Named num [1:11] -3 -1 1 2 3 4 5 6 7 8 ... ## ..- attr(*, &quot;names&quot;)= chr [1:11] &quot;onbekend&quot; &quot;OP &lt; 12 jr of volgt actueel bas.ondw.&quot; &quot;basisonderwijs&quot; &quot;vmbo&quot; ... attr(cv08_haven$var006n, &quot;labels&quot;) ## onbekend OP &lt; 12 jr of volgt actueel bas.ondw. ## -3e+00 -1e+00 ## basisonderwijs vmbo ## 1e+00 2e+00 ## mavo havo/vwo ## 3e+00 4e+00 ## mbo hbo ## 5e+00 6e+00 ## wo wo ## 7e+00 8e+00 ## Onbekend ## 1e+10 table(cv08_haven$var006n, useNA=&quot;always&quot;) ## ## -3 1 2 3 4 5 6 8 &lt;NA&gt; ## 5 380 287 137 106 543 339 166 0 #recode values, all missings as one value cv08_haven &lt;- mutate(cv08_haven, educ3=recode(var006n, &#39;-3&#39;=-9, &#39;-1&#39;=1, &#39;1&#39;=1, &#39;2&#39;= 2 , &#39;3&#39;= 2, &#39;4&#39;= 2, &#39;5&#39;= 2, &#39;6&#39;= 3, &#39;7&#39;= 3, &#39;8&#39;= 3, &#39;10&#39;= -9), .keep_value_labels = FALSE) #replace missing values with NA. cv08_haven &lt;- mutate(cv08_haven, educ3=na_if(educ3, -9)) #make educ3 a factor cv08_haven &lt;- mutate(cv08_haven, educ3=factor(educ3, levels = c(1,2,3), labels = c(&quot;primary&quot;, &quot;secondary&quot;, &quot;tertiary&quot;))) #check table(cv08_haven$educ3, useNA=&quot;always&quot;) ## ## primary secondary tertiary &lt;NA&gt; ## 380 1073 505 5 Personally, I think this is all quite complicated. But I guess this is a matter of taste. And advantage of the Tidy way is that you could use the %&gt;%, piping, operator. Now, your code does not read from the inside out but from left to right. For many people this is more intuitive. The output of the function on the left is transported to the (first argument of the) function on the right. Thus, in the example below, you see that in the second and third call to mutate I dont have to tell the function which dataset I am using. cv08_haven &lt;- mutate(cv08_haven, educ3=recode(var006n, &#39;-3&#39;=-9, &#39;-1&#39;=1, &#39;1&#39;=1, &#39;2&#39;= 2 , &#39;3&#39;= 2, &#39;4&#39;= 2, &#39;5&#39;= 2, &#39;6&#39;= 3, &#39;7&#39;= 3, &#39;8&#39;= 3, &#39;10&#39;= -9), .keep_value_labels = FALSE) %&gt;% mutate(educ3=na_if(educ3, -9)) %&gt;% mutate(educ3=factor(educ3, levels = c(1,2,3), labels = c(&quot;primary&quot;, &quot;secondary&quot;, &quot;tertiary&quot;))) Perhaps an even tidier way would be: cv08_haven &lt;- cv08_haven %&gt;% mutate(educ3=recode(var006n, &#39;-3&#39;=-9, &#39;-1&#39;=1, &#39;1&#39;=1, &#39;2&#39;= 2 , &#39;3&#39;= 2, &#39;4&#39;= 2, &#39;5&#39;= 2, &#39;6&#39;= 3, &#39;7&#39;= 3, &#39;8&#39;= 3, &#39;10&#39;= -9), .keep_value_labels = FALSE) %&gt;% mutate(educ3=na_if(educ3, -9)) %&gt;% mutate(educ3=factor(educ3, levels = c(1,2,3), labels = c(&quot;primary&quot;, &quot;secondary&quot;, &quot;tertiary&quot;))) In the example above, it still may feel a little clumsy to have to make a call to the same mutate function three times. Well, this is indeed not necessary. Thus, the most tidy way is: cv08_haven &lt;- cv08_haven %&gt;% mutate(educ3=recode(var006n, &#39;-3&#39;=-9, &#39;-1&#39;=1, &#39;1&#39;=1, &#39;2&#39;= 2 , &#39;3&#39;= 2, &#39;4&#39;= 2, &#39;5&#39;= 2, &#39;6&#39;= 3, &#39;7&#39;= 3, &#39;8&#39;= 3, &#39;10&#39;= -9, .keep_value_labels = FALSE), educ3=na_if(educ3, -9), educ3=factor(educ3, levels = c(1,2,3), labels = c(&quot;primary&quot;, &quot;secondary&quot;, &quot;tertiary&quot;))) A.9 Means and counting specific values A.9.1 R Base Next step. Lets calculate a mean. We will use three questions in CV on polarization. This does not make any theoretical sense of course. #Step 1: have a look at the vars summary(cv08$int055) ## Geen opgave N.v.t. Weet niet ## 0 0 85 ## Weigert Zeer groot Groot ## 0 57 551 ## Niet zo groot Helemaal geen tegenstelling ## 1213 57 summary(cv08$int056) ## Geen opgave N.v.t. Weet niet ## 0 0 118 ## Weigert Zeer groot Groot ## 0 258 987 ## Niet zo groot Helemaal geen tegenstelling ## 571 29 summary(cv08$int057) ## Geen opgave N.v.t. Weet niet ## 0 0 145 ## Weigert Zeer groot Groot ## 0 213 803 ## Niet zo groot Helemaal geen tegenstelling ## 756 46 #Step 2: make numeric cv08$int055n &lt;- as.numeric(cv08$int055) table(cv08$int055n, useNA=&quot;always&quot;) ## ## 3 5 6 7 8 &lt;NA&gt; ## 85 57 551 1213 57 0 cv08$int056n &lt;- as.numeric(cv08$int056) table(cv08$int056n, useNA=&quot;always&quot;) ## ## 3 5 6 7 8 &lt;NA&gt; ## 118 258 987 571 29 0 cv08$int057n &lt;- as.numeric(cv08$int057) table(cv08$int057n, useNA=&quot;always&quot;) ## ## 3 5 6 7 8 &lt;NA&gt; ## 145 213 803 756 46 0 #Step 3: define missings and recode cv08$int055n[cv08$int055n&lt;5] &lt;- NA cv08$int055n &lt;- cv08$int055n - 4 cv08$int056n[cv08$int056n&lt;5] &lt;- NA cv08$int056n &lt;- cv08$int056n - 4 cv08$int057n[cv08$int057n&lt;5] &lt;- NA cv08$int057n &lt;- cv08$int057n - 4 #Step 4: calculate means. #How does the function mean work in R? mean(cv08$int055n) ## [1] NA mean(cv08$int055n, na.rm=TRUE) ## [1] 2.676251 mean(c(cv08$int055n, cv08$int056n, cv08$int057n), na.rm = T) ## [1] 2.410756 This is not what we want. What we want is to calculate a mean for each row/respondent. This will do the trick: testmeans &lt;- rowMeans(cbind(cv08$int055n, cv08$int056n, cv08$int057n), na.rm = T) head(testmeans) ## [1] 2.333333 2.666667 2.666667 2.333333 1.500000 1.333333 What we really want is a mean but only if there is a maximum of 1 NA in the three variables. #lets first count how many missings we have for each respondent nmis &lt;- rowSums(is.na(cbind(cv08$int055n, cv08$int056n, cv08$int057n))) # ?is.na # ?rowSums testmeans &lt;- ifelse(nmis&lt;2,testmeans, NA) #add the calculated means to our dataset cv08$int_mean &lt;- testmeans #Bonus: count specific values #so now we have this, it is easy to find how many times respondents answered &#39;zeer groot&#39;, that is &#39;1&#39; timesZG &lt;- rowSums(cbind(cv08$int055n, cv08$int056n, cv08$int057n)==1, na.rm=T) You need to add a lot of very powerful functions to your cheat sheet: mean(), rowMeans(), rowSums, cbind(), is.na(), ifelse(). Did you also notice that the logicals FALSE and TRUE can be summed? (FALSE equals 0 and TRUE equals 1). A.9.2 Tidy #Step 1: have a look at the vars str(cv08_haven$int055) ## dbl+lbl [1:1963] 3, 3, 3, 2, -3, 1, 2, 3, 3, 2, 2, 3, 3, 3, 3, 2, 3, 2, 3, ... ## @ label : chr &quot;Tegenstelling arbeidersklasse en middenklasse&quot; ## @ format.spss : chr &quot;F10.0&quot; ## @ display_width: int 12 ## @ labels : Named num [1:8] -6 -5 -3 -2 1 2 3 4 ## ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Geen opgave&quot; &quot;N.v.t.&quot; &quot;Weet niet&quot; &quot;Weigert&quot; ... attr(cv08_haven$int055, &quot;labels&quot;) ## Geen opgave N.v.t. Weet niet ## -6 -5 -3 ## Weigert Zeer groot Groot ## -2 1 2 ## Niet zo groot Helemaal geen tegenstelling ## 3 4 summary(cv08_haven$int055) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -3.00 2.00 3.00 2.43 3.00 4.00 summary(cv08_haven$int056) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -3.000 2.000 2.000 1.888 3.000 4.000 summary(cv08_haven$int057) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -3.000 2.000 2.000 1.954 3.000 4.000 table(cv08_haven$int055n, useNA=&quot;always&quot;) ## Warning: Unknown or uninitialised column: `int055n`. ## ## &lt;NA&gt; ## 0 table(cv08_haven$int056, useNA=&quot;always&quot;) ## ## -3 1 2 3 4 &lt;NA&gt; ## 118 258 987 571 29 0 table(cv08_haven$int057, useNA=&quot;always&quot;) ## ## -3 1 2 3 4 &lt;NA&gt; ## 145 213 803 756 46 0 #Step 2: define missings and recode cv08_haven &lt;- mutate(cv08_haven, int055n=recode(int055, &#39;-6&#39;=-9, &#39;-5&#39;=-9,&#39;-3&#39;=-9,&#39;-2&#39;=-9, &#39;1&#39;=4, &#39;2&#39;= 3 , &#39;3&#39;= 2, &#39;4&#39;= 1), .keep_value_labels = FALSE) %&gt;% mutate(int055n=na_if(int055n, -9)) %&gt;% mutate(int055n=labelled(int055n, c(&quot;Helemaal geen tegenstelling&quot; = 1, &quot;Niet zo groot&quot; = 2, &quot;Groot&quot;=3, &quot;Zeer groot&quot;=4))) cv08_haven &lt;- mutate(cv08_haven, int056n=recode(int056, &#39;-6&#39;=-9, &#39;-5&#39;=-9,&#39;-3&#39;=-9,&#39;-2&#39;=-9, &#39;1&#39;=4, &#39;2&#39;= 3 , &#39;3&#39;= 2, &#39;4&#39;= 1), .keep_value_labels = FALSE) %&gt;% mutate(int056n=na_if(int056n, -9)) %&gt;% mutate(int056n=labelled(int056n, c(&quot;Helemaal geen tegenstelling&quot; = 1, &quot;Niet zo groot&quot; = 2, &quot;Groot&quot;=3, &quot;Zeer groot&quot;=4))) cv08_haven &lt;- mutate(cv08_haven, int057n=recode(int057, &#39;-6&#39;=-9, &#39;-5&#39;=-9,&#39;-3&#39;=-9,&#39;-2&#39;=-9, &#39;1&#39;=4, &#39;2&#39;= 3 , &#39;3&#39;= 2, &#39;4&#39;= 1), .keep_value_labels = FALSE) %&gt;% mutate(int057n=na_if(int057n, -9)) %&gt;% mutate(int057n=labelled(int057n, c(&quot;Helemaal geen tegenstelling&quot; = 1, &quot;Niet zo groot&quot; = 2, &quot;Groot&quot;=3, &quot;Zeer groot&quot;=4))) #Step 3: calculate means. ## option 1 cv08_haven &lt;- cv08_haven %&gt;% rowwise() %&gt;% mutate(int_mean = mean(c(int055n, int056n, int057n), na.rm=TRUE)) ## option 2 cv08_haven &lt;- cv08_haven %&gt;% mutate(int_mean = rowMeans(cbind(int055n, int056n, int057n), na.rm=TRUE)) #what we really want is a mean but only if there is a maximum of 1 NA in the three variables cv08_haven &lt;- cv08_haven %&gt;% mutate(int_mean_temp = rowMeans(cbind(int055n, int056n, int057n), na.rm=TRUE), nmis = rowSums(is.na(cbind(int055n, int056n, int057n))), int_mean = ifelse(nmis&lt;2, int_mean_temp, NA)) %&gt;% select(-int_mean_temp, -nmis) So what are you adding to your cheat sheet? rowwise(), select(). A.10 Merging data files What you need to know 1: Panel or stacked cross-sections? What you need to know 2: If panel, do you want data in long or wide format? We need to follow these steps: Step1: select variables Step2: make consistent Step3: perform the actual merging. Make sure to include necessary identifier variables. Step4: check your results!! A.10.1 R Base A.10.1.1 Step1: select variables #step 1: selecting the variables you want to keep. #for this tutorial only 6 variables: id, age, sex, educ, health, region (not that R is case sensitive) cv08_sel &lt;- cv08[,c(&quot;we_id&quot;, &quot;lftop&quot;, &quot;geslacht&quot;, &quot;var006n&quot;, &quot;v401&quot;, &quot;landd&quot;)] cv10_sel &lt;- cv10[,c(&quot;Sleutel&quot;, &quot;var002&quot;, &quot;var001&quot;, &quot;Vltoplop&quot;, &quot;V401&quot;, &quot;Landd&quot;)] Note that to select rows, you need to set an expression before the , [row,] and to select columns, after the , [,col]. Thus with dataset[i,j] you will select row i and column j. You have learned to subset dataframes by using indici (e.g. dataset[,1:3]), logical expressions (e.g. dataset[var1&gt;1,]), and names (e.g. dataset[,\"varname\"]). A.10.1.2 Step2: make consistent #step 2: making the variables similar across individual datasets #step 2a: making names the same names(cv08_sel) &lt;- names(cv10_sel) &lt;- c(&quot;id&quot;, &quot;age&quot;, &quot;sex&quot;, &quot;educ&quot;, &quot;health&quot;, &quot;region&quot;) #step 2b: making levels and labels consistent summary(cv08_sel) summary(cv10_sel) #they look very consistent already. but check carefully. #we don&#39;t want id to be a factor but numeric. Note that we don&#39;t want the factor level values as numbers but the actual labels as numbers. #id cv08_sel$id &lt;- as.numeric(as.character(cv08_sel$id)) cv10_sel$id &lt;- as.numeric(as.character(cv10_sel$id)) #age cv08_sel$age &lt;- as.numeric(as.character(cv08_sel$age)) ## Warning: NAs introduced by coercion cv10_sel$age &lt;- as.numeric(as.character(cv10_sel$age)) #sex men levels(cv08_sel$sex) levels(cv10_sel$sex) table(cv08_sel$sex, useNA=&quot;always&quot;) table(cv10_sel$sex, useNA=&quot;always&quot;) #lets make it a numeric var first cv08_sel$sexn &lt;- as.numeric(cv08_sel$sex) table(cv08_sel$sexn) #recode into dummy cv08_sel$men &lt;- ifelse(cv08_sel$sexn==2, 1, 0) cv08_sel$men &lt;- ifelse(cv08_sel$sexn==1, NA, cv08_sel$men) #check table(cv08_sel$men, useNA=&quot;always&quot;) #lets make it a numeric var first cv10_sel$sexn &lt;- as.numeric(cv10_sel$sex) table(cv10_sel$sexn) #recode into dummy cv10_sel$men &lt;- ifelse(cv10_sel$sexn==2, 1, 0) #check table(cv10_sel$men, useNA=&quot;always&quot;) #educ educ3 levels(cv08_sel$educ) levels(cv10_sel$educ) table(cv08_sel$educ, useNA=&quot;always&quot;) table(cv10_sel$educ, useNA=&quot;always&quot;) #lets make it a numeric var first cv08_sel$educn &lt;- as.numeric(cv08_sel$educ) table(cv08_sel$educn) #recode into 3cats: 1 primair, 2 secundair, 3 is tertiair cv08_sel$educ3 &lt;- NA cv08_sel$educ3[cv08_sel$educn==2 | cv08_sel$educn==3] &lt;- 1 cv08_sel$educ3[cv08_sel$educn&gt;3 &amp; cv08_sel$educn&lt;8] &lt;- 2 cv08_sel$educ3[cv08_sel$educn&gt;7 &amp; cv08_sel$educn&lt;11] &lt;- 3 #check table(cv08_sel$educ3, useNA=&quot;always&quot;) prop.table(table(cv08_sel$educ3, useNA=&quot;always&quot;)) #lets make it a numeric var first cv10_sel$educn &lt;- as.numeric(cv10_sel$educ) table(cv10_sel$educn) #recode into 3cats: 1 primair, 2 secundari, 3 is tertiair cv10_sel$educ3 &lt;- NA cv10_sel$educ3[cv10_sel$educn&lt;3] &lt;- 1 #correct? cv10_sel$educ3[cv10_sel$educn&gt;2 &amp; cv10_sel$educn&lt;6] &lt;- 2 cv10_sel$educ3[cv10_sel$educn==6] &lt;- 3 #check table(cv10_sel$educ3, useNA=&quot;always&quot;) prop.table(table(cv10_sel$educ3, useNA=&quot;always&quot;)) A.10.1.3 Step3: merge #lets add a wave variable cv08_sel$wave &lt;- 2008 cv10_sel$wave &lt;- 2010 #let make a fake ID, we will use this later when we pretend CV is panel data. cv08_sel$id2 &lt;- rank(cv08_sel$id) cv10_sel$id2 &lt;- rank(cv10_sel$id) #simply place one dataset under the other thus row bind (rbind) #check first if same vars in both datasets. #perhaps clean up first. cv08_sel &lt;- cv08_sel[,c(&quot;id&quot;,&quot;id2&quot;, &quot;age&quot;, &quot;men&quot;, &quot;educ3&quot;, &quot;health&quot;, &quot;region&quot;, &quot;wave&quot;)] cv10_sel &lt;- cv10_sel[,c(&quot;id&quot;, &quot;id2&quot;, &quot;age&quot;, &quot;men&quot;, &quot;educ3&quot;, &quot;health&quot;, &quot;region&quot;, &quot;wave&quot;)] summary(cv08_sel) ## id id2 age men educ3 ## Min. :36775330 Min. : 1.0 Min. :16.00 Min. :0.00 Min. :1.000 ## 1st Qu.:37604540 1st Qu.: 491.5 1st Qu.:33.00 1st Qu.:0.00 1st Qu.:2.000 ## Median :38724230 Median : 982.0 Median :46.00 Median :1.00 Median :2.000 ## Mean :38830177 Mean : 982.0 Mean :46.67 Mean :0.51 Mean :2.064 ## 3rd Qu.:40598965 3rd Qu.:1472.5 3rd Qu.:60.00 3rd Qu.:1.00 3rd Qu.:3.000 ## Max. :41199300 Max. :1963.0 Max. :91.00 Max. :1.00 Max. :3.000 ## NA&#39;s :4 NA&#39;s :10 NA&#39;s :5 ## health region wave ## goed, :1060 Postcode (nog) onbekend: 0 Min. :2008 ## zeer goed, : 504 Noord-Nederland :220 1st Qu.:2008 ## gaat wel, : 320 Oost-Nederland :416 Median :2008 ## slecht, : 67 West-Nederland :853 Mean :2008 ## of zeer slecht?: 12 Zuid-Nederland :474 3rd Qu.:2008 ## Geen opgave : 0 Max. :2008 ## (Other) : 0 summary(cv10_sel) ## id id2 age men educ3 ## Min. :20131231 Min. : 1.0 Min. :16.00 Min. :0.000 Min. :1.000 ## 1st Qu.:20131965 1st Qu.: 734.8 1st Qu.:34.00 1st Qu.:0.000 1st Qu.:2.000 ## Median :20132698 Median :1468.5 Median :48.00 Median :0.000 Median :2.000 ## Mean :20132698 Mean :1468.5 Mean :48.27 Mean :0.485 Mean :2.106 ## 3rd Qu.:20133432 3rd Qu.:2202.2 3rd Qu.:63.00 3rd Qu.:1.000 3rd Qu.:3.000 ## Max. :20134166 Max. :2936.0 Max. :96.00 Max. :1.000 Max. :3.000 ## NA&#39;s :3 ## health region wave ## goed, :1592 Noord-Nederland: 306 Min. :2010 ## zeer goed, : 776 Oost-Nederland : 678 1st Qu.:2010 ## gaat wel, : 466 West-Nederland :1263 Median :2010 ## slecht, : 79 Zuid-Nederland : 689 Mean :2010 ## of zeer slecht?: 22 3rd Qu.:2010 ## Weigert : 1 Max. :2010 ## (Other) : 0 cv_tot &lt;- rbind(cv08_sel, cv10_sel) A.10.1.4 Step4: check summary(cv_tot) ## id id2 age men educ3 ## Min. :20131231 Min. : 1 Min. :16.00 Min. :0.000 Min. :1.000 ## 1st Qu.:20132456 1st Qu.: 613 1st Qu.:33.00 1st Qu.:0.000 1st Qu.:2.000 ## Median :20133680 Median :1225 Median :47.00 Median :0.000 Median :2.000 ## Mean :27624666 Mean :1274 Mean :47.63 Mean :0.495 Mean :2.089 ## 3rd Qu.:37978375 3rd Qu.:1838 3rd Qu.:62.00 3rd Qu.:1.000 3rd Qu.:3.000 ## Max. :41199300 Max. :2936 Max. :96.00 Max. :1.000 Max. :3.000 ## NA&#39;s :4 NA&#39;s :10 NA&#39;s :8 ## health region wave ## goed, :2652 Postcode (nog) onbekend: 0 Min. :2008 ## zeer goed, :1280 Noord-Nederland : 526 1st Qu.:2008 ## gaat wel, : 786 Oost-Nederland :1094 Median :2010 ## slecht, : 146 West-Nederland :2116 Mean :2009 ## of zeer slecht?: 34 Zuid-Nederland :1163 3rd Qu.:2010 ## Weigert : 1 Max. :2010 ## (Other) : 0 head(cv_tot) ## id id2 age men educ3 health region wave ## 1 36775330 1 51 1 3 goed, West-Nederland 2008 ## 2 36775340 2 39 0 3 goed, West-Nederland 2008 ## 3 36775420 3 16 0 2 goed, West-Nederland 2008 ## 4 36775440 4 29 1 3 goed, West-Nederland 2008 ## 5 36775450 5 57 1 3 gaat wel, West-Nederland 2008 ## 6 36775460 6 49 0 2 goed, West-Nederland 2008 Okay, lets pretend it was panel data. cv_tot would then be a panel dataset in long format. But oftentimes, you want a panel dataset in wide format. If you dont know the difference between long and wide format, check the differences between cv_tot and cv_tot_panel after step3b. A.10.1.5 Step3b: merge #lets make a panel dataset in wide format cv_tot_panel &lt;- merge(cv08_sel, cv10_sel, all=TRUE, by=&quot;id2&quot;) head(cv_tot_panel) ## id2 id.x age.x men.x educ3.x health.x region.x wave.x id.y age.y men.y educ3.y ## 1 1 36775330 51 1 3 goed, West-Nederland 2008 20131231 20 0 2 ## 2 2 36775340 39 0 3 goed, West-Nederland 2008 20131232 29 0 3 ## 3 3 36775420 16 0 2 goed, West-Nederland 2008 20131233 30 1 2 ## 4 4 36775440 29 1 3 goed, West-Nederland 2008 20131234 64 1 2 ## 5 5 36775450 57 1 3 gaat wel, West-Nederland 2008 20131235 45 1 1 ## 6 6 36775460 49 0 2 goed, West-Nederland 2008 20131236 80 0 2 ## health.y region.y wave.y ## 1 goed, West-Nederland 2010 ## 2 zeer goed, West-Nederland 2010 ## 3 goed, West-Nederland 2010 ## 4 goed, West-Nederland 2010 ## 5 goed, West-Nederland 2010 ## 6 goed, West-Nederland 2010 #rename variables. and when necessary merge again with third wave. not very efficient but it works. #many people prefer the reshape function. (i like doing it myself but here it goes) cv_tot_panel &lt;- reshape(cv_tot, timevar=&quot;wave&quot;, idvar=&quot;id2&quot;, direction=&quot;wide&quot;) head(cv_tot_panel) ## id2 id.2008 age.2008 men.2008 educ3.2008 health.2008 region.2008 id.2010 age.2010 men.2010 ## 1 1 36775330 51 1 3 goed, West-Nederland 20131231 20 0 ## 2 2 36775340 39 0 3 goed, West-Nederland 20131232 29 0 ## 3 3 36775420 16 0 2 goed, West-Nederland 20131233 30 1 ## 4 4 36775440 29 1 3 goed, West-Nederland 20131234 64 1 ## 5 5 36775450 57 1 3 gaat wel, West-Nederland 20131235 45 1 ## 6 6 36775460 49 0 2 goed, West-Nederland 20131236 80 0 ## educ3.2010 health.2010 region.2010 ## 1 2 goed, West-Nederland ## 2 3 zeer goed, West-Nederland ## 3 2 goed, West-Nederland ## 4 2 goed, West-Nederland ## 5 1 goed, West-Nederland ## 6 2 goed, West-Nederland A.10.2 Tidy A.10.2.1 Step1: select variables #step 1: selecting the variables you want to keep. #for this tutorial only 6 variables: id, age, sex, educ, health, region (not that R is case sensitive) cv08_sel &lt;- cv08_haven %&gt;% select(c(&quot;we_id&quot;, &quot;lftop&quot;, &quot;geslacht&quot;, &quot;var006n&quot;, &quot;v401&quot;, &quot;landd&quot;)) cv10_sel &lt;- cv10_haven %&gt;% select(c(&quot;Sleutel&quot;, &quot;var002&quot;, &quot;var001&quot;, &quot;Vltoplop&quot;, &quot;V401&quot;, &quot;Landd&quot;)) A.10.2.2 Step2: make consistent #step 2: making the variables similar across individual datasets #step 2a: making names the same names(cv08_sel) &lt;- names(cv10_sel) &lt;- c(&quot;id&quot;, &quot;age&quot;, &quot;sex&quot;, &quot;educ&quot;, &quot;health&quot;, &quot;region&quot;) #step 2b: making levels and labels consistent str(cv08_sel) str(cv10_sel) #summary(cv08_sel) #summary(cv10_sel) #they look very consistent already. but check carefully. #id is okay #age: replace &#39;onbekend&#39; cv08_sel &lt;- cv08_sel %&gt;% mutate(age=na_if(age, 99)) cv10_sel &lt;- cv10_sel %&gt;% mutate(age=na_if(age, 99)) #sex: men cv08_sel &lt;- cv08_sel %&gt;% mutate(men=recode(sex, &#39;9&#39;=-9, &#39;M&#39;=1, &#39;V&#39;=0, .keep_value_labels = FALSE), men=na_if(men,-9), men=labelled(men, c(&quot;man&quot;=1, &quot;vrouw&quot;=0))) cv10_sel &lt;- cv10_sel %&gt;% mutate(men=recode(sex, &#39;2&#39;=0, .keep_value_labels = FALSE), men=labelled(men, c(&quot;man&quot;=1, &quot;vrouw&quot;=0))) #educ educ3 attr(cv08_sel$educ, &quot;labels&quot;) attr(cv10_sel$educ, &quot;labels&quot;) cv08_sel &lt;- cv08_sel %&gt;% mutate(educ3=recode(educ, &#39;-3&#39;=-9, &#39;-1&#39;=1, &#39;1&#39;=1, &#39;2&#39;= 2 , &#39;3&#39;= 2, &#39;4&#39;= 2, &#39;5&#39;= 2, &#39;6&#39;= 3, &#39;7&#39;= 3, &#39;8&#39;= 3, &#39;10&#39;= -9, .keep_value_labels = FALSE), educ3=na_if(educ3, -9), educ3=factor(educ3, levels = c(1,2,3), labels = c(&quot;primary&quot;, &quot;secondary&quot;, &quot;tertiary&quot;))) cv10_sel &lt;- cv10_sel %&gt;% mutate(educ3=recode(educ, &#39;-1&#39;=1, &#39;1&#39;=1, &#39;2&#39;= 2 , &#39;3&#39;= 2, &#39;4&#39;= 2, &#39;5&#39;= 3, &#39;10&#39;= -9, .keep_value_labels = FALSE), educ3=na_if(educ3, -9), educ3=factor(educ3, levels = c(1,2,3), labels = c(&quot;primary&quot;, &quot;secondary&quot;, &quot;tertiary&quot;))) A.10.2.3 Step3: merge #lets add a wave variable cv08_sel$wave &lt;- 2008 cv10_sel$wave &lt;- 2010 #let make a fake ID, we will use this later when we pretend CV is panel data. cv08_sel$id2 &lt;- rank(cv08_sel$id) cv10_sel$id2 &lt;- rank(cv10_sel$id) #simply place one dataset under the other thus row bind (rbind) #check first if same vars in both datasets. #perhaps clean up first. cv08_sel &lt;- cv08_sel %&gt;% select(c(&quot;id&quot;,&quot;id2&quot;, &quot;age&quot;, &quot;men&quot;, &quot;educ3&quot;, &quot;health&quot;, &quot;region&quot;, &quot;wave&quot;)) cv10_sel &lt;- cv10_sel %&gt;% select(c(&quot;id&quot;,&quot;id2&quot;, &quot;age&quot;, &quot;men&quot;, &quot;educ3&quot;, &quot;health&quot;, &quot;region&quot;, &quot;wave&quot;)) cv_tot_tidy &lt;- cv08_sel %&gt;% add_row(cv10_sel) A.10.2.4 Step4: check summary(cv_tot_tidy) ## id id2 age men educ3 ## Min. :20131231 Min. : 1 Min. :16.00 Min. :0.000 primary : 839 ## 1st Qu.:20132456 1st Qu.: 613 1st Qu.:33.00 1st Qu.:0.000 secondary:2777 ## Median :20133680 Median :1225 Median :47.00 Median :1.000 tertiary :1275 ## Mean :27624666 Mean :1274 Mean :47.63 Mean :0.513 NA&#39;s : 8 ## 3rd Qu.:37978375 3rd Qu.:1838 3rd Qu.:62.00 3rd Qu.:1.000 ## Max. :41199300 Max. :2936 Max. :96.00 Max. :1.000 ## NA&#39;s :4 NA&#39;s :10 ## health region wave ## Min. :-2.000 Min. :1.000 Min. :2008 ## 1st Qu.: 1.000 1st Qu.:2.000 1st Qu.:2008 ## Median : 2.000 Median :3.000 Median :2010 ## Mean : 1.979 Mean :2.799 Mean :2009 ## 3rd Qu.: 2.000 3rd Qu.:3.000 3rd Qu.:2010 ## Max. : 5.000 Max. :4.000 Max. :2010 ## head(cv_tot_tidy) ## # A tibble: 6 x 8 ## # Rowwise: ## id id2 age men educ3 health region wave ## &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;fct&gt; &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 36775330 1 51 1 [man] tertiary 2 [goed,] 3 2008 ## 2 36775340 2 39 0 [vrouw] tertiary 2 [goed,] 3 2008 ## 3 36775420 3 16 0 [vrouw] secondary 2 [goed,] 3 2008 ## 4 36775440 4 29 1 [man] tertiary 2 [goed,] 3 2008 ## 5 36775450 5 57 1 [man] tertiary 3 [gaat wel,] 3 2008 ## 6 36775460 6 49 0 [vrouw] secondary 2 [goed,] 3 2008 Okay, lets pretend it was panel data cv_tot would then be a panel dataset in long format. But oftentimes, you want a panel dataset in wide format. If you dont know the difference between long and wide format, check the differences between cv_tot and cv_tot_panel after step 3b. A.10.2.5 Step3b: merge #lets make a panel dataset in wide format cv_tot_panel_tidy &lt;- full_join(cv08_sel, cv10_sel, by=&quot;id2&quot;, suffix=c(&quot;.2008&quot;, &quot;.2010&quot;)) A.11 Aggregate data Lets suppose you want to add the mean age of each region as contextual variable to your data. A.11.1 R Base #step 1. construct dataset with aggregate info age_region &lt;- aggregate(cv_tot$age, by=list(cv_tot$region), FUN=mean) head(age_region) ## Group.1 x ## 1 Noord-Nederland 47.77567 ## 2 Oost-Nederland 48.04113 ## 3 West-Nederland NA ## 4 Zuid-Nederland NA Ai, we have missings in age. Luckily the aggregate function can deal with missings. #step 1. construct dataset with aggregate info age_region &lt;- aggregate(cv_tot$age, by=list(cv_tot$region), FUN=mean, na.rm = TRUE) head(age_region) #lets correct variable names names(age_region) &lt;- c(&quot;region&quot;,&quot;age_region&quot;) age_region #step 2. match to dataset cv_total &lt;- merge(cv_tot, age_region, by=&quot;region&quot;, all.x=TRUE) head(cv_total) tail(cv_total) ## Group.1 x ## 1 Noord-Nederland 47.77567 ## 2 Oost-Nederland 48.04113 ## 3 West-Nederland 46.88416 ## 4 Zuid-Nederland 48.52500 ## region age_region ## 1 Noord-Nederland 47.77567 ## 2 Oost-Nederland 48.04113 ## 3 West-Nederland 46.88416 ## 4 Zuid-Nederland 48.52500 ## region id id2 age men educ3 health wave age_region ## 1 Noord-Nederland 40604110 1728 30 0 3 zeer goed, 2008 47.77567 ## 2 Noord-Nederland 37975380 610 41 0 2 goed, 2008 47.77567 ## 3 Noord-Nederland 40604300 1741 23 0 2 goed, 2008 47.77567 ## 4 Noord-Nederland 38722490 890 49 1 2 gaat wel, 2008 47.77567 ## 5 Noord-Nederland 20131654 424 60 0 1 goed, 2010 47.77567 ## 6 Noord-Nederland 40604100 1727 18 1 2 goed, 2008 47.77567 ## region id id2 age men educ3 health wave age_region ## 4894 Zuid-Nederland 39568320 1429 78 1 2 goed, 2008 48.525 ## 4895 Zuid-Nederland 20133708 2478 62 0 2 goed, 2010 48.525 ## 4896 Zuid-Nederland 20134032 2802 49 1 2 zeer goed, 2010 48.525 ## 4897 Zuid-Nederland 20132436 1206 52 1 1 slecht, 2010 48.525 ## 4898 Zuid-Nederland 20131923 693 46 1 2 goed, 2010 48.525 ## 4899 Zuid-Nederland 20134031 2801 50 1 2 slecht, 2010 48.525 # You can also define your own functions and use these. fmean_narm &lt;- function(x){mean(x,na.rm=T)} age_region_test &lt;- aggregate(cv_tot$age, by=list(cv_tot$region), FUN=fmean_narm) head(age_region_test) ## Group.1 x ## 1 Noord-Nederland 47.77567 ## 2 Oost-Nederland 48.04113 ## 3 West-Nederland 46.88416 ## 4 Zuid-Nederland 48.52500 A.11.2 Tidy ** TO DO ** A.12 Missing values A.12.1 R Base Suppose you want to estimate the following model: model1 &lt;- lm(as.numeric(health) ~ men + age + as.factor(educ3) + as.factor(region), data=cv_total) summary(model1) ## ## Call: ## lm(formula = as.numeric(health) ~ men + age + as.factor(educ3) + ## as.factor(region), data = cv_total) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.8504 -0.5991 0.0100 0.3289 3.2407 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.6427632 0.0515902 109.377 &lt; 2e-16 *** ## men -0.0155079 0.0211182 -0.734 0.463 ## age 0.0115217 0.0005858 19.667 &lt; 2e-16 *** ## as.factor(educ3)2 -0.1831809 0.0293149 -6.249 4.49e-10 *** ## as.factor(educ3)3 -0.3248725 0.0330650 -9.825 &lt; 2e-16 *** ## as.factor(region)Oost-Nederland -0.0535139 0.0391705 -1.366 0.172 ## as.factor(region)West-Nederland -0.0152383 0.0360003 -0.423 0.672 ## as.factor(region)Zuid-Nederland 0.0140803 0.0388009 0.363 0.717 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7371 on 4869 degrees of freedom ## (22 observations deleted due to missingness) ## Multiple R-squared: 0.09928, Adjusted R-squared: 0.09799 ## F-statistic: 76.67 on 7 and 4869 DF, p-value: &lt; 2.2e-16 You see that 22 cases are deleted due to missingness but what happened with your health variable? cv_total$health[cv_total$health==&quot;Weigert&quot;] &lt;- NA cv_total$healthn &lt;- as.numeric(cv_total$health) - 4 table(cv_total$health, useNA = &quot;always&quot;) table(cv_total$healthn, useNA = &quot;always&quot;) ## ## Geen opgave N.v.t. Weet niet Weigert zeer goed, goed, ## 0 0 0 0 1280 2652 ## gaat wel, slecht, of zeer slecht? &lt;NA&gt; ## 786 146 34 1 ## ## 1 2 3 4 5 &lt;NA&gt; ## 1280 2652 786 146 34 1 Of course we have several options: * listwise deletion. Only use when very few missings * replace missing values with intuitive values or add missing as a separate category. * impute missing values. A bit complicated but the best option. A.12.1.1 Option 1: listwise deletion #step1 define all missings summary(cv_total) ## region id id2 age men ## Postcode (nog) onbekend: 0 Min. :20131231 Min. : 1 Min. :16.00 Min. :0.000 ## Noord-Nederland : 526 1st Qu.:20132456 1st Qu.: 613 1st Qu.:33.00 1st Qu.:0.000 ## Oost-Nederland :1094 Median :20133680 Median :1225 Median :47.00 Median :0.000 ## West-Nederland :2116 Mean :27624666 Mean :1274 Mean :47.63 Mean :0.495 ## Zuid-Nederland :1163 3rd Qu.:37978375 3rd Qu.:1838 3rd Qu.:62.00 3rd Qu.:1.000 ## Max. :41199300 Max. :2936 Max. :96.00 Max. :1.000 ## NA&#39;s :4 NA&#39;s :10 ## educ3 health wave age_region healthn ## Min. :1.000 goed, :2652 Min. :2008 Min. :46.88 Min. :1.00 ## 1st Qu.:2.000 zeer goed, :1280 1st Qu.:2008 1st Qu.:46.88 1st Qu.:1.00 ## Median :2.000 gaat wel, : 786 Median :2010 Median :47.78 Median :2.00 ## Mean :2.089 slecht, : 146 Mean :2009 Mean :47.63 Mean :1.98 ## 3rd Qu.:3.000 of zeer slecht?: 34 3rd Qu.:2010 3rd Qu.:48.04 3rd Qu.:2.00 ## Max. :3.000 (Other) : 0 Max. :2010 Max. :48.52 Max. :5.00 ## NA&#39;s :8 NA&#39;s : 1 NA&#39;s :1 model2 &lt;- lm(as.numeric(healthn) ~ men + age + as.factor(educ3) + as.factor(region), data=cv_total) summary(model2) ## ## Call: ## lm(formula = as.numeric(healthn) ~ men + age + as.factor(educ3) + ## as.factor(region), data = cv_total) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.6261 -0.6001 0.0094 0.3288 3.2415 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.6429046 0.0515620 31.863 &lt; 2e-16 *** ## men -0.0162517 0.0211087 -0.770 0.441 ## age 0.0115192 0.0005855 19.673 &lt; 2e-16 *** ## as.factor(educ3)2 -0.1831872 0.0292989 -6.252 4.39e-10 *** ## as.factor(educ3)3 -0.3233545 0.0330525 -9.783 &lt; 2e-16 *** ## as.factor(region)Oost-Nederland -0.0535499 0.0391492 -1.368 0.171 ## as.factor(region)West-Nederland -0.0153441 0.0359807 -0.426 0.670 ## as.factor(region)Zuid-Nederland 0.0157006 0.0387850 0.405 0.686 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7367 on 4868 degrees of freedom ## (23 observations deleted due to missingness) ## Multiple R-squared: 0.09925, Adjusted R-squared: 0.09795 ## F-statistic: 76.63 on 7 and 4868 DF, p-value: &lt; 2.2e-16 You see 23 cases deleted due to missingness A.12.1.2 Option 2: replacing missing values. Dont replace missings on dependent variable. For categorical variables add category missing. For continues/metric variables replace missing with mean value. cv_total$men2 &lt;- ifelse(is.na(cv_total$men), 2, cv_total$men) summary(cv_total$men2) cv_total$educ3b &lt;- ifelse(is.na(cv_total$educ3), 4, cv_total$educ3) summary(cv_total$educ3b) cv_total$age2 &lt;- ifelse(is.na(cv_total$age), mean(cv_total$age, na.rm=TRUE), cv_total$age) #And lets make a dummy that indicates for whom we replaced missing values. cv_total$age_mis &lt;- ifelse(is.na(cv_total$age), 1,0) summary(cv_total$age2) table(cv_total$age_mis) #pay attention, now use categorical variable men2 model3 &lt;- lm(healthn ~ as.factor(men2) + age2 + age_mis + as.factor(educ3b) + as.factor(region), data=cv_total) summary(model3) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0000 0.0000 0.0000 0.4981 1.0000 2.0000 ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.000 2.000 2.000 2.092 3.000 4.000 ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 16.00 33.50 47.00 47.63 62.00 96.00 ## ## 0 1 ## 4895 4 ## ## Call: ## lm(formula = healthn ~ as.factor(men2) + age2 + age_mis + as.factor(educ3b) + ## as.factor(region), data = cv_total) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.6200 -0.6013 0.0103 0.3268 3.2422 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.6430251 0.0516038 31.839 &lt; 2e-16 *** ## as.factor(men2)1 -0.0186500 0.0211416 -0.882 0.378 ## as.factor(men2)2 -0.2534807 0.2341966 -1.082 0.279 ## age2 0.0114647 0.0005852 19.592 &lt; 2e-16 *** ## age_mis 0.1067769 0.3699339 0.289 0.773 ## as.factor(educ3b)2 -0.1786212 0.0293068 -6.095 1.18e-09 *** ## as.factor(educ3b)3 -0.3193546 0.0330785 -9.654 &lt; 2e-16 *** ## as.factor(educ3b)4 -0.4032117 0.2624656 -1.536 0.125 ## as.factor(region)Oost-Nederland -0.0548586 0.0391963 -1.400 0.162 ## as.factor(region)West-Nederland -0.0146274 0.0360252 -0.406 0.685 ## as.factor(region)Zuid-Nederland 0.0157363 0.0388302 0.405 0.685 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7384 on 4887 degrees of freedom ## (1 observation deleted due to missingness) ## Multiple R-squared: 0.09797, Adjusted R-squared: 0.09612 ## F-statistic: 53.08 on 10 and 4887 DF, p-value: &lt; 2.2e-16 A.12.1.3 Option 3: impute missing values We will use the R package mice (van Buuren and Groothuis-Oudshoorn (2011)). For theory please see: * https://stefvanbuuren.name/Winnipeg * https://stefvanbuuren.name/Winnipeg/Lectures/Winnipeg.pdf * For great reading see: https://bookdown.org/mwheymans/bookmi/ Read the literature, lectures and have a look at all vignettes of the package mice (here). This is not basic stuff! #lets start with the original dataset, that is without replacement of the missings cv_total &lt;- cv_total[,c(&quot;id&quot;, &quot;id2&quot;, &quot;age&quot;, &quot;men&quot;, &quot;educ3&quot;, &quot;health&quot;, &quot;region&quot;, &quot;wave&quot;)] #define all missings #only for health needs to be redefined cv_total$health[cv_total$health==&quot;Weigert&quot;] &lt;- NA cv_total$health &lt;- as.numeric(cv_total$health) - 4 #multiple imputation #take into account measurement level of variables cv_total$men &lt;- as.factor(cv_total$men) cv_total$educ3 &lt;- as.factor(cv_total$educ3) #check pattern md.pattern(cv_total) #we do not have real patterns. thus MCAR. This is only seldom the case!! #lets impute names(cv_total) #We do not want to use id id2 and wave to predict the other variables thus we need to tell mice in the predictorMatrix argument. Easiest way is to first estimate and then correct. imp &lt;- mice(data=cv_total, method=c(&quot;&quot;,&quot;&quot;, &quot;cart&quot;, &quot;logreg&quot;, &quot;polr&quot;, &quot;cart&quot;, &quot;&quot; ,&quot;&quot; )) ## Warning: Number of logged events: 100 attributes(imp) pred &lt;- imp$pred pred[,&quot;id&quot;] &lt;- 0 pred[,&quot;id2&quot;] &lt;- 0 pred[,&quot;wave&quot;] &lt;- 0 pred #let us also use a seed, so we have the same data in class. imp &lt;- mice(data=cv_total, method=c(&quot;&quot;,&quot;&quot;, &quot;cart&quot;, &quot;logreg&quot;, &quot;polr&quot;, &quot;cart&quot;, &quot;&quot; ,&quot;&quot; ), pred=pred, seed=45622) ## Warning: Number of logged events: 100 summary(cv_total) summary(complete(imp)) plot(imp) #in real life: check convergence, check plausible values. see vignette 2 of mice package #and fit model on imputed dataset model_imp &lt;- with(imp, lm(as.numeric(health) ~ men + age + educ3 + region)) pool_model_imp &lt;- pool(model_imp) summary(pool_model_imp) ## id id2 region wave health age educ3 men ## 4876 1 1 1 1 1 1 1 1 0 ## 10 1 1 1 1 1 1 1 0 1 ## 8 1 1 1 1 1 1 0 1 1 ## 4 1 1 1 1 1 0 1 1 1 ## 1 1 1 1 1 0 1 1 1 1 ## 0 0 0 0 1 4 8 10 23 ## [1] &quot;id&quot; &quot;id2&quot; &quot;age&quot; &quot;men&quot; &quot;educ3&quot; &quot;health&quot; &quot;region&quot; &quot;wave&quot; ## ## iter imp variable ## 1 1 age men educ3 health ## 1 2 age men educ3 health ## 1 3 age men educ3 health ## 1 4 age men educ3 health ## 1 5 age men educ3 health ## 2 1 age men educ3 health ## 2 2 age men educ3 health ## 2 3 age men educ3 health ## 2 4 age men educ3 health ## 2 5 age men educ3 health ## 3 1 age men educ3 health ## 3 2 age men educ3 health ## 3 3 age men educ3 health ## 3 4 age men educ3 health ## 3 5 age men educ3 health ## 4 1 age men educ3 health ## 4 2 age men educ3 health ## 4 3 age men educ3 health ## 4 4 age men educ3 health ## 4 5 age men educ3 health ## 5 1 age men educ3 health ## 5 2 age men educ3 health ## 5 3 age men educ3 health ## 5 4 age men educ3 health ## 5 5 age men educ3 health ## $names ## [1] &quot;data&quot; &quot;imp&quot; &quot;m&quot; &quot;where&quot; &quot;blocks&quot; ## [6] &quot;call&quot; &quot;nmis&quot; &quot;method&quot; &quot;predictorMatrix&quot; &quot;visitSequence&quot; ## [11] &quot;formulas&quot; &quot;post&quot; &quot;blots&quot; &quot;ignore&quot; &quot;seed&quot; ## [16] &quot;iteration&quot; &quot;lastSeedValue&quot; &quot;chainMean&quot; &quot;chainVar&quot; &quot;loggedEvents&quot; ## [21] &quot;version&quot; &quot;date&quot; ## ## $class ## [1] &quot;mids&quot; ## ## id id2 age men educ3 health region wave ## id 0 0 1 1 1 1 1 0 ## id2 0 0 1 1 1 1 1 0 ## age 0 0 0 1 1 1 1 0 ## men 0 0 1 0 1 1 1 0 ## educ3 0 0 1 1 0 1 1 0 ## health 0 0 1 1 1 0 1 0 ## region 0 0 1 1 1 1 0 0 ## wave 0 0 1 1 1 1 1 0 ## ## iter imp variable ## 1 1 age men educ3 health ## 1 2 age men educ3 health ## 1 3 age men educ3 health ## 1 4 age men educ3 health ## 1 5 age men educ3 health ## 2 1 age men educ3 health ## 2 2 age men educ3 health ## 2 3 age men educ3 health ## 2 4 age men educ3 health ## 2 5 age men educ3 health ## 3 1 age men educ3 health ## 3 2 age men educ3 health ## 3 3 age men educ3 health ## 3 4 age men educ3 health ## 3 5 age men educ3 health ## 4 1 age men educ3 health ## 4 2 age men educ3 health ## 4 3 age men educ3 health ## 4 4 age men educ3 health ## 4 5 age men educ3 health ## 5 1 age men educ3 health ## 5 2 age men educ3 health ## 5 3 age men educ3 health ## 5 4 age men educ3 health ## 5 5 age men educ3 health ## id id2 age men educ3 health ## Min. :20131231 Min. : 1 Min. :16.00 0 :2469 1 : 839 Min. :1.00 ## 1st Qu.:20132456 1st Qu.: 613 1st Qu.:33.00 1 :2420 2 :2777 1st Qu.:1.00 ## Median :20133680 Median :1225 Median :47.00 NA&#39;s: 10 3 :1275 Median :2.00 ## Mean :27624666 Mean :1274 Mean :47.63 NA&#39;s: 8 Mean :1.98 ## 3rd Qu.:37978375 3rd Qu.:1838 3rd Qu.:62.00 3rd Qu.:2.00 ## Max. :41199300 Max. :2936 Max. :96.00 Max. :5.00 ## NA&#39;s :4 NA&#39;s :1 ## region wave ## Postcode (nog) onbekend: 0 Min. :2008 ## Noord-Nederland : 526 1st Qu.:2008 ## Oost-Nederland :1094 Median :2010 ## West-Nederland :2116 Mean :2009 ## Zuid-Nederland :1163 3rd Qu.:2010 ## Max. :2010 ## ## id id2 age men educ3 health ## Min. :20131231 Min. : 1 Min. :16.00 0:2471 1: 842 Min. :1.000 ## 1st Qu.:20132456 1st Qu.: 613 1st Qu.:33.00 1:2428 2:2779 1st Qu.:1.000 ## Median :20133680 Median :1225 Median :47.00 3:1278 Median :2.000 ## Mean :27624666 Mean :1274 Mean :47.62 Mean :1.979 ## 3rd Qu.:37978375 3rd Qu.:1838 3rd Qu.:62.00 3rd Qu.:2.000 ## Max. :41199300 Max. :2936 Max. :96.00 Max. :5.000 ## region wave ## Postcode (nog) onbekend: 0 Min. :2008 ## Noord-Nederland : 526 1st Qu.:2008 ## Oost-Nederland :1094 Median :2010 ## West-Nederland :2116 Mean :2009 ## Zuid-Nederland :1163 3rd Qu.:2010 ## Max. :2010 ## term estimate std.error statistic df p.value ## 1 (Intercept) 1.64227489 0.0515381739 31.8652131 4883.812 0.000000e+00 ## 2 men1 -0.01821954 0.0211574583 -0.8611405 4683.712 3.892048e-01 ## 3 age 0.01146351 0.0005846149 19.6086530 4854.560 0.000000e+00 ## 4 educ32 -0.17813172 0.0292524289 -6.0894676 4881.477 1.219647e-09 ## 5 educ33 -0.31977903 0.0330290911 -9.6817388 4859.881 0.000000e+00 ## 6 regionOost-Nederland -0.05554060 0.0391698388 -1.4179430 4888.390 1.562711e-01 ## 7 regionWest-Nederland -0.01515412 0.0360044223 -0.4208962 4888.453 6.738494e-01 ## 8 regionZuid-Nederland 0.01582036 0.0387973170 0.4077694 4888.453 6.834609e-01 A.12.2 Tidy ** TO DO ** Thank you for reading this tutorial!! Programmers like to confuse us simple persons. They thus make up mock names to indicate that the name is irrelevant. Thus a real programmer will never use functionname() but will use foo() or bar() or foobar() . "],["variance.html", "B Covariance and Correlation", " B Covariance and Correlation Social scientists try to explain variance and covariance. It is therefore a good idea to learn by heart the formula for variance and covariance. The sample variance of a random continuous variable X, VAR(X), is as follows: \\[VAR(X)=s_{xx}^2 = s_x^2= \\frac{\\Sigma^n_{i=1}(X_i-\\overline{X})(X_i-\\overline{X})}{n-1}= \\frac{\\Sigma^n_{i=1}(X_i-\\overline{X})^2}{n-1}\\] The sample standard deviation is given by: \\[STD(X)=\\sqrt{s_x^2}=s_x\\] The sample covariance of two random continuous variables X and Y, COV(X,Y) is as follows: \\[COV(X,Y)=s_{xy}^2 = \\frac{\\Sigma^n_{i=1}(X_i-\\overline{X})(Y_i-\\overline{Y})}{n-1}\\] The sample correlation coefficient between two random continuous variables X and Y, COR(X,Y), is a covariance on standardized variables (\\(z_x=X_{sd}=(X-\\overline{X})/s_x\\)) and hence: \\[COR(X,Y)=r_{xy} = \\frac{s_{xy}^2}{s_x s_y}= \\frac{\\Sigma^n_i(X_i-\\overline{X})(Y_i-\\overline{Y})}{\\sqrt{\\Sigma^n_i(X_i-\\overline{X})^2}\\sqrt{\\Sigma^n_i(Y_i-\\overline{Y})^2}}\\] Just to be complete. The population equivalent of the covariance: \\[\\sigma _{xy}^2 = \\frac{\\Sigma^n_i(X_i - \\mu_x)(Y_i-\\mu_y)}{N},\\] with \\(\\mu\\) the population mean. And the correlation within the population is: \\[\\rho_{xy} = \\frac{\\sigma_{xy}^2}{\\sigma_x \\sigma_y}\\] "],["references.html", "References", " References Ackland, Robert. 2013. Web Social Science: Concepts, Data and Tools for Social Scientists in the Digital Age. Sage. Bartel, Sara J, Simon B Sherry, Danielle S Molnar, Aislin R Mushquash, Kenneth E Leonard, Gordon L Flett, and Sherry H Stewart. 2017. Do Romantic Partners Influence Each Others Heavy Episodic Drinking? Support for the Partner Influence Hypothesis in a Three-Year Longitudinal Study. Addictive Behaviors 69: 5558. . 2017. Do Romantic Partners Influence Each Others Heavy Episodic Drinking? Support for the Partner Influence Hypothesis in a Three-Year Longitudinal Study. Addictive Behaviors 69: 5558. Blossfeld, Hans-Peter. 2009. Educational Assortative Marriage in Comparative Perspective. Annual Review of Sociology 35: 51330. Coleman, James S. 1994. Foundations of Social Theory. Harvard university press. Golder, Scott A, and Michael W Macy. 2014. Digital Footprints: Opportunities and Challenges for Online Social Research. Annual Review of Sociology 40: 12952. Goldthorpe, John H. 1998. Rational Action Theory for Sociology. British Journal of Sociology, 16792. Hofstra, Bas. 2017. Online Social Networks: Essays on Membership, Privacy, and Structure. PhD thesis, Utrecht University. Hofstra, Bas, Rense Corten, and Frank van Tubergen. 2021. Beyond the Core: Who Has Larger Social Networks? Social Forces 99 (3): 12741305. Hofstra, Bas, Rense Corten, Frank Van Tubergen, and Nicole B Ellison. 2017. Sources of Segregation in Social Networks: A Novel Approach Using Facebook. American Sociological Review 82 (3): 62556. Kalmijn, Matthijs. 1998. Intermarriage and Homogamy: Causes, Patterns, Trends. Annual Review of Sociology 24 (1): 395421. Lazer, David, Alex Pentland, Lada Adamic, Sinan Aral, Albert-Laszlo Barabasi, Devon Brewer, Nicholas Christakis, et al. 2009. Social Science. Computational Social Science. Science (New York, NY) 323 (5915): 72123. Marsden, Peter V. 1990. Network Data and Measurement. Annual Review of Sociology 16 (1): 43563. McPherson, Miller, Lynn Smith-Lovin, and James M Cook. 2001. Birds of a Feather: Homophily in Social Networks. Annual Review of Sociology 27 (1): 41544. Mulder, Jeroen D, and Ellen L Hamaker. 2020. Three Extensions of the Random Intercept Cross-Lagged Panel Model. Structural Equation Modeling: A Multidisciplinary Journal, 111. Raub, Werner, Vincent Buskens, and Marcel ALM Van Assen. 2011. Micro-Macro Links and Microfoundations in Sociology. The Journal of Mathematical Sociology 35 (1-3): 125. Schwartz, Christine R. 2013. Trends and Variation in Assortative Mating: Causes and Consequences. Annual Review of Sociology 39: 45170. Spiro, Emma S. 2016. Research Opportunities at the Intersection of Social Media and Survey Data. Current Opinion in Psychology 9: 6771. van Buuren, Stef, and Karin Groothuis-Oudshoorn. 2011. mice: Multivariate Imputation by Chained Equations in r. Journal of Statistical Software 45 (3): 167. https://www.jstatsoft.org/v45/i03/. Van Tubergen, Frank. 2020. Introduction to Sociology. Routledge. Wasserman, Stanley, Katherine Faust, and others. 1994. Social Network Analysis: Methods and Applications. Watts, Duncan J. 2011. Everything Is Obvious:* Once You Know the Answer. Currency. # References {-} "]]
